{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "image_classification",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1fqVQG3CVgpsrjEk9DZ6JjDIU0qFit7bs",
      "authorship_tag": "ABX9TyOcuJ0Bg876oVrVYzGu5wiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/Python_Machine_Learning/blob/master/image_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSKwDz4L-7QV",
        "outputId": "75101424-c380-4e5c-d0f0-500cdd7d5b11"
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms  \n",
        "import torchvision\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import torchvision.transforms as transforms \n",
        "from torchvision.transforms import ToTensor,Normalize, RandomHorizontalFlip, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.autograd import Variable\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLwc_tu6OIa4",
        "outputId": "e338a033-f39d-4e41-97ed-3a6a7028fcc8"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sun May 23 08:42:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    25W / 300W |      2MiB / 16160MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2z_907rbOMFj",
        "outputId": "aee9d567-8a87-412e-e4fc-ea85d1e5cc31"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n",
        "  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n",
        "  print('re-execute this cell.')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your runtime has 27.3 gigabytes of available RAM\n",
            "\n",
            "You are using a high-RAM runtime!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VKevojWGmlk"
      },
      "source": [
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = 0.01\n",
        "EPOCHS = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57Di2_glEvpF"
      },
      "source": [
        "data_dir_Train = '/content/drive/MyDrive/input/programmers/train'\n",
        "data_dir_Test = '/content/drive/MyDrive/input/programmers/test'\n",
        "\n",
        "train_dir = data_dir_Train + '/train'\n",
        "test_dir = data_dir_Test + '/test'\n",
        "\n",
        "outcomes = os.listdir(train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LawpP4MoFRrl",
        "outputId": "6345927a-e8d8-472d-c83f-41bcecf66e40"
      },
      "source": [
        "print(outcomes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['elephant', 'giraffe', 'guitar', 'house', 'horse', 'dog', 'person']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzE1w6ksFSc7"
      },
      "source": [
        "## Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vaNh1FVuFYws"
      },
      "source": [
        "# 이미지 정규화 및 좌우 반전 증강\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])\n",
        "\n",
        "# Test 데이터는 정규화만\n",
        "transform_tests = torchvision.transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpiO_KcKF2ts"
      },
      "source": [
        "train_data = torchvision.datasets.ImageFolder(root = train_dir,\n",
        "                                              transform=transform)\n",
        "test_data = torchvision.datasets.ImageFolder(root = test_dir,\n",
        "                                              transform=transform_tests)\n",
        "\n",
        "valid_size = 0.2\n",
        "# train 데이터  validation 데이터로 나누기\n",
        "num_train = len(train_data)\n",
        "indices = list(range(num_train))\n",
        "np.random.shuffle(indices)\n",
        "split = int(np.floor(valid_size * num_train))\n",
        "train_idx, valid_idx = indices[split:], indices[:split]\n",
        "\n",
        "train_sampler = SubsetRandomSampler(train_idx)\n",
        "valid_sampler = SubsetRandomSampler(valid_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kkWgf4WGWgl"
      },
      "source": [
        "train_loader = DataLoader(train_data, batch_size = BATCH_SIZE, sampler = train_sampler, num_workers = 2)\n",
        "valid_loader = DataLoader(train_data, batch_size = 2 * BATCH_SIZE, sampler = valid_sampler, num_workers = 3)\n",
        "test_loader = DataLoader(test_data, batch_size = 32, shuffle = False, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0yGD2E0HoZi"
      },
      "source": [
        "train_on_gpu = torch.cuda.is_available() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuesmHmNHtZk"
      },
      "source": [
        "## Using Pretrained Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZn7TWl6BdYu"
      },
      "source": [
        "- pretrained model은 비교적 최신에 나오고 가벼운 efficientnet을 사용\n",
        "\n",
        "- 버전은 우리 사진 데이터가 227*227이기 때문에 224*224를 인풋으로 받는 b0를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlq69oC_dgUK",
        "outputId": "126a4571-4d2d-441c-c1ad-50a3175ecdb3"
      },
      "source": [
        "!pip install efficientnet_pytorch\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "model_name = 'efficientnet-b0' \n",
        "\n",
        "image_size = EfficientNet.get_image_size(model_name)\n",
        "print(image_size)\n",
        "# 클래스가 7개이므로 마지막에 7개로 분류하는 레이어 추가\n",
        "model = EfficientNet.from_pretrained(model_name, num_classes=7)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: efficientnet_pytorch in /usr/local/lib/python3.7/dist-packages (0.7.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from efficientnet_pytorch) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch->efficientnet_pytorch) (1.19.5)\n",
            "224\n",
            "Loaded pretrained weights for efficientnet-b0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edAy-E8Be7zT",
        "outputId": "0165aafc-e98c-432e-8784-7e7970005c90"
      },
      "source": [
        "model\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (_fc): Linear(in_features=1280, out_features=7, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STBcM5KVIwSM"
      },
      "source": [
        "# loss function, optimizer 설정\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "lmbda = lambda epoch: 0.98739\n",
        "scheduler = optim.lr_scheduler.MultiplicativeLR(optimizer, lr_lambda=lmbda)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dg1h8q-CJYuj"
      },
      "source": [
        "## Train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ZGBfePn3qea",
        "outputId": "0fc87c90-35c5-41c8-abfa-94d882828fff"
      },
      "source": [
        "# train epoch 설정\n",
        "epochs = EPOCHS\n",
        "\n",
        "# loss 추적\n",
        "valid_loss_min = np.Inf\n",
        "val_loss = []\n",
        "tn_loss = []\n",
        "for epoch in range(1,epochs+1):\n",
        "\n",
        "    # train/ validation loss 초기화\n",
        "    train_loss = 0.0\n",
        "    valid_loss = 0.0\n",
        "\n",
        "    # 모델 훈련\n",
        "\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):       \n",
        "        \n",
        "        if train_on_gpu:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "        # optimizer 초기화\n",
        "        optimizer.zero_grad()\n",
        "        # 계산\n",
        "        output = model(data)\n",
        "        # loss 계산\n",
        "        loss = criterion(output, target)\n",
        "        # 그래디언트 계산\n",
        "        loss.backward()\n",
        "        # optimizer 업데이트\n",
        "        optimizer.step()\n",
        "        \n",
        "        # train loss 업데이트\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # 모델 검증\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(valid_loader):\n",
        "            \n",
        "            if train_on_gpu:\n",
        "                data, target = data.to(device), target.to(device)\n",
        "            # 계산\n",
        "            output = model(data)\n",
        "            # loss 계산\n",
        "            loss = criterion(output, target)\n",
        "            # validation loss 업데이트\n",
        "            valid_loss += loss.item()*data.size(0)\n",
        "    \n",
        "    # 평균 loss 계산\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
        "    val_loss.append(valid_loss)\n",
        "    tn_loss.append(train_loss)\n",
        "    # learning rate 업데이트\n",
        "    scheduler.step()\n",
        "    # loss statistics 출력\n",
        "    print('Epoch: {} \\t Training Loss: {:.3f} \\t Validation Loss: {:.3f}'.format(epoch, train_loss, valid_loss))\n",
        "    \n",
        "    # validation loss 감소할 경우 모델 저장\n",
        "    if valid_loss <= valid_loss_min:\n",
        "        print(\"Validation loss decreased {:.4f}--->{:.4f}  Saving model...\".format(valid_loss_min, valid_loss))\n",
        "        # 현재 모델 저장\n",
        "        torch.save(model.state_dict(), 'model_state.pt')\n",
        "        valid_loss_min = valid_loss\n",
        "    print('Learning Rate ------------->{:.4f}'.format(optimizer.state_dict()['param_groups'][0]['lr']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 \t Training Loss: 1.443 \t Validation Loss: 493821.223\n",
            "Validation loss decreased inf--->493821.2234  Saving model...\n",
            "Learning Rate ------------->0.0099\n",
            "Epoch: 2 \t Training Loss: 1.006 \t Validation Loss: 11153979.870\n",
            "Learning Rate ------------->0.0097\n",
            "Epoch: 3 \t Training Loss: 0.768 \t Validation Loss: 425614.029\n",
            "Validation loss decreased 493821.2234--->425614.0295  Saving model...\n",
            "Learning Rate ------------->0.0096\n",
            "Epoch: 4 \t Training Loss: 0.505 \t Validation Loss: 166017.981\n",
            "Validation loss decreased 425614.0295--->166017.9811  Saving model...\n",
            "Learning Rate ------------->0.0095\n",
            "Epoch: 5 \t Training Loss: 0.360 \t Validation Loss: 7911.787\n",
            "Validation loss decreased 166017.9811--->7911.7866  Saving model...\n",
            "Learning Rate ------------->0.0094\n",
            "Epoch: 6 \t Training Loss: 0.273 \t Validation Loss: 413.431\n",
            "Validation loss decreased 7911.7866--->413.4310  Saving model...\n",
            "Learning Rate ------------->0.0093\n",
            "Epoch: 7 \t Training Loss: 0.166 \t Validation Loss: 241.995\n",
            "Validation loss decreased 413.4310--->241.9953  Saving model...\n",
            "Learning Rate ------------->0.0091\n",
            "Epoch: 8 \t Training Loss: 0.162 \t Validation Loss: 238.891\n",
            "Validation loss decreased 241.9953--->238.8914  Saving model...\n",
            "Learning Rate ------------->0.0090\n",
            "Epoch: 9 \t Training Loss: 0.199 \t Validation Loss: 51.992\n",
            "Validation loss decreased 238.8914--->51.9921  Saving model...\n",
            "Learning Rate ------------->0.0089\n",
            "Epoch: 10 \t Training Loss: 0.260 \t Validation Loss: 88.910\n",
            "Learning Rate ------------->0.0088\n",
            "Epoch: 11 \t Training Loss: 0.241 \t Validation Loss: 312.801\n",
            "Learning Rate ------------->0.0087\n",
            "Epoch: 12 \t Training Loss: 0.136 \t Validation Loss: 16.747\n",
            "Validation loss decreased 51.9921--->16.7467  Saving model...\n",
            "Learning Rate ------------->0.0086\n",
            "Epoch: 13 \t Training Loss: 0.063 \t Validation Loss: 9.172\n",
            "Validation loss decreased 16.7467--->9.1723  Saving model...\n",
            "Learning Rate ------------->0.0085\n",
            "Epoch: 14 \t Training Loss: 0.061 \t Validation Loss: 7.999\n",
            "Validation loss decreased 9.1723--->7.9989  Saving model...\n",
            "Learning Rate ------------->0.0084\n",
            "Epoch: 15 \t Training Loss: 0.074 \t Validation Loss: 26.853\n",
            "Learning Rate ------------->0.0083\n",
            "Epoch: 16 \t Training Loss: 0.076 \t Validation Loss: 13.118\n",
            "Learning Rate ------------->0.0082\n",
            "Epoch: 17 \t Training Loss: 0.081 \t Validation Loss: 10.662\n",
            "Learning Rate ------------->0.0081\n",
            "Epoch: 18 \t Training Loss: 0.123 \t Validation Loss: 13.464\n",
            "Learning Rate ------------->0.0080\n",
            "Epoch: 19 \t Training Loss: 0.132 \t Validation Loss: 5.953\n",
            "Validation loss decreased 7.9989--->5.9526  Saving model...\n",
            "Learning Rate ------------->0.0079\n",
            "Epoch: 20 \t Training Loss: 0.083 \t Validation Loss: 8.455\n",
            "Learning Rate ------------->0.0078\n",
            "Epoch: 21 \t Training Loss: 0.050 \t Validation Loss: 17.871\n",
            "Learning Rate ------------->0.0077\n",
            "Epoch: 22 \t Training Loss: 0.047 \t Validation Loss: 6.013\n",
            "Learning Rate ------------->0.0076\n",
            "Epoch: 23 \t Training Loss: 0.051 \t Validation Loss: 7.699\n",
            "Learning Rate ------------->0.0075\n",
            "Epoch: 24 \t Training Loss: 0.045 \t Validation Loss: 14.247\n",
            "Learning Rate ------------->0.0074\n",
            "Epoch: 25 \t Training Loss: 0.029 \t Validation Loss: 4.080\n",
            "Validation loss decreased 5.9526--->4.0801  Saving model...\n",
            "Learning Rate ------------->0.0073\n",
            "Epoch: 26 \t Training Loss: 0.028 \t Validation Loss: 4.240\n",
            "Learning Rate ------------->0.0072\n",
            "Epoch: 27 \t Training Loss: 0.021 \t Validation Loss: 6.052\n",
            "Learning Rate ------------->0.0071\n",
            "Epoch: 28 \t Training Loss: 0.029 \t Validation Loss: 5.718\n",
            "Learning Rate ------------->0.0070\n",
            "Epoch: 29 \t Training Loss: 0.025 \t Validation Loss: 5.258\n",
            "Learning Rate ------------->0.0069\n",
            "Epoch: 30 \t Training Loss: 0.023 \t Validation Loss: 3.656\n",
            "Validation loss decreased 4.0801--->3.6558  Saving model...\n",
            "Learning Rate ------------->0.0068\n",
            "Epoch: 31 \t Training Loss: 0.009 \t Validation Loss: 2.949\n",
            "Validation loss decreased 3.6558--->2.9489  Saving model...\n",
            "Learning Rate ------------->0.0067\n",
            "Epoch: 32 \t Training Loss: 0.013 \t Validation Loss: 2.361\n",
            "Validation loss decreased 2.9489--->2.3607  Saving model...\n",
            "Learning Rate ------------->0.0067\n",
            "Epoch: 33 \t Training Loss: 0.018 \t Validation Loss: 2.015\n",
            "Validation loss decreased 2.3607--->2.0151  Saving model...\n",
            "Learning Rate ------------->0.0066\n",
            "Epoch: 34 \t Training Loss: 0.008 \t Validation Loss: 2.473\n",
            "Learning Rate ------------->0.0065\n",
            "Epoch: 35 \t Training Loss: 0.010 \t Validation Loss: 2.289\n",
            "Learning Rate ------------->0.0064\n",
            "Epoch: 36 \t Training Loss: 0.010 \t Validation Loss: 2.530\n",
            "Learning Rate ------------->0.0063\n",
            "Epoch: 37 \t Training Loss: 0.009 \t Validation Loss: 2.452\n",
            "Learning Rate ------------->0.0063\n",
            "Epoch: 38 \t Training Loss: 0.021 \t Validation Loss: 1.842\n",
            "Validation loss decreased 2.0151--->1.8416  Saving model...\n",
            "Learning Rate ------------->0.0062\n",
            "Epoch: 39 \t Training Loss: 0.016 \t Validation Loss: 1.794\n",
            "Validation loss decreased 1.8416--->1.7944  Saving model...\n",
            "Learning Rate ------------->0.0061\n",
            "Epoch: 40 \t Training Loss: 0.029 \t Validation Loss: 1.612\n",
            "Validation loss decreased 1.7944--->1.6116  Saving model...\n",
            "Learning Rate ------------->0.0060\n",
            "Epoch: 41 \t Training Loss: 0.013 \t Validation Loss: 1.893\n",
            "Learning Rate ------------->0.0059\n",
            "Epoch: 42 \t Training Loss: 0.031 \t Validation Loss: 2.053\n",
            "Learning Rate ------------->0.0059\n",
            "Epoch: 43 \t Training Loss: 0.027 \t Validation Loss: 2.663\n",
            "Learning Rate ------------->0.0058\n",
            "Epoch: 44 \t Training Loss: 0.046 \t Validation Loss: 2.802\n",
            "Learning Rate ------------->0.0057\n",
            "Epoch: 45 \t Training Loss: 0.044 \t Validation Loss: 2.807\n",
            "Learning Rate ------------->0.0056\n",
            "Epoch: 46 \t Training Loss: 0.027 \t Validation Loss: 3.004\n",
            "Learning Rate ------------->0.0056\n",
            "Epoch: 47 \t Training Loss: 0.040 \t Validation Loss: 2.321\n",
            "Learning Rate ------------->0.0055\n",
            "Epoch: 48 \t Training Loss: 0.024 \t Validation Loss: 2.423\n",
            "Learning Rate ------------->0.0054\n",
            "Epoch: 49 \t Training Loss: 0.030 \t Validation Loss: 2.161\n",
            "Learning Rate ------------->0.0054\n",
            "Epoch: 50 \t Training Loss: 0.016 \t Validation Loss: 2.534\n",
            "Learning Rate ------------->0.0053\n",
            "Epoch: 51 \t Training Loss: 0.011 \t Validation Loss: 2.256\n",
            "Learning Rate ------------->0.0052\n",
            "Epoch: 52 \t Training Loss: 0.006 \t Validation Loss: 2.062\n",
            "Learning Rate ------------->0.0052\n",
            "Epoch: 53 \t Training Loss: 0.011 \t Validation Loss: 1.969\n",
            "Learning Rate ------------->0.0051\n",
            "Epoch: 54 \t Training Loss: 0.007 \t Validation Loss: 1.932\n",
            "Learning Rate ------------->0.0050\n",
            "Epoch: 55 \t Training Loss: 0.012 \t Validation Loss: 2.235\n",
            "Learning Rate ------------->0.0050\n",
            "Epoch: 56 \t Training Loss: 0.008 \t Validation Loss: 1.648\n",
            "Learning Rate ------------->0.0049\n",
            "Epoch: 57 \t Training Loss: 0.003 \t Validation Loss: 1.486\n",
            "Validation loss decreased 1.6116--->1.4865  Saving model...\n",
            "Learning Rate ------------->0.0049\n",
            "Epoch: 58 \t Training Loss: 0.003 \t Validation Loss: 1.512\n",
            "Learning Rate ------------->0.0048\n",
            "Epoch: 59 \t Training Loss: 0.003 \t Validation Loss: 1.455\n",
            "Validation loss decreased 1.4865--->1.4547  Saving model...\n",
            "Learning Rate ------------->0.0047\n",
            "Epoch: 60 \t Training Loss: 0.002 \t Validation Loss: 1.415\n",
            "Validation loss decreased 1.4547--->1.4153  Saving model...\n",
            "Learning Rate ------------->0.0047\n",
            "Epoch: 61 \t Training Loss: 0.001 \t Validation Loss: 1.315\n",
            "Validation loss decreased 1.4153--->1.3154  Saving model...\n",
            "Learning Rate ------------->0.0046\n",
            "Epoch: 62 \t Training Loss: 0.001 \t Validation Loss: 1.213\n",
            "Validation loss decreased 1.3154--->1.2127  Saving model...\n",
            "Learning Rate ------------->0.0046\n",
            "Epoch: 63 \t Training Loss: 0.000 \t Validation Loss: 1.145\n",
            "Validation loss decreased 1.2127--->1.1455  Saving model...\n",
            "Learning Rate ------------->0.0045\n",
            "Epoch: 64 \t Training Loss: 0.002 \t Validation Loss: 1.059\n",
            "Validation loss decreased 1.1455--->1.0591  Saving model...\n",
            "Learning Rate ------------->0.0044\n",
            "Epoch: 65 \t Training Loss: 0.001 \t Validation Loss: 1.055\n",
            "Validation loss decreased 1.0591--->1.0548  Saving model...\n",
            "Learning Rate ------------->0.0044\n",
            "Epoch: 66 \t Training Loss: 0.002 \t Validation Loss: 1.044\n",
            "Validation loss decreased 1.0548--->1.0438  Saving model...\n",
            "Learning Rate ------------->0.0043\n",
            "Epoch: 67 \t Training Loss: 0.002 \t Validation Loss: 0.962\n",
            "Validation loss decreased 1.0438--->0.9620  Saving model...\n",
            "Learning Rate ------------->0.0043\n",
            "Epoch: 68 \t Training Loss: 0.001 \t Validation Loss: 0.923\n",
            "Validation loss decreased 0.9620--->0.9225  Saving model...\n",
            "Learning Rate ------------->0.0042\n",
            "Epoch: 69 \t Training Loss: 0.000 \t Validation Loss: 0.905\n",
            "Validation loss decreased 0.9225--->0.9048  Saving model...\n",
            "Learning Rate ------------->0.0042\n",
            "Epoch: 70 \t Training Loss: 0.000 \t Validation Loss: 0.898\n",
            "Validation loss decreased 0.9048--->0.8980  Saving model...\n",
            "Learning Rate ------------->0.0041\n",
            "Epoch: 71 \t Training Loss: 0.000 \t Validation Loss: 0.895\n",
            "Validation loss decreased 0.8980--->0.8952  Saving model...\n",
            "Learning Rate ------------->0.0041\n",
            "Epoch: 72 \t Training Loss: 0.000 \t Validation Loss: 0.895\n",
            "Learning Rate ------------->0.0040\n",
            "Epoch: 73 \t Training Loss: 0.000 \t Validation Loss: 0.895\n",
            "Validation loss decreased 0.8952--->0.8952  Saving model...\n",
            "Learning Rate ------------->0.0040\n",
            "Epoch: 74 \t Training Loss: 0.000 \t Validation Loss: 0.892\n",
            "Validation loss decreased 0.8952--->0.8923  Saving model...\n",
            "Learning Rate ------------->0.0039\n",
            "Epoch: 75 \t Training Loss: 0.000 \t Validation Loss: 0.891\n",
            "Validation loss decreased 0.8923--->0.8910  Saving model...\n",
            "Learning Rate ------------->0.0039\n",
            "Epoch: 76 \t Training Loss: 0.000 \t Validation Loss: 0.899\n",
            "Learning Rate ------------->0.0038\n",
            "Epoch: 77 \t Training Loss: 0.000 \t Validation Loss: 0.902\n",
            "Learning Rate ------------->0.0038\n",
            "Epoch: 78 \t Training Loss: 0.000 \t Validation Loss: 0.902\n",
            "Learning Rate ------------->0.0037\n",
            "Epoch: 79 \t Training Loss: 0.000 \t Validation Loss: 0.904\n",
            "Learning Rate ------------->0.0037\n",
            "Epoch: 80 \t Training Loss: 0.000 \t Validation Loss: 0.905\n",
            "Learning Rate ------------->0.0036\n",
            "Epoch: 81 \t Training Loss: 0.000 \t Validation Loss: 0.904\n",
            "Learning Rate ------------->0.0036\n",
            "Epoch: 82 \t Training Loss: 0.000 \t Validation Loss: 0.903\n",
            "Learning Rate ------------->0.0035\n",
            "Epoch: 83 \t Training Loss: 0.000 \t Validation Loss: 0.912\n",
            "Learning Rate ------------->0.0035\n",
            "Epoch: 84 \t Training Loss: 0.000 \t Validation Loss: 0.930\n",
            "Learning Rate ------------->0.0034\n",
            "Epoch: 85 \t Training Loss: 0.000 \t Validation Loss: 0.936\n",
            "Learning Rate ------------->0.0034\n",
            "Epoch: 86 \t Training Loss: 0.000 \t Validation Loss: 0.940\n",
            "Learning Rate ------------->0.0034\n",
            "Epoch: 87 \t Training Loss: 0.001 \t Validation Loss: 0.945\n",
            "Learning Rate ------------->0.0033\n",
            "Epoch: 88 \t Training Loss: 0.000 \t Validation Loss: 0.961\n",
            "Learning Rate ------------->0.0033\n",
            "Epoch: 89 \t Training Loss: 0.000 \t Validation Loss: 0.987\n",
            "Learning Rate ------------->0.0032\n",
            "Epoch: 90 \t Training Loss: 0.000 \t Validation Loss: 0.993\n",
            "Learning Rate ------------->0.0032\n",
            "Epoch: 91 \t Training Loss: 0.000 \t Validation Loss: 0.986\n",
            "Learning Rate ------------->0.0032\n",
            "Epoch: 92 \t Training Loss: 0.000 \t Validation Loss: 0.979\n",
            "Learning Rate ------------->0.0031\n",
            "Epoch: 93 \t Training Loss: 0.000 \t Validation Loss: 0.955\n",
            "Learning Rate ------------->0.0031\n",
            "Epoch: 94 \t Training Loss: 0.000 \t Validation Loss: 0.944\n",
            "Learning Rate ------------->0.0030\n",
            "Epoch: 95 \t Training Loss: 0.000 \t Validation Loss: 0.941\n",
            "Learning Rate ------------->0.0030\n",
            "Epoch: 96 \t Training Loss: 0.000 \t Validation Loss: 0.938\n",
            "Learning Rate ------------->0.0030\n",
            "Epoch: 97 \t Training Loss: 0.000 \t Validation Loss: 0.923\n",
            "Learning Rate ------------->0.0029\n",
            "Epoch: 98 \t Training Loss: 0.002 \t Validation Loss: 0.926\n",
            "Learning Rate ------------->0.0029\n",
            "Epoch: 99 \t Training Loss: 0.000 \t Validation Loss: 1.082\n",
            "Learning Rate ------------->0.0028\n",
            "Epoch: 100 \t Training Loss: 0.004 \t Validation Loss: 0.931\n",
            "Learning Rate ------------->0.0028\n",
            "Epoch: 101 \t Training Loss: 0.000 \t Validation Loss: 1.018\n",
            "Learning Rate ------------->0.0028\n",
            "Epoch: 102 \t Training Loss: 0.000 \t Validation Loss: 1.052\n",
            "Learning Rate ------------->0.0027\n",
            "Epoch: 103 \t Training Loss: 0.001 \t Validation Loss: 1.030\n",
            "Learning Rate ------------->0.0027\n",
            "Epoch: 104 \t Training Loss: 0.001 \t Validation Loss: 0.992\n",
            "Learning Rate ------------->0.0027\n",
            "Epoch: 105 \t Training Loss: 0.001 \t Validation Loss: 1.054\n",
            "Learning Rate ------------->0.0026\n",
            "Epoch: 106 \t Training Loss: 0.000 \t Validation Loss: 1.013\n",
            "Learning Rate ------------->0.0026\n",
            "Epoch: 107 \t Training Loss: 0.000 \t Validation Loss: 0.971\n",
            "Learning Rate ------------->0.0026\n",
            "Epoch: 108 \t Training Loss: 0.001 \t Validation Loss: 0.957\n",
            "Learning Rate ------------->0.0025\n",
            "Epoch: 109 \t Training Loss: 0.000 \t Validation Loss: 0.950\n",
            "Learning Rate ------------->0.0025\n",
            "Epoch: 110 \t Training Loss: 0.000 \t Validation Loss: 0.942\n",
            "Learning Rate ------------->0.0025\n",
            "Epoch: 111 \t Training Loss: 0.000 \t Validation Loss: 0.947\n",
            "Learning Rate ------------->0.0024\n",
            "Epoch: 112 \t Training Loss: 0.001 \t Validation Loss: 0.997\n",
            "Learning Rate ------------->0.0024\n",
            "Epoch: 113 \t Training Loss: 0.001 \t Validation Loss: 1.018\n",
            "Learning Rate ------------->0.0024\n",
            "Epoch: 114 \t Training Loss: 0.000 \t Validation Loss: 1.036\n",
            "Learning Rate ------------->0.0024\n",
            "Epoch: 115 \t Training Loss: 0.001 \t Validation Loss: 1.000\n",
            "Learning Rate ------------->0.0023\n",
            "Epoch: 116 \t Training Loss: 0.000 \t Validation Loss: 0.993\n",
            "Learning Rate ------------->0.0023\n",
            "Epoch: 117 \t Training Loss: 0.000 \t Validation Loss: 0.987\n",
            "Learning Rate ------------->0.0023\n",
            "Epoch: 118 \t Training Loss: 0.001 \t Validation Loss: 0.992\n",
            "Learning Rate ------------->0.0022\n",
            "Epoch: 119 \t Training Loss: 0.000 \t Validation Loss: 1.054\n",
            "Learning Rate ------------->0.0022\n",
            "Epoch: 120 \t Training Loss: 0.000 \t Validation Loss: 1.121\n",
            "Learning Rate ------------->0.0022\n",
            "Epoch: 121 \t Training Loss: 0.001 \t Validation Loss: 1.087\n",
            "Learning Rate ------------->0.0022\n",
            "Epoch: 122 \t Training Loss: 0.000 \t Validation Loss: 1.051\n",
            "Learning Rate ------------->0.0021\n",
            "Epoch: 123 \t Training Loss: 0.000 \t Validation Loss: 1.025\n",
            "Learning Rate ------------->0.0021\n",
            "Epoch: 124 \t Training Loss: 0.000 \t Validation Loss: 1.009\n",
            "Learning Rate ------------->0.0021\n",
            "Epoch: 125 \t Training Loss: 0.000 \t Validation Loss: 0.995\n",
            "Learning Rate ------------->0.0020\n",
            "Epoch: 126 \t Training Loss: 0.000 \t Validation Loss: 0.981\n",
            "Learning Rate ------------->0.0020\n",
            "Epoch: 127 \t Training Loss: 0.000 \t Validation Loss: 0.959\n",
            "Learning Rate ------------->0.0020\n",
            "Epoch: 128 \t Training Loss: 0.000 \t Validation Loss: 0.930\n",
            "Learning Rate ------------->0.0020\n",
            "Epoch: 129 \t Training Loss: 0.000 \t Validation Loss: 0.924\n",
            "Learning Rate ------------->0.0019\n",
            "Epoch: 130 \t Training Loss: 0.000 \t Validation Loss: 0.918\n",
            "Learning Rate ------------->0.0019\n",
            "Epoch: 131 \t Training Loss: 0.000 \t Validation Loss: 0.915\n",
            "Learning Rate ------------->0.0019\n",
            "Epoch: 132 \t Training Loss: 0.000 \t Validation Loss: 0.913\n",
            "Learning Rate ------------->0.0019\n",
            "Epoch: 133 \t Training Loss: 0.000 \t Validation Loss: 0.915\n",
            "Learning Rate ------------->0.0018\n",
            "Epoch: 134 \t Training Loss: 0.000 \t Validation Loss: 0.916\n",
            "Learning Rate ------------->0.0018\n",
            "Epoch: 135 \t Training Loss: 0.000 \t Validation Loss: 0.917\n",
            "Learning Rate ------------->0.0018\n",
            "Epoch: 136 \t Training Loss: 0.000 \t Validation Loss: 0.917\n",
            "Learning Rate ------------->0.0018\n",
            "Epoch: 137 \t Training Loss: 0.000 \t Validation Loss: 0.918\n",
            "Learning Rate ------------->0.0018\n",
            "Epoch: 138 \t Training Loss: 0.000 \t Validation Loss: 0.919\n",
            "Learning Rate ------------->0.0017\n",
            "Epoch: 139 \t Training Loss: 0.000 \t Validation Loss: 0.918\n",
            "Learning Rate ------------->0.0017\n",
            "Epoch: 140 \t Training Loss: 0.000 \t Validation Loss: 0.914\n",
            "Learning Rate ------------->0.0017\n",
            "Epoch: 141 \t Training Loss: 0.000 \t Validation Loss: 0.913\n",
            "Learning Rate ------------->0.0017\n",
            "Epoch: 142 \t Training Loss: 0.000 \t Validation Loss: 0.913\n",
            "Learning Rate ------------->0.0016\n",
            "Epoch: 143 \t Training Loss: 0.000 \t Validation Loss: 0.913\n",
            "Learning Rate ------------->0.0016\n",
            "Epoch: 144 \t Training Loss: 0.000 \t Validation Loss: 0.913\n",
            "Learning Rate ------------->0.0016\n",
            "Epoch: 145 \t Training Loss: 0.000 \t Validation Loss: 0.912\n",
            "Learning Rate ------------->0.0016\n",
            "Epoch: 146 \t Training Loss: 0.000 \t Validation Loss: 0.915\n",
            "Learning Rate ------------->0.0016\n",
            "Epoch: 147 \t Training Loss: 0.000 \t Validation Loss: 0.953\n",
            "Learning Rate ------------->0.0015\n",
            "Epoch: 148 \t Training Loss: 0.000 \t Validation Loss: 0.974\n",
            "Learning Rate ------------->0.0015\n",
            "Epoch: 149 \t Training Loss: 0.000 \t Validation Loss: 0.993\n",
            "Learning Rate ------------->0.0015\n",
            "Epoch: 150 \t Training Loss: 0.003 \t Validation Loss: 0.961\n",
            "Learning Rate ------------->0.0015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrTJotRDUwPk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VverHO0JxXL"
      },
      "source": [
        "## 훈련/ 검증 loss 그래프 비교"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVOfOJEeQYAE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "a2a5e373-2ff4-43e4-8f84-d271e44cfcd8"
      },
      "source": [
        "plt.plot(tn_loss, label='Training loss')\n",
        "plt.plot(val_loss, label='Validation loss')\n",
        "plt.xlim(1,epoch)\n",
        "plt.ylim(1.5,2)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ab4g_MDoUI50"
      },
      "source": [
        "## Load Saved Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9L0tm0E7QeJL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98fd7b0d-7d04-4c7b-bd65-339c1008598f"
      },
      "source": [
        "model.load_state_dict(torch.load('model_state.pt'))\n",
        "model.eval()\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        32, 32, kernel_size=(3, 3), stride=[1, 1], groups=32, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        32, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 32, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(16, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        96, 96, kernel_size=(3, 3), stride=[2, 2], groups=96, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(96, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        96, 4, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        4, 96, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=(1, 1), groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(5, 5), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(5, 5), stride=(1, 1), groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(40, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        240, 240, kernel_size=(3, 3), stride=[2, 2], groups=240, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(240, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        240, 10, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        10, 240, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(3, 3), stride=(1, 1), groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(80, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        480, 480, kernel_size=(5, 5), stride=[1, 1], groups=480, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(480, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        480, 20, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        20, 480, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[2, 2], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(5, 5), stride=(1, 1), groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1152, 1152, kernel_size=(3, 3), stride=[1, 1], groups=1152, bias=False\n",
              "        (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1152, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1152, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        48, 1152, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(320, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1280, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.2, inplace=False)\n",
              "  (_fc): Linear(in_features=1280, out_features=7, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0LUBtfgUNyW"
      },
      "source": [
        "## Predictions on test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZny3jScUQk4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb75feb1-6fb5-42f4-ff43-7a59bf58c1b0"
      },
      "source": [
        "running_loss, running_corrects, num_cnt = 0.0, 0, 0\n",
        "results = []\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        if torch.cuda.is_available():\n",
        "            images = images.cuda()\n",
        "            labels = labels.cuda()\n",
        "\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            results.appen()\n",
        "            running_loss += loss.item() * images.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            num_cnt += images.size(0)\n",
        "        test_loss = running_loss / num_cnt\n",
        "        test_acc = running_corrects.double() / num_cnt\n",
        "    \n",
        "print('Number of image Tested=', num_cnt)\n",
        "print('test done : loss/acc : %.2f / %.1f' % (test_loss, test_acc*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of image Tested= 350\n",
            "test done : loss/acc : 12.66 / 13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-cxhrQ1UQBC"
      },
      "source": [
        "## Image Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3557ro6WeG2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "outputId": "e2d933ef-69e4-4de8-f278-7f0ebcf1e914"
      },
      "source": [
        "preds."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-f29e1b342598>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'items'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRCJERcbc5uL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}