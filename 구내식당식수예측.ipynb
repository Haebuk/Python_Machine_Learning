{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "구내식당식수예측.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1Zq0t1LDhgmlkJbZrlR8Oq05FmPV7QoYe",
      "authorship_tag": "ABX9TyPWHsgjMeLpJK37JgjHQ0jZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/Python_Machine_Learning/blob/master/%EA%B5%AC%EB%82%B4%EC%8B%9D%EB%8B%B9%EC%8B%9D%EC%88%98%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTW17ZhzhDvU"
      },
      "source": [
        "# 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maw3fEx49_Ol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80cd5d7b-a3b0-409c-827e-47e7d88f2af2"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from copy import deepcopy\n",
        "!pip install -U gensim -q\n",
        "from gensim.models import Word2Vec, FastText\n",
        "!pip install https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl\n",
        "\n",
        "!pip install lightgbm --install-option=--gpu\n",
        "# ! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "# ! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;    \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "!pip install optuna -q\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback\n",
        "from optuna.samplers import TPESampler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 23.9MB 72.4MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
            "  warnings.warn(msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa\n",
            "\u001b[?25l  Downloading https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl (166.7MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7MB 37kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.19.5)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.4.0-SNAPSHOT\n",
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (2.2.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->lightgbm) (1.0.1)\n",
            "\u001b[K     |████████████████████████████████| 307kB 4.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 10.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 43.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 42.2MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 40.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 8.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 11.9MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csa4UxDQETuu"
      },
      "source": [
        "# 파일 로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq5HFK3L-QWR"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/input/235743_구내식당 식사 인원 예측 AI 경진대회_data/'\n",
        "train_df = pd.read_csv(PATH + 'train.csv')\n",
        "test_df = pd.read_csv(PATH + 'test.csv')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hd5qtehu0uBx",
        "outputId": "2c634d65-2e58-4652-d954-60483881ad56"
      },
      "source": [
        "train_df.iloc[204, :]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "일자                                                       2016-11-30\n",
              "요일                                                                수\n",
              "본사정원수                                                          2689\n",
              "본사휴가자수                                                           68\n",
              "본사출장자수                                                          207\n",
              "본사시간외근무명령서승인건수                                                    0\n",
              "현본사소속재택근무자수                                                       0\n",
              "조식메뉴              모닝롤/카스텔라  우유/주스 스크램블에그 누룽지탕/쌀밥 (쌀:국내산) 고추장찌개  ...\n",
              "중식메뉴              나물비빔밥 (쌀:국내산) 가쯔오장국  치킨핑거*요거트D  감자샐러드  오복지무침  ...\n",
              "석식메뉴                                                      *        \n",
              "중식계                                                            1109\n",
              "석식계                                                               0\n",
              "Name: 204, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVVZGTl3-4RC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "outputId": "469d4f97-a6ff-421c-8933-ed61058c7abc"
      },
      "source": [
        "train_df.head(10)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>요일</th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-01</td>\n",
              "      <td>월</td>\n",
              "      <td>2601</td>\n",
              "      <td>50</td>\n",
              "      <td>150</td>\n",
              "      <td>238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 오징어찌개  쇠불고기 (쇠고기:호주산) 계란찜 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 육개장  자반고등어구이  두부조림  건파래무침 ...</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>화</td>\n",
              "      <td>2601</td>\n",
              "      <td>50</td>\n",
              "      <td>173</td>\n",
              "      <td>319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치찌개  가자미튀김  모둠소세지구이  마늘쫑무...</td>\n",
              "      <td>콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무...</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-02-03</td>\n",
              "      <td>수</td>\n",
              "      <td>2601</td>\n",
              "      <td>56</td>\n",
              "      <td>180</td>\n",
              "      <td>111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...</td>\n",
              "      <td>카레덮밥 (쌀,현미흑미:국내산) 팽이장국  치킨핑거 (닭고기:국내산) 쫄면야채무침 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 청국장찌개  황태양념구이 (황태:러시아산) 고기...</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-02-04</td>\n",
              "      <td>목</td>\n",
              "      <td>2601</td>\n",
              "      <td>104</td>\n",
              "      <td>220</td>\n",
              "      <td>355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 쇠고기무국  주꾸미볶음  부추전  시금치나물  ...</td>\n",
              "      <td>미니김밥*겨자장 (쌀,현미흑미:국내산) 우동  멕시칸샐러드  군고구마  무피클  포...</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-02-05</td>\n",
              "      <td>금</td>\n",
              "      <td>2601</td>\n",
              "      <td>278</td>\n",
              "      <td>181</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 떡국  돈육씨앗강정 (돼지고기:국내산) 우엉잡채...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 차돌박이찌개 (쇠고기:호주산) 닭갈비 (닭고기:...</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-02-11</td>\n",
              "      <td>목</td>\n",
              "      <td>2601</td>\n",
              "      <td>383</td>\n",
              "      <td>143</td>\n",
              "      <td>417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 시래기국  훈제오리구이  도토리묵무침  쌈무/양...</td>\n",
              "      <td>참치회덮밥 (쌀,현미흑미:국내산) 맑은국  군만두  과일샐러드  락교  포기김치 (...</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-02-12</td>\n",
              "      <td>금</td>\n",
              "      <td>2601</td>\n",
              "      <td>389</td>\n",
              "      <td>156</td>\n",
              "      <td>93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 꽃게탕  돈육굴소스볶음  옥수수전  유채나물  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치콩나물국  미니함박  어묵볶음  물파래무침 ...</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-02-15</td>\n",
              "      <td>월</td>\n",
              "      <td>2601</td>\n",
              "      <td>87</td>\n",
              "      <td>204</td>\n",
              "      <td>482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 시금치국  닭감자조림 (닭고기:국내산) 연두부*양념장  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 홍합미역국  등갈비김치찜 (돼지고기,김치:국내산) 임연수...</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-02-16</td>\n",
              "      <td>화</td>\n",
              "      <td>2601</td>\n",
              "      <td>72</td>\n",
              "      <td>236</td>\n",
              "      <td>526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 쇠고기무국 (쇠고기:호주산) 탕수어 (동태:러시아산) 오...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 된장찌개  쇠불고기 (쇠고기:호주산) 해파리겨자채  봄동...</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-02-17</td>\n",
              "      <td>수</td>\n",
              "      <td>2601</td>\n",
              "      <td>78</td>\n",
              "      <td>250</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 냉이된장국  쇠고기장조림 (쇠고기:호주산) 통도라지구이 ...</td>\n",
              "      <td>볶음밥*자장소스 (쌀:국내산) 맑은국  새우또띠아  쨔샤이무침  요플레  포기김치 ...</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자 요일  ...     중식계    석식계\n",
              "0  2016-02-01  월  ...  1039.0  331.0\n",
              "1  2016-02-02  화  ...   867.0  560.0\n",
              "2  2016-02-03  수  ...  1017.0  573.0\n",
              "3  2016-02-04  목  ...   978.0  525.0\n",
              "4  2016-02-05  금  ...   925.0  330.0\n",
              "5  2016-02-11  목  ...  1045.0  550.0\n",
              "6  2016-02-12  금  ...   909.0  598.0\n",
              "7  2016-02-15  월  ...  1268.0  672.0\n",
              "8  2016-02-16  화  ...  1014.0  523.0\n",
              "9  2016-02-17  수  ...   916.0  588.0\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgSYY8gz_AuO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "4e3d9efe-82d4-4b1f-f949-b677b277d6d0"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>요일</th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>수</td>\n",
              "      <td>2983</td>\n",
              "      <td>88</td>\n",
              "      <td>182</td>\n",
              "      <td>5</td>\n",
              "      <td>358.0</td>\n",
              "      <td>모닝롤/연유버터베이글 우유/주스 계란후라이/찐계란 단호박죽/흑미밥 우거지국 고기완자...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 대구지리 매운돈갈비찜 오꼬노미계란말이 상추무침 포기김치 양상추...</td>\n",
              "      <td>흑미밥 얼큰순두부찌개 쇠고기우엉볶음 버섯햄볶음 (New)아삭이고추무절임 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>목</td>\n",
              "      <td>2983</td>\n",
              "      <td>104</td>\n",
              "      <td>212</td>\n",
              "      <td>409</td>\n",
              "      <td>348.0</td>\n",
              "      <td>모닝롤/대만샌드위치 우유/주스 계란후라이/찐계란 누룽지탕/흑미밥 황태국 시래기지짐 ...</td>\n",
              "      <td>쌀밥/보리밥/찰현미밥 우렁된장찌개 오리주물럭 청양부추전 수제삼색무쌈 겉절이김치 양상...</td>\n",
              "      <td>충무김밥 우동국물 오징어무침 꽃맛살샐러드 얼갈이쌈장무침 석박지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>금</td>\n",
              "      <td>2983</td>\n",
              "      <td>270</td>\n",
              "      <td>249</td>\n",
              "      <td>0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>모닝롤/핫케익 우유/주스 계란후라이/찐계란 오곡죽/흑미밥 매생이굴국 고구마순볶음 양...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 팽이장국 수제돈까스*소스 가자미조림 동초나물무침 포기김치 양상...</td>\n",
              "      <td>흑미밥 물만둣국 카레찜닭 숯불양념꼬지어묵 꼬시래기무침 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>월</td>\n",
              "      <td>2924</td>\n",
              "      <td>108</td>\n",
              "      <td>154</td>\n",
              "      <td>538</td>\n",
              "      <td>322.0</td>\n",
              "      <td>모닝롤/촉촉한치즈케익 우유/주스 계란후라이/찐계란 누룽지탕/흑미밥 두부김칫국 새우완...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 배추들깨국 오리대패불고기 시금치프리타타 부추고추장무침 포기김치...</td>\n",
              "      <td>흑미밥 동태탕 돈육꽈리고추장조림 당면채소무침 모자반무침 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>화</td>\n",
              "      <td>2924</td>\n",
              "      <td>62</td>\n",
              "      <td>186</td>\n",
              "      <td>455</td>\n",
              "      <td>314.0</td>\n",
              "      <td>모닝롤/토마토샌드 우유/주스 계란후라이/찐계란 채소죽/흑미밥 호박맑은국 오이생채 양...</td>\n",
              "      <td>쌀밥/팥밥/찰현미밥 부대찌개 닭살데리야끼조림 버섯탕수 세발나물무침 알타리김치/사과푸...</td>\n",
              "      <td>흑미밥 바지락살국 쇠고기청경채볶음 두부구이*볶은김치 머위된장무침 백김치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자  ...                                           석식메뉴\n",
              "0  2021-01-27  ...  흑미밥 얼큰순두부찌개 쇠고기우엉볶음 버섯햄볶음 (New)아삭이고추무절임 포기김치 \n",
              "1  2021-01-28  ...            충무김밥 우동국물 오징어무침 꽃맛살샐러드 얼갈이쌈장무침 석박지 \n",
              "2  2021-01-29  ...            흑미밥 물만둣국 카레찜닭 숯불양념꼬지어묵 꼬시래기무침 포기김치 \n",
              "3  2021-02-01  ...           흑미밥 동태탕 돈육꽈리고추장조림 당면채소무침 모자반무침 포기김치 \n",
              "4  2021-02-02  ...       흑미밥 바지락살국 쇠고기청경채볶음 두부구이*볶은김치 머위된장무침 백김치 \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxe-kkV6AlNF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30802541-9238-4acd-a130-fc9407d74f8e"
      },
      "source": [
        "print(train_df.shape, test_df.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 12) (50, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SasndXbCF8MZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a2dd1ee5-c2d4-492b-a579-d86eeaea4a6c"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2807.815768</td>\n",
              "      <td>157.913693</td>\n",
              "      <td>241.142739</td>\n",
              "      <td>274.117012</td>\n",
              "      <td>43.506224</td>\n",
              "      <td>890.334440</td>\n",
              "      <td>461.772614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>171.264404</td>\n",
              "      <td>144.190572</td>\n",
              "      <td>43.532298</td>\n",
              "      <td>246.239651</td>\n",
              "      <td>109.937400</td>\n",
              "      <td>209.505057</td>\n",
              "      <td>139.179202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2601.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2645.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>217.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>406.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2760.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>483.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2962.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>272.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>545.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3305.000000</td>\n",
              "      <td>1224.000000</td>\n",
              "      <td>378.000000</td>\n",
              "      <td>1044.000000</td>\n",
              "      <td>533.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>905.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             본사정원수       본사휴가자수  ...          중식계          석식계\n",
              "count  1205.000000  1205.000000  ...  1205.000000  1205.000000\n",
              "mean   2807.815768   157.913693  ...   890.334440   461.772614\n",
              "std     171.264404   144.190572  ...   209.505057   139.179202\n",
              "min    2601.000000    23.000000  ...   296.000000     0.000000\n",
              "25%    2645.000000    71.000000  ...   758.000000   406.000000\n",
              "50%    2760.000000   105.000000  ...   879.000000   483.000000\n",
              "75%    2962.000000   185.000000  ...  1032.000000   545.000000\n",
              "max    3305.000000  1224.000000  ...  1459.000000   905.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_b3BlgMEVlZ"
      },
      "source": [
        "# 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCX96_qDEZnQ"
      },
      "source": [
        "## 비율 변수 추가 및 날짜 변수 조정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 546
        },
        "id": "dhg1YrRaBq9N",
        "outputId": "73c47612-2efd-4c32-bf4a-3b1525acf37a"
      },
      "source": [
        "all_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "all_df['vac_ratio'] = all_df['본사휴가자수'] / all_df['본사정원수']\n",
        "all_df['trip_ratio'] = all_df['본사출장자수'] / all_df['본사정원수']\n",
        "all_df['home'] = all_df['현본사소속재택근무자수'] / all_df['본사정원수']\n",
        "all_df['extra'] = all_df['본사시간외근무명령서승인건수'] / all_df['본사정원수']\n",
        "all_df['total'] = (all_df['본사정원수'] - all_df['본사휴가자수'] \n",
        "                   - all_df['본사출장자수'] - all_df['현본사소속재택근무자수']) / all_df['본사정원수']\n",
        "\n",
        "all_df['일자'] = pd.to_datetime(all_df['일자'])\n",
        "\n",
        "all_df['year'] = all_df['일자'].dt.year\n",
        "all_df['month'] = all_df['일자'].dt.month\n",
        "all_df['date'] = all_df['일자'].dt.day\n",
        "all_df['week'] = all_df['일자'].dt.isocalendar().week\n",
        "all_df['dayofweek'] = all_df['일자'].dt.weekday\n",
        "\n",
        "all_df.drop(['본사휴가자수', '본사출장자수', '현본사소속재택근무자수', \n",
        "             '본사시간외근무명령서승인건수', '본사정원수', '일자', '요일'], axis=1, inplace=True)\n",
        "all_df['week'] = all_df['week'].astype(np.int64)\n",
        "all_df.rename({'조식메뉴':'breakfast', '중식메뉴':'lunch', '석식메뉴':'dinner', '중식계':'lunch_y', '석식계':'dinner_y'}, inplace=True)\n",
        "\n",
        "all_df.head(10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 오징어찌개  쇠불고기 (쇠고기:호주산) 계란찜 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 육개장  자반고등어구이  두부조림  건파래무침 ...</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치찌개  가자미튀김  모둠소세지구이  마늘쫑무...</td>\n",
              "      <td>콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무...</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...</td>\n",
              "      <td>카레덮밥 (쌀,현미흑미:국내산) 팽이장국  치킨핑거 (닭고기:국내산) 쫄면야채무침 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 청국장찌개  황태양념구이 (황태:러시아산) 고기...</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 쇠고기무국  주꾸미볶음  부추전  시금치나물  ...</td>\n",
              "      <td>미니김밥*겨자장 (쌀,현미흑미:국내산) 우동  멕시칸샐러드  군고구마  무피클  포...</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 떡국  돈육씨앗강정 (돼지고기:국내산) 우엉잡채...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 차돌박이찌개 (쇠고기:호주산) 닭갈비 (닭고기:...</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 시래기국  훈제오리구이  도토리묵무침  쌈무/양...</td>\n",
              "      <td>참치회덮밥 (쌀,현미흑미:국내산) 맑은국  군만두  과일샐러드  락교  포기김치 (...</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>0.147251</td>\n",
              "      <td>0.054979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160323</td>\n",
              "      <td>0.797770</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 꽃게탕  돈육굴소스볶음  옥수수전  유채나물  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치콩나물국  미니함박  어묵볶음  물파래무침 ...</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>0.149558</td>\n",
              "      <td>0.059977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.790465</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 시금치국  닭감자조림 (닭고기:국내산) 연두부*양념장  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 홍합미역국  등갈비김치찜 (돼지고기,김치:국내산) 임연수...</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>0.033449</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185313</td>\n",
              "      <td>0.888120</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 쇠고기무국 (쇠고기:호주산) 탕수어 (동태:러시아산) 오...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 된장찌개  쇠불고기 (쇠고기:호주산) 해파리겨자채  봄동...</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.090734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.202230</td>\n",
              "      <td>0.881584</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 냉이된장국  쇠고기장조림 (쇠고기:호주산) 통도라지구이 ...</td>\n",
              "      <td>볶음밥*자장소스 (쌀:국내산) 맑은국  새우또띠아  쨔샤이무침  요플레  포기김치 ...</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.096117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008843</td>\n",
              "      <td>0.873895</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                조식메뉴  ... dayofweek\n",
              "0  모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...  ...         0\n",
              "1  모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...  ...         1\n",
              "2  모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...  ...         2\n",
              "3  모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...  ...         3\n",
              "4  모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...  ...         4\n",
              "5  팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...  ...         3\n",
              "6  모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...  ...         4\n",
              "7  모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...  ...         0\n",
              "8  모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...  ...         1\n",
              "9  모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...  ...         2\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R23Ti5cSEeob"
      },
      "source": [
        "## 타겟 값 분포 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "fDMBD9vNzrmU",
        "outputId": "b3589df0-6127-4b6f-d74c-69d519a6112e"
      },
      "source": [
        "f, ax = plt.subplots(1, 2,figsize=(10,6))\n",
        "ax[0].hist(all_df['중식계'], bins=100)\n",
        "ax[0].set_title('Lunch')\n",
        "ax[1].hist(all_df['석식계'], bins=100)\n",
        "ax[1].set_title('Dinner')\n",
        "plt.show()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhwnDKVEEil1"
      },
      "source": [
        "## 괄호 및 여러 특수문자 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkp67IZOwBOu"
      },
      "source": [
        "def split_process(x):\n",
        "    regex = '\\*.*|\\((.*?)\\)|[+%><]|\\&.*' \n",
        "    x_ = []\n",
        "    x = x.split(' ')\n",
        "    for i in x:\n",
        "        if '(' in i or ':' in i or ')' in i:\n",
        "            continue\n",
        "        if '/' in i:\n",
        "            x_.extend(i.split('/'))\n",
        "        elif ',' in i:\n",
        "            x_.extend(i.split(','))\n",
        "        elif '-' in i:\n",
        "            x_.extend(i.split('-'))\n",
        "        else:\n",
        "            x_.append(re.sub(regex, '', i))\n",
        "        \n",
        "    x_ = list(set(x_)) # 가끔 중복되는 메뉴 제거(계란후라이가 두번 들어있는 식단도 있음)\n",
        "    x_.remove('')\n",
        "    return x_\n",
        "\n",
        "breakfast_list = []\n",
        "lunch_list = []\n",
        "dinner_list = []\n",
        "\n",
        "breakfast_list += all_df['조식메뉴'].apply(lambda x: split_process(x)).to_list()\n",
        "lunch_list += all_df['중식메뉴'].apply(lambda x: split_process(x)).to_list()\n",
        "dinner_list += all_df['석식메뉴'].apply(lambda x: split_process(x)).to_list()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDTZW_YEGaJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5660008-cb5e-446b-e744-7b98c414df4f"
      },
      "source": [
        "print(all_df['조식메뉴'][0])\n",
        "print(breakfast_list[0])\n",
        "print(all_df['석식메뉴'][1])\n",
        "print(dinner_list[1])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐어채무침  포기김치 (배추,고추가루:국내산) \n",
            "['우유', '쌀밥', '두유', '쥐어채무침', '찐빵', '포기김치', '호두죽', '계란후라이', '주스', '모닝롤', '된장찌개']\n",
            "콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무침  바나나  포기김치 (배추,고추가루:국내산) \n",
            "['콩나물밥', '어묵국', '포기김치', '유산슬', '바나나', '아삭고추무침']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4EgTYkfEo_c"
      },
      "source": [
        "## 시간대별 메뉴 리스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhH6XUDmwkSt",
        "outputId": "948b6799-3744-49c3-e474-4f7330c2f2c1"
      },
      "source": [
        "def make_set(list):\n",
        "    menu_set = set()\n",
        "    for row in list:\n",
        "        menu_set.update(row)\n",
        "    return menu_set\n",
        "\n",
        "breakfast_set = make_set(breakfast_list)\n",
        "lunch_set = make_set(lunch_list)\n",
        "dinner_set = make_set(dinner_list)\n",
        "\n",
        "# 조중석식 메뉴 중복 제거 리스트\n",
        "print(breakfast_set)\n",
        "print(lunch_set)\n",
        "print(dinner_set)\n",
        "\n",
        "# 조중석식 메뉴 개수\n",
        "print(len(breakfast_set), len(lunch_set), len(dinner_set))\n",
        "# 겹치는 메뉴 개수\n",
        "print(len(breakfast_set & lunch_set & dinner_set))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'감자샌드', '브로컬리초장', '감자조림', '매운감자조림', '크림롤케익', '생크림단팥빵', '머위나물무침', '도라지생채', '삶은계란', '방풍나물', '감자고추장찌개', '마늘쫑메추리알장조림', '쇠고기미역국', '명엽채볶음', '케익', '후르츠산도', '크로와상', '어묵꽈리고추볶음', '브로콜리감자볶음', '얼갈이된장국', '우엉채조림', '오이맛살볶음', '홍게살죽', '꽃게탕', '사과롤케익', '곰피초장', '시금치나물무침', '오이도라지무침', '생크림와플', '오렌지케익빵', '콩가루배추국', '순두부계란국', '무생채', '피자토스트', '참나물생채', '오징어무국', '치즈케익', '양념김', '무청된장국', '옥수수스프', '시래기들깨탕', '건파래무침', '연근조림', '파래무침', '마약토스트', '열무된장나물', '전주식콩나물국해장국', '해물땡굴소스볶음', '검정콩조림', '두부김치국', '톳무침', '어묵토마토조림', '녹차호떡', '조각케익', '건새우아욱국', '동태탕', '맑은순두부국', '섭산적구이', '머핀', '피바지락국', '새알만두국', '김치도토리묵무침', '에그타르트', '호두죽', '브로컬리들깨소스', '시나몬페스츄리', '베이컨에그슬럿', '바지락무국', '토마토리코타치즈샐러드', '순두부백탕', '홍합살무국', '아귀지리탕', '크루통크림스프', '느타리팽이볶음', '아귀지리', '부추김무침', '김잔파무침', '파래김', '김치어묵국', '명엽채고추장볶음', '쑥갓무침', '건파래볶음', '커피콩빵', '치즈프레즐', '앙버터모닝빵', '건새우마늘쫑볶음', '꽈리고추멸치볶음', '야채호빵', '바지락살국', '감자스프', '열무나물', '소고기샤브국', '올갱이아욱국', '샌드위치', '쇠고기해장국', '사과베이비샐러드', '애호박새우젓볶음', '재래김', '차돌박이찌개', '초코핫케익', '소보로빵', '핫케이크', '크랜베리멸치볶음', '우엉간장조림', '팬케익', '김치콩나물국', '청포묵무침', '어묵고추장볶음', '버섯들깨탕', '감자햄볶음', '애호박나물볶음', '허니브레드', '감자채피망볶음', '매운사태조림', '자반무침', '단호박죽', '베이컨맥모닝', '참치죽', '비엘티샌드위치', '야채햄샌드', '바지락쑥국', '참나물땅콩가루무침', '홍합죽', '군대리아', '토란탕', '콩나물무침', '버섯국', '두부동그랑땡', '톳두부무침', '가지쇠고기볶음', '해물순두부찌개', '차돌박이된장찌개', '소보루빵', '소고기무국', '페퍼로니피자', '연근호두조림', '시금치팬케익', '해물완자전', '마늘빵', '주스', '참치채소볶음', '만두국', '바나나팬케이크', '계란장조림', '연두부', '핫도그', '마늘쫑맛살볶음', '꽁치김치조림', '생깻잎지', '연유후레쉬', '고구마파이', '해초무침', '콩죽', '민물새우찌개', '표고버섯죽', '수박', '쑥갓나물', '버섯들깨죽', '사과오이초무침', '살라미샌드위치', '사골우거지국', '모닝샌드위치', '유채나물무침', '북어무우국', '숙주나물무침', '꽃게된장찌개', '아삭고추된장무침', '얼갈이국', '유부장국', '우엉어묵볶음', '파게트', '어묵고추장무침', '매운버섯국', '돈사태찜', '느타리버섯장조림', '삼색샌드위치', '베이글', '와플&생크림', '삼겹살김치볶음', '구구마순나물', '길거리토스트', '베이컨숙주볶음', '카스텔라', '쇠고기샤브국', '유부김치국', '참치채소죽', '유채나물', '연두부찌개', '소시지감자볶음', '연두부탕', '새우완자국', '김치국', '과일샐러드', '두부계란전', '콩비지찌개', '오이무침', '홍합살미역국', '멸치호두볶음', '브로컬리들깨무침', '스태프핫도그', '촉촉한치즈빵', '호박새우젓국', '누룽지탕', '오이생채', '베이비샐러드', '두부양념찜', '들깨시래기국', '진미채볶음', '연두부샐러드', '알타리김치', '고구마줄기볶음', '냉이바지락국', '진미채간장조림', '골뱅이무침', '미나리나물', '메추리알곤약조림', '맑은버섯육개장', '애플잼쿠키', '와플', '바나나팬케익', '페스츄리', '에그맥모닝', '멸치아몬드볶음', '마샐러드', '팥호빵', '스크램블', '맑은꽃게탕', '두부김칫국', '감자양파국', '비엔나소세지볶음', '애호박건새우볶음', '단호박찐빵', '시금치샐러드', '두부고기조림', '양념깻잎지찜', '방울토마토', '호박볶음', '버섯볶음', '보리누룽지탕', '건포도머핀', '호박죽', '양념깻잎지', '애플파이', '매운콩나물국', '알감자조림', '마늘종숙회', '소고기국', '채소죽', '시금치두부무침', '북어계란국', '통마늘너비아니조림', '달래오이무침', '옛날소시지전', '아욱된장국', '동태찌개', '건새우무조림', '야채샌드', '건새우무채국', '비름나물', '감자채햄볶음', '미역레몬초무침', '미니새송이볶음', '배추시래기국', '선지해장국', '견과류죽', '토스트', '야채샌드위치', '김칫국', '옹심이만두떡국', '단팥죽', '고사리들깨나물', '시금치나물', '호박잎찌개', '찐빵', 'BLT샌드', '버섯매운국', '수제비국', '배추맑은국', '돈육장조림', '애호박새우젓국', '우거지국', '황태해장국', '콩나물오징어국', '증편', '맑은감자국', '모카카스테라', '콘스프', '단호박크림스프', '명엽채무침', '호밧젓국찌개', '아오리사과', '쇠고기무국', '단팥빵', '크로아상샌드위치', '리코타치즈샐러드', '두부쑥갓무침', '소고기채소죽', '버섯맑은국', '우엉조림', '대구찌개', '새우야채죽', '롤케이크', '냉이국', '흑미두부죽', '단호박피자빵', '두부구이', '두부새우젓국', '무채나물', '꿀호떡', '새우살미역국', '참치김치볶음', '겨울초나물', '시금치프리타타', '닭개장', '딤섬', '마늘쫑새우볶음', '콩나물국', '참치김치찌개', '치킨샌드', '쪽파숙회', '크래미샌드', '돈육마늘장조림', '사과', '숙주미나리나물', '수제어묵볶음', '냉이된장국', '채소새우죽', '된장찌개', '콩나물김칫국', '콩가루된장국', '쇠고기매운국', '팥죽', '김가루실파무침', '낙지김치죽', '맑은만두국', '오이사과무침', '야채죽', '고사리들깨볶음', '고기완자전', '동태매운탕', '도토리묵무침', '해물죽', '토마토샐러드', '들기름무채볶음', '새송이버섯죽', '브리또', '감자국', '바나나샌드', '감자찌개', '섭산적조림', '크로와상샌드', '구운어묵볶음', '오곡죽', '감자된장찌개', '낙지죽', '치즈팡샌드', '연유버터베이글', '모둠묵', '어묵매운국', '베이컨샌드위치', '단배추들깨무침', '참나물땅콩무침', '늙은호박죽', '맑은만두육개장', '매생이굴국', '쇠고기꽈리고추장조림', '멸치볶음', '대구지리', '모닝샌드', '고구마죽', '오이보트샐러드', '햄에그샌드', '참나물무침', '마늘쫑햄볶음', '쑥갓두부무침', '가지양파나물', '맑은콩나물국', '구이김', '치즈베이글', '미역죽', '들깨무채국', '크래미미역줄기볶음', '미니케익', '흑미밥', '참치새드', '토마토샌드위치', '미역나물', '메추리알조림', '어묵국', '머위대나물', '롤케익', '가지양파무침', '양상추샐러드', '피자빵', '김치죽', '노각무침', '모듬묵', '느타리버섯볶음', '땅콩크림빵', '사과잼쿠키', '연두부국', '쌀밥', '쑥갓겉절이', '브로컬리무침', '메론빵', '햄에그치즈토스트', '크림누룽지탕', '비엔나구이', '황태두부국', '닭살해장국', '무채국', '고들빼기무침', '홍초콩나물국', '김치황태국', '북어국', '바지락죽', '볼어묵볶음', '유채된장무침', '크렌베리멸치볶음', '떡국', '미역줄기볶음', '두부들깨탕', '감자맛살볶음', '프렌치토스트', '두부양념구이', '지리멸치볶음', '오징어콩나물국', '순두부탕', '북어콩나물국', '아귀매운탕', '비엔나채소볶음', '소고기미역국', '병아리', '콥샐러드', '마늘종호두조림', '포기김치', '느타리버섯국', '물파래무침', '소라살죽', '콩나물된장국', '무비트생채', '쥐어채무침', '햄야채샌드', '미니햄버거', '시금치초무침', '스틱치즈케익', '크로와상샌드위치', '얼큰낙지죽', '대구지리탕', '느타리볶음', '가지두반장볶음', '문어꽈리초조림', '멸치고추장볶음', '컵케익', '블루베리크림치즈베이글', '무나물', '섭산적채소조림', '우렁살된장국', '해물동그랑땡전', '취나물', '치즈볼', '더덕무침', '곤약어묵볶음', '토마토', '흑임자죽', '우거지올갱이국', '크로크무슈', '치커리무침', '사과샌드위치', '모시조개시금치국', '마늘쫑볶음', '오렌지빵', '호빵', '참나물', '녹차카스테라', '쇠고기죽', '황태국', '아욱국', '새우완자전', '봄동겉절이', '우엉땅콩조림', '매콤부들어묵볶음', '메론롤케익', '모닝사라다빵', '시래기조림', '근대감자국', '게살모닝샌드', '새알팥죽', '절편', '배추된장국', '비트무생채', '멸치고추장무침', '버섯햄볶음', '바나나시나몬토스트', '두부조림', '소고기죽', '취나물무침', '새우살죽', '블루베리사과샌드', '콩자반', '치커리유자청무침', '햄에그샌드위치', '고구마샌드', '동초나물무침', '땅콩샌드', '양송이스프', '샐러드', '조랭이떡국', '민물새우찌깨', '브라우니', '소시지볶음', '캔꽁치무조림', '브로컬리두부무침', '근대나물무침', '사각어묵볶음', '카야잼샌드', '통아몬드멸치볶음', '멸치마늘종볶음', '들깨미역국', '겨울초겉절이', '참치샌드', '누룽지탕죽', '상추양념장', '어묵볶음', '촉촉한치즈케익', '땅콩죽', '바나나베이비샐러드', '스콘', '크래미숙주무침', '트위스터버거', '들깨버섯국', '시금치죽', '미나리숙주무침', '카레감자채볶음', '멸치캐슈넛볶음', '브로컬리들깨찜', '북어맑은국', '새송이버섯곤약장조림', '올챙이만두국', '시래기국', '분홍소세지구이', '가지볶음', '비엔나곤약조림', '어묵탕', '취나물된장무침', '우거지해장국', '두부브로컬리무침', '고구마오븐구이', '도토리묵', '도라지나물', '매생이국', '호박된장국', '단배추나물', '120명', '갈릭파이', '고르곤졸라', '사각어묵무침', '베이컨감자볶음', '고구마스프', '마늘쫑건새우볶음', '시금치국', '오징어젓갈무침', '브로콜리스프', '호박맑은국', '인기가요샌드', '계란후라이', '고추장찌개', '마늘쫑건새우무침', '오색떡국', '아삭고추무침', '피자샌드', '고구마순나물', '대구매운탕', '볼어묵조림', '깻잎순볶음', '느타리호박볶음', '새알미역국', '베이컨치즈베이글', '대구탕', '두부떡국', '누룽지', '청경채무침', '호박새우젓찌개', '스팸구이', '두유', '건새우무국', '봄동된장국', '마늘쫑무침', '게살모닝샌드위치', '깻순나물', '두부양념조림', '콩나물간장조림', '고구마순볶음', '연근땅콩조림', '닭죽', '후르츠팬케익', '열무된장국', '맑은연두부탕', '자반김', '참나물두부샐러드', '계란빵', '호박채볶음', '김가루잔파무침', '시래기지짐', '모둠사태조림', '열무김치', '오징어국', '인절미샌드', '소고기무우국', '비타민샐러드', '미역소고기죽', '참치야채', '재첩국', '인절미토스트', '사과파이', '치커리유자무침', '에그포테이토샌드위치', '남친샌드위치', '쇠고기마늘죽', '도라지볶음', '수삼닭죽', '불고기브리또', '옹심이만두국', '치아바타샌드', '햄치즈샌드', '얼갈이겉절이', '배추국', '양송이죽', '피홍합탕', '김실파무침', '매운어묵국', '근대된장국', '에그갈릭토스트', '모듬묵샐러드', '배추겉절이', '에그단호박샌드', '조랭이미역국', '치커리사과무침', '버섯비엔나조림', '쿠키', '피바지락배추국', '매운소고기국', '북어해장국', '깍두기', '대만샌드위치', '방풍나물무침', '순두부찌개', '호박숙', '얼큰소고기국', '매운감자국', '햄야채볶음', '식빵피자', '새송이죽', '꽈리고추찜', '영양부추생채', '참치모닝샌드', '봄동나물', '호박젓국찌개', '토란국', '베이컨숙주굴소스볶음', '김치순두부찌개', '진미채무침', '달래된장찌개', '동전문어조림', '시래기나물', '우유', '옥수수샌드', '잣죽', '느타리애호박볶음', '새우살야채죽', '애플샌드', '가지나물', '두반장가지볶음', '호박채나물', '시래기된장국', '명엽체고추장볶음', '참치야채죽', '비엔나야채볶음', '꽃맛살볶음', '바나나', '핫케익', '쇠고기우거지국', '동전쥐포무침', '버섯매운탕', '아귀채무침', '버섯굴죽', '단호박샌드', '호박고구마오븐구이', '구운계란', '파운드케익', '대만식연유샌드위치', '오이맛살냉채', '야채모닝샌드', '고르곤졸라피자', '라즈베리빵', '감자채볶음', '쑥국', '카레감자볶음', '황태채국', '치커리오이무침', '새송이버섯볶음', '깻잎순나물볶음', '브로컬리', '김구이', '커피', '모닝롤', '프레즐', '게살죽', '콩가루배춧국', '얼갈이나물', '옹심이만둣국', '매콤사태찜', '애호박나물', '깨찰빵', '모닝에그빵', '김치두부국', '양배추샐러드', '시금치고추장국', '북어채국', '계란찜', '대추채멸치볶음', '딸기파이', '수제동그랑땡전', '땅콩멸치볶음', '브로콜리맛살볶음', '죽순버섯볶음', '브로컬리된장무침', '씨크립샌드', '소고기스프', '매생이떡국', '마늘바게트', '카스테라', '녹두죽', '그린샐러드', '아메리카노', '에그샌드', '유부김칫국', '매운감자양파국', '시금치된장국', '애호박볶음', '호떡맥모닝', '찐계란', '들깨감자국', '사골파국', '크림치즈와플', '스크램블에그', '조갯살근대국', '크림치즈프레즐', '칠리소스두부브로컬리볶음', '숙주나물', '비엔나브로콜리볶음', '꽃게된장국', '방울양배추베이컨볶음', '청양콩나물국', '옹심이국', '베이컨샌드', '조랭이떡미역국', '맑은조개탕', '모둠장조림', '새송이볶음', 'BLT샌드위치', '햄치즈샌드위치', '실곤약흑임자무침', '근대국', '흑미쌀찐빵', '콩조림', '야채소시지전', '밤죽', '콩나물김치국', '마계토스트', '맑은버섯국', '북엇국', '순두부된장국', '토마토샌드', '미역국', '땅콩아몬드조림', '바지락콩나물국', '쇠고기버섯국', '양념깻잎찜', '순두부국', '키위드레싱샐러드', '알탕', '시금치핫케익', '호박나물', '닭곰탕', '버섯죽', '김자반', '블루베리프렌치토스트', '게살채소죽', '땅콩조림', '바지락국', '새송이조림', '보코치니샐러드', '홍루이젠', '두부젓국찌개', '영양닭죽', '가자미양념찜', '브로컬리죽', '콩나물해장국', '홍합탕', '멸치크랜베리볶음', '취나물볶음', '쥐포무침', '호떡', '몽골식돈육볶음'}\n",
            "{'두릅소고기샐러드', '파스타샐러드', '계란', '오징어젓무침', '연근유자피클', '해물잡채', '수제탕수육', '떡잡채', '홍합국', '수제돈까스', '춘권', '더덕오이생채', '참나물생채', '훈제오리마늘볶음', '가자미무조림', '양념김', '아삭이고추된장무침', '소불고기', '부추겉절이', '건파래무침', '제육고추장불고기', '야채비빔만두', '두부김치국', '사과푸딩', '깻잎', '건새우아욱국', '또띠아칩', '미니함박조림', '매콤낙지볶음', '맑은순두부국', '나쵸콥샐러드', '부추고추전', '새알만두국', '미트볼칠리조림', '쪽파무침', '풍기샐러드', '소고기장조림', '갈치무조림', '꽈리고추멸치볶음', '깻잎통닭', '카레닭찜', '물파래전', '망고푸딩', '차돌박이찌개', '상추파무침', '어묵고추장볶음', '청경채깨장나물', '곤약야채무침', '돈육보쌈', '간장마늘치킨', '병아리콩밥', '탱크보이', '단무지락교무침', '모둠버섯구이', '버섯국', '두부된장찌개', '고구마치즈돈까스', '미역무침', '차돌박이된장찌개', '소고기불고기', '갈치양념조림', '닭볶음탕', '배추김치', '생선까스', '사골우거지국', '파프리카해초무침', '미트볼채소볶음', '녹두전', '동파육', '아삭고추된장무침', '닭오븐구이', '미나리오이무침', '매운버섯국', '바베큐폭립', '배추들깨국', '고구마그라탕', '갈비만두', '고추지', '쇠고기샤브국', '올방개묵무침', '유기농식혜', '오이지무침', '동파삼겹수육', '귀리밥', '오이무침', '피클', '시리얼샐러드', '냉모밀국수', '불낙찌개', '치자밥', '양념돼지갈비찜', '짜장소스', '메추리알곤약조림', '단호박채소전', '맑은버섯육개장', '코다리강정', '고추*쌈장', '시금치무침', '고추장고구마순무침', '건다래순볶음', '어묵매운탕', '명태코다리조림', '감자양파국', '양배추채무침', '소불고기덮밥', '양념두부조림', '청경채사과생채', '나쵸', '통도라지구이', '맛살전', '돌나물유자청무침', '단호박영양밥', '북어계란국', '푸딩', '건새우무채국', '비름나물', '고구마튀김', '쇠고기장조림', '소갈비찜', '새싹샐러드', '옹심이만두떡국', '더덕양념구이', '청포묵', '그린샐러드*키위D', '쇠불고기', '날치알계란찜', '매운쇠고기버섯볶음', '쇠고기무국', '통계란꼬치어묵탕', '가지고추장무침', '교촌간장치킨', '류산슬', '유채겉절이', '오리주물럭', '잔치국수', '영양모듬견과', '수제함박스테이크', '새우살미역국', '요플레', '시금치프리타타', '콩나물냉국', '양장피', '꽃맛살과일샐러드', '비엔케찹볶음', '마시는요거트', '곤드레밥', '닭간장조림', '콩나물김칫국', '두부맑은국', '수제보쌈김치', '카레덮밥', '갈릭순살치킨', '동태매운탕', '수원왕갈비통닭', '고기완자전', '도토리묵무침', '돈육잡채', '감자국', '해물부추전', '매운계란파국', '연어스테이크', '우묵냉국', '고등어김치말이', '명이나물-장아찌', '구이김', '쇠고기두부찜', '야채고로케', '쌈추', '머위대나물', '경상도식소고기국', '모둠소시지구이', '노각무침', '쌀밥', '유자청제육볶음', '콜리샐러드', '계란말이', '홍초콩나물국', '북어국', '오징어볶음', '미역줄기볶음', '훈제오리', '김말이튀김', '세발나물', '비엔나채소볶음', '콥샐러드', '병아리콩', '기장밥', '매실짱아찌', '깍둑오이초무침', '무비트생채', '오이초무침', '굴떡국', '옥수수콘치즈구이', '완두콩밥', '매운어묵무침', '건새우호박볶음', '오징어튀김', '삼색물만두무침', '치즈불닭', '김치빈대떡', '김치우동', '곤약흑임자무침', '열무물국수', '낙지비빔밥', '황태국', '모듬양채쌈', '계란파국', '김치제육덮밥', '돈간장불고기', '봄동겉절이', '홍어채무침', '비엔나케찹볶음', '견과류샐러드', '설렁탕', '사과즙', '감자전', '콩나물동태찜', '꼬들단무지무침', '갓김치', '파프리카감자채볶음', '콩나물파채무침', '돈육피망볶음', '옥수수밥', '어묵잡채', '히레카츠', '임연수구이', '바지락냉이국', '오이소배기', '깐풍육', '매실주스', '메밀전병', '미트볼조림', '건강비빔밥', '김치볶음', '고구마순무침', '굴비구이', '쇠고기버섯볶음', '맑은국', '가지나물무침', '들깨미역국', '어묵볶음', '짜장밥', '해물탕', '버섯탕수', '수제피클', '코다리조림', '도토리묵야채무침', '들깨버섯국', '삼치무조림', '돈육씨앗강정', '카레감자채볶음', '올챙이만두국', '단호박범벅', '토마토계란볶음', '깻잎완자전', '고추장찌개', '다시마쌈', '새우완자탕', '고사리육개장', '아삭고추무침', '새알미역국', '베리베리샐러드', '대구탕', '마늘쫑무침', '냉이나물무침', '송편', '삼치양념구이', '군고구마', '해물동그랑땡', '콩나물파채절이', '유니짜장밥', '돈육간장강정', '열무김치', '양파절임', '치커리유자무침', '사과푸딩샐러드', '맛살콩나물냉채', '달래된장국', '도라지볶음', '돈육떡강정', '무말랭이', '단호박물김치', '마파두부', '배추국', '오꼬노미야끼', '버섯구이', '김치찐만두', '떡갈비', '모듬묵샐러드', '춘천닭갈비', '매운주꾸미볶음', '단무지', '깍두기', '닭가슴살장조림', '불고기덮밥', '얼큰소고기국', '후라이드', '봄동전', '삼치데리야끼', '살살치킨', '돈육콩나물불고기', '탕수육', '허니버터치킨', '알리오올리오파스타', '소고기숙주볶음', '호박채나물', '호박잎', '꽃맛살볶음', '버섯매운탕', '미역초무침', '오이사과냉국', '다시마', '버섯초무침', '코다리양념조림', '양파링카레튀김', '강된장', '수제두부까스', '수수부꾸미', '부추샐러드', '귤', '상추쌈', '새송이버섯볶음', '김구이', '콩가루배춧국', '얼갈이나물', '검정콩밥', '냉이콩나물국', '치커리유자샐러드', '수제과일잼샌드', '가자미엿장조림', '쇠고기낙지볶음', '계란찜', '요거트파르페', '땅콩멸치볶음', '콩나물밥', '마늘바게트', '유부김칫국', '갈릭버섯탕수', '구운채소', '미역오이초무침', '풋고추양파쌈장무침', '꽁치오븐구이', '비엔나브로콜리볶음', '머위된장나물', '마카로니샐러드', '브로콜리숙회', '모둠장조림', '볶음김치', '콩조림', '마카로니콘샐러드', '다슬기아욱국', '호박잎쌈', '해물돼지갈비찜', '완자전', '돌나물', '두반장감자볶음', '미니쌀국수', '들깨버섯무침', '오이', '꽁치캔김치조림', '가자미양념찜', '건새우미역국', '홍합탕', '마약계란장조림', '훈제오리냉채', '딸기푸딩', '맛탕', '연근깨소스무침', '명엽채볶음', '머위나물', '미나리초무침', '두부강정', '콩나물부추무침', '간장치킨', '오리대패불고기', '삼겹살오븐구이', '아이스슈', '꽃게탕', '콩가루배추국', '무생채', '새송이너비아니구이', '콩나물겨자채무침', '축하떡', '베이컨김치볶음밥', '고구마치즈구이', '무청된장국', '채소전', '파프리카계란말이', '부대찌개', '옥수수스프', '또띠아피자', '톳무침', '상추파채무침', '양장피잡채', '비엔나떡조림', '동태탕', '꽈리고추찹쌀무침', '청양고추계란말이', '백김치', '등심돈까스', '오징어브로컬리', '청국장찌개', '한식잡채', '해물전', '개성감자만두', '파래김', '가자미튀김', '붕어빵', '건새우마늘쫑볶음', '팽이버섯국', '꽃상추겉절이', '열무나물', '식혜', '치킨너겟', '차돌비빔국수', '돈육굴소스볶음', '주꾸미초무침', '청양부추전', '쇠고기납작당면볶음', '해물누룽지탕', '치커리유자청생채', '콩나물무침', '연복풍덮밥', '야채스틱', '부추양파무침', '천도복숭아', '적어구이', '톳두부무침', '총각김치', '생선커틀릿', '치커리사과생채', '소고기무국', '생야채', '순대채소볶음', '오미산적', '감자만두', '파프리카잡채', '두릅새송이초무침', '자반고등어구이', '도라지오이초무침', '해초무침', '사천식탕수육', '민물새우찌개', '부추생채', '열기어구이', '간장찜닭', '비엔나감자조림', '감자비엔나볶음', '늙은호박전', '양념파닭', '참치야채전', '꽃게된장찌개', '칠리탕수육', '찹쌀호떡', '모듬버섯구이', '호박고추장찌개', '무말랭이무침', '쫄면무침', '짜장덮밥', '흑임자연근샐러드', '산고추지무침', '채소스틱&쌈장', '참나물겉절이', '소세지오븐구이', '가래떡구이', '파닭', '연두부탕', '고춧잎볶음', '두부고기양념찜', '두부계란전', '군만두', '깻잎*쌈장', '청경채사과무침', '매운족발볶음', '조갯살아욱국', '메추리알떡볶이', '알타리김치', '고구마줄기볶음', '비트무피클', '계란채소볶음밥', '꽁치레몬구이', '감자프리타타', '미나리나물', '오렌지주스', '개성식메밀부침개', '세발나물무침', '쌈채소', '시금치샐러드', '미소장국', '부추만두', '수육', '오이미역무침', '방울토마토', '매실음료', '영양부추', '버섯볶음', '묵은지닭볶음탕', '치커리생채', '양념깻잎지', '매운어묵볶음', '돈갈비찜', '소고기국', '순살양념치킨', '수떡수떡화채', '옛날돈까스', '도라지나물볶음', '미역레몬초무침', '채소프리타타', '쫄면', '치커리사과유자청무침', '매콤떡갈비조림', '쌈', '토마토프리타타', '해물수제비국', '훈제오리볶음', '쨔샤이무침', '반달호박나물', '소고기매운무국', '제육미나리볶음', '맛살계란말이', '우엉조림', '쇠고기당면볶음', '두부구이', '홍어무침', '명태코다리강정', '짜장닭볶음', '열무나물무침', '떡만두국', '치즈계란찜', '낙지볶음밥', '참치김치볶음', '닭개장', '갈비탕', '유부채소겨자냉채', '꽈리고추어묵볶음', '견과류마카로니범벅', '사과', '냉이된장국', '꽃맛살햄볶음', '아삭고추쌈장무침', '바질페스토스파게티', '당면채소무침', '닭살겨자냉채', '보름나물', '상추초무침', '돈육볶음', '양파호박채나물', '생강채*쌈장', '모둠묵', '쇠고기숙주볶음', '부추고추장무침', '찰현미밥', '실곤약초무침', '쑥갓쌈&쌈장', '오징어초무침', '닭살겨자채', '매콤해물볶음', '모듬장조림', '쥬시쿨', '프로바이오틱', '쑥갓두부무침', '가쯔오국', '모둠버섯볶음', '청경채나물', '닭갈비', '메추리알조림', '매콤콩나물국', '팝콘치킨', '닭양념조림', '보쌈', '콩나물불고기', '계란버섯장조림', '느타리버섯볶음', '할라피뇨채소피클', '김치제육볶음', '요거트D', '복숭아미역냉국', '청포도주스', '골뱅이소면무침', '순두부탕', '돌나물초장무침', '소고기미역국', '순살닭갈비', '모둠채소무침', '삼색꼬지전', '파인애플볶음밥', '유채나물겉절이', '시금치초무침', '유부채소겨자무침', '가지두반장볶음', '탕평채', '닭다리살스테이크', '바지락미역국', '취나물', '호박전', '토마토', '매운쇠고기샤브샤브', '오향장육', '유채나물된장무침', '마늘쫑볶음', '웨지감자오븐구이', '명태엿장조림', '짜파치킨', '가래떡츄러스', '시래기조림', '새알팥죽', '소고기된장찌개', '버섯들깨국', '소고기콩나물밥', '시금치고추장나물', '너비아니구이', '도라지무침', '돈삼겹보쌈', '단호박장조림', '수제오미산적', '삼겹보쌈', '두부조림', '양념장', '취나물무침', '스프링롤', '콩자반', '모듬소세지볶음', '삼겹살구이', '무쌈말이', '봉추찜닭', '석박지', '시금치고추장나물무침', '고추지무침', '매콤돼지갈비찜', '매운동태찜', '유자청돈육볶음', '양파짱아찌', '꽁치구이', '견과류연근조림', '오이볶음', '알감자버터구이', '포도주스', '토마토스크램블', '팽이된장국', '어묵탕', 'LA갈비구이', '우거지해장국', '꽈리고추메추리알조림', '도라지나물', '단배추나물', '닭데리야끼조림', '물만두국', '쭈꾸미볶음', '깐풍기', '오이양파무침', '버섯숙회*초장', '목살데리야끼', '메밀전병만두', '고구마순나물', '파인애플', '양념찜닭', '파채상추무침', '숙주미나리무침', '갈비통통만두', '채소계란말이', '새송이버섯전', '사과나무주스', '아욱수제비국', '배즙', '고구마범벅', '푸실리파스타샐러드', '봄동된장국', '미니핫도그', '깻순나물', '두부양념조림', '쇠고기매운버섯국', '고추장감자조림', '떡볶이', '메추리알짜장떡볶이', '적어양념장구이', '오이소박이', '감자채카레볶음', '가자미구이', '시래기지짐', '갈치구이', '오징어국', '돈사태김치찜', '망고', '단호박', '스위트칠리미트볼', '어묵간장조림', '쇠고기볶음', '미트볼케찹조림', '만두찜', '샐러드파스타', '깐풍연근', '나쵸칩', '차돌박이구이', '매운돈갈비찜', '연근', '노각생채', '이연복의', '치커리사과무침', '비엔나간장볶음', '북어해장국', '주꾸미야채무침', '방풍나물무침', '육전', '돈육강정', '청경채겉절이', '미나리초장무침', '수원왕갈비', '토란국', '매콤볼어묵볶음', '더덕구이', '닭매운찜', '버섯메추리알장조림', '바나나', '크림새우', '해물청경채볶음', '주꾸미굴소스볶음', '콩나물제육볶음', '고등어조림', '감자채볶음', '황태채국', '옹심이만둣국', '오꼬노미계란말이', '삼계탕', '꼬시래기무침', '애호박나물', '김치두부국', '새송이떡갈비구이', '양배추샐러드', '북어채국', '만두탕수육', '복숭아아이스티', '두부커틀렛', '그린샐러드', '시금치된장국', '알로에주스', '닭강정', '들깨버섯탕', '꽃게된장국', '옹심이국', '타래과', '한방소갈비찜', '조랭이떡미역국', '한방설렁탕', '치즈함박스테이크', '어묵고추장떡', '삼겹살김치찜', '안동찜닭', '갈릭돈가스', '토마토두부카프레제', '알배기', '모듬쌈', '차돌박이숙주볶음', '그린샐러드*오렌지드레싱', '쭈꾸미삼겹고추장볶음', '감자채전', '맑은떡국', '크림스프', '열무비빔밥', '브로콜리새송이메추리알조림', '팥밥', '무쌈채소말이', '닭곰탕', '호박나물', '요구르트', '오징어야채무침', '멸치크랜베리볶음', '사과고구마그라탱', '부추와사비무침', '해파리무침', '수제삼색무쌈', '도라지생채', '방풍나물', '감자고추장찌개', '수박화채', '야채계란찜', '꽁치김치말이찜', '쇠고기미역국', '유부주머니된장국', '사골우거지탕', '락교', '어묵꽈리고추볶음', '가지무침', '양배추', '오이도라지무침', '우렁된장찌개', '가쯔오장국', '새송이*가지구이', '모둠소세지구이', '시래기들깨탕', '연근조림', '근대나물', '볶은김치', '해파리냉채', '단감', '조각케익', '황태채마늘쫑무침', '비름나물고추장무침', '치커리들깨무침', '홍합살무국', '순두부백탕', '계란국', '강낭콩밥', '간장파닭', '궁중떡찜', '부추깻잎전', '강된장찌개', '두부계란부침', '치커리만다린샐러드', '치킨샐러드', '홍삼', '쇠고기해장국', '훈제오리단호박볶음', '청포묵무침', '김치콩나물국', '소고기숙주나물볶음', '연두부찜', '버섯들깨탕', '동그랑땡', '메밀버섯전', '춘권튀김', '브로컬리오징어숙회', '감자샐러드', '비름나물된장무침', '토란탕', '우거지된장국', '마늘', '양상추*쌈장', '배추깻잎', '살구복숭아주스', '배추쌈', '미역미소시루국', '오리들깨탕', '찐햇감자', '해물완자전', '쌈배추', '김치전', '우엉불고기', '김치필라프', '두부카프레제', '참치채소볶음', '라면땅', '순살파닭', '우엉잡채', '연두부', '마늘*새우젓', '핫도그', '찹쌀밥', '수제고기육전', '매운호박볶음', '사골떡국', '수박', '꽈배기도넛', '사과오이초무침', '양념치킨', '유채나물무침', '얼갈이생채', '유부장국', '쇠고기모듬장조림', '오렌지자몽샐러드', '짜글이돼지찌개', '목살구이', '카프레제샐러드', '치킨커틀렛', '삼겹살김치볶음', '상추쑥갓생채', '가지완자튀김', '단호박어묵탕수', '누룽지탕수육', '야채볶음밥', '닭살냉채', '소고기당면국', '유채나물', '만가닥버섯불고기', '소고기떡국', '청경채생채', '진미채오이무침', '부추무침', '과일샐러드', '김치국', '우묵콩국', '크리스마스케익', '콩비지찌개', '해물된장찌개', '홍합살미역국', '물미역초장', '청양된장찌개', '미소국', '마늘간장치킨', '콩나물잡채', '오이생채', '들깨시래기국', '매운쇠고기샤브샤브국', '탄두리치킨', '소세지구이', '펜네파스타샐러드', '골뱅이무침', '조기구이', '멸치아몬드볶음', '비엔나컬리플라워조림', '고추장누들떡볶이', '가자미유린기', '차조밥', '문어꽈리고추조림', '생선커틀렛', '오리고추장볶음', '돈육김치볶음', '뼈없는감자탕', '동그랑땡구이', '훈제오리구이', '김치찌개', '건새우호박채전', '과일요거트샐러드', '김말이강정', '세발나물생채', '새우튀김', '마늘종숙회', '맛살냉채', '햄피망볶음', '상추', '아몬드멸치볶음', '상추무침', '호박채나물볶음', '오삼불고기', '두부새싹구이', '감자볶음', '시금치나물', '호박잎찌개', '물미역', '양배추숙쌈', '유산슬', '모듬소시지볶음', '머위된장무침', '해물볶음우동', '부럼', '해물겨자냉채', '모듬버섯볶음', '검은깨올방개묵무침', '동그랑땡전', '깻잎찜', '매콤미니함박', '봄동달래무침', '굴미역국', '삼색콜리', '양잡피잡채', '견과류조림', '미역오이냉국', '모둠양채쌈', '돈육꽈리고추볶음', '호박꼬지', '간장깻잎지', '통들깨부추무침', '치즈닭갈비', '깻잎전', '딸기드레싱샐러드', '건취나물볶음', '비타민흑임자샐러드', '쫑상추무침', '허니순살치킨', '통감자오븐구이', '돌나물무침', '참치김치찌개', '소세지감자조림', '아귀순살찜', '비엔나컬리플라워볶음', '부추호박전', '베이비크랩강정', '삼색묵무침', '된장찌개', '쇠고기매운국', '오리고추장불고기', '오이사과무침', '동태알탕', '매운소고기무국', '토마토샐러드', '매운닭찜', '장각백숙', '오징어찌개', '돼지고기유자청볶음', '칠리새우', '김치고기전', '맑은계란국', '호박된장찌개', '호두견과류강정', '대구지리', '나가사끼짬뽕국', '맑은콩나물국', '등갈비김치말이', '미니케익', '흑미밥', '어묵국', '하와이언함박스테이크', '쌈다시마초장', '얼갈이된장무침', '모듬묵', '깻잎양념지', '부들어묵볶음', '취나물쌈장무침', '브로컬리무침', '장어구이', '돈육고추장불고기', '호박잎된장국', '이벤트행사', '오복지', '청경채', '무채국', '홍시', '돈수육', '물미역초고추장무침', '돈육두루치기', '치킨텐더샐러드', '떡국', '북어콩나물국', '명란계란말이', '포기김치', '해물동그랑땡채소볶음', '느타리버섯국', '물파래무침', '동태전', '브로콜리버섯볶음', '새우까스', '마카로니치즈범벅', '오프룻요거트', '언양식불고기', '버섯불고기', '왕갈비탕', '브로컬리맛살볶음', '더덕무침', '대파육개장', '시리얼', '모듬소세지구이', '토마토스파게티', '찐옥수수', '참나물', '아욱국', '레몬미역초무침', '감자범벅', '표고버섯탕수육', '봄나물비빔밥', '와사비무쌈', '배추된장국', '상추*쌈장', '케일*우렁쌈장', '오리훈제고추장볶음', '참나물두부무침', '고등어김치말이찜', '시저샐러드', '깐풍두부', '고추튀김', '콩비지김치찌개', '차돌된장찌개', '두부스테이크', '치커리유자청무침', '채소스틱', '오이지냉국', '동초나물무침', '꼬지어묵탕', '우동국', '모듬소세지버섯구이', '쫄면채소무침', '햄계란말이', '브로컬리두부무침', '사각어묵볶음', '목살데리야끼구이', '모듬야채쌈', '상추겉절이', '청포도', '양배추피클', '홍어미나리초무침', '오이맛살초무침', '냉족발야채무침', '나주곰탕', '매운소불고기', '시래기국', '하루나겉절이', '쇠고기느타리국', '사과오이냉국', '비엔나케찹조림', '오징어링', '순남시래기국', '무쌈', '치커리만다린무침', '두부까스', '고구마오븐구이', '도토리묵', '마늘쫑건새우볶음', '시금치국', '호박맑은국', '치즈계란말이', '계란후라이', '궁중떡볶이', '오이무초무침', '꽈리고추감자조림', '대구매운탕', '매콤소갈비찜', '마파두부덮밥', '대패삽겹숙주볶음', '하와이안샐러드', '청경채무침', '유부된장국', '보리밥', '보쌈김치', '장각허브오븐구이', '수제돈가스', '꽁치한마리레몬구이', '케일숙쌈*양념간장', '고구마순볶음', '연근땅콩조림', '열무된장국', '모듬묵양념장', '애기새송이버섯볶음', '크루통샐러드', '블랙페퍼쉬림프', '치커리유자생채', '고추장불고기', '묵은지닭찜', '쭈꾸미숙회무침', '유부주머니국', '오미자주스', '김치볶음밥', '간장두부조림', '얼갈이겉절이', '고구마고로케', '매운어묵국', '한방갈비탕', '과일그라탕', '대패삼겹', '순두부찌개', '꽁치한마리구이', '호박숙', '콩나물맛살냉채', '다시마쌈*씨앗쌈장', '꽈리고추찜', '영양부추생채', '들깨수제비', '표고돈육탕수', '해물파전', '소고기버섯볶음', '진미채무침', '시래기나물', '두반장가지볶음', '사과맛살초무침', '콩나물겨자채', '고등어카레구이', '수제찹쌀꿔바로우', '김치어묵탕', '적포도', '과일탕수육', '카레닭볶음', '나물비빔밥', '브로컬리', '콩가루배추된장국', '미니채소떡갈비', '유린기', '오이달래무침', '깻잎무쌈', '치킨핑거', '임연수무조림', '삼겹살수육', '다시마*초장', '짬뽕불고기', '레몬유린기', '잡채', '어묵꽈리고추조림', '명태조림', '열무보리비빔밥', '산채비빔밥', '스팸계란전', '닭다리바베큐오븐구이', '겉절이김치', '무피클', '돼지간장불고기', '오이스틱', '순대국밥', '간장돼지갈비찜', '청경채새송이볶음', '실곤약흑임자무침', '근대국', '멕시칸샐러드', '소고기브로컬리볶음', '콩나물김치국', '참나물생채무침', '타코야끼', '미역국', '알탕', '닭살카레라이스', '돈육간장불고기', '소고기잡채', '실곤약야채무침', '배도라지주스', '땅콩조림', '봄동된장무침', '브로컬리초장', '감자조림', '버블샐러드', '해초샐러드', '돈육김치찌개', '마늘치킨', '얼갈이된장국', '감자고구마샐러드', '명이절임', '와사비무쌈*쌈장', '모듬어묵볶음', '타꼬야끼', '통도라지고추장구이', '돈육도라지고추장볶음', '곰피초장', '낙지볶음', '주꾸미떡볶음', '단호박견과류구이', '돈갈비양념구이', '오복지무침', '목살스테이크', '순살닭강정', '짬뽕국', '열무된장나물', '주꾸미브로콜리숙회', '볼어묵굴소스볶음', '검정콩조림', '상추부추생채', '쭈꾸미삼겹살볶음', '오징어돈육볶음', '김밥볶음밥', '해물섞어찜', '쇠고기잡채', '맛살겨자초무침', '찰보리밥', '무채와사비무침', '궁중떡볶음', '두부계란구이', '콩나물파채불고기', '매운돼지갈비찜', '브로콜리땅콩소스무침', '오곡밥', '미니우동', '새우날치알볶음밥', '쫄면야채무침', '맛살떡샐러드', '메밀전', '소고기샤브국', '올갱이아욱국', '옥수수전', '돈육고추장볶음', '오이부추무침', '대패삼겹살볶음', '오이냉국', '만다린샐러드', '청', '풋마늘초무침', '두부', '참나물땅콩가루무침', '브로콜리쌈장무침', '바싹불고기', '가지찜', '목살찹스테이크', '청경채만다린생채', '해물순두부찌개', '탕수어', '조갯살무국', '비엔나볶음', '후르츠탕수육', '오지치즈후라이', '얼큰순두부찌개', '가자미조림', '닭살데리야끼조림', '계란장조림', '닭감자조림', '삼겹살고추장구이', '야채계란말이', '삼색만두채소무침', '생깻잎지', '비빔메밀국수', '양배추쌈', '쑥갓나물', '닭볶음', '두부오꼬노미야끼', '숙주나물무침', '물미역무침', '갈치감자조림', '얼갈이국', '모듬묵흑임자샐러드', '돈나물유자청무침', '꽈리고추어묵조림', '생선가스', '비엔나피망볶음', '황태포무침', '해물콩나물찜', '지중해샐러드', '시금치초생채', '비빔야채만두', '돈육간장볶음', '탕수만두', '불닭볶음', '초복특식', '멸치호두볶음', '자몽에이드', '씨리얼과일샐러드', '양념', '황태콩나물해장국', '고기듬뿍카레라이스', '순대볶음', '오꼬노미야끼계란말이', '달래두부무침', '수완왕갈비맛통닭', '꽃게찌개', '온두부', '비엔나감자볶음', '단호박카레라이스', '마파무조림', '매운쇠고기국', '눈꽃치즈샐러드', '떡갈비조림', '동그랑땡부침', '돼지갈비찜', '매운콩나물국', '실곤약무침', '참치야채샐러드', '햇고구마오븐구이', '호박새우젓볶음', '오이미역냉국', '아욱된장국', '동태찌개', '청경채찜', '황태양념구이', '김칫국', '닭찜', '닭데리야끼구이', '봄새싹비빔밥', '닭다리튀김', '통오이고추무침', '수제비국', '연어훈제샐러드', '분홍소시지전', '명태양념조림', '돈육장조림', '참치회덮밥', '우거지국', '오징어굴소스볶음', '솎음열무나물무침', '짜요짜요', '치킨텐더', '시금치부침개', '양파치킨', '삼치구이', '쇠고기단호박조림', '돼지고추장불고기', '실곤약냉채', '크란치바', '오이도라지생채', '크래미해초무침', '대구찌개', '매콤함박스테이크', '냉이국', '꽁치와사비구이', '미니짬뽕', '타워함박스테이크', '영양부추무침', '풋고추', '모듬튀김', '로스트치킨샐러드', '애호박전', '꿀호떡', '제육볶음', '달래무침', '단무지무침', '매생이전', '햄감자채볶음', '단호박계란찜', '콩나물국', '미역미소시루', '요거닭', '깻잎순무침', '콩나물두루치기', '꼬지삼색전', '콩나물볶음', '멸치크렌베리볶음', '오이사과생채', '버섯들깨찌개', '맛살겨자채', '데리야끼파닭', '도라지초무침', '쭈삼불고기', '꽃상추무침', '새싹두부구이', '고추잡채', '인절미', '감자채파프리카볶음', '두부커틀릿', '꼬들빼기김치', '참나물땅콩무침', '꽃맛살오리엔탈샐러드', '과일', '메밀부추전', '멸치볶음', '모닝샌드', '참나물무침', '고등어구이', '삼겹살더덕고추장구이', '들깨무채국', '해물김치전', '오이나물볶음', '장어고추장양념구이', '버섯메밀전', '소고기낙지볶음', '양상추샐러드', '냉이된장찌개', '잡곡밥', '신김치도토리묵', '연두부국', '닭가슴살냉채', '감자그라탕', '비빔메밀면', '치킨무', '쪽파국', '도토리묵냉국', '갈릭돈까스', '볼어묵볶음', '멸치국수', '버섯잡채', '곰취', '돈육칠리강정', '참나물상추겉절이', '삼치된장구이', '삼색유자청무침', '부추전', '맛살계란찜', '바지락살무국', '크레미계란말이', '대구지리탕', '요거트드링킹', '쌈추겉절이', '새송이버섯조림', '무나물', '감자수제비국', '곤약어묵볶음', '콩나물냉채', '황태미역국', '치커리무침', '돈육춘장볶음', '음료', '꼬막미나리초무침', '고추잎나물', '버섯영양밥', '셀프무쌈말이', '함박스테이크', '전주비빔밥', '소세지피망볶음', '임연수찜', '물만두', '꽁치김치말이', '새송이전', '비빔냉면', '베추겉절이', '매운소고기낙지볶음', '모둠쌈', '매운콩나물무침', '비트무생채', '레몬탕수육', '불고기비빔밥', '꽃맛살샐러드', '곤약메추리알조림', '동태무조림', '장각삼계탕', '장어강정', '조랭이떡국', '사과고구마그라탕', '렌틸콩밥', '순살깐풍기', '등갈비김치찜', '옥수수계란찜', '동태', '두부참치조림', '크래미숙주무침', '고구마함박스테이크', '브로컬리들깨찜', '찜닭', '가자미카레튀김', '씨앗쌈장', '가지볶음', '가래떡돼지갈비찜', '오이쑥갓생채', '돼지김치찌개', '열대과일', '모듬채소', '카레라이스', '불미나리무침', '냉메밀소바', '호박된장국', '오므라이스', '전주식콩나물해장국', '우무콩국', '깻잎쌈', '사각어묵무침', '베이컨감자볶음', '찰떡떡갈비조림', '오징어', '풋마늘대무침', '파채콩나물무침', '츄러스', '전복장각삼계탕', '츄러스채소맛탕', '버섯초장무침', '브로콜리깨소스무침', '건새우무국', '부추팽이겉절이', '솎음열무나물', '비빔밥', '갈치조림', '고추간장지', '돈육버섯고추장덮밥', '요거트푸딩', '콩나물맑은국', '황태맑은국', '치킨까스', '어묵꽈리볶음', '문어오이미역초무침', '오렌지', '옹심이만두국', '미소시루', '메추리알탕수', '머위대들깨볶음', '근대된장국', '쇠고기불고기', '해물굴소스볶음', '오징어숙회무침', '배추겉절이', '쑥된장국', '매운소고기국', '떡밤초', '녹두김치전', '봄동나물', '굴김치두부국', '들깨시락국', '고추', '인절미츄러스맛탕', '수수밥', '도라지오이생채', '가지나물', '시래기된장국', '청량된장찌개', '콘샐러드', '팽이장국', '도라지오이무침', '호박부추전', '쌈무', '파김치', '꼬시래기무초무침', '바베큐장각오븐구이', '콩나물파채', '쑥국', '치커리오이무침', '매콤어묵볶음', '해파리겨자채', '황도샐러드', '견과류멸치볶음', '미역장국', '주꾸미볶음', '가자미엿장구이', '물만둣국', '제첩두부국', '감자치즈구이', '고기전', '모듬소시지구이', '콘치즈오븐구이', '우무묵냉국', '오리양념불고기', '콘슬로우', '해물까스', '야채튀김', '숙주나물', '주꾸미세비체샐러드', '아귀콩나물찜', '오리불고기', '두부맛전', '오징어브로컬리숙회', '깻잎지', '골뱅이채소무침', '훈제오리고추장볶음', '육개장', '북엇국', '미니버거', '시금치고추장무침', '모히토과일샐러드', '봄동숙', '팽이무국', '콩샐러드', '골뱅이야채무침', '수제석박지', '호박잎된장찌개', '고구마치즈빵', '동태포전'}\n",
            "{'파스타샐러드', '계란', '오징어젓무침', '감자햄조림', '방어양념장구이', '라볶이', '메쉬드포테이토', '비빔국수', '수제돈까스', '춘권', '시금치나물무침', '오징어순대볶음', '참나물생채', '부추팽이무침', '사골옹심이만둣국', '소불고기', '건파래무침', '시리얼과일샐러드', '부추겉절이', '야채비빔만두', '두부김치국', '사과푸딩', '날치알볶음밥', '동그랑땡계란부침', '참치덮밥', '절인고추', '또띠아칩', '건새우아욱국', '미니함박조림', '새알만두국', '건새우아욱된장국', '미니팥칼국수', '쪽파무침', '김치어묵국', '풍기샐러드', '소고기장조림', '매운순대국밥', '갈치무조림', '참나물들깨무침', '물파래전', '차돌박이찌개', '상추파무침', '소세지볶음', '해물손수제비', '새우로제파스타', '매운사태조림', '간장마늘치킨', '삼치조림', '코코뱅', '꽁치허브구이', '모둠버섯구이', '두부된장찌개', '고구마치즈돈까스', '미역무침', '차돌박이된장찌개', '돈육계란장조림', '소고기불고기', '갈치양념조림', '나가사키면', '왕만두', '닭볶음탕', '열무김치국수', '나가사키짬뽕국', '배추김치', '생선까스', '사골우거지국', '파프리카해초무침', '미트볼채소볶음', '소고기콜라비조림', '녹두전', '동파육', '무초절이', '아삭고추된장무침', '닭오븐구이', '매운버섯국', '얼갈이열무겉절이', '스프', '연두부계란찜', '소시지오븐구이', '삼겹살볶음밥', '고구마그라탕', '갈비만두', '빠에야', '닭겨자냉채', '새싹피자', '쇠고기샤브국', '시금치초고추장무침', '올방개묵무침', '오이지무침', '동파삼겹수육', '오이무침', '콘치즈구이', '깐쇼새우', '감귤쥬스', '미니잔치국수', '피클', '무쌈깻잎', '김치참치주먹밥', '꽁채캔김치조림', '가지마파두부', '냉모밀국수', '등뼈묵은지찜', '물미역초무침', '짜장소스', '메추리알곤약조림', '두부매콤조림', '코다리강정', '깻잎양념찜', '시금치무침', '그린빈베이컨볶음', '멸치마늘종조림', '어묵매운탕', '우동장국', '감자양파국', '북어짬뽕국', '순대오징어볶음', '단호박달걀찜', '가자미찜', '통도라지구이', '맛살전', '돌나물유자청무침', '씨앗콩자반', '순대들깨볶음', '북어계란국', '푸딩', '감자채햄볶음', '고구마튀김', '비름나물', '쇠고기장조림', '야채전', '버섯육개장', '꼬시래기초무침', '브로컬리꽃맛살샐러드', '쇠불고기', '우불고기볶음', '날치알계란찜', '계란김밥', '어묵깻잎전', '루꼴라샐러드', '온메밀소바', '쇠고기무국', '옛날왕돈가스', '바게뜨', '유부초밥', '감자버터구이', '계란야채말이', '류산슬', '동태콩나물찜', '나가사끼짬뽕', '잔치국수', '요플레', '시금치프리타타', '콩나물냉국', '곤드레밥', '쪽파김무침', '닭간장조림', '수제어묵볶음', '수제보쌈김치', '카레덮밥', '옥수수샐러드', '동태매운탕', '수원왕갈비통닭', '도토리묵무침', '돈육잡채', '꽁치감자조림', '야채쫄면무침', '감자국', '우엉곤약조림', '옥수수맛살전', '백종원의', '하루나무침', '수제연근유자피클', '매생이굴국', '해물부추전', '고춧잎무침', '매운계란파국', '고등어김치말이', '돈채표고버섯볶음', '돈나물오리엔탈무침', '구이김', '두부카프레제샐러드', '수제오징어튀김', '쇠고기두부찜', '셀프충무김밥', '꼬지어묵국', '머위대나물', '닭윙강정튀김', '모둠소시지구이', '우삼겹부대찌개', '노각무침', '돈까스또띠아', '쌀밥', '유자청제육볶음', '초계국수', '물만두찜', '칠리미트볼조림', '계란말이', '김계란말이', '북어국', '오징어볶음', '미역줄기볶음', '훈제오리', '김말이튀김', '세발나물', '비엔나채소볶음', '새우미역초무침', '콘치즈', '콥샐러드', '수제맛쵸킹탕수육', '깍둑오이초무침', '무비트생채', '오이초무침', '새송이버섯장조림', '마늘쫑건새우', '오징어튀김', '망고주스', '낙지덮밥', '비트채소절임', '김치우동', '열무물국수', '양상추', '낙지비빔밥', '황태국', '모듬양채쌈', '계란파국', '과일플레인샐러드', '생파김치', '봄동겉절이', '양상추메추리알샐러드', '홍어채무침', '비엔나케찹볶음', '돈까스김치나베', '설렁탕', '오징어떡볶음', '감자전', '꼬들단무지무침', '갓김치', '취나물된장볶음', '콩나물파채무침', '돈육피망볶음', '어묵잡채', '임연수구이', '깐풍육', '멘보샤', '매실주스', '미트볼조림', '채소쌈', '김치볶음', '오이피클', '알리오올리오', '근대나물무침', '굴비구이', '맑은국', '들깨미역국', '어묵볶음', '짜장밥', '버섯탕수', '수제피클', '쇠고기탕수', '코다리조림', '도토리묵야채무침', '꼬막채소무침', '들깨버섯국', '돈육씨앗강정', '카레감자채볶음', '후리가케덮밥', '오이지', '비트무절임', '올챙이만두국', '단호박범벅', '샤워크림새우', '단무지채무침', '비빔만두', '해물칼국수', '자장소스', '스팸계란말이', '비빔칼국수', '잡채밥', '고추장찌개', '아삭고추무침', '볼어묵조림', '새알미역국', '홍시드레싱샐러드', '대구탕', '나초콥샐러드', '마늘쫑무침', '베이컨볶음밥', '스팸주먹밥', '삼치양념구이', '군고구마', '김치국수', '중국식볶음밥', '고구마연근맛탕', '해물동그랑땡', '돈육간장강정', '열무김치', '순대야채볶음', '양파절임', '어묵곤약볶음', '섭산적데리야끼조림', '치커리유자무침', '자반고등어찜', '달래된장국', '매운사태찜', '칼국수', '무말랭이', '마파두부', '춘장돈육볶음', '배추국', '오꼬노미야끼', '오이양배추피클', '모듬묵샐러드', '춘천닭갈비', '참나물초장무침', '단무지', '깍두기', '닭가슴살장조림', '새우또띠아', '폭탄주먹밥', '삼치데리야끼', '탕수육', '단무지양념무침', '알리오올리오파스타', '소고기숙주볶음', '호박채나물', '김자반볶음', '꽃맛살볶음', '미역초무침', '카레찜닭', '코다리양념조림', '수수부꾸미', '순대찜', '귤', '오이맛살무침', '상추쌈', '새송이버섯볶음', '김구이', '해물순두부국', '얼갈이나물', '매쉬드포테이토', '모자반무침', '깨찰빵', '수제무말랭이무침', '훈제오리불고기', '쇠고기낙지볶음', '계란찜', '작은밥', '콩나물밥', '마늘바게트', '근대두부된장국', '구운채소', '꽁치오븐구이', '닭불고기', '스팸', '고추장멸치볶음', '투움바스파게티', '청양콩나물국', '양념갈비찜', '브로콜리숙회', '모둠장조림', '오이쑥갓겉절이', '콩조림', '납작군만두', '다슬기아욱국', '치킨까스김치나베', '돌나물', '미니쌀국수', '들깨버섯무침', '가자미양념찜', '반반치킨', '홍합탕', '훈제오리냉채', '취나물볶음', '참치야채비빔밥', '부추오리엔탈무침', '맛탕', '감자튀김', '매운감자조림', '브로컬리새우전', '연근깨소스무침', '명엽채볶음', '돈육두릅장조림', '어묵잡채볶음', '청양해물파전', '짬뽕', '간장치킨', '우육비빔냉면', '오이무피클', '아이스슈', '꽃게탕', '간장불고기', '콩가루배추국', '무생채', '새송이너비아니구이', '베이컨김치볶음밥', '고구마치즈구이', '무청된장국', '부대찌개', '옥수수스프', '또띠아피자', '쇠미역쌈', '매운등뼈조림', '양장피잡채', '동태탕', '꽈리고추찹쌀무침', '백김치', '등심돈까스', '얼큰동태탕', '오징어브로컬리', '청국장찌개', '왕만두찜', '한식잡채', '해물전', '개성감자만두', '돼지국밥', '스팸김치찌개', '무우짱아찌', '파래김', '건파래볶음', '쑥갓무침', '감자간장조림', '사과오이무침', '얼갈이쌈장무침', '가자미튀김', '건새우마늘쫑볶음', '팽이버섯국', '무초절임', '열무나물', '짬뽕수제비', '애호박새우젓볶음', '식혜', '크랜베리멸치볶음', '섭산적고추장구이', '차돌비빔국수', '참치주먹밥', '훈제오리떡볶음', '오리훈제마늘볶음', '돈육굴소스볶음', '주꾸미초무침', '잔멸치볶음', '홍합미역국', '가지된장무침', '해물누룽지탕', '새우살볶음밥', '콩나물무침', '야채스틱', '천도복숭아', '톳두부무침', '브로콜리', '시금치초장무침', '생선커틀릿', '오리훈제볶음밥', '날＞', '코다리엿장조림', '치커리사과생채', '소고기무국', '생야채', '순대채소볶음', '어묵피망볶음', '주스', '감자만두', '야채부케', '자반고등어구이', '도라지오이초무침', '해초무침', '사천식탕수육', '김치수제비국', '민물새우찌개', '열무비빔국수', '부추생채', '간장찜닭', '비엔나감자조림', '감자비엔나볶음', '늙은호박전', '참치야채전', '완두콩스프', '베리베리퐁당요플레', '배', '해물짬뽕', '무말랭이무침', '쫄면무침', '짜장덮밥', '산고추지무침', '참나물겉절이', '파닭', '연두부탕', '애호박새우젓나물', '두부계란전', '해물짬뽕국', '군만두', '스태프핫도그', '쇠고기청경채볶음', '매실쥬스', '청경채사과무침', '매운족발볶음', '카레돈까스정식', '당면계란만두', '조갯살아욱국', '알타리김치', '빌소세지구이', '비트무피클', '청양멸치주먹밥', '감자프리타타', '땅콩멸치조림', '양파장아찌', '장국', '오렌지주스', '칠리베이비크랩', '세발나물무침', '시금치샐러드', '미소장국', '부추만두', '양파', '두부고기조림', '오이미역무침', '방울토마토', '짜장면', '묵은지닭볶음탕', '치커리생채', '양념깻잎지', '매운어묵볶음', '시금치흑임자샐러드', '돈갈비찜', '쇠고기모둠장조림', '옛날돈까스', '시래기들개탕', '통마늘너비아니조림', '김치말이국수', '미역레몬초무침', '양념고추지무침', '부추팽이버섯생채무침', '쫄면', '돈육꽈리고추장조림', '단호박두부탕수', '바베큐함박찹스테이크', '채소볶음우동', '애호박새우젓국', '훈제오리볶음', '삼치양념찜', '쨔샤이무침', '소고기매운무국', '우엉조림', '새우살호박볶음', '뉴욕핫도그', '사과주스', '두부구이', '열무나물무침', '미니돈까스', '딸기생크림와플', '떡만두국', '치즈계란찜', '참치김치볶음', '청포도피클', '닭개장', '삼치엿장구이', '유부채소겨자냉채', '꽈리고추어묵볶음', '스팸볶음밥', '사과', '가쓰오장국', '숙주미나리나물', '냉이된장국', '불고기필라프', '당면채소무침', '해물떡볶이', '닭살겨자냉채', '상추초무침', '봄동무침', '돈육볶음', '또띠아견과칩', '미트볼파스타', '모둠묵', '유산슬덮밥', '쇠고기숙주볶음', '실곤약초무침', '오징어초무침', '닭살겨자채', '어묵무침', '버섯맛살볶음', '가쯔오국', '쑥갓두부무침', '짜장잡채덮밥', '모둠버섯볶음', '청경채나물', '닭갈비', '메추리알조림', '팝콘치킨', '새우만두', '퀘사디아', '콩나물불고기', '느타리버섯볶음', '연근샐러드', '쑥갓겉절이', '사과오이생채', '맑은장국', '햄감자볶음', '소고기미역국', '통새우김밥', '순살닭갈비', '모둠채소무침', '마늘쫑메추리알조림', '야채샐러드', '파인애플볶음밥', '시금치초무침', '미트볼떡조림', '감자소세지볶음', '해물누룽지', '돼지고기장조림', '탕평채', '숯불양념꼬치어묵', '취나물', '꽈배기도너츠', '토마토', '찹쌀도너츠', '유채나물된장무침', '마늘쫑볶음', '꼬들단무지', '미니국수', '풋고추튀김', '시래기조림', '소고기된장찌개', '도토리묵채소무침', '도라지무침', '돈삼겹보쌈', '고구마맛탕', '소고기퀘사디아', '버섯햄볶음', '삼겹보쌈', '볶음쌀국수', '쇠고기국', '두부조림', '양파*쌈장', '취나물무침', '소고기계란장조림', '콩자반', '모듬소세지볶음', '삼겹살구이', '무쌈말이', '석박지', '옛날돈가스', '맑은버섯닭개장', '고추지무침', '겨울초겉절이', '모듬어묵탕', '새우볶음밥', '코코넛새우튀김', '해물수제비', '유자청돈육볶음', '모듬버섯탕수육', '꽁치구이', '실곤약채소무침', '오이볶음', '포도주스', '바나나와플', '취나물된장무침', '우거지해장국', '해물짜장면', '도라지나물', '쌈만두', '비트피클', '단배추나물', '닭데리야끼조림', '물만두국', '쭈꾸미볶음', '깐풍기', '오이양파무침', '모듬소세지', '메밀전병만두', '고구마순나물', '오렌지쥬스', '청경채김치', '소떡소떡', '쇠고기퀘사디아', '숙주미나리무침', '건도토리묵파프리카볶음', '새송이버섯전', '연유꽃빵튀김', '고구마범벅', '봄동된장국', '쇠고기들깨소스무침', '두부양념조림', '깻순나물', '떡볶이', '찹쌀순대볶음', '오이소박이', '오징어무침', '감자채카레볶음', '가자미구이', '김가루잔파무침', '미니쫄우동', '시래기지짐', '닭가슴살겨자무침', '꼬막찜', '갈치구이', '오징어국', '돈가스또띠아', '단호박', '구슬떡볶이', '미트볼케찹조림', '만두찜', '샐러드파스타', '볶음밥', '깐풍연근', '볼어묵곤약볶음', '모짜렐라핫도그', '새송이고추장구이', '매운돈갈비찜', '연근', '찐감자', '치커리사과무침', '북어해장국', '봄동쌈', '돈육청경채볶음', '돈육강정', '햄볶음밥', '청경채겉절이', '호박젓국찌개', '달래된장찌개', '닭매운찜', '낙지젓무침', '바나나', '크림새우', '해물청경채볶음', '주꾸미굴소스볶음', '해라피겨자채', '고등어조림', '옛날왕돈까스', '오이맛살냉채', '고르곤졸라피자', '감자채볶음', '우동', '조갯살미역국', '옹심이만둣국', '오꼬노미계란말이', '삼색귤소스무침', '김치주먹밥', '애호박나물', '꼬시래기무침', '고등어김치찜', '김치두부국', '양배추샐러드', '돈육모듬장조림', '단호박스프', '시금치된장국', '닭강정', '연근튀김', '들깨버섯탕', '두부부침', '옹심이국', '크래미오이보트샐러드', '조랭이떡미역국', '치즈함박스테이크', '안동찜닭', '머위순나물', '알배기', '비빔채소만두', '모듬쌈', '계발의', '감자채전', '크림스프', '소고기매운국', '닭곰탕', '호박나물', '김자반', '요구르트', '호박잎된장찌개', '케이준치킨샐러드', '물냉면', '오징어야채무침', '메밀비빔국수', '마제소바', '도라지생채', '방풍나물', '감자고추장찌개', '야채계란찜', '쇠고기미역국', '매운닭개장', '유부주머니된장국', '허니슈스트링감자', '쫄면비빔만두', '락교', '어묵꽈리고추볶음', '장아찌', '수제등심찹쌀꿔바로우', '멸치주먹밥', '가지무침', '만둣국', '오이도라지무침', '오징어무국', '가지탕수', '가쯔오장국', '흑임자샐러드', '하루야채주스', '시래기들깨탕', '연근조림', '뼈감자탕', '매콤시래기된장지짐', '갈치튀김', '꽁치김치찜', '삼치데리야끼구이', '열무김치볶음', '세발나물오리엔탈무침', '해파리냉채', '상추부추무침', '풋고추양파무침', '목살필라프', '달래새우전', '케일숙쌈*쌈장', '숙주나물당근무침', '순두부백탕', '햄전', '계란국', '궁중떡찜', '옥수수볼맛탕', '두부계란부침', '치킨샐러드', '수제미니햄버거', '감자치즈오븐구이', '단호박팥찜', '상추치커리무침', '재래김', '청포묵무침', '김치콩나물국', '코다리무조림', '버섯들깨탕', '토마토계란찜', '브로컬리오징어숙회', '수제치킨까스', '감자샐러드', '매운순대국', '토란탕', '미니함박', '돈까스김밥', '우거지된장국', '오징어땅콩조림', '슈크림', '임연수엿장조림', '꽁치양파조림', '찐햇감자', '얼큰감자국', '김치전', '김치필라프', '두부카프레제', '만두국', '꽃삼겹김치찜', '추가밥', '순살파닭', '연두부', '우엉잡채', '핫도그', '깻잎고기전', '찹쌀밥', '수제고기육전', '수박', '돌나물오이무침', '양념치킨', '유채나물무침', '미나리전', '팽이가쯔오장국', '얼갈이생채', '유부장국', '메추리알꽈리고추조림', '오징어어묵무침', '유부우동', '주꾸미무침', '토마토설탕절인', '수제고로케', '가자미양념조림', '누룽지탕수육', '야채볶음밥', '닭살냉채', '유채나물', '연두부찌개', '만가닥버섯불고기', '청경채생채', '진미채오이무침', '부추무침', '과일샐러드', '김치국', '콩비지찌개', '해물된장찌개', '마늘간장치킨', '오이생채', '들깨시래기국', '탄두리치킨', '채소튀김', '꼬치어묵떡볶이', '참치샐러드', '골뱅이무침', '호박반달나물', '수제핫도그', '조기구이', '멸치아몬드볶음', '생선초밥', '왕새우튀김', '가자미유린기', '닭칼국수', '만두', '무채맑은국', '고갈비구이', '치커리단감무침', '옥수수콘치즈', '만두튀김', '뼈없는감자탕', '돈육김치볶음', '김치찌개', '훈제오리구이', '건새우호박채전', '김말이강정', '해물볶음밥', '과일요거트샐러드', '새우튀김', '미소된장국', '해물볶음', '맛살냉채', '상추', '부추오이생채', '아몬드멸치볶음', '상추무침', '오삼불고기', '두부새싹구이', '열대과일샐러드', '미더덕콩나물찜', '시금치나물', '호박잎찌개', '유산슬', '삼선짬뽕국', '머위된장무침', '해물볶음우동', '해물겨자냉채', '봄나물튀김', '다시마채무초무침', '동그랑땡전', '삼겹살야채비빔면', '깻잎찜', '아오리사과', '굴미역국', '매콤호박볶음', '견과류조림', '간장깻잎지', '치즈닭갈비', '깻잎전', '딸기드레싱샐러드', '비타민흑임자샐러드', '꼬지어묵우동', '쫑상추무침', '목살김치찌개', '물만두탕수', '손수제비국', '참치김치찌개', '감자만두국', '매콤돈육메추리알장조림', '비엔나컬리플라워볶음', '부추호박전', '춘전닭갈비', '팽이버섯장국', '된장찌개', '쇠고기매운국', '연근흑임자샐러드', '포도', '닭갈비볶음밥', '오이사과무침', '동태알탕', '매운소고기무국', '브로컬리초회', '매운닭찜', '무채유자무침', '장각닭죽', '김치고기전', '갈치카레구이', '홍합짬뽕국', '얼갈이나물된장무침', '대구지리', '나가사끼짬뽕국', '수제마늘바게트', '갈릭파닭', '맑은콩나물국', '흑미밥', '청포묵야채무침', '어묵국', '굴소스해물볶음밥', '얼갈이된장무침', '메추리알장조림', '모듬묵', '황태무채국', '내사랑포도', '부들어묵볶음', '돈육고추장찌개', '돈육고추장불고기', '해초레몬무침', '오복지', '무채국', '고들빼기무침', '돈수육', '주먹밥', '굴소스파인볶음밥', '돈육두루치기', '국물떡볶이', '노가리고추조림', '떡국', '등심찹쌀꿔바로우', '과일주스', '채소라면', '포기김치', '느타리버섯국', '물파래무침', '동태전', '섬초무침', '새우까스', '마카로니치즈범벅', '등갈비오븐구이', '삼치튀김', '언양식불고기', '버섯불고기', '쫑상추새콤무침', '토마토시금치달걀볶음', '해물동그랑땡전', '브로컬리맛살볶음', '더덕무침', '토마토스파게티', '모듬소세지구이', '치커리깨소스무침', '찐옥수수', '샐러리샐러드', '참나물', '짬뽕순두부찌개', '쇠고기덮밥', '아욱국', '복주머니딤섬', '어묵우동', '감자범벅', '푸실리샐러드', '표고버섯탕수육', '배추된장국', '시저샐러드', '단호박조림', '고추튀김', '차돌된장찌개', '두부스테이크', '콩나물간장볶음', '김치미나리전', '치커리유자청무침', '채소스틱', '꼬지어묵탕', '황태국수', '양송이스프', '쫄면채소무침', '애플카레라이스', '햄계란말이', '허니버터옥수수', '상추겉절이', '청포도', '밀떡볶이', '양배추피클', '오이맛살초무침', '명란계란찜', '자기개발의날', '숯불양념꼬지어묵', '매운소불고기', '등뼈김치찜', '짜사이볶음', '시래기국', '사과오이냉국', '전주식콩나물국', '무쌈', '고구마오븐구이', '도토리묵', '짬뽕수제비국', '마늘쫑건새우볶음', '주꾸미채소볶음', '시금치국', '치즈계란말이', '계란후라이', '오뗄햄김밥', '궁중떡볶이', '취나물땅콩무침', '대구매운탕', '느타리호박볶음', '마파두부덮밥', '하와이안샐러드', '청경채무침', '유부된장국', '쇠고기볶음밥', '수제돈가스', '해쉬포테이토', '나박물김치', '돈육가지두반장볶음', '고구마순볶음', '＜자기', '연근땅콩조림', '열무된장국', '맑은연두부탕', '크랜베리단호박샐러드', '쇠고기우엉볶음', '멸치견과류볶음', '고추장불고기', '묵은지닭찜', '도넛츠', '유부주머니국', '후난식볶음밥', '김치볶음밥', '얼갈이겉절이', '닭봉오븐구이', '매운어묵국', '대패삼겹', '계란떡볶이', '꿔바로우탕수육', '순두부찌개', '꽁치한마리구이', '부추생채무침', '꽈리고추찜', '고추,양파', '영양부추생채', '소고기메추리알장조림', '김치순두부찌개', '해물파전', '카레홍합찜', '소고기버섯볶음', '진미채무침', '쑥갓생무침', '돈육고구마강정', '감자카레볶음', '두반장가지볶음', '사과맛살초무침', '콩나물겨자채', '고등어카레구이', '수제찹쌀꿔바로우', '김치어묵탕', '케찹', '고구마떡볶이', '과일탕수육', '브로컬리', '키위그린샐러드', '미니채소떡갈비', '유린기', '야채쫄면', '오이달래무침', '팽이버섯채소전', '단배추겉절이', '치킨핑거', '오징어불고기', '단감치커리무침', '짬뽕불고기', '사천탕수육', '컵라면', '잡채', '블루베리드레싱샐러드', '명태조림', '산채비빔밥', '겉절이김치', '무피클', '제육춘장볶음', '실곤약흑임자무침', '근대국', '멕시칸샐러드', '콩나물김치국', '맑은버섯국', '참나물생채무침', '버섯들깨나물', '타코야끼', '미역국', '언양식바싹불고기', '교자만두', '뼈해장국', '알탕', '돈육간장불고기', '실곤약야채무침', '땅콩조림', '가래떡오븐구이', '딸기와플', '브로컬리초장', '낙지미나리볶음', '돈육김치찌개', '마늘치킨', '얼갈이된장국', '타꼬야끼', '숙주고기짬뽕', '낙지볶음', '주꾸미떡볶음', '수제칠리핫도그', '냉이김칫국', '오복지무침', '치커리귤무침', '목살스테이크', '순살닭강정', '짬뽕국', '열무된장나물', '검정콩조림', '떡갈비주먹밥', '김밥볶음밥', '짜장잡채밥', '양파초절임', '주꾸미삼겹살볶음', '궁중떡볶음', '두부계란구이', '쇠고기가지조림', '콩국수', '모둠채소전', '매운돼지갈비찜', '쇠고기야채볶음', '그린요거트샐러드', '쌈장', '미니우동', '바지락살국', '회오리감자', '미니김밥', '쫄면야채무침', '흑임자곤약샐러드', '메밀전', '찐만두', '아쿠아돈까스', '올갱이아욱국', '고등어양념구이', '옥수수전', '돈육고추장볶음', '바지락수제비', '미나리숙주나물', '스파게티', '참치파개장', '도라지채무침', '풋마늘초무침', '숙주미나리잡채', '김치녹두전', '두부', '녹두빈대떡', '비엔나감자구이', '참나물땅콩가루무침', '등갈비바베큐조림', '모둠튀김', '애플망고두유', '매운떡볶이', '쇠고기규동덮밥', '해물순두부찌개', '탕수어', '비엔나볶음', '후르츠탕수육', '얼큰순두부찌개', '마늘빵', '김말이', '소고기주먹밥', '모둠버섯초무침', '계란장조림', '두부찜', '생깻잎지', '비빔메밀국수', '양배추쌈', '로제스파게티', '쑥갓나물', '양념고추지', '닭볶음', '부채살오므라이스', '두부오꼬노미야끼', '꼬마김밥', '얼갈이국', '닭카레볶음', '꽈리고추어묵조림', '양배추비트피클', '자몽샐러드', '생선가스', '등갈비묵은지찜', '수제두부동그랑땡', '베이컨숙주볶음', '콩나물굴소스볶음', '비빔야채만두', '돈육간장볶음', '매운오징어국', '메추리알풋고추조림', '탕수만두', '유부우동국물', '멸치호두볶음', '너비아니', '브로컬리크림스프', '호박새우젓국', '씨리얼과일샐러드', '두부양념찜', '오징어채소볶음', '고추잡채덮밥', '짜샤이볶음', '순대볶음', '오꼬노미야끼계란말이', '파채*소스', '온두부', '채소계란찜', '비엔나감자볶음', '고구마까스', '고구마샐러드', '로제파스타', '팽이버섯부추무침', '섭산적표고굴소스볶음', '온모밀국수', '단호박카레라이스', '매운쇠고기국', '마늘쫑장아찌', '두부미소된장국', '떡갈비조림', '돼지갈비찜', '매운콩나물국', '볶음우동', '옛날소시지전', '떡꼬지', '동태찌개', '청경채찜', '망고드레싱샐러드', '황태양념구이', '김칫국', '닭데리야끼구이', '근대고추장무침', '건새우무나물', '비프스파게티', '새우튀김우동', '수제비국', '버섯매운국', '통새우또띠아', '돈육장조림', '참치회덮밥', '스틱단무지', '우거지국', '황태해장국', '오징어굴소스볶음', '꼬치어묵매운탕', '치킨텐더', '양파치킨', '간장계란장', '삼치구이', '오이도라지생채', '대구찌개', '냉이국', '미니짬뽕', '타워함박스테이크', '돈사태떡찜', '피크닉', '미나리무침', '영양부추무침', '굴소스볶음밥', '풋고추', '모듬튀김', '해물우동볶음', '치킨퀘사디야', '백종원의사라다빵', '제육볶음', '단무지무침', '매생이전', '달래오이생채', '딤섬', '치커리배생채', '햄감자채볶음', '단호박계란찜', '콩나물국', '조각사과', '우불고기', '콩나물볶음', '메추리알치즈떡볶이', '오이사과생채', '돈채호박볶음', '통배추겉절이', '땡초주먹밥', '데리야끼파닭', '쇠고기육전', '도라지초무침', '마늘종멸치볶음', '양배추숙', '꼬치어묵탕', '고기짬뽕국', '시래기삼치조림', '꽃상추무침', '새싹두부구이', '감자찌개', '무나물들깨볶음', '고추잡채', '감자채파프리카볶음', '두부커틀릿', '참나물땅콩무침', '두반장가지나물', '과일', '멸치볶음', '해물가스', '오이보트샐러드', '참나물무침', '옥수수맛탕', '고등어구이', '콤비네이션피자', '들깨무채국', '해물김치전', '오이나물볶음', '비빔만두채소무침', '쇠고기숙주규동덮밥', '버섯메밀전', '소고기낙지볶음', '양상추샐러드', '냉이된장찌개', '까르보나라떡볶이', '하와이안필라프', '잡곡밥', '신김치도토리묵', '닭가슴살냉채', '홍합무우국', '닭살채소굴소스볶음', '쭈꾸미불고기', '닭간장볶음', '치킨무', '도토리묵냉국', '버섯잡채', '마파두부소스', '돈육칠리강정', '아귀매운탕', '삼치된장구이', '고구마순들깨볶음', '부추전', '쌀국수', '미니햄버거', '채소볶음밥', '새송이버섯조림', '무나물', '샐러드김밥', '콩나물냉채', '황태미역국', '치커리무침', '유부주머니우동국', '음료', '호빵', '흑임자시금치샐러드', '모둠묵샐러드', '사과양상추샐러드', '버섯영양밥', '채소피클', '함박스테이크', '셀프무쌈말이', '치즈시즈닝치킨', '임연수찜', '꽁치김치말이', '케이준샐러드', '고추짜장', '묵은지삼겹살찜', '감자양념조림', '매운콩나물무침', '비트무생채', '파인애플주스', '레몬탕수육', '미나리나물무침', '꽃맛살샐러드', '장어강정', '대패삼겹숙주볶음', '우동국물', '샐러드', '볼어묵고추장볶음', '메추리알곤약장조림', '순살깐풍기', '미트볼피망볶음', '해물굴소스볶음밥', '등갈비김치찜', '소고기모듬장조림', '미니떡갈비조림', '해초배무침', '꽁보리밥', '옥수수계란찜', '제육김치덮밥', '김밥', '찜닭', '가자미카레튀김', '컵주스', '미역줄기', '수제오이피클', '펜네베이컨샐러드', '카레라이스', '냉메밀소바', '오므라이스', '쌈추전', '깻잎쌈', '찰떡떡갈비조림', '오징어젓갈무침', '오징어', '참치마요덮밥', '풋마늘대무침', '츄러스', '햄맛살볶음', '계란볶음밥', '꽃빵튀김', '돌나물초장', '포테이토오븐구이', '옥수수감자범벅', '얼큰소고기무국', '부추팽이겉절이', '브로콜리깨소스무침', '배추흑임자무침', '솎음열무나물', '비빔밥', '물파래초무침', '갈치조림', '햄치즈또띠아', '김주먹밥', '모둠과일', '참외', '동그랑땡강정', '로제찜닭', '짜사이채무침', '치킨까스', '오렌지', '옹심이만두국', '미소시루', '근대된장국', '오징어숙회무침', '배추겉절이', '크림카레우동', '쑥된장국', '웨지감자', '옹심이감자국', '모듬떡볶이', '매운소고기국', '목살간장조림', '제육간장불고기', '매운감자국', '마늘베이컨볶음밥', '적어양념구이', '메밀국수', '가정의날', '도라지오이생채', '가지나물', '고사리볶음', '비엔나야채볶음', '콘샐러드', '팽이장국', '도라지오이무침', '호박부추전', '쌈무', '사과청경채무침', '페퍼로니치즈피자', '파김치', '조각티라미수', '바지락된장찌개', '짠지오이무침', '자기계발의날', '매콤어묵볶음', '해파리겨자채', '베이컨계란말이', '주꾸미볶음', '미역장국', '오이선', '가자미엿장구이', '물만둣국', '삼겹살마늘볶음밥', '감자치즈구이', '고기전', '충무김밥', '모듬소시지구이', '콘치즈오븐구이', '마늘바게뜨', '더덕고추장불고기', '머위대초무침', '낙지볶음덮밥', '콘슬로우', '해물까스', '사골파국', '고등어자반찜', '야채튀김', '잡채말이어묵국', '숙주나물', '아귀콩나물찜', '컬리플라워샐러드', '통고추쌈장무침', '날치알김치볶음밥', '오리불고기', '김치두루치기', '깻잎지', '골뱅이채소무침', '진미채무말랭이무침', '돈육매콤조림', '꼬치어묵국', '육개장', '미니버거', '키위드레싱샐러드', '우거지탕', '미니야채떡갈비', '야채주먹밥', '모닝빵', '몽골식돈육볶음', '생과일플레인샐러드', '돈까스', '치킨마요덮밥', '삼계국밥', '동태포전'}\n",
            "805 1590 1580\n",
            "228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9BsdF2eTFf4"
      },
      "source": [
        "## 자주 나오는 메뉴 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj7_EReTyz1C"
      },
      "source": [
        "def tfidf_transform(list, set):\n",
        "    word2id = defaultdict(lambda: 0) # 메뉴 이름 담을 딕셔너리\n",
        "    list_contents = [] # 리스트로 저장된 식단을 코퍼스 단위로 바꿔 저장하는 리스트\n",
        "    list_transformed = [] # tfidf 변환된 값을 저장하는 리스트\n",
        "    emb = TfidfVectorizer(vocabulary=set, lowercase=False)\n",
        "    for row in list:\n",
        "        list_contents.append(' '.join(row)) # 코퍼스 단위로 변환\n",
        "    emb_list = emb.fit_transform(list_contents) # tfidf 변환\n",
        "    for idx, feature in enumerate(emb.get_feature_names()):\n",
        "        word2id[feature] = idx # 딕셔너리에 메뉴 이름 저장\n",
        "    for i, sent in enumerate(list_contents):\n",
        "        list_transformed.append([(token, emb_list[i, word2id[token]])for token in sent.split()])\n",
        "\n",
        "            \n",
        "    return list_transformed\n",
        "\n",
        "breakfast_tfidf = tfidf_transform(breakfast_list, breakfast_set)\n",
        "lunch_tfidf = tfidf_transform(lunch_list, lunch_set)\n",
        "dinner_tfidf = tfidf_transform(dinner_list, dinner_set)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERR-GViJ88Ro",
        "outputId": "fa764527-5106-497c-e897-a8a5a7dc298e"
      },
      "source": [
        "THRESHOLD = 0.20 ### threshold보다 값이 작으면 제거\n",
        "def delete_menu(THRESHOLD, list):\n",
        "    useless = []\n",
        "    for i, d in enumerate(list):\n",
        "        for idx, m in enumerate(d):\n",
        "            if m[1] < THRESHOLD:\n",
        "                useless.append(m[0])\n",
        "    return set(useless)\n",
        "# 제거 대상\n",
        "brkfst_del = list(delete_menu(THRESHOLD, breakfast_tfidf))\n",
        "lunch_del = list(delete_menu(THRESHOLD, lunch_tfidf))\n",
        "dinner_del = list(delete_menu(THRESHOLD, dinner_tfidf))\n",
        "print(brkfst_del)\n",
        "print(lunch_del)\n",
        "print(dinner_del)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['흑미밥', '쌀밥', '우유', '와플&생크림', '스크램블에그', '모닝롤', '양상추샐러드', '누룽지탕', '포기김치', '계란후라이', '주스']\n",
            "['귤', '흑미밥', '배추겉절이', '깻잎*쌈장', '양상추샐러드', '케일숙쌈*양념간장', '상추*쌈장', '잡곡밥', '케일*우렁쌈장', '쌀밥', '다시마쌈*씨앗쌈장', '와사비무쌈*쌈장', '양상추*쌈장', '그린샐러드*오렌지드레싱', '고추*쌈장', '생강채*쌈장', '찰현미밥', '쌈', '새송이*가지구이', '쑥갓쌈&쌈장', '버섯숙회*초장', '다시마*초장', '채소스틱&쌈장', '그린샐러드*키위D', '마늘*새우젓', '명이나물-장아찌', '청', '포기김치']\n",
            "['귤', '흑미밥', '쌀밥', '＜자기', '날＞', '고추,양파', '배', '케일숙쌈*쌈장', '양파*쌈장', '파채*소스', '잡곡밥', '포기김치']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41SbxjzbJJkE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2be43890-60fc-497c-faa3-e18bc99f23ce"
      },
      "source": [
        "for i in [brkfst_del, lunch_del, dinner_del]:\n",
        "    print(len(i))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "11\n",
            "28\n",
            "12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ek0FvBHv0hPy",
        "outputId": "4d6cb7e2-fd34-463b-984f-8d2a7c259fe9"
      },
      "source": [
        "dinner_list[204]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOmZCqSbY4HG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ceaa4298-dc0a-46f3-d664-0096888dcbb9"
      },
      "source": [
        "for i in range(5):\n",
        "    print(breakfast_list[i])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['우유', '쌀밥', '두유', '쥐어채무침', '찐빵', '포기김치', '호두죽', '계란후라이', '주스', '모닝롤', '된장찌개']\n",
            "['시래기조림', '우유', '쌀밥', '팥죽', '두유', '단호박샌드', '포기김치', '호박젓국찌개', '계란후라이', '주스', '모닝롤']\n",
            "['표고버섯죽', '베이글', '우유', '쌀밥', '두유', '느타리호박볶음', '포기김치', '계란후라이', '주스', '모닝롤', '콩나물국']\n",
            "['우유', '쌀밥', '토마토샌드', '닭죽', '근대국', '두유', '멸치볶음', '포기김치', '계란후라이', '주스', '모닝롤']\n",
            "['우유', '쇠고기죽', '쌀밥', '두유', '방풍나물', '와플', '재첩국', '포기김치', '계란후라이', '주스', '모닝롤']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3hqu1HVR9rb",
        "outputId": "2c9af9d6-7c13-49bf-dac0-aacfb96997ba"
      },
      "source": [
        "del_col = [brkfst_del, lunch_del, dinner_del]\n",
        "B = deepcopy(breakfast_list)\n",
        "L = deepcopy(lunch_list)\n",
        "D = deepcopy(dinner_list)\n",
        "menu_list = [B, L, D]\n",
        "\n",
        "def menu_processing(del_list, menu_list):\n",
        "    list = []\n",
        "    for d in del_list:\n",
        "        for i in menu_list:\n",
        "            if d in i:\n",
        "                i.remove(d)\n",
        "\n",
        "for i, j in zip(del_col,[B, L, D]):\n",
        "    menu_processing(i, j)\n",
        "\n",
        "B[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['두유', '쥐어채무침', '찐빵', '호두죽', '된장찌개']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-f4Jgw8E4Ps"
      },
      "source": [
        "### 제거후 데이터 프레임"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "Cq4X45tCz7js",
        "outputId": "d2b48e2e-dc6e-4ffb-a56a-acaf0c7d57e8"
      },
      "source": [
        "for i in range(len(all_df)):\n",
        "    all_df['조식메뉴'][i] = B[i]\n",
        "    all_df['중식메뉴'][i] = L[i]\n",
        "    all_df['석식메뉴'][i] = D[i]\n",
        "all_df.rename(columns={'조식메뉴':'breakfast', '중식메뉴':'lunch', '석식메뉴':'dinner', '중식계':'lunch_y', '석식계':'dinner_y'}, inplace=True)\n",
        "\n",
        "all_df.head(10)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breakfast</th>\n",
              "      <th>lunch</th>\n",
              "      <th>dinner</th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[두유, 쥐어채무침, 찐빵, 호두죽, 된장찌개]</td>\n",
              "      <td>[요구르트, 쇠불고기, 청포묵무침, 계란찜, 오징어찌개]</td>\n",
              "      <td>[육개장, 두부조림, 자반고등어구이, 건파래무침]</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[시래기조림, 팥죽, 두유, 단호박샌드, 호박젓국찌개]</td>\n",
              "      <td>[요구르트, 모둠소세지구이, 마늘쫑무침, 김치찌개, 가자미튀김]</td>\n",
              "      <td>[콩나물밥, 어묵국, 유산슬, 바나나, 아삭고추무침]</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[표고버섯죽, 베이글, 두유, 느타리호박볶음, 콩나물국]</td>\n",
              "      <td>[요구르트, 카레덮밥, 쫄면야채무침, 견과류조림, 팽이장국, 치킨핑거]</td>\n",
              "      <td>[청국장찌개, 새송이버섯볶음, 황태양념구이, 고기전]</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[토마토샌드, 닭죽, 근대국, 두유, 멸치볶음]</td>\n",
              "      <td>[쇠고기무국, 요구르트, 주꾸미볶음, 시금치나물, 부추전]</td>\n",
              "      <td>[우동, 군고구마, 미니김밥, 멕시칸샐러드, 무피클]</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[쇠고기죽, 두유, 방풍나물, 와플, 재첩국]</td>\n",
              "      <td>[청경채무침, 요구르트, 우엉잡채, 돈육씨앗강정, 떡국]</td>\n",
              "      <td>[닭갈비, 감자소세지볶음, 콩나물무침, 차돌박이찌개]</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[팬케익, 두유, 찐빵, 감자찌개, 명엽채무침, 견과류죽]</td>\n",
              "      <td>[요구르트, 시래기국, 쌈무, 양파절임, 도토리묵무침, 훈제오리구이]</td>\n",
              "      <td>[군만두, 락교, 맑은국, 과일샐러드, 참치회덮밥]</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>0.147251</td>\n",
              "      <td>0.054979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160323</td>\n",
              "      <td>0.797770</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[고구마죽, 야채샌드, 두유, 봄동된장국, 숙주나물]</td>\n",
              "      <td>[요구르트, 유채나물, 돈육굴소스볶음, 꽃게탕, 옥수수전]</td>\n",
              "      <td>[물파래무침, 깍두기, 미니함박, 김치콩나물국, 어묵볶음]</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>0.149558</td>\n",
              "      <td>0.059977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.790465</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[치즈프레즐, 잣죽, 두유, 콩조림, 민물새우찌개]</td>\n",
              "      <td>[요구르트, 콩나물무침, 연두부, 닭감자조림, 시금치국]</td>\n",
              "      <td>[브로컬리초장, 임연수구이, 홍합미역국, 등갈비김치찜]</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>0.033449</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185313</td>\n",
              "      <td>0.888120</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[어묵국, 단호박죽, 두유, 김구이, 마늘빵]</td>\n",
              "      <td>[쇠고기무국, 요구르트, 탕수어, 오징어숙회무침, 취나물]</td>\n",
              "      <td>[쇠불고기, 해파리겨자채, 된장찌개, 봄동무침]</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.090734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.202230</td>\n",
              "      <td>0.881584</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[흑임자죽, 북어계란국, 무생채, 두유, 참치샌드]</td>\n",
              "      <td>[요구르트, 냉이된장국, 치커리무침, 통도라지구이, 쇠고기장조림]</td>\n",
              "      <td>[요플레, 맑은국, 새우또띠아, 쨔샤이무침, 볶음밥]</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.096117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008843</td>\n",
              "      <td>0.873895</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          breakfast  ... dayofweek\n",
              "0        [두유, 쥐어채무침, 찐빵, 호두죽, 된장찌개]  ...         0\n",
              "1    [시래기조림, 팥죽, 두유, 단호박샌드, 호박젓국찌개]  ...         1\n",
              "2   [표고버섯죽, 베이글, 두유, 느타리호박볶음, 콩나물국]  ...         2\n",
              "3        [토마토샌드, 닭죽, 근대국, 두유, 멸치볶음]  ...         3\n",
              "4         [쇠고기죽, 두유, 방풍나물, 와플, 재첩국]  ...         4\n",
              "5  [팬케익, 두유, 찐빵, 감자찌개, 명엽채무침, 견과류죽]  ...         3\n",
              "6     [고구마죽, 야채샌드, 두유, 봄동된장국, 숙주나물]  ...         4\n",
              "7      [치즈프레즐, 잣죽, 두유, 콩조림, 민물새우찌개]  ...         0\n",
              "8         [어묵국, 단호박죽, 두유, 김구이, 마늘빵]  ...         1\n",
              "9      [흑임자죽, 북어계란국, 무생채, 두유, 참치샌드]  ...         2\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNAF6R7a9LLl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c19e16a7-e843-4dfa-d974-25f2fd750a2c"
      },
      "source": [
        "type(all_df['breakfast'][0])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9jpcLHYOo41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ed89d13-82a4-483a-e71b-9b653a1919c7"
      },
      "source": [
        "all_df.shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1255, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vS-UycDxGe7o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a0e61d9-8805-4cb5-a219-ae3b38b3753f"
      },
      "source": [
        "da = []\n",
        "for i in all_df['lunch']:\n",
        "    for menu in i:\n",
        "        da.append(menu)\n",
        "print(da)\n",
        "print(len(set(da)))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['요구르트', '쇠불고기', '청포묵무침', '계란찜', '오징어찌개', '요구르트', '모둠소세지구이', '마늘쫑무침', '김치찌개', '가자미튀김', '요구르트', '카레덮밥', '쫄면야채무침', '견과류조림', '팽이장국', '치킨핑거', '쇠고기무국', '요구르트', '주꾸미볶음', '시금치나물', '부추전', '청경채무침', '요구르트', '우엉잡채', '돈육씨앗강정', '떡국', '요구르트', '시래기국', '쌈무', '양파절임', '도토리묵무침', '훈제오리구이', '요구르트', '유채나물', '돈육굴소스볶음', '꽃게탕', '옥수수전', '요구르트', '콩나물무침', '연두부', '닭감자조림', '시금치국', '쇠고기무국', '요구르트', '탕수어', '오징어숙회무침', '취나물', '요구르트', '냉이된장국', '치커리무침', '통도라지구이', '쇠고기장조림', '요구르트', '유부장국', '낙지비빔밥', '고구마치즈구이', '해초무침', '요구르트', '치킨무', '새송이버섯볶음', '마늘간장치킨', '대구찌개', '돌나물무침', '요구르트', '파래김', '쇠고기느타리국', '호박꼬지', '갈치구이', '오곡밥', '부럼', '요구르트', '버섯잡채', '꽃상추무침', '돈육간장볶음', '콩나물국', '요구르트', '맛탕', '소세지피망볶음', '비빔밥', '팽이장국', '닭갈비', '곰피초장', '요구르트', '새싹두부구이', '북어계란국', '요구르트', '오징어볶음', '수제비국', '계란찜', '도라지초무침', '치커리생채', '요구르트', '제육볶음', '얼갈이된장국', '늙은호박전', '맛살계란말이', '주꾸미볶음', '쇠고기미역국', '아삭고추무침', '탕수육', '근대된장국', '요구르트', '무생채', '새송이버섯조림', '깍두기', '열무된장나물', '메추리알조림', '부대찌개', '가자미튀김', '닭갈비', '모둠묵', '톳두부무침', '콩나물국', '깍두기', '소세지구이', '풋마늘초무침', '고등어김치말이', '차돌박이찌개', '홍어무침', '시금치나물', '북어국', '돈육장조림', '닭데리야끼조림', '고추장찌개', '취나물', '해물파전', '탕평채', '수제돈가스', '배추된장국', '쫄면무침', '모둠양채쌈', '어묵국', '콩나물파채무침', '돈육고추장볶음', '쑥국', '골뱅이무침', '소불고기', '마늘쫑볶음', '두부계란부침', '곤드레밥', '콩나물김치국', '무나물', '미니채소떡갈비', '깍두기', '탕수어', '파래김', '사골우거지국', '깻순나물', '연근땅콩조림', '부추생채', '시금치국', '쌈무', '훈제오리구이', '버섯불고기', '꽃게탕', '도토리묵무침', '계란말이', '쇠고기샤브국', '깍두기', '유채나물', '두부', '코다리강정', '땅콩조림', '콩나물밥', '맑은국', '실곤약초무침', '치킨텐더', '시래기나물', '오징어초무침', '북어계란국', '쇠고기장조림', '닭개장', '자반고등어구이', '비엔나볶음', '열무나물', '닭갈비', '얼갈이된장국', '해파리냉채', '취나물', '새송이버섯전', '주꾸미볶음', '옹심이만두국', '치커리유자청생채', '알감자버터구이', '오렌지', '봄새싹비빔밥', '쪽파국', '오징어튀김', '매운콩나물국', '돈육굴소스볶음', '동태전', '봄동나물', '우엉잡채', '갈치조림', '버섯들깨탕', '아삭고추무침', '쇠불고기', '풋마늘초무침', '브로컬리맛살볶음', '순두부찌개', '시금치나물', '북어국', '오징어볶음', '모둠소시지구이', '제육볶음', '두부조림', '모둠쌈', '올갱이아욱국', '어묵국', '무생채', '매운돼지갈비찜', '해물파전', '메추리알조림', '콩나물무침', '순살양념치킨', '배추된장국', '시래기국', '풋마늘초무침', '양파절임', '무쌈', '훈제오리구이', '쇠고기단호박조림', '시금치나물', '열무나물', '부대찌개', '돈육굴소스볶음', '무생채', '양배추쌈', '수제비국', '닭데리야끼조림', '콩나물무침', '냉이된장찌개', '도라지초무침', '브로컬리두부무침', '돈육강정', '배추된장국', '콩나물잡채', '육개장', '꽁치한마리구이', '고기전', '해초무침', '근대된장국', '콩나물밥', '매콤떡갈비조림', '청포묵무침', '부추생채', '대구매운탕', '쇠고기볶음', '청경채생채', '옥수수전', '연근조림', '깻잎양념지', '열무김치', '북어국', '등갈비김치찜', '김치전', '버섯볶음', '돈간장불고기', '콩나물국', '쇠고기무국', '주꾸미볶음', '풋마늘대무침', '치즈계란말이', '알감자버터구이', '궁중떡찜', '나물비빔밥', '유기농식혜', '미소장국', '동그랑땡부침', '양념파닭', '미역국', '치킨무', '콩자반', '깍두기', '고등어카레구이', '미트볼조림', '치커리사과무침', '돈육김치찌개', '닭갈비', '맛살겨자채', '시금치국', '비름나물', '온두부', '무채국', '실곤약초무침', '곤드레밥', '모둠장조림', '볶은김치', '쇠고기샤브국', '무생채', '동태전', '오징어볶음', '매운어묵국', '양파절임', '무쌈', '도토리묵무침', '훈제오리구이', '버섯불고기', '오징어초무침', '시금치나물', '콩나물국', '돈육칠리강정', '가지나물', '멸치크랜베리볶음', '시래기된장국', '단호박영양밥', '꽃맛살볶음', '오징어국', '통도라지구이', '찜닭', '치커리유자생채', '매운돼지갈비찜', '해물파전', '된장찌개', '돈육굴소스볶음', '꽃상추무침', '감자고추장찌개', '계란찜', '깍두기', '고등어김치말이', '비름나물', '들깨버섯탕', '고기전', '요플레', '연근땅콩조림', '산채비빔밥', '미소장국', '치킨핑거', '열무된장국', '골뱅이무침', '숙주나물', '미니채소떡갈비', '새송이버섯전', '닭오븐구이', '불미나리무침', '순두부찌개', '쇠고기불고기', '북어콩나물국', '옥수수전', '오이무침', '치커리생채', '한방갈비탕', '오징어숙회무침', '꼬지삼색전', '석박지', '탕수어', '낙지볶음밥', '미역장국', '매실주스', '우엉조림', '무생채', '비엔나감자볶음', '갈치구이', '쇠고기해장국', '깍두기', '고구마순나물', '닭양념조림', '동그랑땡전', '배추된장국', '명태조림', '콩나물김치국', '오이도라지생채', '누룽지탕수육', '닭갈비', '근대된장국', '깻잎양념지', '잡채', '열무비빔밥', '음료', '오징어튀김', '궁중떡볶이', '강된장찌개', '오이미역냉국', '두부구이', '실곤약초무침', '모둠장조림', '차돌박이찌개', '머위대나물', '찜닭', '김치전', '돈육굴소스볶음', '가지나물', '북어계란국', '홍어채무침', '참치김치찌개', '브로컬리초장', '깍두기', '순살깐풍기', '맛살콩나물냉채', '돼지갈비찜', '매운콩나물국', '비름나물', '부추전', '치커리사과무침', '오징어볶음', '모둠소시지구이', '된장찌개', '제육볶음', '참치야채전', '북어콩나물국', '모둠쌈', '열무김치', '탕평채', '닭양념조림', '배추된장국', '어묵볶음', '열무된장나물', '카레덮밥', '맑은국', '쫄면무침', '떡갈비조림', '깍두기', '가자미양념찜', '고기전', '부대찌개', '해초무침', '버섯잡채', '돈육강정', '꽃게탕', '김구이', '어묵국', '시금치나물', '레몬탕수육', '명태엿장조림', '치킨무', '간장치킨', '마늘쫑볶음', '대구찌개', '오이무침', '시래기국', '새송이버섯전', '상추쌈', '콩나물파채무침', '돈삼겹보쌈', '쇠고기무국', '매콤낙지볶음', '메추리알조림', '숙주나물', '간장깻잎지', '골뱅이무침', '도토리묵냉국', '목살데리야끼구이', '실곤약초무침', '쌈무', '야채스틱', '배추된장국', '훈제오리구이', '육개장', '닭가슴살냉채', '마늘쫑무침', '고등어구이', '상추겉절이', '계란말이', '간장돼지갈비찜', '콩나물국', '버섯들깨찌개', '열무김치', '닭오븐구이', '치커리사과무침', '김치전', '두부새싹구이', '유자청제육볶음', '양배추쌈', '수제비국', '버섯불고기', '감자고추장찌개', '맛살겨자초무침', '노각무침', '모둠소세지구이', '비름나물', '꽁치김치말이찜', '쇠고기미역국', '닭강정', '가쯔오장국', '곤드레밥', '통도라지구이', '해물파전', '돈육잡채', '갈치조림', '오이생채', '된장찌개', '감자볶음', '영양부추', '우무묵냉국', '갈릭돈까스', '알타리김치', '돈육굴소스볶음', '모듬쌈', '호박잎찌개', '홍어채무침', '꽃맛살볶음', '순살파닭', '도라지나물', '건새우아욱국', '감자만두', '수박', '오이냉국', '나물비빔밥', '사천식탕수육', '브로컬리두부무침', '동태전', '매운주꾸미볶음', '배추된장국', '알타리김치', '열무김치', '삼치구이', '가지나물', '북어계란국', '등갈비김치찜', '새송이버섯전', '돈육떡강정', '해초무침', '순두부찌개', '시래기국', '늙은호박전', '치커리들깨무침', '목살데리야끼', '청포묵무침', '사골우거지탕', '미트볼조림', '골뱅이무침', '고추장불고기', '깻잎지', '우묵콩국', '명태엿장조림', '알타리김치', '토마토', '락교', '고구마치즈구이', '참치회덮밥', '미소장국', '춘권', '불닭볶음', '참나물생채', '쌈무', '쇠고기미역국', '해파리겨자채', '연근조림', '청국장찌개', '미니채소떡갈비', '계란말이', '수박', '오이도라지무침', '감자채볶음', '시금치국', '동파삼겹수육', '꽃게탕', '동그랑땡전', '훈제오리냉채', '콩자반', '꽁치오븐구이', '연복풍덮밥', '도토리묵냉국', '마늘쫑무침', '양배추피클', '갈치구이', '꽈리고추찜', '닭살겨자냉채', '부대찌개', '유기농식혜', '열무보리비빔밥', '웨지감자오븐구이', '꽃맛살볶음', '팽이장국', '알타리김치', '메추리알조림', '콩나물무침', '버섯들깨탕', '레몬탕수육', '닭데리야끼조림', '복숭아미역냉국', '비엔나감자볶음', '시금치무침', '연근', '무생채', '열무김치', '매콤돼지갈비찜', '오징어튀김', '된장찌개', '유자청제육볶음', '오꼬노미계란말이', '호박잎된장국', '도라지초무침', '미니함박조림', '오이무침', '오징어브로컬리숙회', '콩나물국', '치커리생채', '우엉잡채', '사과오이냉국', '장어강정', '매운어묵볶음', '시래기국', '삼겹살오븐구이', '상추', '불고기덮밥', '맑은국', '고구마범벅', '새우까스', '노각무침', '비엔나피망볶음', '알타리김치', '해초무침', '고등어조림', '닭곰탕', '청경채무침', '대구매운탕', '오징어볶음', '고기전', '열무된장국', '실곤약초무침', '마늘쫑볶음', '갈릭돈가스', '땅콩조림', '쑥갓두부무침', '도토리묵냉국', '소고기숙주볶음', '단호박영양밥', '꽃게탕', '오이무침', '꽁치와사비구이', '고추잡채', '콩나물무침', '열무김치', '두부조림', '칠리탕수육', '배추된장국', '연근조림', '치커리유자청무침', '닭볶음', '해물된장찌개', '육개장', '동태무조림', '올방개묵무침', '부추전', '마늘치킨', '꽃맛살오리엔탈샐러드', '홍어채무침', '떡국', '골뱅이무침', '소불고기', '아삭고추무침', '순두부찌개', '버섯매운탕', '호박잎쌈', '갈치구이', '모듬소시지볶음', '낙지비빔밥', '열무김치', '가쯔오장국', '단무지무침', '과일샐러드', '계란말이', '브로컬리초장', '버섯잡채', '오징어국', '목살데리야끼', '청경채무침', '닭찜', '시래기된장국', '해물파전', '쇠고기샤브국', '연두부', '오징어볶음', '옥수수전', '참나물땅콩무침', '파김치', '모둠버섯볶음', '부대찌개', '가자미카레튀김', '두부맑은국', '곤드레밥', '돈육떡강정', '계란찜', '오이무침', '오리고추장볶음', '알타리김치', '부추생채', '콩나물잡채', '된장찌개', '숙주나물', '황태맑은국', '도토리묵무침', '유린기', '깍두기', '시래기국', '닭볶음', '상추겉절이', '동그랑땡', '매운돼지갈비찜', '쑥갓두부무침', '토란국', '어묵볶음', '오리훈제고추장볶음', '어묵국', '애호박나물', '계란말이', '얼갈이된장국', '감자채볶음', '참나물생채', '레몬탕수육', '땅콩조림', '열무비빔밥', '핫도그', '음료', '너비아니구이', '깍두기', '팽이장국', '쇠고기무국', '임연수찜', '햄피망볶음', '단배추나물', '무생채', '두부조림', '오징어국', '소고기숙주볶음', '아욱된장국', '우엉잡채', '유자청돈육볶음', '양배추쌈', '열무된장나물', '간장파닭', '쫄면무침', '느타리버섯국', '카레덮밥', '새송이버섯조림', '맑은국', '샐러드파스타', '오이무침', '호박부추전', '돈육장조림', '올방개묵무침', '된장찌개', '꽁치한마리구이', '브로컬리초장', '가지볶음', '우거지해장국', '알타리김치', '마늘쫑건새우볶음', '버섯불고기', '골뱅이소면무침', '배추된장국', '콩나물무침', '모둠소세지구이', '매운주꾸미볶음', '차돌박이찌개', '미역국', '한방소갈비찜', '오징어숙회무침', '동태', '새송이전', '대구매운탕', '부추생채', '메추리알곤약조림', '표고돈육탕수', '쇠고기샤브국', '맛살계란말이', '참나물무침', '오징어볶음', '버섯잡채', '시금치된장국', '목살스테이크', '오이무침', '생선커틀릿', '팽이버섯국', '산채비빔밥', '오복지무침', '오렌지주스', '마늘치킨', '열무된장나물', '떡국', '모듬묵', '건새우무국', '애호박나물', '등갈비김치찜', '계란버섯장조림', '매운어묵볶음', '모둠양채쌈', '미역국', '소불고기', '치커리유자청무침', '꽃게탕', '미트볼칠리조림', '부추전', '참치김치찌개', '셀프무쌈말이', '멸치크렌베리볶음', '유린기', '메밀버섯전', '쑥갓두부무침', '꽁치김치말이', '알타리김치', '계란국', '풍기샐러드', '단무지', '사천식탕수육', '짜장밥', '제육볶음', '콩나물무침', '해물파전', '된장찌개', '육개장', '깍두기', '갈치구이', '미역레몬초무침', '고추잡채', '땅콩조림', '실곤약초무침', '곤드레밥', '배추된장국', '데리야끼파닭', '동태찌개', '해초무침', '두부계란전', '돈육장조림', '고등어조림', '비엔나감자볶음', '통도라지구이', '버섯들깨탕', '알타리김치', '근대된장국', '쇠고기숙주볶음', '새송이버섯전', '홍어채무침', '닭갈비', '생선까스', '시금치나물', '알탕', '훈제오리', '콩나물밥', '가쯔오장국', '양파절임', '무쌈', '부추겉절이', '쇠고기무국', '쭈꾸미볶음', '세발나물', '계란말이', '모듬소세지구이', '사골우거지탕', '석박지', '명태엿장조림', '오이무침', '유자청제육볶음', '오징어국', '상추파채무침', '날치알계란찜', '동그랑땡전', '깻잎지', '순살양념치킨', '차돌박이찌개', '연근조림', '무생채', '단호박영양밥', '꽃게탕', '고추잡채', '김치콩나물국', '닭살겨자채', '쇠고기장조림', '멸치아몬드볶음', '알타리김치', '아욱된장국', '치커리무침', '동태전', '칠리탕수육', '소고기버섯볶음', '어묵국', '오징어숙회무침', '부추호박전', '닭데리야끼조림', '브로컬리무침', '김치국', '햄감자채볶음', '청경채무침', '유산슬', '조랭이떡미역국', '임연수구이', '버섯영양밥', '깍두기', '설렁탕', '올방개묵무침', '풋고추', '해물김치전', '쌈다시마초장', '어묵볶음', '갓김치', '순살깐풍기', '콩비지찌개', '계란찜', '시래기된장국', '누룽지탕수육', '도라지초무침', '쇠고기숙주볶음', '대구매운탕', '새싹두부구이', '오이생채', '순두부탕', '청포묵무침', '갈치조림', '파닭', '짬뽕불고기', '우엉잡채', '참나물', '수제비국', '카레덮밥', '연근땅콩조림', '베추겉절이', '맑은국', '샐러드파스타', '통감자오븐구이', '물파래무침', '쇠고기느타리국', '오징어볶음', '모둠소시지구이', '제육볶음', '늙은호박전', '근대국', '모둠쌈', '가쯔오장국', '나물비빔밥', '오복지무침', '감자샐러드', '치킨핑거', '골뱅이무침', '모둠장조림', '톳두부무침', '알타리김치', '콩나물국', '청경채무침', '양념찜닭', '떡국', '콩나물겨자채', '참치야채전', '훈제오리구이', '무쌈말이', '순두부찌개', '실곤약흑임자무침', '배추쌈', '무말랭이', '홍합탕', '삼겹살오븐구이', '짜장밥', '유부장국', '쨔샤이무침', '아이스슈', '해물누룽지탕', '개성감자만두', '양념돼지갈비찜', '버섯메밀전', '아욱국', '상추초무침', '알타리김치', '차돌박이된장찌개', '닭가슴살냉채', '마늘쫑무침', '삼치무조림', '깍두기', '돈육굴소스볶음', '매운어묵무침', '다시마', '콩나물김치국', '오이도라지무침', '돈육잡채', '냉이된장찌개', '코다리강정', '청경채무침', '가쯔오장국', '멕시칸샐러드', '고구마튀김', '소불고기덮밥', '오리고추장볶음', '부추생채', '옥수수계란찜', '콩비지찌개', '쇠고기샤브국', '비엔케찹볶음', '갈치구이', '아삭고추무침', '짬뽕불고기', '하루나겉절이', '감자채볶음', '배추된장국', '깍두기', '꽁치김치말이', '올방개묵무침', '콩나물국', '고추잡채', '가지나물', '마늘간장치킨', '홍어채무침', '된장찌개', '쇠고기버섯볶음', '꽃게탕', '양배추쌈', '오이무침', '치커리유자청무침', '얼갈이국', '동태전', '떡갈비조림', '두부새싹구이', '동태찌개', '풋마늘대무침', '돈육간장불고기', '닭갈비', '열무된장국', '우엉잡채', '군고구마', '콩나물밥', '가쯔오장국', '미트볼케찹조림', '꽃맛살샐러드', '시래기국', '쑥갓두부무침', '소세지감자조림', '오징어볶음', '물미역초장', '꽈리고추어묵볶음', '수제돈까스', '순두부찌개', '사골떡국', '쇠고기낙지볶음', '통도라지구이', '부추깻잎전', '언양식불고기', '매운동태찜', '홍합탕', '콩나물파채절이', '황태국', '꽈리고추멸치볶음', '곤드레밥', '동그랑땡전', '비빔메밀국수', '육개장', '굴비구이', '두반장감자볶음', '청경채생채', '주꾸미초무침', '레몬탕수육', '어묵볶음', '된장찌개', '동파육', '쫑상추무침', '무쌈말이', '콩나물국', '주꾸미떡볶음', '두반장가지볶음', '고기전', '쇠고기미역국', '생선까스', '씨리얼과일샐러드', '오복지무침', '비빔밥', '팽이장국', '어묵국', '매운닭찜', '모듬버섯구이', '봄동된장무침', '짬뽕국', '미니함박조림', '치커리유자생채', '잡채', '얼갈이된장국', '꽃맛살햄볶음', '참나물땅콩무침', '오징어볶음', '시금치초생채', '쇠고기숙주볶음', '삼색묵무침', '순두부찌개', '아욱국', '무쌈', '부추무침', '옥수수전', '훈제오리구이', '청경채무침', '두부새싹구이', '유자청돈육볶음', '수제비국', '파래김', '닭개장', '비엔나케찹볶음', '가자미카레튀김', '새송이버섯전', '냉이콩나물국', '닭볶음', '마늘쫑무침', '감자채볶음', '깻잎찜', '알탕', '돈육간장불고기', '카레덮밥', '맑은국', '오이사과무침', '유린기', '개성감자만두', '콩나물무침', '삼색꼬지전', '배추된장국', '소갈비찜', '진미채무침', '언양식불고기', '미역국', '양잡피잡채', '고추장불고기', '모듬쌈', '닭살겨자채', '시금치된장국', '스위트칠리미트볼', '치커리생채', '갈치구이', '굴김치두부국', '알타리김치', '무생채', '소고기낙지볶음', '연두부찜', '콩나물국', '닭갈비', '감자전', '냉이된장찌개', '단배추나물', '땅콩멸치볶음', '대구매운탕', '실곤약무침', '유산슬', '물미역무침', '콩나물밥', '닭오븐구이', '맑은국', '춘권', '치커리생채', '수제돈까스', '명태조림', '배추국', '알타리김치', '굴비구이', '홍어무침', '소고기무국', '보름나물', '김구이', '오곡밥', '제육볶음', '두부구이', '도라지오이생채', '쇠고기미역국', '돈육잡채', '주꾸미볶음', '숙주나물', '된장찌개', '다시마쌈', '순살파닭', '들깨시래기국', '해물김치전', '얼갈이나물', '오징어초무침', '홍합탕', '소불고기', '깍두기', '어묵국', '동태전', '부추무침', '등갈비김치찜', '동파육', '새송이버섯전', '열무된장국', '치커리유자무침', '낙지볶음', '야채계란찜', '버섯들깨탕', '취나물', '생선까스', '파스타샐러드', '유부장국', '나물비빔밥', '마늘쫑볶음', '알타리김치', '돼지갈비찜', '브로컬리초장', '메추리알조림', '콩나물국', '깐풍기', '톳무침', '수제비국', '어묵볶음', '녹두김치전', '양파절임', '봄동된장국', '훈제오리구이', '오이부추무침', '사골떡국', '언양식불고기', '콩나물동태찜', '돌나물무침', '깍두기', '고등어조림', '팝콘치킨', '해초무침', '돈육김치찌개', '군만두', '카레덮밥', '맑은국', '무피클', '미니채소떡갈비', '어묵국', '동그랑땡전', '치커리사과무침', '순살닭갈비', '꽁치한마리구이', '토란탕', '봄동달래무침', '돈육칠리강정', '미소국', '곤드레밥', '고추간장지', '오징어볶음', '햄감자채볶음', '마늘치킨', '골뱅이무침', '아욱국', '숙주나물', '석박지', '도라지오이생채', '해물청경채볶음', '얼큰순두부찌개', '계란말이', '파래김', '버섯불고기', '오징어국', '야채계란찜', '동태찌개', '우엉잡채', '방풍나물', '미트볼케찹조림', '건새우마늘쫑볶음', '근대국', '양념찜닭', '옥수수전', '돈육굴소스볶음', '모듬쌈', '옹심이만두국', '콩나물겨자채', '치킨커틀렛', '연근땅콩조림', '시금치나물', '고추장찌개', '상추무침', '아욱국', '맛살전', '콩나물불고기', '굴비구이', '부추생채', '냉이된장찌개', '쇠고기장조림', '깍두기', '세발나물', '비엔나볶음', '돈육김치찌개', '유린기', '돼지갈비찜', '콩가루배추국', '통도라지구이', '물파래전', '대구매운탕', '올방개묵무침', '김구이', '고추잡채', '얼갈이나물', '오꼬노미계란말이', '소고기숙주볶음', '알탕', '주꾸미볶음', '탕평채', '시금치나물', '소고기미역국', '땅콩조림', '언양식불고기', '바나나', '봄나물비빔밥', '팽이장국', '북어콩나물국', '쑥갓두부무침', '사천식탕수육', '김치전', '콩나물무침', '닭가슴살장조림', '생선커틀렛', '오이달래무침', '쌈무', '꽃게탕', '양파절임', '쇠불고기', '동태전', '도토리묵무침', '된장찌개', '유산슬', '맑은계란국', '단무지무침', '부추만두', '짜장밥', '마늘치킨', '감자채전', '근대국', '크래미숙주무침', '육개장', '참나물생채', '버섯구이', '미니채소떡갈비', '얼갈이국', '비름나물', '쇠고기낙지볶음', '날치알계란찜', '청경채무침', '열무김치', '우엉잡채', '김치찌개', '해물누룽지탕', '파채상추무침', '들깨미역국', '삼겹살오븐구이', '맛살콩나물냉채', '닭데리야끼조림', '매운어묵볶음', '황태국', '시금치나물', '쇠고기샤브국', '메추리알조림', '오징어볶음', '머위된장나물', '돈육굴소스볶음', '오징어숙회무침', '방풍나물', '된장찌개', '시금치프리타타', '도라지생채', '얼갈이겉절이', '들깨시래기국', '쇠고기장조림', '탕수어', '요플레', '맑은국', '곤드레밥', '쫄면무침', '참치야채전', '열무김치', '아욱국', '가지나물', '등갈비김치찜', '부추생채', '버섯불고기', '콩나물김치국', '브로컬리맛살볶음', '언양식불고기', '아삭고추된장무침', '계란장조림', '부대찌개', '닭강정', '콩나물잡채', '도토리묵무침', '차돌박이찌개', '맑은국', '오징어튀김', '견과류조림', '비빔밥', '깍두기', '하와이안샐러드', '미역국', '삼치구이', '열무김치', '영양부추생채', '매콤함박스테이크', '탕수육', '꽃게찌개', '곤약야채무침', '숙주나물', '참치김치찌개', '열무김치', '부추생채', '쌈무', '올방개묵무침', '양파절임', '훈제오리구이', '닭갈비', '생선까스', '무생채', '들깨미역국', '머위대들깨볶음', '쇠불고기', '고추장찌개', '홍어채무침', '제육볶음', '콩나물무침', '잡채', '된장찌개', '깍두기', '낙지볶음', '새송이버섯전', '콩가루배추국', '비름나물', '옹심이만두떡국', '마늘쫑무침', '카레감자채볶음', '유린기', '매운어묵볶음', '치커리유자청무침', '돈육꽈리고추볶음', '열무김치', '콩비지찌개', '쇠고기샤브국', '맛살계란찜', '오징어볶음', '양념깻잎지', '열무된장국', '동태전', '미나리오이무침', '쇠고기장조림', '청경채무침', '굴비구이', '깍두기', '부대찌개', '고추잡채', '새우살미역국', '참나물생채', '순살양념치킨', '콩나물겨자채', '제육볶음', '버섯구이', '시금치된장국', '양배추', '해초무침', '간장찜닭', '소고기국', '부추전', '콩나물밥', '열무김치', '감자프리타타', '고등어구이', '김치국', '고추지', '두부조림', '오이소박이', '오리불고기', '상추겉절이', '들깨시래기국', '주꾸미떡볶음', '부추생채', '동그랑땡전', '콩나물국', '청경채사과생채', '황태국', '소불고기', '계란찜', '얼갈이된장국', '동파삼겹수육', '맛살전', '아삭고추무침', '가쯔오장국', '오이지무침', '열무보리비빔밥', '탕수만두', '콥샐러드', '깍두기', '오이냉국', '참나물땅콩무침', '등갈비김치찜', '어묵볶음', '도토리묵무침', '삼치된장구이', '돈육김치찌개', '모듬소세지볶음', '돈육굴소스볶음', '근대국', '모둠쌈', '계란말이', '씨앗쌈장', '새송이버섯전', '부추생채', '쌈무', '훈제오리구이', '콩나물국', '얼갈이된장국', '골뱅이무침', '숙주나물', '미니채소떡갈비', '어묵꽈리고추볶음', '깐풍기', '실곤약초무침', '호박잎된장찌개', '쇠고기숙주볶음', '고구마순나물', '연두부탕', '홍어채무침', '깍두기', '쭈꾸미볶음', '늙은호박전', '치커리사과생채', '도토리묵냉국', '파스타샐러드', '가쯔오장국', '곤드레밥', '견과류조림', '치킨핑거', '쇠고기샤브국', '메추리알조림', '무생채', '갈치구이', '아욱된장국', '감자채볶음', '삼겹살구이', '쫑상추무침', '유자청제육볶음', '해물부추전', '오이도라지생채', '들깨시래기국', '연근조림', '오이지냉국', '열무김치', '고등어김치말이', '감자비엔나볶음', '수박', '유부주머니국', '언양식불고기', '카레라이스', '떡볶이', '비빔야채만두', '쇠고기미역국', '해물누룽지탕', '양념깻잎지', '나가사끼짬뽕국', '닭갈비', '셀프무쌈말이', '콩나물무침', '차돌박이찌개', '양배추쌈', '곤약흑임자무침', '훈제오리고추장볶음', '북어콩나물국', '시금치나물', '동그랑땡구이', '오징어볶음', '얼갈이된장국', '콩나물밥', '삼치구이', '잡채', '깍두기', '아삭고추무침', '부추생채', '우무묵냉국', '갈릭돈까스', '두부양념조림', '감자채전', '꼬지어묵탕', '열무김치', '매운닭찜', '미역줄기볶음', '짬뽕불고기', '청경채겉절이', '계란찜', '콩나물국', '낙지볶음', '미역레몬초무침', '배추된장국', '고기전', '군만두', '계란국', '열무김치', '사과', '단무지', '짜장덮밥', '유산슬', '아욱된장국', '참나물', '등갈비김치찜', '어묵볶음', '알타리김치', '오이냉국', '숙주나물', '도토리묵무침', '유린기', '해물겨자냉채', '버섯불고기', '우엉조림', '콩나물국', '브로컬리초장', '주꾸미떡볶음', '어묵국', '두부계란구이', '수박', '초복특식', '삼계탕', '찹쌀밥', '생야채', '깍두기', '돼지갈비찜', '치커리유자청무침', '근대국', '동태전', '버섯잡채', '쑥갓두부무침', '갈치조림', '부대찌개', '알타리김치', '무채국', '모듬양채쌈', '간장두부조림', '돈육고추장볶음', '치커리무침', '열무된장국', '간장찜닭', '통도라지구이', '맑은국', '김치제육덮밥', '양장피잡채', '천도복숭아', '오꼬노미야끼', '알타리김치', '소고기매운무국', '모둠버섯구이', '오징어굴소스볶음', '오이무침', '메밀전', '영양부추생채', '미트볼케찹조림', '닭곰탕', '동그랑땡전', '어묵탕', '얼갈이된장무침', '콩나물불고기', '닭살냉채', '참나물무침', '가자미카레튀김', '된장찌개', '오렌지', '소세지오븐구이', '파스타샐러드', '나물비빔밥', '미소장국', '순살파닭', '오징어브로컬리', '콩나물냉국', '멸치크렌베리볶음', '쇠고기샤브국', '주꾸미떡볶음', '연두부', '해초무침', '시래기조림', '쇠고기숙주볶음', '연두부탕', '홍어채무침', '우엉잡채', '머위대나물', '부대찌개', '해물누룽지탕', '두부계란구이', '치커리사과생채', '꽃게탕', '미니채소떡갈비', '오이미역냉국', '무생채', '닭오븐구이', '꽈리고추어묵조림', '제육볶음', '메추리알조림', '열무김치', '양배추쌈', '호박잎', '콩나물국', '새송이버섯전', '어묵국', '참나물땅콩무침', '쇠고기낙지볶음', '닭갈비', '시금치프리타타', '미역국', '마늘쫑무침', '수제돈까스', '도토리묵냉국', '두부양념조림', '단배추나물', '셀프무쌈말이', '비엔나감자볶음', '갈치구이', '돈육김치찌개', '알타리김치', '고추장찌개', '어묵볶음', '돈육보쌈', '짬뽕불고기', '청경채생채', '옥수수계란찜', '된장찌개', '쇠고기무국', '모듬묵양념장', '오징어볶음', '오이무침', '치커리무침', '매운닭찜', '임연수구이', '들깨시래기국', '열무김치', '맑은국', '단무지', '부추만두', '짜장밥', '해물까스', '콩나물무침', '조랭이떡미역국', '소고기불고기', '김치전', '간장깻잎지', '표고버섯탕수육', '두부조림', '해물된장찌개', '감자채볶음', '열무김치', '가쯔오장국', '검정콩조림', '곤드레밥', '가자미양념찜', '쇠고기샤브국', '비름나물', '주꾸미굴소스볶음', '볼어묵볶음', '마늘쫑무침', '미트볼케찹조림', '알탕', '계란말이', '매운어묵볶음', '쑥갓두부무침', '돈육간장불고기', '콩나물국', '닭갈비', '동태전', '치커리사과생채', '배추된장국', '언양식불고기', '산채비빔밥', '과일샐러드', '미소장국', '아삭고추무침', '육개장', '굴비구이', '탕수만두', '오이무침', '알타리김치', '시래기국', '두부구이', '열무김치', '쌈무', '양파절임', '훈제오리구이', '버섯불고기', '실곤약초무침', '북어국', '야채계란찜', '땅콩조림', '열무김치', '연두부탕', '도토리묵무침', '등갈비김치찜', '마늘치킨', '고구마줄기볶음', '꽃게탕', '양배추쌈', '오징어볶음', '고기전', '쇠고기미역국', '호박나물', '동파육', '셀프무쌈말이', '열무된장국', '통도라지구이', '유자청제육볶음', '치커리무침', '오꼬노미야끼계란말이', '시래기된장국', '돈육잡채', '마늘쫑무침', '해물누룽지탕', '차돌박이찌개', '요플레', '오복지', '미소장국', '모듬묵샐러드', '떡갈비조림', '카레라이스', '닭찜', '두부계란부침', '부추생채', '고사리육개장', '참치김치찌개', '참나물무침', '고등어구이', '단호박장조림', '알타리김치', '감자채전', '언양식불고기', '해물순두부찌개', '쫑상추무침', '소고기낙지볶음', '비엔나케찹조림', '들깨버섯국', '취나물', '메밀전병만두', '콩나물밥', '가쯔오국', '감자프리타타', '아삭고추무침', '쇠고기샤브국', '온두부', '열무김치', '김치제육볶음', '꽁치구이', '콩가루배추국', '순살양념치킨', '모듬묵', '콩나물겨자채', '짬뽕불고기', '실곤약흑임자무침', '근대국', '도라지오이생채', '닭갈비', '해물파전', '숙주나물', '시래기들깨탕', '상추파무침', '삼겹살구이', '어묵볶음', '콩나물국', '두부새싹구이', '브로컬리초장', '매운주꾸미볶음', '차돌박이찌개', '미니케익', '쇠불고기', '미역국', '오징어숙회무침', '잡채', '식혜', '부추생채', '쌈무', '아욱국', '훈제오리구이', '계란찜', '유채나물', '궁중떡찜', '고추장찌개', '레몬탕수육', '닭찜', '새송이버섯전', '해물된장찌개', '얼갈이생채', '쇠고기무국', '치커리유자청무침', '메추리알조림', '오징어볶음', '제육볶음', '모둠쌈', '해파리겨자채', '차돌박이찌개', '고등어조림', '근대국', '참나물생채', '고추잡채', '시금치프리타타', '수제돈가스', '오이무침', '민물새우찌개', '새알미역국', '가지나물', '마파두부', '유린기', '해물청경채볶음', '메밀부추전', '쇠고기매운버섯국', '도라지초무침', '버섯불고기', '마늘쫑볶음', '홍어채무침', '콩나물국', '쭈꾸미볶음', '두부계란부침', '배추된장국', '미역줄기볶음', '가쯔오장국', '쑥갓두부무침', '곤드레밥', '갈치조림', '쇠고기잡채', '알타리김치', '육개장', '물파래무침', '도토리묵무침', '치킨핑거', '돼지갈비찜', '시금치국', '무나물', '어묵볶음', '닭갈비', '연두부', '들깨시래기국', '취나물', '콩나물파채', '상추쌈', '근대국', '옥수수전', '돈삼겹보쌈', '군고구마', '카레덮밥', '파스타샐러드', '맑은국', '개성감자만두', '사골떡국', '치커리사과생채', '오징어볶음', '계란말이', '실곤약초무침', '톳두부무침', '누룽지탕수육', '된장찌개', '짬뽕불고기', '콩가루배추국', '참치야채전', '호박나물', '삼치구이', '수제돈까스', '오징어국', '봄동겉절이', '콩나물밥', '미역장국', '언양식불고기', '과일샐러드', '도라지오이무침', '매운닭찜', '두부조림', '시금치나물', '해물된장찌개', '깍두기', '들깨버섯무침', '숙주나물', '올갱이아욱국', '등갈비김치찜', '해물파전', '시금치국', '통도라지구이', '소고기불고기', '돼지갈비찜', '두부새싹구이', '세발나물', '새알미역국', '알타리김치', '청양된장찌개', '굴비구이', '무생채', '곤드레밥', '궁중떡볶이', '메밀전병만두', '가지무침', '북어계란국', '찜닭', '동태전', '미니채소떡갈비', '콩비지찌개', '양념깻잎지', '치커리유자청무침', '오징어볶음', '계란말이', '알타리김치', '차돌박이찌개', '물파래무침', '어묵국', '순살파닭', '맛살겨자채', '가쯔오장국', '돈육칠리강정', '모듬묵샐러드', '숙주나물', '단호박영양밥', '깍두기', '쇠고기무국', '갈치구이', '오이무침', '고추잡채', '새송이버섯전', '돈육굴소스볶음', '꽃게탕', '물미역', '버섯불고기', '골뱅이무침', '아욱국', '무나물', '참나물생채', '연두부탕', '견과류조림', '사천식탕수육', '군고구마', '나물비빔밥', '코다리조림', '과일샐러드', '미소장국', '깍두기', '제육볶음', '메추리알조림', '콩나물무침', '들깨시래기국', '알타리김치', '취나물', '옥수수전', '찜닭', '동태탕', '모둠쌈', '돈육피망볶음', '들깨무채국', '해파리겨자채', '낙지볶음', '소고기된장찌개', '오이생채', '계란찜', '생선까스', '콩나물밥', '유부주머니국', '단호박범벅', '두부양념조림', '마늘쫑건새우볶음', '닭볶음탕', '봄동된장국', '부추전', '사각어묵볶음', '미트볼케찹조림', '부대찌개', '김구이', '돈육굴소스볶음', '홍어채무침', '해물된장찌개', '양념깻잎지', '깍두기', '오이미역무침', '계란말이', '해물누룽지탕', '차돌박이찌개', '요플레', '오복지', '미소장국', '떡갈비조림', '카레라이스', '모듬묵', '명태코다리조림', '시금치나물', '우거지해장국', '비엔나케찹볶음', '표고버섯탕수육', '마늘쫑무침', '두부오꼬노미야끼', '들깨시래기국', '상추쑥갓생채', '버섯불고기', '실곤약초무침', '오징어국', '주꾸미볶음', '시금치프리타타', '물미역', '달래된장국', '동파육', '새송이버섯전', '파채콩나물무침', '민물새우찌개', '부추생채', '쌈무', '훈제오리구이', '어묵볶음', '순두부찌개', '간장마늘치킨', '오징어초무침', '무나물', '콩나물국', '언양식불고기', '꽃게탕', '날치알계란찜', '호박나물', '동그랑땡전', '오징어볶음', '쇠고기미역국', '무쌈말이', '돼지갈비찜', '아욱된장국', '참나물무침', '콩나물겨자채', '파래김', '연근땅콩조림', '어묵국', '닭볶음탕', '사골떡국', '한방소갈비찜', '식혜', '오이무침', '김치전', '굴비구이', '무생채', '곤드레밥', '청량된장찌개', '궁중떡볶이', '깍두기', '고구마그라탕', '제육볶음', '콩가루배추국', '모둠쌈', '깍두기', '깐풍기', '매운콩나물무침', '부대찌개', '곤약어묵볶음', '청경채사과생채', '황태국', '소불고기', '계란찜', '유채나물', '근대국', '비엔나케찹볶음', '양파치킨', '콩나물밥', '참나물생채', '맑은국', '해물까스', '고추잡채', '참치야채전', '봄동된장국', '오징어돈육볶음', '호박나물', '명태코다리강정', '모둠버섯볶음', '양념깻잎지', '차돌박이찌개', '유자청제육볶음', '아욱국', '숙주나물', '해물파전', '참나물땅콩무침', '꽃게탕', '쫄면무침', '미니채소떡갈비', '요플레', '가쯔오장국', '나물비빔밥', '마늘쫑볶음', '치킨핑거', '알타리김치', '해파리냉채', '통도라지구이', '쇠고기장조림', '된장찌개', '육개장', '탕수어', '버섯잡채', '무생채', '쇠고기숙주볶음', '세발나물무침', '골뱅이무침', '북어국', '오징어볶음', '고기전', '봄동겉절이', '시금치된장국', '과일탕수육', '맑은국', '단무지', '짜장덮밥', '개성감자만두', '돈육굴소스볶음', '김치콩나물국', '모듬쌈', '황태양념구이', '늙은호박전', '순살파닭', '오이사과무침', '연두부탕', '참나물무침', '가래떡돼지갈비찜', '봄동된장국', '콩나물겨자채', '새송이버섯전', '어묵국', '닭볶음', '가지나물', '알타리김치', '김치제육덮밥', '양장피잡채', '미소장국', '계란찜', '아삭고추무침', '매콤미니함박', '삼치구이', '부추생채', '닭곰탕', '표고버섯탕수육', '숙주나물', '해물김치전', '차돌박이찌개', '돈육볶음', '시래기조림', '홍어채무침', '순두부찌개', '콩나물무침', '참치야채전', '쇠고기장조림', '해물된장찌개', '알타리김치', '콩나물밥', '유부주머니국', '언양식불고기', '치즈계란말이', '도라지오이무침', '열무된장국', '연두부', '동파삼겹수육', '양념깻잎지', '깍두기', '메밀전', '도토리묵무침', '해물청경채볶음', '부대찌개', '닭갈비', '실곤약초무침', '양배추쌈', '차돌박이찌개', '아욱된장국', '쑥갓두부무침', '모둠버섯볶음', '사천식탕수육', '오징어숙회무침', '버섯불고기', '취나물', '떡국', '부추생채', '쌈무', '들깨미역국', '두부양념조림', '훈제오리구이', '짬뽕불고기', '늙은호박전', '청경채사과무침', '배추된장국', '알타리김치', '카레덮밥', '파스타샐러드', '맑은국', '고구마치즈구이', '오이무침', '마늘치킨', '모둠묵', '미역줄기볶음', '콩나물국', '깍두기', '맛살냉채', '시금치된장국', '등갈비김치찜', '쫑상추무침', '새송이버섯전', '치커리무침', '황태국', '소고기숙주볶음', '돼지갈비찜', '아욱된장국', '곰피초장', '마늘쫑볶음', '어묵국', '곤드레밥', '콩조림', '도토리묵무침', '치킨핑거', '차돌박이된장찌개', '오징어숙회무침', '구이김', '조기구이', '보름나물', '오곡밥', '부럼', '청경채생채', '소고기장조림', '해파리냉채', '해물순두부찌개', '알타리김치', '근대된장국', '닭강정', '단배추나물', '치킨무', '해물파전', '콩나물밥', '얼갈이나물', '삼치구이', '가쯔오국', '떡잡채', '깍두기', '간장깻잎지', '탕평채', '홍합탕', '오리불고기', '쇠고기샤브국', '두부새싹구이', '주꾸미볶음', '참나물무침', '시금치프리타타', '부추생채', '버섯불고기', '배추된장국', '쇠고기무국', '우엉잡채', '미트볼케찹조림', '가지나물', '깍두기', '시래기지짐', '탕수어', '두부', '시금치된장국', '닭데리야끼조림', '숙주나물', '어묵볶음', '동태탕', '얼갈이국', '세발나물', '동그랑땡전', '오징어볶음', '어묵국', '골뱅이무침', '돈육간장볶음', '무나물', '고기전', '견과류조림', '해물누룽지탕', '된장찌개', '닭볶음탕', '도토리묵무침', '쇠고기미역국', '양배추쌈', '깍두기', '청경채나물', '우거지해장국', '코다리강정', '계란말이', '참나물생채', '열무된장국', '수제돈까스', '메추리알곤약조림', '닭갈비', '새송이버섯조림', '치커리사과무침', '차돌박이찌개', '흑임자연근샐러드', '부추전', '등갈비김치찜', '알타리김치', '콩나물국', '오복지', '유부장국', '단호박카레라이스', '볼어묵볶음', '유린기', '얼큰소고기국', '숙주나물', '계란찜', '고추잡채', '참치김치찌개', '미니함박조림', '깍두기', '주꾸미볶음', '취나물무침', '알타리김치', '소고기낙지볶음', '들깨버섯국', '비엔나간장볶음', '아삭고추무침', '언양식불고기', '쑥갓두부무침', '잡채', '동태매운탕', '시저샐러드', '오징어숙회무침', '닭오븐구이', '가쯔오장국', '곤드레밥', '오꼬노미야끼계란말이', '쑥된장국', '오이도라지생채', '류산슬', '진미채무침', '열무김치', '연두부', '양념치킨', '수제비국', '제육볶음', '모듬쌈', '해파리냉채', '콩나물국', '참나물땅콩무침', '소고기장조림', '홍어채무침', '알타리김치', '민물새우찌개', '아욱국', '새싹두부구이', '오징어볶음', '해초무침', '코다리양념조림', '청경채사과무침', '모듬소시지구이', '순두부찌개', '근대국', '부추생채', '열무김치', '안동찜닭', '해물김치전', '짬뽕불고기', '버섯잡채', '청포묵무침', '배추된장국', '무채국', '두부조림', '양파절임', '쌈무', '훈제오리구이', '궁중떡볶음', '콩나물밥', '열무된장국', '오이미역무침', '치킨핑거', '실곤약초무침', '돈육간장볶음', '가지나물', '알탕', '야채계란찜', '돈육김치찌개', '가자미카레튀김', '쫑상추무침', '알타리김치', '오이도라지무침', '류산슬', '계란말이', '콩나물국', '깐풍기', '꽁치김치말이', '쇠고기미역국', '청경채새송이볶음', '떡밤초', '요플레', '유부장국', '오징어튀김', '비빔밥', '시래기국', '쑥갓두부무침', '닭매운찜', '호박전', '상추부추생채', '쫄면무침', '삼겹살구이', '알타리김치', '순두부찌개', '닭데리야끼조림', '꽃맛살볶음', '치커리무침', '어묵국', '오렌지', '유부장국', '김치제육덮밥', '양장피잡채', '오꼬노미야끼', '알타리김치', '열무김치', '수제돈까스', '도토리묵냉국', '어묵볶음', '오이미역무침', '무청된장국', '취나물무침', '임연수구이', '콩나물제육볶음', '시금치프리타타', '무생채', '버섯불고기', '배추된장국', '탕수어', '열무김치', '우엉잡채', '도라지무침', '돈육김치찌개', '돈육굴소스볶음', '근대국', '양배추쌈', '해파리겨자채', '두부계란부침', '소고기무국', '오징어볶음', '미역줄기볶음', '양파절임', '실곤약무침', '무쌈', '시금치된장국', '훈제오리구이', '새송이버섯전', '얼갈이된장국', '참나물생채', '열무김치', '등갈비김치찜', '어묵꽈리고추볶음', '카레덮밥', '맑은국', '고구마치즈구이', '오이무침', '탕평채', '영양부추무침', '닭볶음탕', '콩나물국', '차돌박이된장찌개', '주꾸미볶음', '동그랑땡전', '양념깻잎지', '짬뽕불고기', '상추파무침', '멸치볶음', '시래기들깨탕', '마늘치킨', '얼갈이된장국', '고추지무침', '곤드레밥', '오징어', '돼지갈비찜', '치커리생채', '두부구이', '조랭이떡국', '청경채무침', '꽁치오븐구이', '사과오이냉국', '떡갈비조림', '제육볶음', '미역국', '모듬쌈', '두부양념조림', '버섯잡채', '올방개묵무침', '해물청경채볶음', '김치찌개', '알타리김치', '콩나물밥', '파스타샐러드', '유부장국', '무생채', '수제돈가스', '오징어국', '깻잎지', '동파삼겹수육', '메밀부추전', '우거지해장국', '오이생채', '명태양념조림', '치킨핑거', '부추생채', '돈육간장볶음', '계란말이', '알타리김치', '콩나물국', '닭갈비', '해파리겨자채', '취나물', '된장찌개', '도라지생채', '갈치구이', '순두부찌개', '고추잡채', '완자전', '대구매운탕', '마늘쫑볶음', '곤약메추리알조림', '콩나물무침', '버섯불고기', '골뱅이무침', '배추된장국', '육개장', '청경채무침', '알타리김치', '고등어김치말이', '모듬소시지구이', '순살파닭', '근대국', '카레감자채볶음', '호박나물', '연두부', '오징어볶음', '부대찌개', '브로컬리맛살볶음', '미역국', '양파절임', '무쌈', '쫄면무침', '훈제오리구이', '꽃게탕', '삼치데리야끼', '비엔나케찹볶음', '아삭고추무침', '방울토마토', '땅콩조림', '열무비빔밥', '미니채소떡갈비', '깍두기', '팽이장국', '짬뽕불고기', '상추파무침', '오이냉국', '명란계란말이', '잡채', '닭개장', '도토리묵무침', '코다리강정', '닭갈비', '어묵국', '시금치프리타타', '해초무침', '생선커틀릿', '열무김치', '영양부추무침', '류산슬', '돈육김치찌개', '구운채소', '카레덮밥', '가쯔오장국', '오복지무침', '깐풍육', '매운돼지갈비찜', '도라지오이생채', '메추리알곤약조림', '들깨버섯국', '육개장', '메밀전병만두', '동태무조림', '올방개묵무침', '유자청제육볶음', '미역줄기볶음', '계란말이', '콩나물국', '아욱국', '소고기장조림', '가지나물', '홍어채무침', '알타리김치', '탕수어', '맑은국', '곤드레밥', '찐옥수수', '오이무침', '근대국', '닭볶음탕', '도라지나물', '해물파전', '매운어묵볶음', '도토리묵냉국', '동파삼겹수육', '쫑상추무침', '돈육굴소스볶음', '브로컬리오징어숙회', '숙주나물', '고추장찌개', '쇠고기매운국', '열무김치', '우엉잡채', '쌈무', '양파절임', '훈제오리구이', '미소장국', '나물비빔밥', '오징어튀김', '과일샐러드', '견과류조림', '깐풍기', '도토리묵', '호박잎된장찌개', '해파리겨자채', '콩나물무침', '어묵국', '연두부', '등갈비김치찜', '알타리김치', '실곤약야채무침', '동그랑땡전', '소불고기', '된장찌개', '수박', '참나물생채', '삼계탕', '찹쌀밥', '생야채', '석박지', '메추리알조림', '콩나물밥', '유부장국', '찐햇감자', '해물까스', '청경채무침', '부추전', '안동찜닭', '해물순두부찌개', '우무콩국', '유자청제육볶음', '통도라지구이', '호박잎', '돈육굴소스볶음', '어묵국', '간장깻잎지', '오징어야채무침', '함박스테이크', '삼치양념구이', '우거지해장국', '아삭고추무침', '쇠고기샤브국', '사각어묵볶음', '유린기', '오이사과생채', '콩나물냉채', '오이지냉국', '매운돼지갈비찜', '참나물땅콩무침', '주꾸미떡볶음', '새송이버섯전', '치커리유자청무침', '닭곰탕', '닭갈비', '시금치프리타타', '근대국', '도라지오이생채', '짬뽕불고기', '버섯잡채', '가지나물', '콩나물국', '감자만두', '오복지', '카레덮밥', '가쯔오장국', '과일', '떡갈비조림', '갈치양념조림', '옥수수전', '열무김치', '청경채사과무침', '돈육김치찌개', '닭오븐구이', '연두부탕', '브로컬리', '꽈리고추어묵조림', '알타리김치', '골뱅이무침', '콩나물김치국', '소불고기', '호박나물', '얼갈이된장국', '오징어볶음', '닭살겨자냉채', '미역줄기볶음', '맑은국', '찐옥수수', '열무보리비빔밥', '깐풍육', '꽃맛살샐러드', '미역오이냉국', '온두부', '양념깻잎지', '볶음김치', '돈육장조림', '굴비구이', '미트볼케찹조림', '사과맛살초무침', '된장찌개', '제육볶음', '참나물무침', '들깨버섯국', '계란찜', '차돌박이된장찌개', '열무김치', '쫄면야채무침', '해초무침', '해물누룽지탕', '아삭고추무침', '닭개장', '주꾸미굴소스볶음', '동태포전', '콩나물무침', '쇠고기단호박조림', '두부오꼬노미야끼', '알탕', '양파절임', '실곤약무침', '무쌈', '시금치된장국', '훈제오리구이', '양념두부조림', '미역국', '열무김치', '도라지나물', '소고기불고기', '영양모듬견과', '미소장국', '비빔밥', '궁중떡볶이', '해물까스', '무생채', '꽁치레몬구이', '동그랑땡', '된장찌개', '마늘치킨', '치커리생채', '우무묵냉국', '계란말이', '어묵볶음', '배추된장국', '홍어채무침', '돈육간장불고기', '쇠고기샤브국', '탕수어', '참나물땅콩무침', '쫄면무침', '메추리알조림', '콩나물밥', '과일샐러드', '팽이장국', '치킨핑거', '근대국', '마파두부', '숙주나물', '모듬장조림', '두부새싹구이', '도라지생채', '소고기낙지볶음', '조랭이떡국', '브로컬리오징어숙회', '버섯불고기', '취나물', '콩나물국', '야채스틱', '동파삼겹수육', '들깨시래기국', '녹두전', '무생채', '열무김치', '맑은국', '김치제육덮밥', '오징어튀김', '샐러드파스타', '연두부', '간장찜닭', '꽃게탕', '마늘쫑무침', '새송이버섯전', '미역국', '매운주꾸미볶음', '건파래무침', '연두부국', '감자채볶음', '돈육고추장불고기', '양배추쌈', '두부스테이크', '흑임자연근샐러드', '쇠고기미역국', '닭매운찜', '구운채소', '가쯔오장국', '오징어튀김', '오복지무침', '소불고기덮밥', '시래기국', '콩나물무침', '부추전', '등갈비김치찜', '상추파무침', '언양식불고기', '고추장찌개', '계란말이', '돈육굴소스볶음', '어묵국', '무생채', '골뱅이무침', '닭개장', '류산슬', '아삭고추무침', '김치전', '메밀전병만두', '카레덮밥', '유부장국', '감자프리타타', '쨔샤이무침', '과일', '파래김', '꽃게탕', '소고기장조림', '명태조림', '돼지갈비찜', '아욱된장국', '송편', '잡채', '식혜', '쭈꾸미숙회무침', '감자채볶음', '모듬쌈', '어묵탕', '돈육고추장불고기', '돈육강정', '맑은국', '곤드레밥', '오이초무침', '사과고구마그라탱', '청경채사과무침', '들깨버섯국', '오징어볶음', '단호박계란찜', '설렁탕', '야채스틱', '오징어젓무침', '과일', '석박지', '김치전', '열무된장국', '버섯불고기', '맛살겨자채', '깻잎지', '참나물생채', '우엉잡채', '매운소고기무국', '조기구이', '생선가스', '콩나물밥', '땅콩조림', '유부장국', '가래떡구이', '열무김치', '감자국', '김치제육볶음', '브로컬리들깨찜', '해물파전', '닭갈비', '연두부', '오징어국', '호박나물', '야채계란찜', '고추장찌개', '돈육간장불고기', '오이무침', '메밀전병만두', '파래김', '닭볶음탕', '콩비지찌개', '깍두기', '톳두부무침', '등갈비김치찜', '어묵볶음', '콩나물국', '시금치프리타타', '얼갈이국', '방풍나물', '쇠고기낙지볶음', '두부새싹구이', '근대국', '시금치나물', '오징어볶음', '콩나물무침', '황태국', '소불고기', '홍어채무침', '실곤약야채무침', '어묵국', '동파삼겹수육', '쫑상추무침', '반달호박나물', '수제돈가스', '닭살겨자채', '콩나물국', '시래기국', '새송이버섯전', '청경채생채', '마늘간장치킨', '참치야채전', '양파절임', '무쌈', '배추된장국', '훈제오리구이', '쇠고기샤브국', '오징어볶음', '단호박계란찜', '도라지초무침', '치커리생채', '매운콩나물국', '닭데리야끼구이', '해파리냉채', '탕평채', '맑은국', '곤드레밥', '오징어젓무침', '사천식탕수육', '닭갈비', '무생채', '미역국', '동태포전', '육개장', '연근조림', '고등어구이', '비엔나케찹볶음', '아삭고추무침', '골뱅이무침', '소고기불고기', '순두부찌개', '유채나물', '돈육강정', '청국장찌개', '두부양념조림', '콩나물밥', '치킨핑거', '얼갈이겉절이', '팽이장국', '꽃맛살샐러드', '유자청제육볶음', '상추무침', '오징어숙회무침', '아욱국', '깍두기', '언양식불고기', '도토리묵무침', '알탕', '부추깻잎전', '매운어묵볶음', '콩나물무침', '돈육굴소스볶음', '꽃게탕', '메추리알조림', '주꾸미볶음', '통도라지구이', '들깨시래기국', '카레덮밥', '파스타샐러드', '맑은국', '새우까스', '오이무침', '물파래무침', '두부구이', '닭볶음탕', '콩나물국', '근대국', '버섯불고기', '쫄면무침', '취나물', '닭갈비', '얼갈이국', '참나물생채', '감자프리타타', '짬뽕불고기', '늙은호박전', '연두부', '배추된장국', '군고구마', '가쯔오장국', '나물비빔밥', '오징어튀김', '과일샐러드', '어묵꽈리고추볶음', '두부김치국', '물미역', '레몬탕수육', '알타리김치', '계란말이', '매운버섯국', '해물누룽지탕', '얼갈이생채', '세발나물', '미역국', '쇠고기낙지볶음', '계란찜', '모듬버섯볶음', '도라지초무침', '유린기', '차돌박이찌개', '파래김', '언양식불고기', '주꾸미초무침', '유부장국', '단호박영양밥', '셀프무쌈말이', '오리불고기', '쫑상추무침', '콩나물국', '쇠고기모듬장조림', '동그랑땡전', '깻잎지', '떡만두국', '제육볶음', '감자그라탕', '아욱국', '콩나물파채무침', '시금치국', '메밀전', '도토리묵무침', '등갈비김치찜', '알타리김치', '콩나물밥', '가쯔오국', '실곤약초무침', '가자미튀김', '고추잡채', '매운어묵국', '참나물겉절이', '동파삼겹수육', '맛살전', '동태찌개', '두부조림', '방풍나물', '치즈함박스테이크', '짬뽕불고기', '메추리알조림', '건새우마늘쫑볶음', '콩나물국', '물파래무침', '닭볶음탕', '연두부탕', '해물김치전', '탕수어', '곤드레밥', '쫄면무침', '팽이장국', '치커리유자청생채', '돼지갈비찜', '두부새싹구이', '알타리김치', '근대국', '호박나물', '갈치양념조림', '닭개장', '고기전', '비트무생채', '매운어묵볶음', '부추생채', '열무된장국', '쌈무', '크리스마스케익', '훈제오리구이', '얼갈이나물', '돈육굴소스볶음', '골뱅이무침', '아욱국', '참나물땅콩무침', '오징어볶음', '계란말이', '순두부찌개', '유채나물', '버섯불고기', '해물동그랑땡', '고추장찌개', '감자채볶음', '돈육고추장불고기', '양배추쌈', '콩나물국', '떡국', '소갈비찜', '식혜', '해물파전', '도라지오이무침', '주꾸미초무침', '꽈리고추찜', '안동찜닭', '차돌박이찌개', '물미역무침', '언양식불고기', '삼치구이', '두부김치국', '시래기국', '쇠고기숙주볶음', '늙은호박전', '부추생채', '청경채생채', '고등어구이', '치즈함박스테이크', '콩나물국', '검정콩조림', '맑은국', '치킨핑거', '비빔밥', '하와이안샐러드', '육개장', '탕수육', '깍두기', '감자프리타타', '깻잎지', '메밀전', '꽃게탕', '시금치나물', '고추잡채', '돈육굴소스볶음', '감자채볶음', '마늘쫑무침', '알탕', '어묵국', '해파리냉채', '등갈비김치말이', '알타리김치', '치커리유자청생채', '군만두', '오렌지', '맑은국', '단무지', '짜장덮밥', '유산슬', '봄동된장국', '쇠고기낙지볶음', '두부스테이크', '오이무침', '순살파닭', '실곤약초무침', '우엉조림', '콩나물김치국', '버섯불고기', '오이사과무침', '야채계란찜', '고추장찌개', '새송이버섯전', '청경채생채', '닭볶음탕', '배추된장국', '알타리김치', '생선까스', '콩나물밥', '파스타샐러드', '맑은국', '오복지무침', '얼갈이국', '오징어초무침', '취나물', '누룽지탕수육', '짬뽕불고기', '멸치호두볶음', '도라지나물', '수제비국', '김치제육볶음', '사과고구마그라탱', '브로컬리들깨찜', '된장찌개', '돈육잡채', '유채나물', '새알만두국', '치킨무', '양파치킨', '카레덮밥', '유부장국', '쫄면무침', '새우까스', '오이무침', '비엔나감자볶음', '청국장찌개', '갈치구이', '콩나물겨자채무침', '간장깻잎지', '시금치국', '동파삼겹수육', '해물파전', '매운어묵볶음', '부추생채', '열무된장국', '쌈무', '훈제오리구이', '제육볶음', '황태국', '들깨버섯무침', '숙주나물', '알타리김치', '어묵국', '실곤약초무침', '소불고기', '계란말이', '물미역', '옥수수전', '돈육장조림', '순두부찌개', '메추리알조림', '낙지비빔밥', '맑은국', '고구마튀김', '오복지무침', '꽃게탕', '카레감자채볶음', '양배추쌈', '미니채소떡갈비', '연두부', '봄동된장국', '오징어볶음', '미역줄기볶음', '새송이버섯전', '유채나물', '치즈함박스테이크', '콩비지찌개', '굴비구이', '오징어야채무침', '구이김', '보름나물', '오곡밥', '부럼', '차돌박이찌개', '요플레', '김치찐만두', '무생채', '맑은국', '곤드레밥', '치킨핑거', '돼지갈비찜', '시금치프리타타', '아욱국', '오이무침', '알타리김치', '언양식불고기', '마늘쫑건새우볶음', '맛살냉채', '돈육김치찌개', '두부양념조림', '버섯불고기', '참나물', '고추장찌개', '미트볼칠리조림', '고등어구이', '숙주나물', '쇠고기미역국', '떡밤초', '유부장국', '음료', '오징어튀김', '비빔밥', '매운어묵볶음', '무말랭이', '콩가루배추된장국', '돈삼겹보쌈', '모듬쌈', '옥수수계란찜', '돈육간장불고기', '해물된장찌개', '육개장', '얼갈이나물', '삼치구이', '고추잡채', '닭가슴살냉채', '콩나물밥', '미역장국', '유채나물겉절이', '코다리강정', '알타리김치', '돌나물', '소고기낙지볶음', '녹두전', '북어해장국', '비엔나컬리플라워조림', '열무나물무침', '해물누룽지탕', '차돌박이찌개', '쇠고기숙주볶음', '어묵국', '건새우마늘쫑볶음', '감자프리타타', '쑥국', '풋마늘대무침', '안동찜닭', '해물김치전', '카레덮밥', '가쯔오장국', '무말랭이', '고구마치즈구이', '쫄면무침', '열무김치', '양념깻잎지', '갈치구이', '우거지해장국', '모듬소시지구이', '메밀전병만두', '열무된장국', '등갈비김치찜', '호박나물', '세발나물', '오징어숙회무침', '버섯불고기', '콩나물국', '동파육', '아욱국', '계란찜', '쫑상추무침', '시저샐러드', '야채튀김', '맑은국', '김치제육덮밥', '오이무침', '알타리김치', '깍두기', '오렌지', '바나나', '미역국', '한방소갈비찜', '동태전', '봄동겉절이', '새송이전', '식혜', '돈육굴소스볶음', '달래두부무침', '양배추쌈', '해물된장찌개', '두부구이', '꽃게탕', '방풍나물', '소고기장조림', '제육볶음', '얼갈이나물', '무채국', '들깨버섯무침', '가쯔오장국', '돈육칠리강정', '모듬묵샐러드', '숙주나물', '단호박영양밥', '열무김치', '매운돼지갈비찜', '부추팽이겉절이', '어묵탕', '야채계란말이', '미니함박조림', '셀프무쌈말이', '파래김', '알탕', '치커리무침', '황태국', '소고기숙주볶음', '계란찜', '궁중떡볶음', '참나물무침', '연두부탕', '오징어볶음', '순대볶음', '온두부', '곤드레밥', '들깨시래기국', '볶음김치', '쫄면', '야채비빔만두', '열무김치', '돈육김치찌개', '안동찜닭', '아삭고추무침', '짬뽕불고기', '간장깻잎지', '조랭이떡미역국', '맛살전', '새송이버섯전', '모듬쌈', '유자청돈육볶음', '된장찌개', '주꾸미볶음', '감자채볶음', '열무김치', '견과류조림', '순두부찌개', '오복지', '가쯔오장국', '나물비빔밥', '오징어튀김', '과일샐러드', '파스타샐러드', '수제돈까스', '오이무침', '콩나물국', '닭오븐구이', '치커리사과생채', '아욱국', '옥수수전', '매운어묵국', '시금치프리타타', '버섯불고기', '도라지오이생채', '고구마순나물', '열무된장국', '우엉잡채', '닭볶음탕', '계란장조림', '오징어볶음', '떡국', '양념깻잎지', '세발나물', '열무김치', '미트볼케찹조림', '매운버섯국', '어묵볶음', '군만두', '맑은국', '단무지', '짜장덮밥', '사천식탕수육', '양배추쌈', '유자청돈육볶음', '들깨시래기국', '콩나물겨자채', '골뱅이무침', '취나물무침', '쇠고기장조림', '된장찌개', '방울토마토', '언양식불고기', '미소장국', '카레라이스', '떡볶이', '두부카프레제', '열무김치', '두부김치국', '무나물', '해물누룽지탕', '돈육간장강정', '미역국', '황태양념구이', '숙주나물', '김치콩나물국', '부추생채', '버섯불고기', '계란찜', '연근조림', '모듬묵샐러드', '소고기샤브국', '오징어볶음', '치커리생채', '버섯볶음', '안동찜닭', '해물된장찌개', '사각어묵무침', '미니채소떡갈비', '단배추나물', '순두부찌개', '어묵국', '두부조림', '양파절임', '쌈무', '훈제오리구이', '요거트D', '콩나물밥', '메추리알조림', '가쯔오장국', '청경채생채', '치킨핑거', '상추쌈', '고추', '근대국', '마늘', '무말랭이무침', '보쌈', '참치김치찌개', '셀프무쌈말이', '깍두기', '실곤약초무침', '소고기장조림', '제육볶음', '아욱국', '호박나물', '해파리겨자채', '차돌된장찌개', '해물청경채볶음', '고기전', '미역줄기볶음', '치킨너겟', '연근땅콩조림', '가쯔오장국', '산채비빔밥', '콘샐러드', '돼지갈비찜', '연두부탕', '취나물', '계란말이', '탕수어', '버섯매운탕', '치커리유자청무침', '온두부', '볶음김치', '소고기숙주나물볶음', '코다리조림', '방풍나물', '된장찌개', '사각어묵볶음', '참나물생채', '열무김치', '수원왕갈비통닭', '해물순두부찌개', '연두부', '도토리묵야채무침', '꽃게탕', '새송이떡갈비구이', '시금치고추장무침', '소고기국', '돈육장조림', '가자미튀김', '땅콩조림', '낙지비빔밥', '부추전', '계란찜', '콩나물국', '시금치프리타타', '북어국', '돈육콩나물불고기', '쫑상추무침', '감자채전', '오이소박이', '오징어국', '안동찜닭', '수제돈가스', '마파두부', '배추된장국', '돈나물유자청무침', '육개장', '깍두기', '파래김', '야채비빔만두', '고등어구이', '함박스테이크', '봄나물비빔밥', '동태전', '맑은국', '마늘쫑무침', '짬뽕불고기', '메추리알조림', '모듬쌈', '콩나물국', '두부계란부침', '콩나물무침', '열무김치', '아욱국', '등갈비김치찜', '맑은국', '곤드레밥', '코다리조림', '과일샐러드', '계란말이', '버섯잡채', '언양식불고기', '고추장찌개', '오이무침', '매운어묵국', '골뱅이무침', '소불고기', '숙주나물', '땅콩조림', '열무김치', '연두부', '오징어볶음', '부대찌개', '맑은국', '김치제육덮밥', '사과고구마그라탕', '맛살냉채', '오복지무침', '깍두기', '닭볶음탕', '옹심이만두국', '신김치도토리묵', '치커리유자청생채', '오이냉국', '양념깻잎지', '사천식탕수육', '해물파전', '돼지고기유자청볶음', '열무된장국', '잡채', '취나물무침', '무생채', '매운돼지갈비찜', '흑임자연근샐러드', '북어해장국', '깐풍기', '물만두', '맑은국', '쨔샤이무침', '단무지', '짜장덮밥', '주꾸미볶음', '시금치프리타타', '감자국', '아삭고추무침', '사과오이초무침', '청국장찌개', '소고기장조림', '김치전', '어묵국', '소불고기', '옥수수계란찜', '가지나물', '참치김치찌개', '열무김치', '해파리냉채', '맛살전', '돈육장조림', '카레덮밥', '가쯔오장국', '무말랭이', '고구마치즈구이', '쫄면무침', '파래김', '양념치킨', '비엔나볶음', '소고기미역국', '콩나물밥', '치킨핑거', '얼갈이겉절이', '팽이장국', '꽃맛살샐러드', '매운어묵볶음', '청경채생채', '치즈함박스테이크', '순두부찌개', '우엉잡채', '사과오이냉국', '쇠고기낙지볶음', '쫑상추무침', '치킨너겟', '파스타샐러드', '맑은국', '찐옥수수', '마파두부덮밥', '짬뽕불고기', '감자채볶음', '열무된장국', '호박잎', '열무김치', '쌈무', '양파절임', '동그랑땡전', '김치두부국', '훈제오리구이', '부추겉절이', '버섯불고기', '오징어국', '꽃맛살볶음', '치커리유자청생채', '시래기국', '도라지생채', '닭볶음탕', '어묵꽈리볶음', '시저샐러드', '가쯔오장국', '열무보리비빔밥', '오복지무침', '깐풍육', '삼겹보쌈', '근대국', '무말랭이', '해물김치전', '수박', '초복특식', '삼계탕', '찹쌀밥', '생야채', '수제석박지', '돈육굴소스볶음', '시금치나물', '주꾸미야채무침', '차돌박이찌개', '닭갈비', '셀프무쌈말이', '열무김치', '간장두부조림', '북어계란국', '요플레', '야채튀김', '산채비빔밥', '미소장국', '아삭고추무침', '참나물생채', '모듬묵양념장', '돈육김치찌개', '미니채소떡갈비', '무생채', '비엔나감자볶음', '갈치구이', '소고기무국', '매운어묵국', '치킨샐러드', '소고기숙주볶음', '양파짱아찌', '깍두기', '파프리카잡채', '콩나물무침', '시금치된장국', '등갈비김치찜', '가쯔오국', '쫄면야채무침', '호두견과류강정', '카레라이스', '갈비통통만두', '코다리조림', '치커리사과무침', '매운소고기국', '유린기', '우묵냉국', '오이맛살초무침', '고구마함박스테이크', '김치전', '유자청제육볶음', '시금치국', '사과고구마그라탕', '오이무침', '콩나물무침', '사과오이냉국', '장어강정', '햄감자채볶음', '메밀전병만두', '오복지', '맑은국', '곤드레밥', '찐햇감자', '해물누룽지탕', '청경채생채', '닭볶음탕', '아욱국', '오징어브로컬리숙회', '꽈리고추찜', '미트볼케찹조림', '고추장찌개', '계란말이', '닭갈비', '실곤약흑임자무침', '건새우마늘쫑볶음', '콩나물국', '짬뽕불고기', '도토리묵냉국', '양배추쌈', '계란찜', '군만두', '맑은국', '단무지무침', '짜장덮밥', '고추잡채', '돼지갈비찜', '치커리유자청무침', '아욱국', '어묵볶음', '주꾸미볶음', '차돌된장찌개', '옥수수전', '양념깻잎지', '소고기숙주볶음', '고추잎나물', '모듬묵', '된장찌개', '언양식불고기', '꽃게탕', '감자프리타타', '깻잎찜', '올챙이만두국', '콩나물밥', '모히토과일샐러드', '쨔샤이무침', '유린기', '잡채', '닭개장', '쇠고기장조림', '비름나물된장무침', '해물겨자냉채', '시래기국', '유자청제육볶음', '연두부', '닭강정', '모듬소세지구이', '소고기미역국', '얼갈이겉절이', '요플레', '오징어튀김', '산채비빔밥', '미소장국', '아삭고추무침', '열무김치', '오꼬노미야끼계란말이', '오이도라지생채', '류산슬', '닭곰탕', '자반고등어구이', '숙주나물', '돈육김치찌개', '미니채소떡갈비', '함박스테이크', '콩나물무침', '꽃게탕', '사과고구마그라탕', '동태전', '버섯불고기', '레몬미역초무침', '고추장찌개', '오복지', '카레덮밥', '쫄면야채무침', '맑은국', '과일', '치킨핑거', '매운어묵볶음', '쌈무', '양파절임', '배추된장국', '훈제오리구이', '부추겉절이', '굴비구이', '비엔나컬리플라워볶음', '부대찌개', '김구이', '궁중떡볶음', '돈육김치볶음', '쫑상추무침', '들깨시락국', '참나물생채', '소고기장조림', '갈치무조림', '차돌박이찌개', '유부장국', '새송이너비아니구이', '양장피', '단호박영양밥', '오이무침', '호박부추전', '매운돼지갈비찜', '도토리묵야채무침', '토란국', '수제돈까스', '통도라지구이', '미역무침', '된장찌개', '짬뽕불고기', '버섯잡채', '김치콩나물국', '모듬쌈', '맑은순두부국', '감자프리타타', '청경채겉절이', '사천식탕수육', '송편', '생선까스', '갈비만두', '나물비빔밥', '과일', '식혜', '팽이장국', '황태국', '부추생채', '연두부', '쌈무', '훈제오리고추장볶음', '꽃게된장찌개', '돈육굴소스볶음', '꽃상추겉절이', '날치알계란찜', '탄두리치킨', '파스타샐러드', '오징어숙회무침', '과일', '소고기미역국', '오렌지주스', '쇠고기샤브국', '주꾸미볶음', '카레감자채볶음', '호박나물', '대패삼겹', '사각어묵무침', '열무된장국', '비름나물', '유자청제육볶음', '근대국', '동그랑땡전', '얼갈이겉절이', '얼갈이된장국', '버섯불고기', '골뱅이무침', '미역줄기볶음', '돈육강정', '맑은국', '곤드레밥', '사과고구마그라탕', '오복지무침', '깍두기', '마늘쫑무침', '콩나물김치국', '두부스테이크', '해물누룽지탕', '언양식불고기', '어묵국', '청경채생채', '계란말이', '짬뽕불고기', '콩가루배추국', '메추리알조림', '얼갈이겉절이', '닭갈비', '깍두기', '우엉잡채', '돈육김치찌개', '부추겉절이', '소불고기', '미역레몬초무침', '두부양념조림', '해물된장찌개', '돈육굴소스볶음', '마늘쫑건새우볶음', '콩비지찌개', '해파리겨자채', '새송이버섯전', '치커리사과무침', '마늘간장치킨', '동태탕', '청경채무침', '굴비구이', '미트볼조림', '옹심이만두국', '파스타샐러드', '매운돼지갈비찜', '아욱국', '건파래무침', '제육볶음', '감자채볶음', '야채스틱', '북어해장국', '닭갈비', '부추생채', '어묵볶음', '콩나물국', '콩나물밥', '돈육강정', '가쯔오국', '모히토과일샐러드', '쨔샤이무침', '치커리유자청무침', '해물굴소스볶음', '쇠고기두부찜', '알탕', '우거지된장국', '마늘쫑무침', '옥수수전', '쇠고기장조림', '훈제오리단호박볶음', '부추생채', '골뱅이무침', '양파절임', '고추장찌개', '짬뽕불고기', '잡채', '얼큰순두부찌개', '도토리묵무침', '메밀전병만두', '우동국', '단무지', '카레라이스', '유린기', '바나나', '열무김치', '등갈비김치말이', '계란말이', '숙주나물무침', '건새우아욱국', '생선까스', '갈비만두', '나물비빔밥', '식혜', '팽이장국', '메추리알조림', '유자청제육볶음', '모듬쌈', '소고기미역국', '두부새싹구이', '파래김', '열무김치', '오징어볶음', '된장찌개', '시저샐러드', '무비트생채', '맑은국', '마파두부덮밥', '치킨핑거', '매운콩나물국', '늙은호박전', '동파삼겹수육', '쫑상추무침', '수제피클', '음료', '딸기드레싱샐러드', '옛날돈까스', '옥수수스프', '감자범벅', '청경채사과생채', '근대국', '소고기낙지볶음', '계란찜', '콩나물무침', '순살파닭', '감자채볶음', '고추장찌개', '시금치프리타타', '열무김치', '가쯔오장국', '동태전', '김치제육덮밥', '오이무침', '물파래무침', '멸치호두볶음', '오징어국', '미니채소떡갈비', '미역장국', '멕시칸샐러드', '단무지', '사천식탕수육', '야채볶음밥', '진미채무침', '언양식불고기', '잡채', '돈육김치찌개', '주꾸미볶음', '차돌된장찌개', '옥수수전', '양념깻잎지', '돈육강정', '맑은국', '곤드레밥', '사과고구마그라탕', '오복지무침', '미역레몬초무침', '해물누룽지탕', '모듬소시지구이', '콩나물국', '나가사끼짬뽕국', '방울토마토', '피클', '김치볶음밥', '치킨텐더샐러드', '또띠아칩', '시금치프리타타', '김치콩나물국', '소고기장조림', '오이무침', '육개장', '탕수어', '온두부', '김치볶음', '참나물', '오이도라지무침', '닭강정', '콩나물밥', '청포묵무침', '미소장국', '실곤약흑임자무침', '비빔야채만두', '류산슬', '된장찌개', '아몬드멸치볶음', '생선까스', '카레덮밥', '쫄면야채무침', '맑은국', '과일', '버섯불고기', '고추장찌개', '계란말이', '아삭고추무침', '깍두기', '파래김', '마파두부', '김치두부국', '누룽지탕수육', '군만두', '나물비빔밥', '맑은국', '감자치즈구이', '치커리유자청생채', '열무김치', '청경채생채', '닭볶음탕', '아욱국', '해물파전', '군고구마', '과일', '모듬튀김', '미소장국', '콘샐러드', '오므라이스', '열무된장국', '우엉잡채', '쌈무', '양파절임', '훈제오리구이', '마늘쫑무침', '홍합탕', '마늘간장치킨', '부추전', '요플레', '열무김치', '계란', '김치볶음밥', '비트무생채', '콥샐러드', '팽이장국', '해물까스', '쇠고기샤브국', '닭갈비', '동태전', '가지나물', '깍두기', '근대국', '수제돈가스', '계란찜', '양념깻잎지', '시금치나물', '유자청돈육볶음', '들깨시래기국', '콩나물겨자채', '코다리조림', '치커리사과무침', '매운소고기국', '유린기', '유부장국', '새송이너비아니구이', '양장피', '단호박영양밥', '오이무침', '호박부추전', '굴미역국', '매운돼지갈비찜', '도토리묵야채무침', '참치김치찌개', '깍두기', '가지무침', '안동찜닭', '고추잡채', '훈제오리볶음', '열무된장국', '쌈무', '양파절임', '떡잡채', '무채국', '메추리알곤약조림', '소고기숙주볶음', '유채겉절이', '가래떡츄러스', '콩나물밥', '언양식불고기', '미소장국', '샐러드파스타', '대패삼겹', '연두부', '해물콩나물찜', '된장찌개', '두부커틀릿', '간장깻잎지', '감자양파국', '매운닭찜', '깍두기', '돈육김치볶음', '모듬쌈', '아욱국', '비엔나감자조림', '콩나물무침', '오징어국', '애호박전', '조각케익', '치킨핑거', '짬뽕불고기', '열무김치', '물미역', '녹두전', '된장찌개', '콘치즈오븐구이', '가쯔오장국', '파인애플볶음밥', '단무지무침', '사천식탕수육', '고추장찌개', '버섯불고기', '두부양념조림', '오이무침', '닭볶음탕', '배추된장국', '양배추쌈', '부추깻잎전', '제육볶음', '유채나물', '시금치프리타타', '떡국', '식혜', '탕수어', '마늘쫑무침', '과일샐러드', '미소장국', '비빔밥', '사각어묵볶음', '돈육김치볶음', '쫑상추무침', '된장찌개', '오이도라지무침', '감자채전', '순살파닭', '미역국', '돈육강정', '맑은국', '곤드레밥', '사과고구마그라탕', '오복지무침', '육개장', '치커리무침', '언양식불고기', '가자미튀김', '락교', '또띠아피자', '과일샐러드', '미소장국', '참치회덮밥', '근대국', '부추생채', '명이절임', '마늘쫑볶음', '훈제오리구이', '함박스테이크', '시래기국', '두부구이', '오이무침', '콩나물무침', '오징어숙회무침', '연두부탕', '고기전', '단호박영양밥', '깐풍두부', '묵은지닭찜', '해물된장찌개', '아삭고추무침', '김치필라프', '크림스프', '토마토스파게티', '수제피클', '열무김치', '콥샐러드', '닭갈비', '치커리사과유자청무침', '고등어구이', '순두부찌개', '콩나물냉채', '땅콩조림', '어묵국', '열무김치', '등갈비김치찜', '오이무침', '미역장국', '허니버터치킨', '모듬묵흑임자샐러드', '불고기비빔밥', '돼지갈비찜', '동태전', '아욱국', '시금치초무침', '오리고추장볶음', '미역오이초무침', '황태국', '어묵꽈리고추조림', '콩나물밥', '가쯔오장국', '청경채생채', '치킨핑거', '꽃맛살샐러드', '닭오븐구이', '달래두부무침', '시금치나물', '들깨시래기국', '계란국', '시저샐러드', '김치제육덮밥', '열무나물', '오징어튀김', '세발나물생채', '미역국', '쇠고기낙지볶음', '계란찜', '돈육강정', '모듬버섯볶음', '도라지초무침', '차돌박이찌개', '파래김', '언양식불고기', '주꾸미초무침', '유부장국', '단호박영양밥', '감자채볶음', '어묵탕', '동파삼겹수육', '오이무침', '굴비구이', '두부김치국', '미트볼조림', '보름나물', '오곡밥', '부럼', '유채나물', '매운콩나물국', '골뱅이무침', '소고기숙주볶음', '실곤약흑임자무침', '냉이된장찌개', '레몬탕수육', '양념깻잎지', '닭데리야끼조림', '바나나', '곤드레밥', '비빔야채만두', '팽이장국', '동태찌개', '사각어묵볶음', '돈육간장볶음', '쫑상추무침', '또띠아칩', '크림새우', '김밥볶음밥', '미니짬뽕', '하와이안샐러드', '쇠고기샤브국', '미역오이초무침', '유자청제육볶음', '우엉잡채', '주꾸미볶음', '차돌된장찌개', '고기전', '봄동겉절이', '메밀전병만두', '나물비빔밥', '도라지오이생채', '사과고구마그라탕', '미소장국', '간장마늘치킨', '근대국', '열무김치', '오징어초무침', '호박채나물', '짬뽕불고기', '새송이버섯전', '들깨미역국', '치커리만다린무침', '깍두기', '돈육김치볶음', '실곤약초무침', '계란찜', '된장찌개', '늙은호박전', '열무김치', '부추생채', '양파절임', '부대찌개', '훈제오리구이', '낙지비빔밥', '마늘쫑무침', '과일샐러드', '치킨텐더', '팽이장국', '닭갈비', '두부계란부침', '콩나물무침', '북어국', '세발나물생채', '아욱국', '소고기장조림', '황태양념구이', '소고기버섯볶음', '깍두기', '치커리유자청무침', '두부김치국', '모듬묵', '쇠고기무국', '꽃맛살볶음', '오징어볶음', '양념깻잎지', '콩나물밥', '갈치구이', '고추장찌개', '떡잡채', '오이무침', '미역국', '치킨무', '수원왕갈비통닭', '돌나물무침', '김치전', '쫄면야채무침', '곤드레밥', '돈육간장볶음', '브로컬리', '건새우아욱국', '소불고기', '옥수수계란찜', '오이도라지생채', '콩나물국', '대파육개장', '꼬들단무지무침', '가자미엿장조림', '청경채겉절이', '감자만두', '미소시루', '골뱅이야채무침', '애기새송이버섯볶음', '카레라이스', '꼬들빼기김치', '열무김치', '해물돼지갈비찜', '가지완자튀김', '순두부찌개', '설렁탕', '야채스틱', '석박지', '동태포전', '부추겉절이', '돈육굴소스볶음', '어묵국', '오징어숙회무침', '열무김치', '아삭고추쌈장무침', '시금치나물', '차돌박이숙주볶음', '브로컬리', '대구탕', '콩나물냉채', '레몬유린기', '조갯살무국', '고춧잎볶음', '마파두부덮밥', '짜장닭볶음', '햄계란말이', '콩비지찌개', '고추장고구마순무침', '칠리새우', '감자채볶음', '갈비탕', '풋마늘대무침', '시래기국', '미역초무침', '봄동전', '오리양념불고기', '깍두기', '김치고기전', '치커리사과무침', '소고기미역국', '해물누룽지탕', '유부주머니국', '파스타샐러드', '목살스테이크', '오이무침', '제육볶음', '모듬쌈', '배추된장국', '계란찜', '치킨너겟', '시저샐러드', '봄나물비빔밥', '맑은국', '마늘쫑무침', '주꾸미볶음', '우렁된장찌개', '오꼬노미계란말이', '연두부', '모듬버섯볶음', '고추장찌개', '안동찜닭', '참나물생채무침', '배추깻잎', '삼겹살수육', '들깨시래기국', '오복지무침', '참치김치볶음', '감자채볶음', '치커리오이무침', '경상도식소고기국', '등갈비김치찜', '살구복숭아주스', '고추튀김', '오이', '부추무침', '순대국밥', '백김치', '간장깻잎지', '미역국', '음료', '오리불고기', '후르츠탕수육', '유채나물무침', '두부양념조림', '꽃게된장국', '셀프무쌈말이', '닭강정', '계란국', '낙지비빔밥', '짜요짜요', '두부김치국', '영양부추생채', '소고기브로컬리볶음', '시금치부침개', '미니우동', '고구마고로케', '고기듬뿍카레라이스', '실곤약무침', '오렌지자몽샐러드', '오렌지', '아욱국', '치즈닭갈비', '숙주나물', '참치야채샐러드', '고구마치즈빵', '새우튀김', '열무김치', '홍초콩나물국', 'LA갈비구이', '청포도', '주꾸미세비체샐러드', '참나물땅콩가루무침', '해물잡채', '얼갈이겉절이', '전복장각삼계탕', '육전', '연어스테이크', '소고기당면국', '비트무피클', '바질페스토스파게티', '머위된장무침', '카프레제샐러드', '황태국', '야채계란말이', '오이사과생채', '우엉불고기', '깍두기', '오향장육', '꼬막미나리초무침', '베리베리샐러드', '멸치국수', '양배추', '식혜', '황태포무침', '오미자주스', '춘천닭갈비', '단호박견과류구이', '가지나물무침', '나주곰탕', '자몽에이드', '두릅새송이초무침', '고구마치즈돈까스', '연어훈제샐러드', '새우완자탕', '해물볶음우동', '알타리김치', '카레닭볶음', '모듬소세지버섯구이', '그린샐러드', '대구지리탕', '요거트드링킹', '문어오이미역초무침', '육개장', '양파호박채나물', '열무김치', '브로콜리새송이메추리알조림', '크란치바', '수원왕갈비', '홍삼', '황태채마늘쫑무침', '제첩두부국', '건강비빔밥', '깻잎전', '이벤트행사', '오이무초무침', '새우날치알볶음밥', '춘권튀김', '복숭아아이스티', '장어구이', '배추김치', '망고', '적포도', '버섯들깨국', '곰취', '콩나물부추무침', '배추김치', '삼겹살더덕고추장구이', '오렌지주스', '꼬시래기무초무침', '황도샐러드', '포도주스', '쫄면야채무침', '왕갈비탕', '석박지', '해물전', '프로바이오틱', '히레카츠', '양배추채무침', '과일', '견과류연근조림', '냉메밀소바', '깍두기', '치커리유자샐러드', '아욱수제비국', '크레미계란말이', '해물섞어찜', '통오이고추무침', '알로에주스', '백김치', '마시는요거트', '냉족발야채무침', '사과', '양념', '돈육김치찌개', '두부참치조림', '호박숙', '열무물국수', '새우튀김', '오징어링', '소갈비찜', '꽃맛살과일샐러드', '떡갈비', '감자채볶음', '인절미츄러스맛탕', '닭개장', '배즙', '골뱅이야채무침', '요플레', '파인애플', '소고기콩나물밥', '야채스틱', '들깨미역국', '바싹불고기', '고추장누들떡볶이', '블랙페퍼쉬림프', '꽈리고추찹쌀무침', '생선까스', '사과즙', '해초샐러드', '유부주머니된장국', '제육볶음', '시금치프리타타', '모듬쌈', '연두부탕', '닭볶음탕', '명엽채볶음', '도토리묵무침', '들깨수제비', '미역미소시루', '견과류멸치볶음', '비빔메밀면', '후르츠탕수육', '닭살카레라이스', '주꾸미볶음', '차돌된장찌개', '두부스테이크', '청경채만다린생채', '땅콩조림', '야채비빔만두', '맑은국', '소불고기덮밥', '어묵볶음', '짬뽕불고기', '매콤콩나물국', '연두부', '쫑상추무침', '시래기국', '청경채겉절이', '동그랑땡구이', '고추잡채', '꽁치한마리구이', '만두탕수육', '열무김치', '무채국', '곤드레밥', '쨔샤이무침', '깍두기', '간장깻잎지', '옥수수계란찜', '오징어볶음', '콩비지찌개', '레몬유린기', '두릅소고기샐러드', '유부장국', '오이지무침', '마파두부덮밥', '닭갈비', '셀프무쌈말이', '콩나물잡채', '소고기미역국', '사각어묵무침', '모듬야채쌈', '돈육고추장볶음', '된장찌개', '시저샐러드', '매실짱아찌', '가쯔오장국', '강된장', '열무보리비빔밥', '깐풍육', '육개장', '소고기장조림', '비름나물', '녹두전', '수박', '야채고로케', '베이컨김치볶음밥', '해물부추전', '냉모밀국수', '깍두기', '오이무침', '요구르트', '해물동그랑땡', '오삼불고기', '대구탕', '두부구이', '닭볶음탕', '시금치된장국', '미역줄기볶음', '깻잎순무침', '요구르트', '오이사과냉국', '나물비빔밥', '맛살떡샐러드', '치킨핑거', '굴비구이', '토마토프리타타', '매운소고기국', '도라지오이무침', '요구르트', '돈육버섯고추장덮밥', '참나물생채', '양파링카레튀김', '팽이무국', '모듬어묵볶음', '고구마순볶음', '메밀전병', '냉모밀국수', '매운돈갈비찜', '대파육개장', '어묵잡채', '콩자반', '홍어미나리초무침', '과일요거트샐러드', '요구르트', '부추고추전', '쫄면야채무침', '동태알탕', '카레라이스', '감자채파프리카볶음', '춘천닭갈비', '옥수수계란찜', '매운소고기무국', '물만두국', '콩나물맛살냉채', '핫도그', '양배추숙쌈', '오리불고기', '채소스틱', '매실음료', '통들깨부추무침', '오징어초무침', '한방설렁탕', '콩자반', '석박지', '시저샐러드', '닭볶음탕', '도라지오이초무침', '시금치된장국', '건새우호박채전', '무채와사비무침', '마카로니샐러드', '쌈채소', '맑은콩나물국', '돈육고추장볶음', '콩자반', '미역미소시루', '레몬유린기', '만두찜', '숙주미나리무침', '마파두부덮밥', '쭈꾸미삼겹고추장볶음', '건새우무채국', '두부커틀렛', '비타민흑임자샐러드', '쫑상추무침', '콩가루배춧국', '치커리만다린샐러드', '열기어구이', '무말랭이무침', '도토리묵', '비빔밥', '해물잡채', '장각삼계탕', '가지찜', '아삭고추쌈장무침', '깍둑오이초무침', '수제돈가스', '석박지', '양배추샐러드', '김치우동', '호박새우젓볶음', '돈육김치볶음', '호박맑은국', '두부맛전', '모둠채소무침', '타래과', '브로콜리숙회', '닭개장', '양장피', '치자밥', '꽃맛살샐러드', '고등어카레구이', '아욱국', '매운콩나물무침', '오리불고기', '오이소배기', '로스트치킨샐러드', '새싹샐러드', '병아리콩밥', '치킨무', '깻잎통닭', '소고기미역국', '콘슬로우', '김치전', '만가닥버섯불고기', '실곤약냉채', '열무나물', '해물수제비국', '양배추샐러드', '황태미역국', '얼갈이나물', '토마토스크램블', '안동찜닭', '기장밥', '가자미엿장구이', '꽈리고추감자조림', '호박된장찌개', '목살스테이크', '토마토샐러드', '우거지국', '보쌈김치', '삼겹살수육', '풋고추', '수박화채', '그린샐러드', '모둠쌈', '부추무침', '후라이드', '미나리초무침', '낙지비빔밥', '브로콜리깨소스무침', '그린샐러드', '팽이장국', '짜글이돼지찌개', '마늘종숙회', '양배추샐러드', '어묵고추장떡', '새우까스', '오리대패불고기', '열무나물', '김치두부국', '골뱅이채소무침', '견과류샐러드', '수수밥', '돈갈비찜', '삼색콜리', '오징어튀김', '냉이된장국', '오이양파무침', '탱크보이', '장어강정', '맑은콩나물국', '눈꽃치즈샐러드', '꽈리고추메추리알조림', '쭈삼불고기', '검정콩밥', '파프리카해초무침', '찐옥수수', '콜리샐러드', '분홍소시지전', '새송이전', '건새우아욱국', '유부채소겨자냉채', '닭다리바베큐오븐구이', '얼갈이된장국', '시리얼샐러드', '아귀순살찜', '근대나물', '생선까스', '뼈없는감자탕', '해파리무침', '양배추', '푸실리파스타샐러드', '렌틸콩밥', '수떡수떡화채', '매운쇠고기버섯볶음', '떡국', '더덕무침', '열무김치', '청경채깨장나물', '타꼬야끼', '그린샐러드', '오징어볶음', '북어채국', '황도샐러드', '참나물두부무침', '부들어묵볶음', '유부장국', '차조밥', '바베큐폭립', '브로콜리버섯볶음', '살살치킨', '사과푸딩샐러드', '부추와사비무침', '동태탕', '나쵸콥샐러드', '보리밥', '김말이튀김', '상추무침', '치즈닭갈비', '부대찌개', '단호박', '채소계란말이', '그린샐러드', '맑은버섯육개장', '고구마순무침', '매콤해물볶음', '깍두기', '갈릭버섯탕수', '마카로니콘샐러드', '검은깨올방개묵무침', '츄러스', '순남시래기국', '오리불고기', '요구르트', '오향장육', '어묵국', '고추지무침', '모둠쌈', '김치볶음', '크루통샐러드', '콩나물두루치기', '바지락미역국', '버섯메추리알장조림', '더덕오이생채', '고구마순볶음', '시리얼', '수수밥', '김치빈대떡', '카레닭찜', '시금치된장국', '얼갈이나물', '그린샐러드', '나주곰탕', '적어구이', '한식잡채', '석박지', '모닝샌드', '다슬기아욱국', '요구르트', '검정콩밥', '열무김치', '돈사태김치찜', '닭살겨자냉채', '삼색유자청무침', '견과류샐러드', '노각생채', '소불고기', '코다리강정', '순두부찌개', '요구르트', '황태콩나물해장국', '시금치프리타타', '가지고추장무침', '우무콩국', '황도샐러드', '우거지국', '기장밥', '매콤돼지갈비찜', '호박채나물볶음', '삼색만두채소무침', '바나나', '냉족발야채무침', '부추샐러드', '꽃맛살샐러드', '열무김치', '쫄면채소무침', '매운계란파국', '그린샐러드', '마파두부', '찰보리밥', '치킨핑거', '오징어초무침', '옹심이만두국', '양배추숙쌈', '대패삽겹숙주볶음', '딸기푸딩', '아욱된장국', '생선까스', '오이사과무침', '마카로니치즈범벅', '나쵸칩', '짬뽕국', '군만두', '취나물쌈장무침', '계란채소볶음밥', '짜장소스', '열대과일', '홍합살미역국', '매콤볼어묵볶음', '와사비무쌈', '수육', '수수밥', '콩나물볶음', '미나리초장무침', '그린샐러드', '돈육김치찌개', '수완왕갈비맛통닭', '참나물두부무침', '순대채소볶음', '잔치국수', '알타리김치', '사과나무주스', '오리고추장불고기', '모둠쌈', '미트볼채소볶음', '배추국', '견과류샐러드', '가자미엿장구이', '오이양파무침', '햇고구마오븐구이', '류산슬', '귀리밥', '순두부찌개', '유부장국', '할라피뇨채소피클', '목살찹스테이크', '쇠고기낙지볶음', '건새우호박볶음', '감자수제비국', '버섯국', '통도라지고추장구이', '시리얼샐러드', '비엔나떡조림', '병아리콩', '주꾸미브로콜리숙회', '옹심이만둣국', '춘천닭갈비', '청경채겉절이', '딸기푸딩', '김말이강정', '매운콩나물국', '수수밥', '참나물무침', '돈갈비찜', '과일샐러드', '오향장육', '부추고추장무침', '갈비탕', '한식잡채', '석박지', '실곤약야채무침', '북엇국', '겉절이김치', '콩나물파채불고기', '그린샐러드', '나쵸칩', '찰보리밥', '해물파전', '황도샐러드', '고구마순볶음', '감자조림', '닭다리살스테이크', '동태탕', '꽁치캔김치조림', '파프리카해초무침', '사과', '오리대패불고기', '떡만두국', '식혜', '춘권튀김', '쫄면채소무침', '건새우미역국', '매운소불고기', '치커리무침', '단호박카레라이스', '열무김치', '두부강정', '통계란꼬치어묵탕', '요거트파르페', '고추장누들떡볶이', '인절미', '바베큐장각오븐구이', '버섯초무침', '파프리카감자채볶음', '시금치샐러드', '꽃게탕', '총각김치', '우거지된장국', '렌틸콩밥', '부추무침', '닭살겨자냉채', '오이볶음', '훈제오리볶음', '시금치고추장나물', '찹쌀호떡', '김칫국', '배도라지주스', '수수밥', '알배기', '청양부추전', '장어고추장양념구이', '순남시래기국', '깻잎', '도라지나물볶음', '겉절이김치', '츄러스채소맛탕', '두부된장찌개', '만다린샐러드', '청경채무침', '두반장가지볶음', '돈갈비양념구이', '시리얼샐러드', '홍합살무국', '임연수무조림', '갈릭순살치킨', '열무김치', '매운쇠고기국', '브로콜리쌈장무침', '얼갈이된장국', '푸딩', '쌈추', '쭈꾸미삼겹살볶음', '단호박어묵탕수', '아귀콩나물찜', '요플레', '연근유자피클', '유부김칫국', '치킨까스', '크루통샐러드', '찰보리밥', '토마토계란볶음', '미역미소시루국', '핫도그', '차돌비빔국수', '쌈추겉절이', '견과류샐러드', '버섯잡채', '겉절이김치', '곤드레밥', '양념장', '돼지고추장불고기', '삼색물만두무침', '된장찌개', '북엇국', '춘천닭갈비', '오이생채', '건새우호박채전', '요구르트', '생선까스', '브로콜리숙회', '맑은콩나물국', '묵은지닭볶음탕', '기장밥', '감자고구마샐러드', '오삼불고기', '쇠고기미역국', '계란말이', '유부채소겨자무침', '삼계탕', '방풍나물', '고기완자전', '석박지', '깐풍기', '겉절이김치', '차조밥', '감자채볶음', '단감', '도토리묵', '적어양념장구이', '쇠고기숙주볶음', '무생채', '통들깨부추무침', '건새우아욱국', '얼갈이나물', '당면채소무침', '돼지김치찌개', '고구마오븐구이', '대패삼겹살볶음', '수수밥', '어묵고추장볶음', '동태매운탕', '상추', '전주비빔밥', '찰떡떡갈비조림', '모둠버섯볶음', '바지락냉이국', '과일그라탕', '완두콩밥', '물미역', '쇠고기낙지볶음', '홍합국', '알타리김치', '근대된장국', '수제탕수육', '치커리오이무침', '매콤해물볶음', '아욱된장국', '매운족발볶음', '돌나물유자청무침', '해물까스', '동파육', '겉절이김치', '꽈배기도넛', '청경채', '미역국', '도라지볶음', '귀리밥', '개성식메밀부침개', '참나물무침', '한방설렁탕', '골뱅이채소무침', '석박지', '북엇국', '수수밥', '타꼬야끼', '해물돼지갈비찜', '갓김치', '숙주미나리무침', '톳무침', '수제두부까스', '나쵸', '시금치된장국', '안동찜닭', '바나나', '호박된장찌개', '부추양파무침', '메추리알탕수', '오리주물럭', '겉절이김치', '미니버거', '알리오올리오파스타', '해파리냉채', '미소장국', '두부고기양념찜', '찰보리밥', '라면땅', '오이쑥갓생채', '비엔나채소볶음', '순두부찌개', '가자미유린기', '얼갈이된장국', '검정콩밥', '물미역', '쇠고기당면볶음', '제육고추장불고기', '황도샐러드', '황태채국', '쌈추', '콩나물파채무침', '어묵매운탕', '등심돈까스', '홍시', '솎음열무나물', '차조밥', '시금치나물', '코다리강정', '불낙찌개', '크루통샐러드', '수제과일잼샌드', '콩비지김치찌개', '탕평채', '고추장감자조림', '깍두기', '해물누룽지탕', '강낭콩밥', '겉절이김치', '취나물무침', '조갯살아욱국', '돼지간장불고기', '이연복의', '청경채찜', '팽이된장국', '오징어볶음', '고기완자전', '굴미역국', '쑥갓나물', '붕어빵', '눈꽃치즈샐러드', '닭간장조림', '스팸계란전', '오프룻요거트', '펜네파스타샐러드', '축하떡', 'LA갈비구이', '김치두부국', '삼색유자청무침', '한식잡채', '찰보리밥', '겉절이김치', '메밀전병', '채소프리타타', '산고추지무침', '팽이장국', '오향장육', '팥밥', '더덕구이', '양배추', '된장찌개', '육개장', '갈치감자조림', '톳두부무침', '두부구이', '유부주머니국', '삼겹살김치볶음', '어묵간장조림', '아귀콩나물찜', '우거지국', '꿀호떡', '기장밥', '훈제오리마늘볶음', '봄동나물', '겉절이김치', '만가닥버섯불고기', '호박고추장찌개', '크래미해초무침', '치즈계란찜', '제육고추장불고기', '북엇국', '수수밥', '고등어카레구이', '알배기', '깍두기', '근대국', '단호박채소전', '진미채오이무침', '닭다리살스테이크', '풋고추양파쌈장무침', '쫄면채소무침', '청포도주스', '석박지', '콩나물파채불고기', '차조밥', '굴떡국', '건취나물볶음', '과일샐러드', '쌈배추', '황도샐러드', '겉절이김치', '가자미무조림', '시금치나물', '해물완자전', '세발나물무침', '오이소박이', '문어꽈리고추조림', '그린샐러드', '청양고추계란말이', '달래무침', '동태알탕', '양배추샐러드', '수제돈까스', '새알팥죽', '오삼불고기', '바지락살무국', '유채나물무침', '소고기잡채', '매운쇠고기샤브샤브', '차조밥', '하와이언함박스테이크', '마늘바게트', '봄동겉절이', '냉이나물무침', '토마토두부카프레제', '마파무조림', '건새우아욱국', '고등어김치말이찜', '파래김', '오리대패불고기', '깍두기', '호박된장국', '오미산적', '소고기떡국', '동태전', '봉추찜닭', '콩나물잡채', '식혜', '유부된장국', '보리밥', '과일그라탕', '봄동숙', '돈육도라지고추장볶음', '콩샐러드', '아삭이고추된장무침', '오리들깨탕', '꽁치한마리레몬구이', '파프리카계란말이', '미니핫도그', '아욱된장국', '참치채소볶음', '수수밥', '무쌈채소말이', '목살스테이크', '매운소고기낙지볶음', '콩나물맑은국', '양배추쌈', '메추리알짜장떡볶이', '미역국', '오리대패불고기', '옥수수계란찜', '쪽파무침', '검정콩밥', '쑥갓나물', '콩나물볶음', '버블샐러드', '된장찌개', '타코야끼', '겉절이김치', '상추쌈', '돈육두루치기', '시금치된장국', '콩나물김칫국', '차조밥', '두부까스', '지중해샐러드', '소갈비찜', '매운호박볶음', '채소스틱', '뼈없는감자탕', '고등어구이', '솎음열무나물', '석박지', '어묵국', '바나나', '춘천닭갈비', '그린샐러드', '감자채카레볶음', '청경채나물', '기장밥', '치커리오이무침', '그린샐러드', '맑은콩나물국', '떡잡채', '삼겹살김치찜', '견과류마카로니범벅', '단호박물김치', '아욱국', '생깻잎지', '수제함박스테이크', '동파육', '수수밥', '청경채', '무생채', '봄동전', '냉이된장국', '전주비빔밥', '계란파국', '파프리카해초무침', '올방개묵무침', '요거닭', '연두부', '양념김', '봄동겉절이', '깐풍연근', '돈육간장불고기', '전주식콩나물해장국', '요구르트', '옥수수콘치즈구이', '가지고추장무침', '들깨미역국', '교촌간장치킨', '양배추샐러드', '귀리밥', '상추무침', '오꼬노미계란말이', '대구지리', '매운돈갈비찜', '수제삼색무쌈', '보리밥', '겉절이김치', '청양부추전', '우렁된장찌개', '오리주물럭', '동초나물무침', '가자미조림', '수제돈까스', '팽이장국', '시금치프리타타', '부추고추장무침', '오리대패불고기', '배추들깨국', '버섯탕수', '닭살데리야끼조림', '세발나물무침', '팥밥', '사과푸딩', '부대찌개', '알타리김치', '감자조림', '아욱국', '미나리나물', '매콤해물볶음', '콥샐러드', '고등어김치말이찜', '설렁탕', '볼어묵굴소스볶음', '차조밥', '브로콜리숙회', '석박지', '북엇국', '솎음열무나물무침', '닭볶음탕', '채소전', '감자양파국', '돈수육', '콩나물파채무침', '매콤어묵볶음', '적어양념장구이', '채소스틱', '기장밥', '겉절이김치', '도라지오이초무침', '장각백숙', '짬뽕국', '수제찹쌀꿔바로우', '단무지락교무침', '그린샐러드', '계란후라이', '유니짜장밥', '참나물겉절이', '한식잡채', '떡국', '소갈비찜', '육개장', '수박', '수수밥', '탕평채', '닭살겨자냉채', '오이스틱', '깍두기', '미니쌀국수', '동초나물무침', '삼겹살고추장구이', '스프링롤', '알타리김치', '김치어묵탕', '연근깨소스무침', '수원왕갈비통닭', '두부양념조림', '완두콩밥', '유부장국', '마약계란장조림', '해물누룽지탕', '김치전', '요구르트', '호박고추장찌개', '마카로니치즈범벅', '세발나물무침', '안동찜닭', '보리밥', '감자채전', '치커리무침', '파스타샐러드', '근대국', '등갈비김치찜', '깍두기', '쇠고기숙주볶음', '맛살계란말이', '물미역초고추장무침', '해물탕', '더덕양념구이', '생선까스', '그린샐러드', '나주곰탕', '석박지', '방풍나물무침', '옹심이국', '목살스테이크', '베이비크랩강정', '오곡밥', '부럼', '베이컨감자볶음', '아욱국', '치즈불닭', '매운콩나물무침', '양배추샐러드', '동파육', '느타리버섯볶음', '황태미역국', '참나물상추겉절이', '망고푸딩', '쑥갓두부무침', '수수부꾸미', '갈치조림', '매운쇠고기샤브샤브국', '알타리김치', '옥수수밥', '쑥국', '미나리나물', '닭다리튀김', '골뱅이채소무침', '얼갈이된장국', '깻잎무쌈', '오리불고기', '차조밥', '도라지오이생채', '갈비탕', '매생이전', '깍두기', '순살닭강정', '쥬시쿨', '봄나물비빔밥', '도토리묵', '수제고기육전', '콥샐러드', '냉이된장국', '콩가루배추국', '타워함박스테이크', '시금치고추장나물무침', '문어꽈리고추조림', '귀리밥', '목살구이', '겉절이김치', '어묵매운탕', '쌈채소', '부추무침', '유부채소겨자냉채', '근대된장국', '요구르트', '묵은지닭찜', '비엔나브로콜리볶음', '깍두기', '건다래순볶음', '대파육개장', '수수밥', '어묵잡채', '고등어구이', '콩샐러드', '제육미나리볶음', '겉절이김치', '물만둣국', '아삭이고추된장무침', '두부까스', '머위나물', '기장밥', '장각허브오븐구이', '열무된장국', '양배추샐러드', '수제오미산적', '버섯매운탕', '돈갈비찜', '그린샐러드', '오이생채', '마카로니콘샐러드', '황태국', '쇠고기납작당면볶음', '삼색유자청무침', '콩나물불고기', '요구르트', '깻잎쌈', '겉절이김치', '검정콩밥', '유채나물된장무침', '장어강정', '순남시래기국', '미역국', '비름나물', '바베큐폭립', '건새우호박채전', '차조밥', '쫄면채소무침', '아욱국', '취나물무침', '양배추샐러드', '짜파치킨', '소불고기', '가지나물', '풋마늘대무침', '돈육김치찌개', '깍두기', '세발나물무침', '요거트푸딩', '그린샐러드', '동태매운탕', '메추리알떡볶이', '차돌박이구이', '수제보쌈김치', '유부장국', '돈수육', '브로콜리땅콩소스무침', '모듬채소', '완두콩밥', '콩가루배추국', '버섯초장무침', '방풍나물', '허니순살치킨', '보리밥', '채소스틱', '바나나', '통들깨부추무침', '석박지', '순대국밥', '해물동그랑땡채소볶음', '김말이강정', '돈육춘장볶음', '닭개장', '꼬시래기무침', '춘천닭갈비', '오지치즈후라이', '쇠고기미역국', '가지두반장볶음', '돌나물초장무침', '시리얼샐러드', '깻잎완자전', '매콤소갈비찜', '귀리밥', '순두부백탕', '비빔냉면', '오이나물볶음', '겉절이김치', '돈육간장불고기', '냉이국', '맑은떡국', '유채나물무침', '가자미구이', '옥수수밥', '청포묵', '비름나물고추장무침', '사골우거지국', '그린샐러드', '석박지', '해물누룽지탕']\n",
            "1562\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yzk7UdDO1sS"
      },
      "source": [
        "def menu_making(col):\n",
        "    array = []\n",
        "    for i in col:\n",
        "        for j in i:\n",
        "            array.append(j)\n",
        "    return list(set(array))\n",
        "\n",
        "breakfast_s = menu_making(all_df['breakfast'])\n",
        "lunch_s = menu_making(all_df['lunch'])\n",
        "dinner_s = menu_making(all_df['dinner'])\n",
        "# print(breakfast_list[:10])\n",
        "# print(lunch_list[:10])\n",
        "# print(dinner_list[:10])\n",
        "# print(len(breakfast_list), len(lunch_list), len(dinner_list))\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoRizuLnTLA_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575f8c5e-18c5-4bfa-d7b9-f901ba12ae58"
      },
      "source": [
        "print(len(breakfast_s), len(lunch_s), len(dinner_s))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "794 1562 1568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OesmiY0_aypI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302ae00d-23f0-4515-9f13-4b71ecb936df"
      },
      "source": [
        "all_df['lunch'][0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['요구르트', '쇠불고기', '청포묵무침', '계란찜', '오징어찌개']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UF5VUheZh9BH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17fb88f4-3baa-47c6-e7af-155159c3be2e"
      },
      "source": [
        "all_df['dinner'][0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['육개장', '두부조림', '자반고등어구이', '건파래무침']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1hfDavyTdIf",
        "outputId": "603d129e-5169-424a-976f-712b842c9da9"
      },
      "source": [
        "train_df = all_df[:len(train_df)]\n",
        "test_df = all_df[len(train_df):]\n",
        "print(train_df.shape, test_df.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 15) (50, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieAC2UUXEObw"
      },
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rX1t1qf7kpum"
      },
      "source": [
        "## OneHot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJCwEIDGxK8G"
      },
      "source": [
        "from sklearn.decomposition import SparsePCA"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uWrSgG_HejCn"
      },
      "source": [
        "lunch_oh = pd.DataFrame(np.zeros([len(all_df), len(lunch_s)]), columns=lunch_s)\n",
        "dinner_oh = pd.DataFrame(np.zeros([len(all_df), len(dinner_s)]), columns=dinner_s)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKRCjSAagP5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa84f7da-880a-4e57-bd3c-448a9bb8b897"
      },
      "source": [
        "for i in range(len(all_df['lunch'])):\n",
        "    for m in all_df['lunch'][i]:\n",
        "        lunch_oh.loc[i, m] = 1\n",
        "\n",
        "lunch_oh.loc[0, all_df['lunch'][0]] "
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "청포묵무침    1.0\n",
              "오징어찌개    1.0\n",
              "계란찜      1.0\n",
              "요구르트     1.0\n",
              "쇠불고기     1.0\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b96szJflh6FX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5113172a-3579-4d9c-9d00-5abefed43ae2"
      },
      "source": [
        "for i in range(len(all_df['dinner'])):\n",
        "    for m in all_df['dinner'][i]:\n",
        "        dinner_oh.loc[i, m] = 1\n",
        "\n",
        "dinner_oh.loc[0, all_df['dinner'][0]] "
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "육개장        1.0\n",
              "건파래무침      1.0\n",
              "자반고등어구이    1.0\n",
              "두부조림       1.0\n",
              "Name: 0, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocFUKoHr-I7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        },
        "outputId": "11846b3c-8e58-4046-cf50-c8e78b62ca70"
      },
      "source": [
        "dinner_oh"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>우거지국</th>\n",
              "      <th>온두부</th>\n",
              "      <th>참나물겉절이</th>\n",
              "      <th>참치마요덮밥</th>\n",
              "      <th>비프스파게티</th>\n",
              "      <th>로제스파게티</th>\n",
              "      <th>모둠묵</th>\n",
              "      <th>미니버거</th>\n",
              "      <th>미더덕콩나물찜</th>\n",
              "      <th>비엔나볶음</th>\n",
              "      <th>너비아니</th>\n",
              "      <th>미니국수</th>\n",
              "      <th>비름나물</th>\n",
              "      <th>낙지젓무침</th>\n",
              "      <th>요플레</th>\n",
              "      <th>돈까스</th>\n",
              "      <th>돌나물</th>\n",
              "      <th>류산슬</th>\n",
              "      <th>시래기삼치조림</th>\n",
              "      <th>허니슈스트링감자</th>\n",
              "      <th>미니우동</th>\n",
              "      <th>후르츠탕수육</th>\n",
              "      <th>고등어김치찜</th>\n",
              "      <th>아오리사과</th>\n",
              "      <th>채소튀김</th>\n",
              "      <th>김가루잔파무침</th>\n",
              "      <th>절인고추</th>\n",
              "      <th>들깨버섯국</th>\n",
              "      <th>숯불양념꼬지어묵</th>\n",
              "      <th>바지락살국</th>\n",
              "      <th>장국</th>\n",
              "      <th>김치국</th>\n",
              "      <th>고추지무침</th>\n",
              "      <th>감자소세지볶음</th>\n",
              "      <th>치커리유자청무침</th>\n",
              "      <th>오이초무침</th>\n",
              "      <th>충무김밥</th>\n",
              "      <th>비빔야채만두</th>\n",
              "      <th>떡갈비주먹밥</th>\n",
              "      <th>오이양파무침</th>\n",
              "      <th>...</th>\n",
              "      <th>건도토리묵파프리카볶음</th>\n",
              "      <th>명엽채볶음</th>\n",
              "      <th>비엔나채소볶음</th>\n",
              "      <th>갓김치</th>\n",
              "      <th>어묵잡채볶음</th>\n",
              "      <th>볶음밥</th>\n",
              "      <th>동파육</th>\n",
              "      <th>언양식바싹불고기</th>\n",
              "      <th>연근조림</th>\n",
              "      <th>김치고기전</th>\n",
              "      <th>찐만두</th>\n",
              "      <th>녹두전</th>\n",
              "      <th>오징어순대볶음</th>\n",
              "      <th>맛살전</th>\n",
              "      <th>김계란말이</th>\n",
              "      <th>차돌비빔국수</th>\n",
              "      <th>배추된장국</th>\n",
              "      <th>부추생채</th>\n",
              "      <th>크래미오이보트샐러드</th>\n",
              "      <th>꼬치어묵탕</th>\n",
              "      <th>청양멸치주먹밥</th>\n",
              "      <th>황태해장국</th>\n",
              "      <th>치킨핑거</th>\n",
              "      <th>참나물생채</th>\n",
              "      <th>섭산적고추장구이</th>\n",
              "      <th>진미채무말랭이무침</th>\n",
              "      <th>해라피겨자채</th>\n",
              "      <th>제육춘장볶음</th>\n",
              "      <th>수제보쌈김치</th>\n",
              "      <th>고추잡채</th>\n",
              "      <th>김말이튀김</th>\n",
              "      <th>떡볶이</th>\n",
              "      <th>잔치국수</th>\n",
              "      <th>우엉잡채</th>\n",
              "      <th>미역국</th>\n",
              "      <th>고등어자반찜</th>\n",
              "      <th>도라지오이초무침</th>\n",
              "      <th>해물파전</th>\n",
              "      <th>꽁치김치찜</th>\n",
              "      <th>삼겹살구이</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1250</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1251</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1252</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1253</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1254</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1255 rows × 1568 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      우거지국  온두부  참나물겉절이  참치마요덮밥  비프스파게티  ...  고등어자반찜  도라지오이초무침  해물파전  꽁치김치찜  삼겹살구이\n",
              "0      0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "1      0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "2      0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "3      0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "4      0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "...    ...  ...     ...     ...     ...  ...     ...       ...   ...    ...    ...\n",
              "1250   0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "1251   0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "1252   0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "1253   0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "1254   0.0  0.0     0.0     0.0     0.0  ...     0.0       0.0   0.0    0.0    0.0\n",
              "\n",
              "[1255 rows x 1568 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G418AX-aivQO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e380fdae-0be2-4ac7-d81c-3b7ec4eb61c0"
      },
      "source": [
        "print(lunch_oh.shape, dinner_oh.shape)"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1255, 1562) (1255, 1568)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3RrU6zoFxgLy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "bcfd88c1-2163-4e1d-a503-f0503490f704"
      },
      "source": [
        "transformer = SparsePCA(n_components=10, random_state=0)\n",
        "transformer.fit(lunch_oh)\n",
        "lunch_pca = transformer.transform(lunch_oh)\n",
        "\n",
        "transformer = SparsePCA(n_components=10, random_state=0)\n",
        "transformer.fit(dinner_oh)\n",
        "dinner_pca = transformer.transform(dinner_oh)\n",
        "\n",
        "print(lunch_pca.shape, dinner_pca.shape)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-92-b16deec153f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtransformer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparsePCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdinner_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mdinner_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdinner_oh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_sparse_pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    191\u001b[0m                                                \u001b[0mcode_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                                                \u001b[0mdict_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                                                return_n_iter=True)\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         components_norm = np.linalg.norm(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36mdict_learning\u001b[0;34m(X, n_components, alpha, max_iter, tol, method, n_jobs, dict_init, code_init, callback, verbose, random_state, return_n_iter, positive_dict, positive_code, method_max_iter)\u001b[0m\n\u001b[1;32m    587\u001b[0m         code = sparse_encode(X, dictionary, algorithm=method, alpha=alpha,\n\u001b[1;32m    588\u001b[0m                              \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpositive_code\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                              max_iter=method_max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;31m# Update dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         dictionary, residuals = _update_dict(dictionary.T, X.T, code.T,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36msparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, n_nonzero_coefs, alpha, copy_cov, init, max_iter, n_jobs, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    316\u001b[0m                               \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                               \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                               positive=positive)\n\u001b[0m\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_dict_learning.py\u001b[0m in \u001b[0;36m_sparse_encode\u001b[0;34m(X, dictionary, gram, cov, algorithm, regularization, copy_cov, init, max_iter, check_input, verbose, positive)\u001b[0m\n\u001b[1;32m    130\u001b[0m                                    \u001b[0mprecompute\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                    positive=positive, max_iter=max_iter)\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mnew_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlasso_lars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, Xy)\u001b[0m\n\u001b[1;32m    965\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    966\u001b[0m         self._fit(X, y, max_iter=max_iter, alpha=alpha, fit_path=self.fit_path,\n\u001b[0;32m--> 967\u001b[0;31m                   Xy=Xy)\n\u001b[0m\u001b[1;32m    968\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    969\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, max_iter, alpha, fit_path, Xy)\u001b[0m\n\u001b[1;32m    924\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m                     \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_n_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m                     positive=self.positive)\n\u001b[0m\u001b[1;32m    927\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36mlars_path\u001b[0;34m(X, y, Xy, Gram, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0malpha_min\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_X\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_Gram\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy_Gram\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         return_n_iter=return_n_iter, positive=positive)\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_least_angle.py\u001b[0m in \u001b[0;36m_lars_path_solver\u001b[0;34m(X, y, Xy, Gram, n_samples, max_iter, alpha_min, method, copy_X, eps, copy_Gram, verbose, return_path, return_n_iter, positive)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn_samples\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mXy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         \u001b[0mCov\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tY5txXsjogu"
      },
      "source": [
        "all_df.drop(['breakfast', 'lunch', 'dinner'], axis=1, inplace=True)\n",
        "\n",
        "all_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zUPKCgbjzOx"
      },
      "source": [
        "print(all_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRyNzcxiiIKR"
      },
      "source": [
        "lunch_oh_df = pd.concat([all_df, lunch_oh], axis=1)\n",
        "dinner_oh_df = pd.concat([all_df, dinner_oh], axis=1)\n",
        "print(lunch_oh_df.shape, dinner_oh_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V_DSx7WkPYn"
      },
      "source": [
        "lunch_oh_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwhOouxwkVGN"
      },
      "source": [
        "dinner_oh_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjIOsxXbklAx"
      },
      "source": [
        "### train test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg4kiyspkwsS"
      },
      "source": [
        "l_oh_train_df = lunch_oh_df[:len(train_df)]\n",
        "l_oh_test_df = lunch_oh_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "d_oh_train_df = dinner_oh_df[:len(train_df)]\n",
        "d_oh_test_df = dinner_oh_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "\n",
        "print(l_oh_train_df.shape, l_oh_test_df.shape)\n",
        "print(d_oh_train_df.shape, d_oh_test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8baG6dOlfZC"
      },
      "source": [
        "lunch_X = l_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "lunch_y = l_oh_train_df['lunch_y']\n",
        "dinner_X = d_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "dinner_y = d_oh_train_df['dinner_y']\n",
        "for col in (lunch_X, lunch_y, dinner_X, dinner_y):\n",
        "    print(col.head(1))\n",
        "# 점심\n",
        "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(lunch_X, lunch_y, test_size=0.2, random_state=2021)\n",
        "# 저녁\n",
        "d_X_train, d_X_test, d_y_train, d_y_test = train_test_split(dinner_X, dinner_y, test_size=0.2, random_state=2021)\n",
        "\n",
        "col1 = [l_X_train, l_X_test, l_y_train, l_y_test]\n",
        "col2 = [d_X_train, d_X_test, d_y_train, d_y_test]\n",
        "for i, j in zip(col1, col2):\n",
        "    print('\\nlunch',i.shape)\n",
        "    print('dinner',j.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v-K9iwVumkLg"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F8FZ8uaomqG6"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "sampler = TPESampler(seed=10)\n",
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 14),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "    lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "    lgbm = lgbm_regr.fit(l_X_train, l_y_train , eval_set = [(l_X_train, l_y_train)], verbose=False)\n",
        "    mae = mean_absolute_error(l_y_test, lgbm.predict(l_X_test))\n",
        "    return mae\n",
        "        \n",
        "l_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxIVqV8UmpaK"
      },
      "source": [
        "sampler = TPESampler(seed=10)\n",
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "    lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "    lgbm = lgbm_regr.fit(d_X_train, d_y_train , eval_set = [(d_X_train, d_y_train)], verbose=False)\n",
        "    mae = mean_absolute_error(d_y_test, lgbm.predict(d_X_test))\n",
        "    return mae\n",
        "        \n",
        "d_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sr3P5SYwmoKS"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_lgb.best_trial.value, l_study_lgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_lgb.best_trial.value, d_study_lgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzYtZXcimnX3"
      },
      "source": [
        "l_trial_lgb = l_study_lgb.best_trial\n",
        "lunch_lgb_params = l_trial_lgb.params\n",
        "print(lunch_lgb_params)\n",
        "d_trial_lgb = d_study_lgb.best_trial\n",
        "dinner_lgb_params = d_trial_lgb.params\n",
        "print(dinner_lgb_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80m7UzzJnWXi"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl26eNqxnB59"
      },
      "source": [
        "lunch_lgb_model = lgb.LGBMRegressor(**lunch_lgb_params)\n",
        "lunch_lgb_model.fit(l_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1), l_oh_train_df['lunch_y'], eval_metric='mae')\n",
        "lunch_lgb_pred = lunch_lgb_model.predict(l_oh_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yy93HpdPnB4c"
      },
      "source": [
        "dinner_lgb_model = lgb.LGBMRegressor(**dinner_lgb_params)\n",
        "dinner_lgb_model.fit(d_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1), d_oh_train_df['dinner_y'], eval_metric='mae')\n",
        "dinner_lgb_pred = dinner_lgb_model.predict(d_oh_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF1OB4RxnB3C"
      },
      "source": [
        "print(lunch_lgb_pred)\n",
        "print(dinner_lgb_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5AJpcwRnB1T"
      },
      "source": [
        "lgb_submit = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "lgb_submit['중식계'] = lunch_lgb_pred\n",
        "lgb_submit['석식계'] = dinner_lgb_pred\n",
        "lgb_submit.to_csv(PATH + 'lgb_pca30.csv', index=False)\n",
        "lgb_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PN57jbVj_aV4"
      },
      "source": [
        "### MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUx86Y9Q_cF_"
      },
      "source": [
        "#trainset과 testset 분리\n",
        "l_oh_train_df = lunch_oh_df[:len(train_df)]\n",
        "l_oh_test_df = lunch_oh_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "d_oh_train_df = dinner_oh_df[:len(train_df)]\n",
        "d_oh_test_df = dinner_oh_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "\n",
        "print(l_oh_train_df.shape, l_oh_test_df.shape)\n",
        "print(d_oh_train_df.shape, d_oh_test_df.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iVEsCELe_evE"
      },
      "source": [
        "#정규화\n",
        "l_oh_train_df['lunch_y'] = StandardScaler().fit_transform(l_oh_train_df['lunch_y'].values.reshape(-1, 1))\n",
        "d_oh_train_df['dinner_y'] = StandardScaler().fit_transform(d_oh_train_df['dinner_y'].values.reshape(-1, 1))\n",
        "l_oh_train_df['year'] = LabelEncoder().fit_transform(l_oh_train_df['year'].values.reshape(-1, 1))\n",
        "l_oh_test_df['year'] = LabelEncoder().fit_transform(l_oh_test_df['year'].values.reshape(-1, 1))\n",
        "d_oh_train_df['year'] = LabelEncoder().fit_transform(d_oh_train_df['year'].values.reshape(-1, 1))\n",
        "d_oh_test_df['year'] = LabelEncoder().fit_transform(d_oh_test_df['year'].values.reshape(-1, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9NtqddN_g3s"
      },
      "source": [
        "lunch_X = l_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "lunch_y = l_oh_train_df['lunch_y']\n",
        "dinner_X = d_oh_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "dinner_y = d_oh_train_df['dinner_y']\n",
        "\n",
        "# 점심\n",
        "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(lunch_X, lunch_y, test_size=0.2, random_state=2021)\n",
        "# 저녁\n",
        "d_X_train, d_X_test, d_y_train, d_y_test = train_test_split(dinner_X, dinner_y, test_size=0.2, random_state=2021)\n",
        "print(l_X_train.shape,l_y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxNqavk6_kOG"
      },
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  l_X_train, l_y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFjfVoWn_i1-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jxm2zru1_lBW"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(l_X_train, l_y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6VX2KC__ltM"
      },
      "source": [
        "lunch_pred=model.predict(l_X_test)\n",
        "lunch_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPdRPioA_m8s"
      },
      "source": [
        "lunch_pred_e = np.std(all_df['lunch_y'][:1205]) * lunch_pred + np.mean(all_df['lunch_y'][:1205])\n",
        "lunch_pred_e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyWAwDWF_o56"
      },
      "source": [
        "l_y_test=np.std(all_df['lunch_y'][:1205])*l_y_test+np.mean(all_df['lunch_y'][:1205])\n",
        "l_y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBcuyuJC_h6T"
      },
      "source": [
        "print(mean_absolute_error(l_y_test,lunch_pred_e))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI4hHh1VAJ_y"
      },
      "source": [
        "lunch_sub=model.predict(l_oh_test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJtJF0pDARGX"
      },
      "source": [
        "lunch_sub_e = np.std(all_df['lunch_y'][:1205]) * lunch_sub + np.mean(all_df['lunch_y'][:1205])\n",
        "lunch_sub_e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSxvxA69ARm7"
      },
      "source": [
        "#모델생성\n",
        "model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu', input_shape=[len(dinner_X.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
        "\n",
        "model.compile(loss='mae',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egtCYegnAS-M"
      },
      "source": [
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "\n",
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  d_X_train, d_y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0,\n",
        "  callbacks=[PrintDot()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xe2KrL0KAUM3"
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(d_X_train, d_y_train,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=0, callbacks=[early_stop, PrintDot()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a53MA1UkAU1Y"
      },
      "source": [
        "dinner_pred=model.predict(d_X_test)\n",
        "dinner_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBBhPl1OAVkU"
      },
      "source": [
        "dinner_pred_e = np.std(all_df['dinner_y'][:1205]) * dinner_pred + np.mean(all_df['dinner_y'][:1205])\n",
        "dinner_pred_e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVzRQEK7AW-9"
      },
      "source": [
        "d_y_test = np.std(all_df['dinner_y'][:1205]) * d_y_test + np.mean(all_df['dinner_y'][:1205])\n",
        "d_y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeaSULj7AZ_T"
      },
      "source": [
        "dinner_sub_e=np.std(all_df['dinner_y'][:1205]) * dinner_sub + np.mean(all_df['dinner_y'][:1205])\n",
        "dinner_sub_e"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kkXy0_KAba8"
      },
      "source": [
        "# write submission\n",
        "DL_submit = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "DL_submit['중식계'] = lunch_sub_e\n",
        "DL_submit['석식계'] = dinner_sub_e\n",
        "DL_submit.to_csv(PATH + 'DL_base.csv', index=False)\n",
        "DL_submit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1GPduQpJRAD"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QenVYubKxB-"
      },
      "source": [
        "# HYPER PARAMETERS\n",
        "\n",
        "class CFG:\n",
        "    emb_dim = 500\n",
        "\n",
        "args = CFG"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yc8CWX-KFUk"
      },
      "source": [
        "def food_combinations(train=True):\n",
        "    col = ['breakfast', 'lunch', 'dinner']\n",
        "    array = []\n",
        "    if train:\n",
        "        for c in col:\n",
        "            for l in all_df[:len(train_df)][c]:\n",
        "                array.append(l)\n",
        "    else:\n",
        "        for c in col:\n",
        "            for l in all_df[len(train_df):][c]:\n",
        "                array.append(l)\n",
        "    print(len(array))\n",
        "    print(array[:3])\n",
        "    return array"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKOsHP6mJYbZ",
        "outputId": "1b0e3188-d977-4410-a8cf-cdb2079de48e"
      },
      "source": [
        "TRAIN_W2V = True\n",
        "\n",
        "try:\n",
        "    model = FastText.load(PATH + 'food_embedding.model')\n",
        "    print(\"Model loaded\")\n",
        "    if not TRAIN_W2V:\n",
        "        print('Training test set using current model')\n",
        "        test_food = food_combinations(train=False)\n",
        "        model.train(test_food, total_examples=len(test_food))\n",
        "\n",
        "except:\n",
        "    if TRAIN_W2V:\n",
        "        print(\"Training w2v\")\n",
        "        train_food = food_combinations(train=True)\n",
        "        model = FastText(\n",
        "            sentences=train_food, \n",
        "            vector_size=args.emb_dim, # 벡터 사이즈\n",
        "            window=30,\n",
        "            workers=-1,\n",
        "            sg=1, # 0: CBOW, 1: skip-gram\n",
        "            epochs=5000\n",
        "                         )\n",
        "        model.save(PATH + 'food_embedding.model')\n",
        "    else:\n",
        "        print(\"Load Model. Do not train.\")\n",
        "        "
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B1tTbqcTQ3q9",
        "outputId": "dfffb7f7-e1d5-4933-bf05-766dd7de277b"
      },
      "source": [
        "model.wv.most_similar('롤케익')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('메론롤케익', 0.2387872338294983),\n",
              " ('핫케익', 0.19615353643894196),\n",
              " ('팬케익', 0.16169056296348572),\n",
              " ('초코핫케익', 0.15142035484313965),\n",
              " ('크림스프', 0.14002297818660736),\n",
              " ('버섯잡채', 0.1309124380350113),\n",
              " ('우엉조림', 0.12402337789535522),\n",
              " ('오이도라지무침', 0.12099647521972656),\n",
              " ('돈육잡채', 0.11367535591125488),\n",
              " ('옛날돈까스', 0.11342933028936386)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gIbbvvmZPIc0",
        "outputId": "ae41f9a1-5cf9-4f65-d606-d15d5348b21d"
      },
      "source": [
        "model.wv.most_similar('돼지갈비찜')"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('매운돼지갈비찜', 0.5322608947753906),\n",
              " ('올챙이만두국', 0.15996651351451874),\n",
              " ('얼갈이된장국', 0.13743513822555542),\n",
              " ('새송이죽', 0.13469423353672028),\n",
              " ('만두국', 0.13191868364810944),\n",
              " ('미소장국', 0.12965227663516998),\n",
              " ('미역줄기볶음', 0.1141514703631401),\n",
              " ('감자양파국', 0.11404674500226974),\n",
              " ('알타리김치', 0.1116693913936615),\n",
              " ('낙지볶음', 0.11138071119785309)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7iBzm3GRt83",
        "outputId": "2bad2735-e0e1-4eea-a4b2-b2253cb9dbc7"
      },
      "source": [
        "model.wv.get_vector('쥐어채무침')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1.45557104e-04, -7.51849788e-04,  3.73546209e-04, -1.64353885e-04,\n",
              "       -1.85506666e-04, -3.40138540e-05,  1.26731815e-04, -4.77848575e-04,\n",
              "        2.34446234e-05,  1.23516656e-04,  4.93232103e-04, -3.80756072e-04,\n",
              "        5.31954574e-04,  3.23976565e-05, -2.46468757e-04, -3.67124245e-04,\n",
              "        1.37738258e-04, -1.71999229e-04,  2.53007838e-05, -1.36086412e-04,\n",
              "        3.71910864e-05,  1.31366818e-04, -1.64176919e-04, -4.08290100e-04,\n",
              "        2.66224291e-04, -2.81337008e-04,  1.35904455e-04,  3.09457449e-04,\n",
              "        4.96791035e-04, -1.18220807e-04,  4.33393907e-05,  7.40717514e-05,\n",
              "        4.08225926e-04,  3.40744184e-04,  3.91921290e-04, -6.15296769e-04,\n",
              "        5.62850910e-04,  1.57421760e-04, -6.50940128e-05,  1.22355152e-04,\n",
              "       -1.84530727e-04, -7.23127887e-05,  5.71310629e-05,  4.74386296e-04,\n",
              "        1.47279963e-04,  2.19473382e-04,  2.95773178e-04, -1.18978205e-04,\n",
              "       -7.20013777e-05, -2.30731006e-04, -4.65098419e-05, -6.74531184e-05,\n",
              "       -3.35399527e-04, -4.15096110e-05,  3.43277527e-04,  6.23917367e-05,\n",
              "       -4.97429341e-04,  2.90933876e-05,  2.48965836e-04,  1.83260432e-04,\n",
              "       -3.26388021e-04,  2.10088518e-04, -5.08380705e-04,  3.84086190e-04,\n",
              "       -6.07926122e-05, -3.58221849e-04, -8.10658821e-05, -2.36348787e-04,\n",
              "       -3.79990233e-04,  5.20749367e-04, -1.08171707e-05, -3.06877395e-04,\n",
              "        4.52326669e-04, -5.21017464e-05,  3.30893934e-04,  1.71198146e-04,\n",
              "        2.60321831e-04,  1.07766282e-04, -3.97863505e-06,  1.10637739e-04,\n",
              "        2.42501599e-04,  7.03896279e-04,  2.05621516e-04,  6.22783497e-04,\n",
              "       -3.71978880e-04, -5.20008616e-05,  7.87258614e-05, -2.97145889e-04,\n",
              "       -2.79661817e-05,  1.52775334e-04, -1.71048436e-04,  1.20045799e-04,\n",
              "        1.71150805e-05,  3.11910495e-04,  5.49323850e-05, -3.06820730e-04,\n",
              "        7.54535577e-05,  3.25720684e-05,  2.27719414e-04,  1.19444783e-04,\n",
              "       -2.02927273e-04,  2.95142177e-04, -3.74018884e-04, -5.45214571e-04,\n",
              "        1.96161112e-04, -1.13367489e-04,  3.47172376e-04, -7.40845644e-05,\n",
              "       -2.09133577e-04,  7.93414220e-05, -1.38685994e-06, -2.83755042e-04,\n",
              "       -2.15022330e-04,  3.00012063e-04, -1.09192979e-05, -3.11079260e-04,\n",
              "       -1.57748043e-04, -6.22309744e-04, -5.77308529e-04, -2.44175346e-04,\n",
              "        2.45203646e-05,  5.71256212e-04, -3.51136783e-04,  2.07540550e-04,\n",
              "        5.50658617e-04,  2.85605667e-04, -7.98689798e-05,  8.96698693e-05,\n",
              "       -1.77892623e-04, -4.80909192e-04,  3.79881567e-05, -2.86050981e-05,\n",
              "       -4.98503330e-04,  1.91196177e-05,  4.29044667e-05, -3.89924215e-04,\n",
              "        2.95759401e-05, -9.37837831e-05, -1.11265588e-04,  2.06258192e-04,\n",
              "        2.78992316e-04,  1.57385672e-04, -3.28150054e-04,  6.22709558e-05,\n",
              "        1.46788792e-04,  2.96120998e-04, -1.51990884e-04, -1.23041187e-04,\n",
              "       -1.12816291e-04,  5.07550314e-04,  8.33105514e-05, -2.51381745e-04,\n",
              "        6.01225591e-04, -3.98312055e-04, -3.55277698e-05,  5.63760077e-05,\n",
              "       -6.01630563e-05, -1.35035414e-04,  3.07594397e-04,  1.11598187e-04,\n",
              "        3.57856334e-04, -2.32994134e-04, -2.75708560e-04,  2.96777405e-04,\n",
              "        3.76991629e-05, -4.31953558e-05, -9.23604457e-05, -3.84215469e-04,\n",
              "       -5.54886530e-04,  3.17986734e-04, -3.74179304e-04,  2.28976758e-04,\n",
              "        1.01110862e-04,  1.94335458e-04,  4.31780005e-04,  5.54124526e-05,\n",
              "        4.11319546e-04,  6.64564795e-05, -6.21888670e-04, -4.40445438e-04,\n",
              "       -4.73155640e-04, -7.69861683e-04, -7.48987441e-05,  5.35501284e-04,\n",
              "       -2.53479287e-04,  4.34085989e-04,  3.95099574e-04,  1.12246989e-05,\n",
              "        5.30941936e-04,  6.49365946e-04, -7.83819196e-05,  6.36094483e-05,\n",
              "       -1.10733956e-04,  3.29208968e-04, -3.04656511e-04, -1.32503948e-04,\n",
              "        2.69527547e-04, -3.71697213e-04,  2.09930979e-04,  3.35857430e-06,\n",
              "        3.86331172e-04, -1.03143145e-06,  6.06760732e-04,  4.76462847e-05,\n",
              "        1.19535827e-04,  2.53625185e-04,  1.15675393e-04, -5.12804894e-04,\n",
              "       -4.80326067e-04,  5.89498959e-04, -5.76552993e-04, -4.05046652e-04,\n",
              "        1.77781665e-04, -2.31061131e-05, -5.78156963e-04,  8.18248373e-06,\n",
              "       -2.80810258e-04, -1.62264652e-04, -1.43689904e-04,  2.03118179e-04,\n",
              "       -1.66137863e-04, -5.21185575e-05, -2.09164267e-04,  3.12108081e-04,\n",
              "        3.34838347e-04, -3.66475288e-04, -2.38744964e-04, -4.63121483e-04,\n",
              "        3.90563189e-04, -3.03969777e-04, -9.96992912e-06,  4.11103974e-04,\n",
              "        1.77851951e-04,  3.60583479e-04,  5.60355220e-05, -1.06600499e-04,\n",
              "       -3.27220943e-04, -6.39547885e-04, -2.36198000e-04,  3.01620139e-06,\n",
              "        2.48025433e-04, -6.00480358e-04,  7.55437432e-05, -3.04806337e-04,\n",
              "        4.66143712e-04, -8.36601757e-05, -6.46656379e-04,  3.48311325e-04,\n",
              "        2.96698825e-04, -3.12711236e-05,  2.50344252e-04,  1.56153896e-04,\n",
              "        6.07237627e-04,  2.69500364e-04, -5.42382477e-04,  3.17437865e-04,\n",
              "        2.21631490e-04, -2.51929945e-04, -1.41125420e-04, -2.74145801e-04,\n",
              "       -3.61197308e-04, -9.15041310e-05,  8.38406340e-05, -1.68591854e-04,\n",
              "       -6.19818456e-05,  6.83611142e-05, -2.93809193e-04, -2.03202813e-04,\n",
              "       -7.02479738e-05, -5.25540905e-04,  2.69147742e-04, -2.04018693e-06,\n",
              "        1.03804174e-04,  3.77196156e-05,  2.36370863e-04, -3.04682850e-04,\n",
              "        3.17039288e-04, -1.22200217e-04, -1.23092323e-04,  2.13564635e-04,\n",
              "       -3.74240568e-04,  1.62515949e-04, -1.94457898e-04,  2.50265963e-04,\n",
              "       -5.86979906e-04, -1.08321154e-04, -1.21920959e-04, -5.94471639e-04,\n",
              "        2.80726381e-04,  5.44395414e-04, -9.96351446e-06,  1.88800579e-04,\n",
              "       -2.34905834e-04, -2.29574740e-04,  2.84140609e-04,  1.35437585e-06,\n",
              "       -3.17559607e-04,  9.38280937e-05, -3.85054940e-04,  2.90911383e-04,\n",
              "        2.83689849e-04,  2.65540264e-04,  1.62313692e-04,  2.01640694e-04,\n",
              "        1.70692307e-04,  5.37568740e-05,  3.56096920e-04,  2.67329251e-05,\n",
              "       -8.12193612e-05, -2.68691045e-04,  6.45532622e-04, -3.74031166e-04,\n",
              "       -5.63013833e-04,  1.21112818e-04,  6.49254362e-04,  6.28500347e-05,\n",
              "        8.74194448e-05, -2.74075050e-04, -4.48422943e-04, -2.64195667e-04,\n",
              "       -2.17622146e-05, -2.18340647e-04, -5.46799216e-04, -2.86195631e-04,\n",
              "       -5.81398723e-04,  8.59733191e-05,  1.45428145e-04, -5.11611754e-04,\n",
              "       -4.22635378e-04, -6.38214333e-05, -4.53530141e-04, -5.91626507e-04,\n",
              "        6.18870399e-05,  5.64252492e-04,  2.54700775e-04, -8.76809790e-05,\n",
              "        1.29948254e-04,  1.73388864e-04, -2.70187320e-05,  3.45455810e-05,\n",
              "       -1.68838495e-04,  7.01846511e-05, -6.64255567e-05,  2.16913322e-04,\n",
              "        6.90843561e-04,  2.89277901e-04,  6.88779328e-05, -1.27166946e-04,\n",
              "       -2.29432735e-05, -6.67495769e-04, -4.43771860e-04,  5.60928347e-05,\n",
              "        4.40390490e-04,  5.09036181e-04,  1.37988216e-04,  1.03576625e-04,\n",
              "        3.27388232e-04,  2.83246598e-04,  4.51983033e-05,  6.92542962e-05,\n",
              "       -3.95002171e-05,  3.29065224e-04,  8.70220247e-05, -6.47786947e-04,\n",
              "        1.79766110e-04,  1.01181860e-04, -3.61928978e-04,  3.71701608e-04,\n",
              "        8.67499839e-05,  1.09679262e-04,  2.25223819e-04, -1.94155014e-04,\n",
              "       -4.47539467e-04,  2.53088772e-04, -6.37923877e-05, -1.56884693e-04,\n",
              "        6.47652254e-04,  4.09645232e-04, -3.66528780e-04,  2.66321411e-04,\n",
              "        5.64173097e-05,  9.56660006e-05, -4.78338363e-04,  2.46162585e-04,\n",
              "       -1.83113647e-04,  2.24953274e-05, -2.45515053e-04, -3.14131583e-04,\n",
              "       -1.10452100e-04,  1.59858915e-04,  2.39184970e-04,  1.09371009e-04,\n",
              "       -4.79100068e-04, -1.30839719e-04, -4.03909100e-04, -3.63985921e-04,\n",
              "       -1.32463945e-04,  1.56792419e-04,  2.09960068e-04, -2.33545346e-04,\n",
              "       -2.54050501e-05,  1.66875398e-04, -8.94514233e-05,  1.15685827e-04,\n",
              "        3.53964278e-04,  5.38313998e-06,  4.07250511e-04, -3.26351204e-04,\n",
              "       -1.01522477e-04, -4.54049878e-04, -5.72253135e-04, -1.23680118e-04,\n",
              "        2.09634556e-04,  3.51196388e-04,  4.29208558e-05, -2.01405797e-04,\n",
              "       -5.54556202e-04, -1.00461883e-04,  1.02114202e-04, -2.73439709e-05,\n",
              "       -4.59206000e-04,  1.23540260e-04, -5.21491165e-04, -2.46771233e-04,\n",
              "        2.90365278e-04,  3.80608690e-04, -3.87171576e-06, -4.80645132e-04,\n",
              "       -2.38523338e-04, -8.88786872e-06,  2.94442929e-04,  9.40889076e-05,\n",
              "        4.76814603e-04,  3.70616384e-04,  1.76180009e-04,  1.08392991e-03,\n",
              "       -1.65637015e-04, -2.23426803e-04,  2.57746346e-04,  1.35626906e-04,\n",
              "        4.75250999e-05,  3.72045797e-05,  2.17571927e-04,  5.16607193e-04,\n",
              "       -2.19156282e-04, -2.28299323e-04,  2.04098877e-04,  1.88484890e-04,\n",
              "       -3.68136243e-04,  1.03079787e-04,  3.67816945e-04,  5.63233159e-04,\n",
              "       -2.53394333e-04,  1.71885258e-04, -3.74532938e-05,  7.42899792e-05,\n",
              "       -4.43977879e-05,  3.22895503e-04, -3.78004945e-04,  3.50348710e-04,\n",
              "       -1.03514169e-04, -7.22386321e-05,  5.50779048e-04, -3.10359988e-04,\n",
              "        8.59249674e-04,  5.42108610e-04, -1.77846261e-04,  2.06270255e-04,\n",
              "       -2.92934070e-04,  1.01768223e-04,  1.89053724e-04, -1.97371512e-04,\n",
              "        6.52993738e-04,  9.57368247e-05, -7.28572995e-05, -2.16612985e-04,\n",
              "       -4.05376777e-04,  2.25532727e-04, -2.20717004e-04,  5.48541255e-04,\n",
              "        3.91474721e-04, -5.23661904e-04,  7.45010504e-04, -1.80265743e-05,\n",
              "        2.95667007e-04, -1.55263944e-04, -1.91948930e-04, -1.38689400e-04,\n",
              "        1.59345756e-04, -1.57594957e-04, -1.49951942e-04, -6.67094078e-04,\n",
              "       -2.27852754e-04,  2.61143374e-04,  2.48977904e-05,  7.84324802e-05,\n",
              "       -1.10348352e-04, -1.93186730e-04, -1.94025852e-04, -1.20643912e-04],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6sogzjl-yjrr",
        "outputId": "14610520-964e-40e4-c0b5-407360a1ac09"
      },
      "source": [
        "train_df = all_df[:len(train_df)]\n",
        "print(train_df.shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMpL4vpfy6QJ"
      },
      "source": [
        "def food_embedding(menu_row):\n",
        "    vec_ = np.zeros(args.emb_dim)\n",
        "    for i in menu_row:\n",
        "        vec = model.wv.get_vector(i)\n",
        "        vec_ += vec\n",
        "    vec_ /= len(menu_row)\n",
        "    return vec_"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaMQLe2YzMEE",
        "outputId": "44250a04-1276-41e7-c5d8-8ed3c81cbccc"
      },
      "source": [
        "train_df['breakfast_embedding'] = train_df['breakfast'].apply(lambda x: food_embedding(x))\n",
        "train_df['lunch_embedding'] = train_df['lunch'].apply(lambda x: food_embedding(x))\n",
        "train_df['dinner_embedding'] = train_df['dinner'].apply(lambda x: food_embedding(x))\n",
        "y_lunch = train_df['lunch_y']\n",
        "y_dinner = train_df['dinner_y']\n",
        "\n",
        "train_df.drop(['breakfast', 'lunch', 'dinner', 'lunch_y', 'dinner_y'], axis=1, inplace=True)\n",
        "X_common = train_df.iloc[:, :10]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py:4174: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sxb-itPt3rhf"
      },
      "source": [
        "#### Fill nan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cc_iHbz1xVlM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bf0cf0-ab91-409f-e79f-26a0d99c1247"
      },
      "source": [
        "for i in range(len(train_df)):\n",
        "    if np.isnan(train_df['dinner_embedding'][i]).sum() != 0:\n",
        "        print(i,':', np.isnan(train_df['dinner_embedding'][i]).sum())\n",
        "        np.nan_to_num(train_df['dinner_embedding'][i], copy=False, nan=0.0)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "204 : 500\n",
            "224 : 500\n",
            "244 : 500\n",
            "262 : 500\n",
            "281 : 500\n",
            "306 : 500\n",
            "346 : 500\n",
            "392 : 500\n",
            "412 : 500\n",
            "424 : 500\n",
            "449 : 500\n",
            "468 : 500\n",
            "492 : 500\n",
            "510 : 500\n",
            "529 : 500\n",
            "549 : 500\n",
            "571 : 500\n",
            "586 : 500\n",
            "589 : 500\n",
            "609 : 500\n",
            "633 : 500\n",
            "648 : 500\n",
            "687 : 500\n",
            "872 : 500\n",
            "890 : 500\n",
            "912 : 500\n",
            "932 : 500\n",
            "955 : 500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ddcM-Tm2YHI",
        "outputId": "42b23cad-1e11-4ee4-b964-08341ad1bc2c"
      },
      "source": [
        "np.isnan(train_df['dinner_embedding'][i]).sum()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "wZV7sb8O1mZg",
        "outputId": "771b075e-9940-4ba2-ad7e-6665315a64ab"
      },
      "source": [
        "train_df.head(3)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>breakfast_embedding</th>\n",
              "      <th>lunch_embedding</th>\n",
              "      <th>dinner_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>[6.532135012093932e-06, 3.563666541595012e-05,...</td>\n",
              "      <td>[0.00011001809034496545, 0.0001505380787421018...</td>\n",
              "      <td>[2.6348612664151005e-05, 0.0001585289625154473...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>[9.996268490795047e-05, 1.1014865594916046e-05...</td>\n",
              "      <td>[9.597888783900999e-05, 2.8851501701865347e-05...</td>\n",
              "      <td>[-0.0002805278236337472, -0.000220696203905390...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>[8.358935374417343e-05, 0.00014487731968984007...</td>\n",
              "      <td>[4.817684839508729e-05, 0.00011808696035586763...</td>\n",
              "      <td>[-0.0003161334670949145, -7.0811178147778264e-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   vac_ratio  ...                                   dinner_embedding\n",
              "0   0.019223  ...  [2.6348612664151005e-05, 0.0001585289625154473...\n",
              "1   0.019223  ...  [-0.0002805278236337472, -0.000220696203905390...\n",
              "2   0.021530  ...  [-0.0003161334670949145, -7.0811178147778264e-...\n",
              "\n",
              "[3 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GA-V9HV85JFo"
      },
      "source": [
        "emb_arr_lunch = np.array(train_df['lunch_embedding'].to_numpy().tolist())\n",
        "emb_arr_dinner = np.array(train_df['dinner_embedding'].to_numpy().tolist())\n",
        "\n",
        "X_train_lunch = np.concatenate((X_common.to_numpy(), emb_arr_lunch), axis=1)\n",
        "X_train_dinner = np.concatenate((X_common.to_numpy(), emb_arr_dinner), axis=1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_otn0v9XhDi2",
        "outputId": "799c2db5-3fa6-4a60-e4e5-438a2c6be4f6"
      },
      "source": [
        "train_df['lunch_embedding'][0][-1]"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8.843973191687837e-05"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9XWvatkgYCb",
        "outputId": "d28eba57-a5b4-4179-99bc-72dd5c703a02"
      },
      "source": [
        "X_train_lunch"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.92233756e-02,  5.76701269e-02,  0.00000000e+00, ...,\n",
              "         1.42352910e-04, -1.39753064e-04,  8.84397319e-05],\n",
              "       [ 1.92233756e-02,  6.65128797e-02,  0.00000000e+00, ...,\n",
              "        -2.02547933e-05, -2.18011146e-05, -1.03104157e-04],\n",
              "       [ 2.15301807e-02,  6.92041522e-02,  0.00000000e+00, ...,\n",
              "        -3.64747272e-05, -5.40556211e-05,  5.69504112e-05],\n",
              "       ...,\n",
              "       [ 8.54844117e-02,  8.31377808e-02,  1.01575595e-01, ...,\n",
              "        -6.90102894e-05, -1.90945753e-05, -1.90992805e-04],\n",
              "       [ 3.58699296e-02,  5.12906470e-02,  1.09621187e-01, ...,\n",
              "        -1.65204966e-04,  6.27871777e-05,  2.63965631e-04],\n",
              "       [ 2.31310761e-02,  6.13476366e-02,  1.21354341e-01, ...,\n",
              "         2.28817392e-05,  8.53871448e-05, -5.36602965e-05]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Guu1ZcUqhAp"
      },
      "source": [
        "### train-test-split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6OtGNv-6SjY"
      },
      "source": [
        "X_train_lunch, X_test_lunch, y_train_lunch, y_test_lunch = train_test_split(X_train_lunch,\n",
        "                                                                            y_lunch,\n",
        "                                                                            test_size=0.2,\n",
        "                                                                            random_state=42)\n",
        "X_train_dinner, X_test_dinner, y_train_dinner, y_test_dinner = train_test_split(X_train_dinner,\n",
        "                                                                                y_dinner,\n",
        "                                                                                test_size=0.2,\n",
        "                                                                                random_state=42)\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcoaCn036byK",
        "outputId": "726c8d0b-f500-4c5e-f2de-4267d1b6d237"
      },
      "source": [
        "# Simple LGBM Regressor w/o tuning\n",
        "model_lunch = LGBMRegressor()\n",
        "model_lunch.fit(X_train_lunch, y_train_lunch)\n",
        "\n",
        "model_dinner = LGBMRegressor()\n",
        "model_dinner.fit(X_train_dinner, y_train_dinner)\n",
        "\n",
        "# Validate\n",
        "pred_lunch = model_lunch.predict(X_test_lunch)\n",
        "pred_dinner = model_dinner.predict(X_test_dinner)\n",
        "\n",
        "print(\"lunch mae: \", mean_absolute_error(y_test_lunch, pred_lunch))\n",
        "print(\"dinner mae: \", mean_absolute_error(y_test_dinner, pred_dinner))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lunch mae:  83.43456259137002\n",
            "dinner mae:  54.64887010569683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3wiYM7UQOyU"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "upcO8IUG65Xz",
        "outputId": "3dab689c-35ae-46c8-a932-153df112734c"
      },
      "source": [
        "# !apt-get -qq install --no-install-recommends nvidia-375\n",
        "# !apt-get -qq install --no-install-recommends nvidia-opencl-icd-375 nvidia-opencl-dev opencl-headers\n",
        "# !apt-get -qq install --no-install-recommends git cmake build-essential libboost-dev libboost-system-dev libboost-filesystem-dev\n",
        "# !pip3 install -qq lightgbm --install-option=--gpu\n"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pip/_internal/commands/install.py:283: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n",
            "  cmdoptions.check_install_build_global(options)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.7/dist-packages (3.2.1.99)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.36.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lightgbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.7/dist-packages (from lightgbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.0.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "5A5wk3QgQLnZ",
        "outputId": "7d91f1a7-094f-445c-a875-cd5cb7b087c6"
      },
      "source": [
        "# 점심\n",
        "from optuna.samplers import TPESampler \n",
        "sampler = TPESampler(seed=10)\n",
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'device': 'gpu',\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "    lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "    lgbm = lgbm_regr.fit(X_train_lunch, y_train_lunch , eval_set = [(X_test_lunch, y_test_lunch)], verbose=False)\n",
        "    mae = mean_absolute_error(y_test_lunch, lgbm.predict(X_test_lunch))\n",
        "    return mae\n",
        "        \n",
        "l_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-13 08:19:21,744]\u001b[0m A new study created in memory with name: no-name-9b8c144c-c638-469a-aea8-c75044085d17\u001b[0m\n",
            "\u001b[33m[W 2021-07-13 08:19:21,798]\u001b[0m Trial 0 failed because of the following error: LightGBMError('GPU Tree Learner was not enabled in this build.\\nPlease recompile with CMake option -DUSE_GPU=1')\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\", line 216, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"<ipython-input-39-50ef81c51035>\", line 25, in objective\n",
            "    lgbm = lgbm_regr.fit(X_train_lunch, y_train_lunch , eval_set = [(X_test_lunch, y_test_lunch)], verbose=False)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\", line 685, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\", line 544, in fit\n",
            "    callbacks=callbacks)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\", line 197, in train\n",
            "    booster = Booster(params=params, train_set=train_set)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\", line 1554, in __init__\n",
            "    ctypes.byref(self.handle)))\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\", line 46, in _safe_call\n",
            "    raise LightGBMError(decode_string(_LIB.LGBM_GetLastError()))\n",
            "lightgbm.basic.LightGBMError: GPU Tree Learner was not enabled in this build.\n",
            "Please recompile with CMake option -DUSE_GPU=1\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "LightGBMError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLightGBMError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-50ef81c51035>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0ml_study_lgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'minimize'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0ml_study_lgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    408\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mgc_after_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgc_after_trial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m             \u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshow_progress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    411\u001b[0m         )\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     73\u001b[0m                 \u001b[0mreseed_sampler_rng\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                 \u001b[0mtime_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0mprogress_bar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             )\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mtrial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mTrialState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAIL\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc_err\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/optuna/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-39-50ef81c51035>\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlgbm_regr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBMRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mlgbm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgbm_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_lunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_lunch\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0meval_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_lunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_lunch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlgbm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_lunch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmae\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    683\u001b[0m                                        \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m                                        \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                                        callbacks=callbacks)\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks)\u001b[0m\n\u001b[1;32m    542\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m                               \u001b[0mcategorical_feature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcategorical_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 544\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevals_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/engine.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, train_set, num_boost_round, valid_sets, valid_names, fobj, feval, init_model, feature_name, categorical_feature, early_stopping_rounds, evals_result, verbose_eval, learning_rates, keep_training_booster, callbacks)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# construct booster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0mbooster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_valid_contain_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0mbooster\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_train_data_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, params, train_set, model_file, silent)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                 \u001b[0mtrain_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0mc_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                 ctypes.byref(self.handle)))\n\u001b[0m\u001b[1;32m   1555\u001b[0m             \u001b[0;31m# save reference to data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_safe_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \"\"\"\n\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mLightGBMError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecode_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLightGBMError\u001b[0m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTiG7BGXQ4ht",
        "outputId": "e7db4f6b-0383-4079-fd68-5d2961d6d398"
      },
      "source": [
        "sampler = TPESampler(seed=10)\n",
        "def objective(trial):\n",
        "\n",
        "    param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'device': 'gpu',\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "    lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "    lgbm = lgbm_regr.fit(X_train_dinner, y_train_dinner , eval_set = [(X_test_dinner, y_test_dinner)], verbose=False)\n",
        "    mae = mean_absolute_error(y_test_dinner, lgbm.predict(X_test_dinner))\n",
        "    return mae\n",
        "        \n",
        "d_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:23:02,091]\u001b[0m A new study created in memory with name: no-name-2ceacf6b-7207-47a7-9fd3-91d20790ea2a\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5348779873185086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5348779873185086\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4656004675652718e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4656004675652718e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5188377188557745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5188377188557745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.014810344004555135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014810344004555135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:23:44,086]\u001b[0m Trial 0 finished with value: 97.37904480864037 and parameters: {'lambda_l1': 0.014810344004555135, 'lambda_l2': 1.4656004675652718e-08, 'num_leaves': 254, 'max_depth': 8, 'n_estimators': 2844, 'feature_fraction': 0.5348779873185086, 'bagging_fraction': 0.5188377188557745, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 0 with value: 97.37904480864037.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8875725769912681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875725769912681\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003040034742832493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003040034742832493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7675156400976328, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675156400976328\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.090008568091192e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.090008568091192e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:24:02,173]\u001b[0m Trial 1 finished with value: 47.76887888236263 and parameters: {'lambda_l1': 5.090008568091192e-08, 'lambda_l2': 0.003040034742832493, 'num_leaves': 382, 'max_depth': 3, 'n_estimators': 2902, 'feature_fraction': 0.8875725769912681, 'bagging_fraction': 0.7675156400976328, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8044801690398071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8044801690398071\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005207224083783965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005207224083783965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6650999046537976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6650999046537976\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21988367156694333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21988367156694333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:24:13,430]\u001b[0m Trial 2 finished with value: 50.92175652694735 and parameters: {'lambda_l1': 0.21988367156694333, 'lambda_l2': 0.005207224083783965, 'num_leaves': 218, 'max_depth': 3, 'n_estimators': 2305, 'feature_fraction': 0.8044801690398071, 'bagging_fraction': 0.6650999046537976, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.945189328485201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.945189328485201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015965313667163816, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015965313667163816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5915416533931271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5915416533931271\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00012738137732610437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00012738137732610437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:25:00,316]\u001b[0m Trial 3 finished with value: 49.955411271789416 and parameters: {'lambda_l1': 0.00012738137732610437, 'lambda_l2': 0.0015965313667163816, 'num_leaves': 241, 'max_depth': 8, 'n_estimators': 2943, 'feature_fraction': 0.945189328485201, 'bagging_fraction': 0.5915416533931271, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8915721974020412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8915721974020412\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.042604022999246406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042604022999246406\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5193685238072874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5193685238072874\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.163471763379958e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.163471763379958e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:25:35,973]\u001b[0m Trial 4 finished with value: 56.59483209001847 and parameters: {'lambda_l1': 8.163471763379958e-08, 'lambda_l2': 0.042604022999246406, 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 3055, 'feature_fraction': 0.8915721974020412, 'bagging_fraction': 0.5193685238072874, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6355175463679523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6355175463679523\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3318126555538504e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3318126555538504e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4560762247351902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4560762247351902\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010893853540963833, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010893853540963833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:25:51,148]\u001b[0m Trial 5 finished with value: 97.2302411208719 and parameters: {'lambda_l1': 0.010893853540963833, 'lambda_l2': 2.3318126555538504e-06, 'num_leaves': 354, 'max_depth': 5, 'n_estimators': 1409, 'feature_fraction': 0.6355175463679523, 'bagging_fraction': 0.4560762247351902, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5508244805242356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508244805242356\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.3581671060741645, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3581671060741645\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7584229889385306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7584229889385306\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.1828116394242723e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1828116394242723e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:26:24,813]\u001b[0m Trial 6 finished with value: 65.46295591306502 and parameters: {'lambda_l1': 1.1828116394242723e-05, 'lambda_l2': 0.3581671060741645, 'num_leaves': 396, 'max_depth': 6, 'n_estimators': 4253, 'feature_fraction': 0.5508244805242356, 'bagging_fraction': 0.7584229889385306, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5984315871892792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5984315871892792\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0618360930258403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0618360930258403e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8642981777263575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8642981777263575\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005267577135346555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005267577135346555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:26:34,924]\u001b[0m Trial 7 finished with value: 97.37929450899564 and parameters: {'lambda_l1': 0.0005267577135346555, 'lambda_l2': 2.0618360930258403e-08, 'num_leaves': 144, 'max_depth': 3, 'n_estimators': 2013, 'feature_fraction': 0.5984315871892792, 'bagging_fraction': 0.8642981777263575, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8579443522862087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8579443522862087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012357458041729475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012357458041729475\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.926857985634915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.926857985634915\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.3068536483753737e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3068536483753737e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:26:59,180]\u001b[0m Trial 8 finished with value: 52.89899697450681 and parameters: {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5818375363906209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5818375363906209\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0006063078395671604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006063078395671604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5452455252421164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5452455252421164\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0001281542517497079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001281542517497079\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:27:04,294]\u001b[0m Trial 9 finished with value: 83.51147514159052 and parameters: {'lambda_l1': 0.0001281542517497079, 'lambda_l2': 0.0006063078395671604, 'num_leaves': 106, 'max_depth': 5, 'n_estimators': 809, 'feature_fraction': 0.5818375363906209, 'bagging_fraction': 0.5452455252421164, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7649442484108072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7649442484108072\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.010479332494921e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.010479332494921e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7880669612015251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7880669612015251\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6785873892849563e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6785873892849563e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:27:27,940]\u001b[0m Trial 10 finished with value: 96.94951796164791 and parameters: {'lambda_l1': 1.6785873892849563e-08, 'lambda_l2': 3.010479332494921e-06, 'num_leaves': 341, 'max_depth': 4, 'n_estimators': 3558, 'feature_fraction': 0.7649442484108072, 'bagging_fraction': 0.7880669612015251, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9991122238129395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9991122238129395\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.61939793719469e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.61939793719469e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585514682875593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585514682875593\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.9826258759353e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.9826258759353e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:31:47,680]\u001b[0m Trial 11 finished with value: 91.93572631454262 and parameters: {'lambda_l1': 8.9826258759353e-07, 'lambda_l2': 2.61939793719469e-05, 'num_leaves': 287, 'max_depth': 9, 'n_estimators': 3632, 'feature_fraction': 0.9991122238129395, 'bagging_fraction': 0.6585514682875593, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9922869658927289, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9922869658927289\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.030766178350701442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030766178350701442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6307116556352568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6307116556352568\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0010032552297938406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010032552297938406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:32:32,735]\u001b[0m Trial 12 finished with value: 50.167622567307276 and parameters: {'lambda_l1': 0.0010032552297938406, 'lambda_l2': 0.030766178350701442, 'num_leaves': 311, 'max_depth': 9, 'n_estimators': 2453, 'feature_fraction': 0.9922869658927289, 'bagging_fraction': 0.6307116556352568, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.41844661211798795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41844661211798795\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00015468424548794194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00015468424548794194\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.995679260563783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995679260563783\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.9886276185414409e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9886276185414409e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:34:03,229]\u001b[0m Trial 13 finished with value: 77.61066725336029 and parameters: {'lambda_l1': 1.9886276185414409e-07, 'lambda_l2': 0.00015468424548794194, 'num_leaves': 387, 'max_depth': 7, 'n_estimators': 3556, 'feature_fraction': 0.41844661211798795, 'bagging_fraction': 0.995679260563783, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9290019894565231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9290019894565231\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9773722751809201, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9773722751809201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.750295356922126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750295356922126\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8821931552561775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8821931552561775e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:34:39,653]\u001b[0m Trial 14 finished with value: 76.56558180227766 and parameters: {'lambda_l1': 2.8821931552561775e-05, 'lambda_l2': 0.9773722751809201, 'num_leaves': 219, 'max_depth': 8, 'n_estimators': 1756, 'feature_fraction': 0.9290019894565231, 'bagging_fraction': 0.750295356922126, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7285367937084144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7285367937084144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.013133026541985783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013133026541985783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5989394570002292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5989394570002292\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0885522537644062e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0885522537644062e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:35:09,963]\u001b[0m Trial 15 finished with value: 53.95428675645124 and parameters: {'lambda_l1': 1.0885522537644062e-08, 'lambda_l2': 0.013133026541985783, 'num_leaves': 28, 'max_depth': 7, 'n_estimators': 3001, 'feature_fraction': 0.7285367937084144, 'bagging_fraction': 0.5989394570002292, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9592124084612702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9592124084612702\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4319355308173353e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4319355308173353e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4072835615446248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4072835615446248\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006757265265334436, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006757265265334436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:35:20,816]\u001b[0m Trial 16 finished with value: 94.3544823931873 and parameters: {'lambda_l1': 0.006757265265334436, 'lambda_l2': 3.4319355308173353e-05, 'num_leaves': 266, 'max_depth': 8, 'n_estimators': 2583, 'feature_fraction': 0.9592124084612702, 'bagging_fraction': 0.4072835615446248, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8133108831404763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8133108831404763\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.19063245323117958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19063245323117958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8359226382813782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8359226382813782\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4749952337893574, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4749952337893574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:35:47,115]\u001b[0m Trial 17 finished with value: 49.719587109631284 and parameters: {'lambda_l1': 0.4749952337893574, 'lambda_l2': 0.19063245323117958, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3778, 'feature_fraction': 0.8133108831404763, 'bagging_fraction': 0.8359226382813782, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8316902541307337, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8316902541307337\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1986749129458716, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1986749129458716\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.852102331897661, subsample=1.0 will be ignored. Current value: bagging_fraction=0.852102331897661\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.5341070393793969, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5341070393793969\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:36:11,759]\u001b[0m Trial 18 finished with value: 52.291706561206745 and parameters: {'lambda_l1': 0.5341070393793969, 'lambda_l2': 0.1986749129458716, 'num_leaves': 172, 'max_depth': 4, 'n_estimators': 4956, 'feature_fraction': 0.8316902541307337, 'bagging_fraction': 0.852102331897661, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6694741937620116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694741937620116\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.11960996313096185, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11960996313096185\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8451630348038253, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8451630348038253\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.045930843168940805, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.045930843168940805\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:36:35,714]\u001b[0m Trial 19 finished with value: 49.20060189715736 and parameters: {'lambda_l1': 0.045930843168940805, 'lambda_l2': 0.11960996313096185, 'num_leaves': 50, 'max_depth': 4, 'n_estimators': 4117, 'feature_fraction': 0.6694741937620116, 'bagging_fraction': 0.8451630348038253, 'bagging_freq': 7, 'min_child_samples': 8}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6616284774777149, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6616284774777149\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.987490648145755, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.987490648145755\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9431218324197076, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9431218324197076\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06110972033000234, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06110972033000234\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:36:44,658]\u001b[0m Trial 20 finished with value: 67.32672725792912 and parameters: {'lambda_l1': 0.06110972033000234, 'lambda_l2': 0.987490648145755, 'num_leaves': 85, 'max_depth': 4, 'n_estimators': 4900, 'feature_fraction': 0.6616284774777149, 'bagging_fraction': 0.9431218324197076, 'bagging_freq': 7, 'min_child_samples': 6}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7163764326313312, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7163764326313312\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.11833370762070886, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.11833370762070886\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8280028563619863, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8280028563619863\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.6043269799125948, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.6043269799125948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:37:11,798]\u001b[0m Trial 21 finished with value: 49.71352693874003 and parameters: {'lambda_l1': 0.6043269799125948, 'lambda_l2': 0.11833370762070886, 'num_leaves': 65, 'max_depth': 5, 'n_estimators': 4006, 'feature_fraction': 0.7163764326313312, 'bagging_fraction': 0.8280028563619863, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7171823115350269, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7171823115350269\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.009082605430143303, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009082605430143303\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7208568833639939, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7208568833639939\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.08640905100680656, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08640905100680656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:37:53,387]\u001b[0m Trial 22 finished with value: 48.29112346662752 and parameters: {'lambda_l1': 0.08640905100680656, 'lambda_l2': 0.009082605430143303, 'num_leaves': 54, 'max_depth': 4, 'n_estimators': 4299, 'feature_fraction': 0.7171823115350269, 'bagging_fraction': 0.7208568833639939, 'bagging_freq': 6, 'min_child_samples': 12}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.47455386592613363, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.47455386592613363\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00314070990870167, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00314070990870167\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7195681763827891, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7195681763827891\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.054682682011769165, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.054682682011769165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:38:35,587]\u001b[0m Trial 23 finished with value: 48.21082431437192 and parameters: {'lambda_l1': 0.054682682011769165, 'lambda_l2': 0.00314070990870167, 'num_leaves': 53, 'max_depth': 4, 'n_estimators': 4663, 'feature_fraction': 0.47455386592613363, 'bagging_fraction': 0.7195681763827891, 'bagging_freq': 7, 'min_child_samples': 5}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4683996773378838, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4683996773378838\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004995273723836076, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004995273723836076\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7164495813503993, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7164495813503993\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.001229428920796091, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001229428920796091\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:38:54,879]\u001b[0m Trial 24 finished with value: 48.77884689098011 and parameters: {'lambda_l1': 0.001229428920796091, 'lambda_l2': 0.004995273723836076, 'num_leaves': 111, 'max_depth': 3, 'n_estimators': 4595, 'feature_fraction': 0.4683996773378838, 'bagging_fraction': 0.7164495813503993, 'bagging_freq': 6, 'min_child_samples': 27}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4017352553190252, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4017352553190252\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0002720461052142622, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0002720461052142622\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6906591546336796, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6906591546336796\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1279842838011136, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1279842838011136\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:39:19,467]\u001b[0m Trial 25 finished with value: 68.98583952727458 and parameters: {'lambda_l1': 0.1279842838011136, 'lambda_l2': 0.0002720461052142622, 'num_leaves': 46, 'max_depth': 4, 'n_estimators': 4664, 'feature_fraction': 0.4017352553190252, 'bagging_fraction': 0.6906591546336796, 'bagging_freq': 7, 'min_child_samples': 41}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.49107055193415616, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.49107055193415616\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.004167918441471967, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.004167918441471967\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7260359759522813, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7260359759522813\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.002013932507979814, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002013932507979814\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:39:32,352]\u001b[0m Trial 26 finished with value: 49.54962824794456 and parameters: {'lambda_l1': 0.002013932507979814, 'lambda_l2': 0.004167918441471967, 'num_leaves': 3, 'max_depth': 3, 'n_estimators': 4982, 'feature_fraction': 0.49107055193415616, 'bagging_fraction': 0.7260359759522813, 'bagging_freq': 6, 'min_child_samples': 14}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7629207286501585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7629207286501585\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.467110111960925e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.467110111960925e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.788166151170405, subsample=1.0 will be ignored. Current value: bagging_fraction=0.788166151170405\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.043045946702427305, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.043045946702427305\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:39:48,577]\u001b[0m Trial 27 finished with value: 95.77766872799917 and parameters: {'lambda_l1': 0.043045946702427305, 'lambda_l2': 3.467110111960925e-05, 'num_leaves': 102, 'max_depth': 6, 'n_estimators': 828, 'feature_fraction': 0.7629207286501585, 'bagging_fraction': 0.788166151170405, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 47.76887888236263.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7723200694083914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7723200694083914\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.020294380954704445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020294380954704445\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.896142844640355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.896142844640355\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.005466400041817161, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005466400041817161\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:40:28,038]\u001b[0m Trial 28 finished with value: 46.693556662904754 and parameters: {'lambda_l1': 0.005466400041817161, 'lambda_l2': 0.020294380954704445, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 3318, 'feature_fraction': 0.7723200694083914, 'bagging_fraction': 0.896142844640355, 'bagging_freq': 5, 'min_child_samples': 5}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8824721302479381, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8824721302479381\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.026297390122741727, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.026297390122741727\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8931335900489045, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8931335900489045\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0058832030488215085, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0058832030488215085\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:40:38,316]\u001b[0m Trial 29 finished with value: 56.61575384528076 and parameters: {'lambda_l1': 0.0058832030488215085, 'lambda_l2': 0.026297390122741727, 'num_leaves': 3, 'max_depth': 5, 'n_estimators': 3259, 'feature_fraction': 0.8824721302479381, 'bagging_fraction': 0.8931335900489045, 'bagging_freq': 5, 'min_child_samples': 99}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7578988734031994, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7578988734031994\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015874060547836468, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015874060547836468\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9608951549867129, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9608951549867129\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00032468992645742415, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00032468992645742415\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:40:56,610]\u001b[0m Trial 30 finished with value: 52.26220852190318 and parameters: {'lambda_l1': 0.00032468992645742415, 'lambda_l2': 0.0015874060547836468, 'num_leaves': 83, 'max_depth': 3, 'n_estimators': 3311, 'feature_fraction': 0.7578988734031994, 'bagging_fraction': 0.9608951549867129, 'bagging_freq': 4, 'min_child_samples': 50}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6945472511209216, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6945472511209216\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.01793959518505903, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01793959518505903\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7916356014926801, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7916356014926801\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.013827748999144972, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.013827748999144972\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:41:20,911]\u001b[0m Trial 31 finished with value: 48.995837163352945 and parameters: {'lambda_l1': 0.013827748999144972, 'lambda_l2': 0.01793959518505903, 'num_leaves': 63, 'max_depth': 4, 'n_estimators': 2738, 'feature_fraction': 0.6945472511209216, 'bagging_fraction': 0.7916356014926801, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.77386956991685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.77386956991685\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.010551017003565703, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.010551017003565703\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6892608075458224, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6892608075458224\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1725550762863309, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1725550762863309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:41:59,163]\u001b[0m Trial 32 finished with value: 47.817977165866935 and parameters: {'lambda_l1': 0.1725550762863309, 'lambda_l2': 0.010551017003565703, 'num_leaves': 31, 'max_depth': 4, 'n_estimators': 3899, 'feature_fraction': 0.77386956991685, 'bagging_fraction': 0.6892608075458224, 'bagging_freq': 5, 'min_child_samples': 13}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7886759316540302, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7886759316540302\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00042632323819788935, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00042632323819788935\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6689339349573019, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6689339349573019\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.9675648318252044, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.9675648318252044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:42:21,833]\u001b[0m Trial 33 finished with value: 63.09543378226003 and parameters: {'lambda_l1': 0.9675648318252044, 'lambda_l2': 0.00042632323819788935, 'num_leaves': 30, 'max_depth': 3, 'n_estimators': 3947, 'feature_fraction': 0.7886759316540302, 'bagging_fraction': 0.6689339349573019, 'bagging_freq': 5, 'min_child_samples': 35}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8456275057228488, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456275057228488\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003159313370667438, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003159313370667438\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6224816484108211, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6224816484108211\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.25020879561161885, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.25020879561161885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:42:34,190]\u001b[0m Trial 34 finished with value: 49.831534095348395 and parameters: {'lambda_l1': 0.25020879561161885, 'lambda_l2': 0.003159313370667438, 'num_leaves': 3, 'max_depth': 4, 'n_estimators': 3382, 'feature_fraction': 0.8456275057228488, 'bagging_fraction': 0.6224816484108211, 'bagging_freq': 5, 'min_child_samples': 23}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8869197802077221, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8869197802077221\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.08000300675893132, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.08000300675893132\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5549382009854602, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5549382009854602\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0031801555022709163, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0031801555022709163\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:43:17,843]\u001b[0m Trial 35 finished with value: 52.34875466455725 and parameters: {'lambda_l1': 0.0031801555022709163, 'lambda_l2': 0.08000300675893132, 'num_leaves': 125, 'max_depth': 5, 'n_estimators': 3152, 'feature_fraction': 0.8869197802077221, 'bagging_fraction': 0.5549382009854602, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9142219857167704, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9142219857167704\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0009339055704762013, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009339055704762013\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7550850979862092, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7550850979862092\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.02851433543239641, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.02851433543239641\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:43:31,883]\u001b[0m Trial 36 finished with value: 59.133004047613184 and parameters: {'lambda_l1': 0.02851433543239641, 'lambda_l2': 0.0009339055704762013, 'num_leaves': 185, 'max_depth': 3, 'n_estimators': 2217, 'feature_fraction': 0.9142219857167704, 'bagging_fraction': 0.7550850979862092, 'bagging_freq': 6, 'min_child_samples': 36}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6381898438453861, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6381898438453861\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.008447393420909988, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.008447393420909988\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8938239062302635, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8938239062302635\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21022529359731815, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21022529359731815\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:44:04,485]\u001b[0m Trial 37 finished with value: 48.90749876705755 and parameters: {'lambda_l1': 0.21022529359731815, 'lambda_l2': 0.008447393420909988, 'num_leaves': 82, 'max_depth': 4, 'n_estimators': 3835, 'feature_fraction': 0.6381898438453861, 'bagging_fraction': 0.8938239062302635, 'bagging_freq': 6, 'min_child_samples': 17}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7997817794677634, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7997817794677634\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.047464253248856454, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.047464253248856454\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6958050338979047, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6958050338979047\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.021075874111076445, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.021075874111076445\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:44:23,523]\u001b[0m Trial 38 finished with value: 50.49666128225872 and parameters: {'lambda_l1': 0.021075874111076445, 'lambda_l2': 0.047464253248856454, 'num_leaves': 217, 'max_depth': 3, 'n_estimators': 2799, 'feature_fraction': 0.7997817794677634, 'bagging_fraction': 0.6958050338979047, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8617166352123751, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8617166352123751\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002506298697700706, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002506298697700706\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8132860042868534, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8132860042868534\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.612703538277141e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.612703538277141e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:45:02,571]\u001b[0m Trial 39 finished with value: 50.16171232556669 and parameters: {'lambda_l1': 4.612703538277141e-05, 'lambda_l2': 0.002506298697700706, 'num_leaves': 20, 'max_depth': 6, 'n_estimators': 4277, 'feature_fraction': 0.8617166352123751, 'bagging_fraction': 0.8132860042868534, 'bagging_freq': 5, 'min_child_samples': 72}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7490647132024959, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7490647132024959\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=9.256308740019208e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=9.256308740019208e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9892512785235259, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9892512785235259\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.617372415707892e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.617372415707892e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:45:44,921]\u001b[0m Trial 40 finished with value: 83.91278119754314 and parameters: {'lambda_l1': 5.617372415707892e-08, 'lambda_l2': 9.256308740019208e-05, 'num_leaves': 139, 'max_depth': 5, 'n_estimators': 2990, 'feature_fraction': 0.7490647132024959, 'bagging_fraction': 0.9892512785235259, 'bagging_freq': 6, 'min_child_samples': 25}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6802444220900846, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6802444220900846\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.009396316506939131, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009396316506939131\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7364449981164974, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7364449981164974\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.10552335932612797, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.10552335932612797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:46:26,198]\u001b[0m Trial 41 finished with value: 49.273127555437775 and parameters: {'lambda_l1': 0.10552335932612797, 'lambda_l2': 0.009396316506939131, 'num_leaves': 45, 'max_depth': 4, 'n_estimators': 4398, 'feature_fraction': 0.6802444220900846, 'bagging_fraction': 0.7364449981164974, 'bagging_freq': 6, 'min_child_samples': 11}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7137937497362592, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7137937497362592\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.5025526021950745, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.5025526021950745\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6424965036259692, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6424965036259692\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0963033979820019, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0963033979820019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:46:43,261]\u001b[0m Trial 42 finished with value: 65.21970799803381 and parameters: {'lambda_l1': 0.0963033979820019, 'lambda_l2': 0.5025526021950745, 'num_leaves': 63, 'max_depth': 4, 'n_estimators': 4786, 'feature_fraction': 0.7137937497362592, 'bagging_fraction': 0.6424965036259692, 'bagging_freq': 7, 'min_child_samples': 17}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7859215447705978, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7859215447705978\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007991275715912847, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007991275715912847\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6845219137134004, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6845219137134004\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010972836349631566, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010972836349631566\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:47:11,880]\u001b[0m Trial 43 finished with value: 47.8404564692525 and parameters: {'lambda_l1': 0.010972836349631566, 'lambda_l2': 0.007991275715912847, 'num_leaves': 21, 'max_depth': 3, 'n_estimators': 4187, 'feature_fraction': 0.7859215447705978, 'bagging_fraction': 0.6845219137134004, 'bagging_freq': 5, 'min_child_samples': 10}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7947256215838473, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7947256215838473\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.056017101788352404, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.056017101788352404\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.67949859011506, subsample=1.0 will be ignored. Current value: bagging_fraction=0.67949859011506\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004892570543411176, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004892570543411176\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:47:31,185]\u001b[0m Trial 44 finished with value: 50.661903215367744 and parameters: {'lambda_l1': 0.004892570543411176, 'lambda_l2': 0.056017101788352404, 'num_leaves': 13, 'max_depth': 3, 'n_estimators': 3672, 'feature_fraction': 0.7947256215838473, 'bagging_fraction': 0.67949859011506, 'bagging_freq': 5, 'min_child_samples': 30}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.830286486435346, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.830286486435346\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00105850922504965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00105850922504965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6009829580119166, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6009829580119166\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00031839965453559426, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00031839965453559426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:48:01,644]\u001b[0m Trial 45 finished with value: 50.0120128505305 and parameters: {'lambda_l1': 0.00031839965453559426, 'lambda_l2': 0.00105850922504965, 'num_leaves': 34, 'max_depth': 3, 'n_estimators': 4119, 'feature_fraction': 0.830286486435346, 'bagging_fraction': 0.6009829580119166, 'bagging_freq': 4, 'min_child_samples': 5}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6120127387532351, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6120127387532351\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.02333252489134072, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.02333252489134072\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7665036152664136, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7665036152664136\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.011833399545645967, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.011833399545645967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:48:20,750]\u001b[0m Trial 46 finished with value: 48.58770161518696 and parameters: {'lambda_l1': 0.011833399545645967, 'lambda_l2': 0.02333252489134072, 'num_leaves': 341, 'max_depth': 3, 'n_estimators': 3516, 'feature_fraction': 0.6120127387532351, 'bagging_fraction': 0.7665036152664136, 'bagging_freq': 3, 'min_child_samples': 10}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9671749894176019, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9671749894176019\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.6040343482308495e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.6040343482308495e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5592046289265016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5592046289265016\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.401413276475576e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.401413276475576e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:49:08,569]\u001b[0m Trial 47 finished with value: 97.36987116186302 and parameters: {'lambda_l1': 1.401413276475576e-06, 'lambda_l2': 4.6040343482308495e-08, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 4558, 'feature_fraction': 0.9671749894176019, 'bagging_fraction': 0.5592046289265016, 'bagging_freq': 5, 'min_child_samples': 22}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7746379039984084, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7746379039984084\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0005149001306211889, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0005149001306211889\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6594662353346037, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6594662353346037\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0007683860911206089, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0007683860911206089\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:50:03,973]\u001b[0m Trial 48 finished with value: 54.05557145309238 and parameters: {'lambda_l1': 0.0007683860911206089, 'lambda_l2': 0.0005149001306211889, 'num_leaves': 97, 'max_depth': 5, 'n_estimators': 3859, 'feature_fraction': 0.7746379039984084, 'bagging_fraction': 0.6594662353346037, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7387541953874566, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7387541953874566\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0022535434882939276, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022535434882939276\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.47200825403593827, subsample=1.0 will be ignored. Current value: bagging_fraction=0.47200825403593827\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0020379257313704762, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0020379257313704762\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-05 16:50:20,125]\u001b[0m Trial 49 finished with value: 51.40351456500241 and parameters: {'lambda_l1': 0.0020379257313704762, 'lambda_l2': 0.0022535434882939276, 'num_leaves': 118, 'max_depth': 3, 'n_estimators': 3413, 'feature_fraction': 0.7387541953874566, 'bagging_fraction': 0.47200825403593827, 'bagging_freq': 5, 'min_child_samples': 39}. Best is trial 28 with value: 46.693556662904754.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdKV7CUIR5lB",
        "outputId": "8c550536-a8ce-41d1-a749-640174f76c0f"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_lgb.best_trial.value, l_study_lgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_lgb.best_trial.value, d_study_lgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunch Best Trial: score 79.23843079626377,\n",
            "params {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}\n",
            "Dinner Best Trial: score 46.693556662904754,\n",
            "params {'lambda_l1': 0.005466400041817161, 'lambda_l2': 0.020294380954704445, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 3318, 'feature_fraction': 0.7723200694083914, 'bagging_fraction': 0.896142844640355, 'bagging_freq': 5, 'min_child_samples': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn-oFRqqR6vB",
        "outputId": "74948ec5-febe-45ee-d553-5900a8b4271e"
      },
      "source": [
        "l_trial_lgb = l_study_lgb.best_trial\n",
        "lunch_lgb_params = l_trial_lgb.params\n",
        "print(lunch_lgb_params)\n",
        "d_trial_lgb = d_study_lgb.best_trial\n",
        "dinner_lgb_params = d_trial_lgb.params\n",
        "print(dinner_lgb_params)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}\n",
            "{'lambda_l1': 0.005466400041817161, 'lambda_l2': 0.020294380954704445, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 3318, 'feature_fraction': 0.7723200694083914, 'bagging_fraction': 0.896142844640355, 'bagging_freq': 5, 'min_child_samples': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3Xd-fwORLky",
        "outputId": "81c0999c-dd7a-4aed-e52d-2da6b31dc982"
      },
      "source": [
        "X_train_lunch = np.concatenate((X_common.to_numpy(), emb_arr_lunch), axis=1)\n",
        "X_train_dinner = np.concatenate((X_common.to_numpy(), emb_arr_dinner), axis=1)\n",
        "\n",
        "lunch_lgb_model = lgb.LGBMRegressor(**lunch_lgb_params)\n",
        "lunch_lgb_model.fit(X_train_lunch, y_lunch, eval_metric='mae')\n",
        "lunch_lgb_pred = lunch_lgb_model.predict(test_lunch)\n",
        "\n",
        "dinner_lgb_model = lgb.LGBMRegressor(**dinner_lgb_params)\n",
        "dinner_lgb_model.fit(X_train_dinner, y_dinner, eval_metric='mae')\n",
        "dinner_lgb_pred = dinner_lgb_model.predict(test_dinner)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7723200694083914, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7723200694083914\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.020294380954704445, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.020294380954704445\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.005466400041817161, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.005466400041817161\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.896142844640355, subsample=1.0 will be ignored. Current value: bagging_fraction=0.896142844640355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDLGd_KVSgwU",
        "outputId": "9776d8d1-ac1d-469f-d082-3b37624c0f47"
      },
      "source": [
        "print(lunch_lgb_pred)\n",
        "print(dinner_lgb_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 964.55808635  947.49236698  760.64151366 1282.59548296 1099.94695157\n",
            "  969.21101705  988.54770411  618.68036226 1248.66493504 1128.5560468\n",
            "  669.33279862 1263.02251518 1141.26650736  994.72925645  951.00219563\n",
            "  569.24248797 1241.65663727 1032.701606    899.73939638  808.13800715\n",
            "  540.06398817 1089.2733492   947.90580183  819.1518227   665.53423547\n",
            " 1207.63233937 1099.14585707 1006.04300278  990.65623399  728.50381792\n",
            " 1175.70443778 1051.93903406 1029.86423     885.78155631  590.21318883\n",
            " 1219.2703703  1050.34486998  872.88999247  815.70613601  667.66742947\n",
            " 1212.24843938 1016.44044549  935.22515893  804.8653144   590.06268893\n",
            " 1299.90247541 1096.58220051  962.33754859  869.15777225  680.64118588]\n",
            "[359.65291337 393.14579024 290.74395731 496.20228527 455.60947688\n",
            " 424.77710584 470.51781852 389.27643585 600.34708032 524.79315474\n",
            " 288.1495656  654.27671682 667.69776675 408.6698936  522.89209716\n",
            " 363.99920681 646.79318187 603.57175579 413.8465659  507.24776167\n",
            " 321.88537769 665.47025187 394.99191904 560.6426719  351.59675642\n",
            " 671.3396149  656.11837841 407.1485498  538.70917698 352.16689829\n",
            " 702.49060627 625.1806474  349.45572905 476.51562923 337.4469595\n",
            " 624.10688714 610.75465227 363.41127293 447.23817585 356.5704135\n",
            " 604.4983027  579.33363989 384.0068637  415.86151227 288.68020771\n",
            " 621.53639705 584.15582537 409.70385826 479.08811209 321.00746053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "H_SHOtHvSik-",
        "outputId": "521b0f4b-4f5d-47f1-f13f-3c5e01be2a9d"
      },
      "source": [
        "lgb_submit = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "lgb_submit['중식계'] = lunch_lgb_pred\n",
        "lgb_submit['석식계'] = dinner_lgb_pred\n",
        "lgb_submit.to_csv(PATH + 'lgb_fasttext.csv', index=False)\n",
        "lgb_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>964.558086</td>\n",
              "      <td>359.652913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>947.492367</td>\n",
              "      <td>393.145790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>760.641514</td>\n",
              "      <td>290.743957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>1282.595483</td>\n",
              "      <td>496.202285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>1099.946952</td>\n",
              "      <td>455.609477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자          중식계         석식계\n",
              "0  2021-01-27   964.558086  359.652913\n",
              "1  2021-01-28   947.492367  393.145790\n",
              "2  2021-01-29   760.641514  290.743957\n",
              "3  2021-02-01  1282.595483  496.202285\n",
              "4  2021-02-02  1099.946952  455.609477"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTezP60R6vco"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYg49nGX6yOB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cb511d7-b441-458f-a07e-be1674edad8d"
      },
      "source": [
        "TRAIN_W2V = False\n",
        "try:\n",
        "    if not TRAIN_W2V:\n",
        "        model = FastText.load('food_embedding.model')\n",
        "        print('Training test set using current model')\n",
        "        test_food = food_combinations(train=False)\n",
        "        model.train(test_food, total_examples=len(test_food))\n",
        "    \n",
        "except:\n",
        "    if TRAIN_W2V:\n",
        "        print(\"Training w2v\")\n",
        "        train_food = food_combinations(train=True)\n",
        "        model = FastText(\n",
        "            sentences=train_food, \n",
        "            vector_size=args.emb_dim, # 벡터 사이즈\n",
        "            window=7, # 주변 4개\n",
        "            workers=4,\n",
        "            sg=1, # 0: CBOW, 1: skip-gram\n",
        "            epochs=5000\n",
        "                         )\n",
        "        model.save('food_embedding.model')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training test set using current model\n",
            "150\n",
            "[['단호박죽', '사과', '고기완자전', '우거지국', '찐계란', '연유버터베이글'], ['시래기지짐', '찐계란', '대만샌드위치', '황태국'], ['고구마순볶음', '오곡죽', '찐계란', '핫케익', '매생이굴국']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g-FWT0mmnKC1",
        "outputId": "76544417-6f06-4a8e-c1de-80e8f388d239"
      },
      "source": [
        "test_food[:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['단호박죽', '사과', '고기완자전', '우거지국', '찐계란', '연유버터베이글'],\n",
              " ['시래기지짐', '찐계란', '대만샌드위치', '황태국'],\n",
              " ['고구마순볶음', '오곡죽', '찐계란', '핫케익', '매생이굴국']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lY5AhS2X633R",
        "outputId": "a5f07272-cf27-421f-f53d-4cdccc907dc0"
      },
      "source": [
        "model.wv.most_similar('우거지국')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('우거지해장국', 0.1815887838602066),\n",
              " ('과일샐러드', 0.11057543009519577),\n",
              " ('크림카레우동', 0.10801000893115997),\n",
              " ('오렌지', 0.10700217634439468),\n",
              " ('맛살냉채', 0.10358025878667831),\n",
              " ('봄동된장국', 0.10342633724212646),\n",
              " ('영양부추무침', 0.10234417766332626),\n",
              " ('부추무침', 0.1021125540137291),\n",
              " ('열무보리비빔밥', 0.09813344478607178),\n",
              " ('감자프리타타', 0.09660380333662033)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJFsfFsMBrIZ"
      },
      "source": [
        "test_df = all_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvd8X5Dw6-pJ"
      },
      "source": [
        "test_df['breakfast_embedding'] = test_df['breakfast'].apply(lambda x: food_embedding(x))\n",
        "test_df['lunch_embedding'] = test_df['lunch'].apply(lambda x: food_embedding(x))\n",
        "test_df['dinner_embedding'] = test_df['dinner'].apply(lambda x: food_embedding(x))\n",
        "test_df.drop(['breakfast', 'lunch', 'dinner'], axis=1, inplace=True)\n",
        "X_test_common = test_df.iloc[:, :10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTlCQGxcBmWO"
      },
      "source": [
        "test_emb_arr_lunch  = np.array(test_df['lunch_embedding'].to_numpy().tolist())\n",
        "test_emb_arr_dinner  = np.array(test_df['dinner_embedding'].to_numpy().tolist())\n",
        "\n",
        "test_lunch  = np.concatenate((X_test_common.to_numpy(), test_emb_arr_lunch), axis=1)\n",
        "test_dinner  = np.concatenate((X_test_common.to_numpy(), test_emb_arr_dinner), axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-0rPme3iu0R",
        "outputId": "f28b7522-eed8-4ac4-c77e-f7ae3d64beb7"
      },
      "source": [
        "test_dinner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 2.95005028e-02,  6.10124036e-02,  1.20013409e-01, ...,\n",
              "        -3.26743078e-05, -2.93306441e-04,  8.17575625e-05],\n",
              "       [ 3.48642306e-02,  7.10693932e-02,  1.16661079e-01, ...,\n",
              "        -8.44453947e-05, -1.40485702e-04, -2.17571462e-04],\n",
              "       [ 9.05129065e-02,  8.34730137e-02,  9.85584982e-02, ...,\n",
              "         1.29570242e-04, -1.15128330e-04,  5.03821611e-05],\n",
              "       ...,\n",
              "       [ 3.22906155e-02,  7.19811638e-02,  1.12344433e-01, ...,\n",
              "         1.18747656e-05,  3.56026931e-05,  5.48526557e-05],\n",
              "       [ 3.53178607e-02,  8.00538177e-02,  1.08980827e-01, ...,\n",
              "         5.71758719e-05, -1.45923451e-04,  5.84947949e-05],\n",
              "       [ 8.71173898e-02,  9.01446350e-02,  7.70265725e-02, ...,\n",
              "         4.81978714e-05, -3.33681104e-04,  3.93561328e-04]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aMxECQKYBarG"
      },
      "source": [
        "test_pred_lunch = model_lunch.predict(test_lunch)\n",
        "test_pred_dinner = model_dinner.predict(test_dinner)\n",
        "\n",
        "submission_df = pd.read_csv(PATH+'sample_submission.csv')\n",
        "submission_df['중식계'] = test_pred_lunch\n",
        "submission_df['석식계'] = test_pred_dinner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poa0hyioCFnO"
      },
      "source": [
        "submission_df.to_csv('fasttext1.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "LtyKUzhm7Iga",
        "outputId": "b1c8a817-d753-40f6-f06e-cb44c61178fb"
      },
      "source": [
        "test_df.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breakfast</th>\n",
              "      <th>lunch</th>\n",
              "      <th>dinner</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "      <th>breakfast_embedding</th>\n",
              "      <th>lunch_embedding</th>\n",
              "      <th>dinner_embedding</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>[찐계란, 단호박죽, 연유버터베이글, 사과, 고기완자전, 우거지국]</td>\n",
              "      <td>[매운돈갈비찜, 상추무침, 오꼬노미계란말이, 대구지리]</td>\n",
              "      <td>[쇠고기우엉볶음, 버섯햄볶음, 얼큰순두부찌개]</td>\n",
              "      <td>0.029501</td>\n",
              "      <td>0.061012</td>\n",
              "      <td>0.120013</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>[-3.002130627767959e-05, -2.6683754792126518e-...</td>\n",
              "      <td>[5.8634714150684886e-05, -1.1691027793858666e-...</td>\n",
              "      <td>[-7.44763219699962e-05, 1.4272785241094728e-06...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  breakfast  ...                                   dinner_embedding\n",
              "1205  [찐계란, 단호박죽, 연유버터베이글, 사과, 고기완자전, 우거지국]  ...  [-7.44763219699962e-05, 1.4272785241094728e-06...\n",
              "\n",
              "[1 rows x 16 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "389Grm3doF5u"
      },
      "source": [
        "### mlp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4788mhQmsK6-",
        "outputId": "9bd64a89-39a8-4be1-d856-011830de057b"
      },
      "source": [
        "print(X_train_lunch.shape, y_train_lunch.shape, X_test_lunch.shape, y_test_lunch.shape)\n",
        "print(X_train_dinner.shape, y_train_dinner.shape, X_test_dinner.shape, y_test_dinner.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 510) (964,) (241, 510) (241,)\n",
            "(964, 510) (964,) (241, 510) (241,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VWyLyFqUvzeb",
        "outputId": "6fbd3111-7455-45c4-b1e6-07a5c5b869b9"
      },
      "source": [
        "for i in [X_train_lunch, y_train_lunch, X_test_lunch, y_test_lunch, X_train_dinner, y_train_dinner, X_test_dinner, y_test_dinner]:\n",
        "    print(np.isnan(i).sum())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EigNtk1GrYie",
        "outputId": "4b96b1e9-bbd0-48fc-b3c1-b01e4a949484"
      },
      "source": [
        "model_lunch = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=X_train_lunch.shape),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "  ])\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "model_lunch.compile(loss='mean_absolute_error', optimizer=Adam(lr=0.001))\n",
        "\n",
        "model_lunch.fit(\n",
        "    X_train_lunch,\n",
        "    y_train_lunch,\n",
        "    callbacks=[early_stop],\n",
        "    validation_data=(X_test_lunch, y_test_lunch), # 검증 데이터를 넣어주면 한 epoch이 끝날때마다 자동으로 검증\n",
        "    epochs=300 # epochs 복수형으로 쓰기!\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 510).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 355.7309 WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "31/31 [==============================] - 1s 8ms/step - loss: 316.9841 - val_loss: 167.4597\n",
            "Epoch 2/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 175.3421 - val_loss: 165.0298\n",
            "Epoch 3/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 169.0528 - val_loss: 167.0692\n",
            "Epoch 4/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 169.0327 - val_loss: 162.8635\n",
            "Epoch 5/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 168.5120 - val_loss: 162.7211\n",
            "Epoch 6/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 170.0725 - val_loss: 163.6532\n",
            "Epoch 7/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 168.5834 - val_loss: 162.3434\n",
            "Epoch 8/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 167.8740 - val_loss: 163.0424\n",
            "Epoch 9/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 170.4843 - val_loss: 164.3315\n",
            "Epoch 10/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 169.3044 - val_loss: 161.5257\n",
            "Epoch 11/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 165.9576 - val_loss: 161.7870\n",
            "Epoch 12/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 167.8101 - val_loss: 163.4734\n",
            "Epoch 13/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 166.8811 - val_loss: 160.6776\n",
            "Epoch 14/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 169.5588 - val_loss: 162.6423\n",
            "Epoch 15/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 166.8822 - val_loss: 161.5451\n",
            "Epoch 16/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 165.3107 - val_loss: 168.1110\n",
            "Epoch 17/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.8543 - val_loss: 159.2580\n",
            "Epoch 18/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.4619 - val_loss: 159.3365\n",
            "Epoch 19/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.2648 - val_loss: 160.8024\n",
            "Epoch 20/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.0085 - val_loss: 161.1713\n",
            "Epoch 21/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.9089 - val_loss: 160.2635\n",
            "Epoch 22/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.0865 - val_loss: 159.4213\n",
            "Epoch 23/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 162.7754 - val_loss: 166.8893\n",
            "Epoch 24/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 162.9714 - val_loss: 165.6219\n",
            "Epoch 25/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 166.6108 - val_loss: 156.8296\n",
            "Epoch 26/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 161.6964 - val_loss: 155.4636\n",
            "Epoch 27/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 164.0273 - val_loss: 160.8936\n",
            "Epoch 28/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 161.7261 - val_loss: 161.4794\n",
            "Epoch 29/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 162.9998 - val_loss: 156.9010\n",
            "Epoch 30/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 159.2395 - val_loss: 154.2181\n",
            "Epoch 31/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 159.9181 - val_loss: 155.3301\n",
            "Epoch 32/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 157.9909 - val_loss: 152.2779\n",
            "Epoch 33/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 155.8118 - val_loss: 151.0738\n",
            "Epoch 34/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 155.1912 - val_loss: 150.2971\n",
            "Epoch 35/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 153.8445 - val_loss: 149.8356\n",
            "Epoch 36/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 157.2859 - val_loss: 149.3769\n",
            "Epoch 37/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 158.5351 - val_loss: 150.9438\n",
            "Epoch 38/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 152.3740 - val_loss: 146.8581\n",
            "Epoch 39/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 151.2744 - val_loss: 149.9547\n",
            "Epoch 40/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 150.9171 - val_loss: 144.2710\n",
            "Epoch 41/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 154.0942 - val_loss: 144.8526\n",
            "Epoch 42/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 150.3891 - val_loss: 159.1995\n",
            "Epoch 43/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 153.3696 - val_loss: 159.6347\n",
            "Epoch 44/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 145.3757 - val_loss: 140.2214\n",
            "Epoch 45/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 142.7916 - val_loss: 138.1558\n",
            "Epoch 46/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 140.0598 - val_loss: 136.8766\n",
            "Epoch 47/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 138.9243 - val_loss: 132.9951\n",
            "Epoch 48/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 136.3645 - val_loss: 133.7151\n",
            "Epoch 49/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 135.0356 - val_loss: 144.2940\n",
            "Epoch 50/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 135.6312 - val_loss: 124.5408\n",
            "Epoch 51/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 141.4455 - val_loss: 154.5023\n",
            "Epoch 52/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 127.6650 - val_loss: 126.8615\n",
            "Epoch 53/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 123.4961 - val_loss: 149.2939\n",
            "Epoch 54/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 127.4110 - val_loss: 115.3735\n",
            "Epoch 55/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 119.2213 - val_loss: 112.3425\n",
            "Epoch 56/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 114.3535 - val_loss: 123.6176\n",
            "Epoch 57/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 115.3682 - val_loss: 110.5092\n",
            "Epoch 58/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 112.9517 - val_loss: 109.9737\n",
            "Epoch 59/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 113.1850 - val_loss: 118.8613\n",
            "Epoch 60/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 110.7058 - val_loss: 102.4373\n",
            "Epoch 61/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 108.2314 - val_loss: 101.9765\n",
            "Epoch 62/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 105.6067 - val_loss: 100.5925\n",
            "Epoch 63/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 117.8202 - val_loss: 102.5007\n",
            "Epoch 64/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 115.2824 - val_loss: 101.0518\n",
            "Epoch 65/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 106.7982 - val_loss: 110.6696\n",
            "Epoch 66/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 104.7753 - val_loss: 100.9453\n",
            "Epoch 67/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 112.7316 - val_loss: 133.5897\n",
            "Epoch 68/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 113.6422 - val_loss: 102.2862\n",
            "Epoch 69/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 104.3643 - val_loss: 108.8000\n",
            "Epoch 70/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 106.6235 - val_loss: 105.5095\n",
            "Epoch 71/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 108.4197 - val_loss: 121.8665\n",
            "Epoch 72/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 104.6235 - val_loss: 101.2760\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb8f01337d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMSnAXmQoHm9",
        "outputId": "4a7515c0-3f3e-40d1-ba9c-5d2fbb505c5b"
      },
      "source": [
        "model_dinner = Sequential([\n",
        "    Dense(64, activation='relu', input_shape=X_train_dinner.shape),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(16, activation='relu'),\n",
        "    Dense(1)\n",
        "  ])\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "model_dinner.compile(loss='mean_absolute_error', optimizer=Adam(lr=0.001))\n",
        "\n",
        "model_dinner.fit(\n",
        "    X_train_dinner,\n",
        "    y_train_dinner,\n",
        "    callbacks=[early_stop],\n",
        "    validation_data=(X_test_dinner, y_test_dinner), # 검증 데이터를 넣어주면 한 epoch이 끝날때마다 자동으로 검증\n",
        "    epochs=300 # epochs 복수형으로 쓰기!\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 510).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning:\n",
            "\n",
            "The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "23/31 [=====================>........] - ETA: 0s - loss: 235.2382 WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_8_input'), name='dense_8_input', description=\"created by layer 'dense_8_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "31/31 [==============================] - 1s 7ms/step - loss: 203.1450 - val_loss: 96.6832\n",
            "Epoch 2/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 100.2656 - val_loss: 96.9418\n",
            "Epoch 3/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.6740 - val_loss: 97.8812\n",
            "Epoch 4/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.5690 - val_loss: 96.4540\n",
            "Epoch 5/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.2217 - val_loss: 96.2692\n",
            "Epoch 6/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.3417 - val_loss: 97.1338\n",
            "Epoch 7/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.6211 - val_loss: 97.5435\n",
            "Epoch 8/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.5526 - val_loss: 96.6002\n",
            "Epoch 9/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.7525 - val_loss: 98.2217\n",
            "Epoch 10/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 100.0890 - val_loss: 95.8032\n",
            "Epoch 11/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.2570 - val_loss: 99.0977\n",
            "Epoch 12/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.1217 - val_loss: 97.6621\n",
            "Epoch 13/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.0656 - val_loss: 98.1302\n",
            "Epoch 14/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.0605 - val_loss: 95.3676\n",
            "Epoch 15/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.1380 - val_loss: 103.2452\n",
            "Epoch 16/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 102.8284 - val_loss: 94.8745\n",
            "Epoch 17/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.1537 - val_loss: 95.3158\n",
            "Epoch 18/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 97.5538 - val_loss: 99.9255\n",
            "Epoch 19/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.0479 - val_loss: 96.7697\n",
            "Epoch 20/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 99.1745 - val_loss: 95.1843\n",
            "Epoch 21/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 100.9398 - val_loss: 94.8170\n",
            "Epoch 22/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.5900 - val_loss: 98.0674\n",
            "Epoch 23/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.3942 - val_loss: 95.0758\n",
            "Epoch 24/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 98.4139 - val_loss: 98.5772\n",
            "Epoch 25/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 97.8725 - val_loss: 95.3716\n",
            "Epoch 26/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 97.1817 - val_loss: 93.9728\n",
            "Epoch 27/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.9138 - val_loss: 93.7971\n",
            "Epoch 28/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.5320 - val_loss: 94.8535\n",
            "Epoch 29/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.8762 - val_loss: 93.7105\n",
            "Epoch 30/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.4128 - val_loss: 94.8383\n",
            "Epoch 31/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 97.5866 - val_loss: 93.5265\n",
            "Epoch 32/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.7109 - val_loss: 97.0539\n",
            "Epoch 33/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.7356 - val_loss: 94.7907\n",
            "Epoch 34/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.5358 - val_loss: 93.3221\n",
            "Epoch 35/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.4441 - val_loss: 93.1147\n",
            "Epoch 36/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 97.4038 - val_loss: 93.9135\n",
            "Epoch 37/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.0246 - val_loss: 92.9016\n",
            "Epoch 38/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.4045 - val_loss: 93.0326\n",
            "Epoch 39/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.0156 - val_loss: 96.4898\n",
            "Epoch 40/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.0296 - val_loss: 95.2512\n",
            "Epoch 41/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.5371 - val_loss: 92.4789\n",
            "Epoch 42/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.7503 - val_loss: 92.9019\n",
            "Epoch 43/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.3665 - val_loss: 92.2009\n",
            "Epoch 44/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.3578 - val_loss: 92.6294\n",
            "Epoch 45/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.7235 - val_loss: 92.0918\n",
            "Epoch 46/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.4709 - val_loss: 93.8260\n",
            "Epoch 47/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.9168 - val_loss: 92.8786\n",
            "Epoch 48/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.9767 - val_loss: 91.9545\n",
            "Epoch 49/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.3824 - val_loss: 95.4119\n",
            "Epoch 50/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.1694 - val_loss: 91.4232\n",
            "Epoch 51/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.0607 - val_loss: 94.4025\n",
            "Epoch 52/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.4620 - val_loss: 91.2731\n",
            "Epoch 53/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.9444 - val_loss: 91.6184\n",
            "Epoch 54/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 96.1384 - val_loss: 100.0032\n",
            "Epoch 55/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 95.1821 - val_loss: 94.7116\n",
            "Epoch 56/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.0934 - val_loss: 94.6912\n",
            "Epoch 57/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.5243 - val_loss: 90.6784\n",
            "Epoch 58/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.0180 - val_loss: 94.2490\n",
            "Epoch 59/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.8205 - val_loss: 93.6788\n",
            "Epoch 60/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.0704 - val_loss: 90.5056\n",
            "Epoch 61/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.5142 - val_loss: 90.3884\n",
            "Epoch 62/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.2436 - val_loss: 90.1489\n",
            "Epoch 63/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.3502 - val_loss: 96.7353\n",
            "Epoch 64/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.9325 - val_loss: 92.1254\n",
            "Epoch 65/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.7656 - val_loss: 98.3848\n",
            "Epoch 66/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.1547 - val_loss: 89.8444\n",
            "Epoch 67/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 94.2941 - val_loss: 92.1757\n",
            "Epoch 68/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.7294 - val_loss: 92.8751\n",
            "Epoch 69/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.2257 - val_loss: 91.5560\n",
            "Epoch 70/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.4231 - val_loss: 89.8564\n",
            "Epoch 71/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.9413 - val_loss: 93.4041\n",
            "Epoch 72/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 92.0497 - val_loss: 89.4223\n",
            "Epoch 73/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.1080 - val_loss: 88.6451\n",
            "Epoch 74/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.9488 - val_loss: 91.0303\n",
            "Epoch 75/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.4577 - val_loss: 89.8371\n",
            "Epoch 76/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.5691 - val_loss: 88.1695\n",
            "Epoch 77/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 93.0228 - val_loss: 88.8062\n",
            "Epoch 78/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.0324 - val_loss: 87.9080\n",
            "Epoch 79/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.9952 - val_loss: 89.1441\n",
            "Epoch 80/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.3701 - val_loss: 88.0696\n",
            "Epoch 81/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.7055 - val_loss: 89.0649\n",
            "Epoch 82/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 89.5231 - val_loss: 90.2704\n",
            "Epoch 83/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.2397 - val_loss: 94.9785\n",
            "Epoch 84/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.2256 - val_loss: 89.3063\n",
            "Epoch 85/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.6714 - val_loss: 88.8869\n",
            "Epoch 86/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.2771 - val_loss: 86.8086\n",
            "Epoch 87/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.0156 - val_loss: 86.7045\n",
            "Epoch 88/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.6096 - val_loss: 94.0647\n",
            "Epoch 89/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.8609 - val_loss: 87.3997\n",
            "Epoch 90/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.3233 - val_loss: 86.4801\n",
            "Epoch 91/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.8340 - val_loss: 89.9084\n",
            "Epoch 92/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.6292 - val_loss: 86.1125\n",
            "Epoch 93/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.0318 - val_loss: 86.5781\n",
            "Epoch 94/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.0592 - val_loss: 86.4161\n",
            "Epoch 95/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.1320 - val_loss: 88.2098\n",
            "Epoch 96/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.3134 - val_loss: 85.6650\n",
            "Epoch 97/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.5816 - val_loss: 98.1025\n",
            "Epoch 98/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.2605 - val_loss: 89.0820\n",
            "Epoch 99/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 91.3580 - val_loss: 89.2904\n",
            "Epoch 100/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.1290 - val_loss: 85.8599\n",
            "Epoch 101/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.6108 - val_loss: 87.1838\n",
            "Epoch 102/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.8639 - val_loss: 85.6080\n",
            "Epoch 103/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.6186 - val_loss: 85.3228\n",
            "Epoch 104/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.6083 - val_loss: 92.7115\n",
            "Epoch 105/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.0933 - val_loss: 86.8936\n",
            "Epoch 106/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.5785 - val_loss: 92.3055\n",
            "Epoch 107/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.6414 - val_loss: 86.2481\n",
            "Epoch 108/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.5360 - val_loss: 86.5787\n",
            "Epoch 109/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.0993 - val_loss: 84.8286\n",
            "Epoch 110/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.9960 - val_loss: 85.1322\n",
            "Epoch 111/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.7103 - val_loss: 85.4395\n",
            "Epoch 112/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 87.3451 - val_loss: 95.5124\n",
            "Epoch 113/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 90.3182 - val_loss: 88.2076\n",
            "Epoch 114/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.3451 - val_loss: 85.2619\n",
            "Epoch 115/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.2972 - val_loss: 84.5012\n",
            "Epoch 116/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.8644 - val_loss: 90.0592\n",
            "Epoch 117/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.8405 - val_loss: 87.4364\n",
            "Epoch 118/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 89.4169 - val_loss: 85.6859\n",
            "Epoch 119/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.8866 - val_loss: 84.7687\n",
            "Epoch 120/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.3810 - val_loss: 85.6828\n",
            "Epoch 121/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.8583 - val_loss: 84.5014\n",
            "Epoch 122/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.1406 - val_loss: 84.2357\n",
            "Epoch 123/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.4910 - val_loss: 87.9281\n",
            "Epoch 124/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.7030 - val_loss: 85.9509\n",
            "Epoch 125/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.4588 - val_loss: 86.1717\n",
            "Epoch 126/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.8775 - val_loss: 88.4761\n",
            "Epoch 127/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.2516 - val_loss: 84.9342\n",
            "Epoch 128/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.6830 - val_loss: 86.6881\n",
            "Epoch 129/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.7877 - val_loss: 84.7624\n",
            "Epoch 130/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.3506 - val_loss: 84.7472\n",
            "Epoch 131/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.7140 - val_loss: 83.9966\n",
            "Epoch 132/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.2942 - val_loss: 84.0077\n",
            "Epoch 133/300\n",
            "31/31 [==============================] - 0s 4ms/step - loss: 86.1435 - val_loss: 91.2993\n",
            "Epoch 134/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 88.6457 - val_loss: 86.0079\n",
            "Epoch 135/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.4575 - val_loss: 84.0009\n",
            "Epoch 136/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.8447 - val_loss: 86.8702\n",
            "Epoch 137/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.4226 - val_loss: 86.3207\n",
            "Epoch 138/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.8410 - val_loss: 92.2595\n",
            "Epoch 139/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.7543 - val_loss: 84.2167\n",
            "Epoch 140/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 86.9432 - val_loss: 87.4217\n",
            "Epoch 141/300\n",
            "31/31 [==============================] - 0s 3ms/step - loss: 87.8646 - val_loss: 86.1396\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb896e212d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr_fzvWuqW0K",
        "outputId": "8f49a63f-7944-4bb7-a07a-6b46074a8daf"
      },
      "source": [
        "lunch_pred=model_lunch.predict(X_test_lunch)\n",
        "dinner_pred=model_dinner.predict(X_test_dinner)\n",
        "print(lunch_pred)\n",
        "print(dinner_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 964, 510) for input KerasTensor(type_spec=TensorSpec(shape=(None, 964, 510), dtype=tf.float32, name='dense_4_input'), name='dense_4_input', description=\"created by layer 'dense_4_input'\"), but it was called on an input with incompatible shape (None, 510).\n",
            "[[ 669.3429 ]\n",
            " [ 938.3764 ]\n",
            " [ 853.8954 ]\n",
            " [ 858.2813 ]\n",
            " [ 667.2478 ]\n",
            " [ 832.0748 ]\n",
            " [ 609.3611 ]\n",
            " [ 663.69653]\n",
            " [ 694.242  ]\n",
            " [ 599.26605]\n",
            " [ 812.17084]\n",
            " [ 913.1294 ]\n",
            " [ 825.7713 ]\n",
            " [ 645.95355]\n",
            " [ 690.3943 ]\n",
            " [1065.4124 ]\n",
            " [1099.298  ]\n",
            " [1136.012  ]\n",
            " [ 931.8857 ]\n",
            " [ 792.6108 ]\n",
            " [ 966.54974]\n",
            " [ 639.6069 ]\n",
            " [1036.5787 ]\n",
            " [1080.9312 ]\n",
            " [1117.5122 ]\n",
            " [1075.9833 ]\n",
            " [ 821.2292 ]\n",
            " [ 844.8619 ]\n",
            " [ 642.7752 ]\n",
            " [ 852.8119 ]\n",
            " [1075.1661 ]\n",
            " [ 747.49146]\n",
            " [ 632.51227]\n",
            " [ 629.65283]\n",
            " [1058.7048 ]\n",
            " [ 820.67377]\n",
            " [1045.5664 ]\n",
            " [ 802.7441 ]\n",
            " [ 899.9165 ]\n",
            " [ 779.05774]\n",
            " [1061.0217 ]\n",
            " [ 781.9298 ]\n",
            " [ 803.96765]\n",
            " [1050.4523 ]\n",
            " [ 932.64386]\n",
            " [ 747.5259 ]\n",
            " [ 989.025  ]\n",
            " [ 863.0437 ]\n",
            " [1005.7161 ]\n",
            " [1133.0739 ]\n",
            " [ 962.22705]\n",
            " [ 746.7683 ]\n",
            " [ 809.46173]\n",
            " [ 739.10443]\n",
            " [ 985.4123 ]\n",
            " [ 664.9412 ]\n",
            " [ 900.2614 ]\n",
            " [1114.659  ]\n",
            " [ 849.7141 ]\n",
            " [ 978.21936]\n",
            " [ 899.10504]\n",
            " [ 750.57635]\n",
            " [ 880.3971 ]\n",
            " [ 915.4759 ]\n",
            " [ 854.9168 ]\n",
            " [ 663.5992 ]\n",
            " [1026.6771 ]\n",
            " [ 825.53284]\n",
            " [ 976.90717]\n",
            " [ 754.5448 ]\n",
            " [ 929.813  ]\n",
            " [ 745.69403]\n",
            " [ 962.2079 ]\n",
            " [1027.1796 ]\n",
            " [ 741.3352 ]\n",
            " [ 993.4933 ]\n",
            " [ 691.6794 ]\n",
            " [ 736.1755 ]\n",
            " [ 859.3893 ]\n",
            " [ 803.58374]\n",
            " [ 638.76184]\n",
            " [ 752.6708 ]\n",
            " [ 836.56604]\n",
            " [ 926.17804]\n",
            " [ 647.37006]\n",
            " [1017.4643 ]\n",
            " [1029.0453 ]\n",
            " [ 752.1479 ]\n",
            " [ 974.8507 ]\n",
            " [ 657.06067]\n",
            " [ 898.3205 ]\n",
            " [ 642.42267]\n",
            " [ 882.7319 ]\n",
            " [ 716.7204 ]\n",
            " [ 935.78784]\n",
            " [1079.3007 ]\n",
            " [1050.692  ]\n",
            " [ 982.9968 ]\n",
            " [ 934.9091 ]\n",
            " [ 818.3162 ]\n",
            " [ 798.2394 ]\n",
            " [ 848.2917 ]\n",
            " [1061.6917 ]\n",
            " [ 606.3525 ]\n",
            " [ 880.43585]\n",
            " [1028.0583 ]\n",
            " [ 965.54443]\n",
            " [ 694.3501 ]\n",
            " [ 596.86816]\n",
            " [ 634.1068 ]\n",
            " [1105.3308 ]\n",
            " [1127.7482 ]\n",
            " [ 883.52576]\n",
            " [1020.0844 ]\n",
            " [1092.4456 ]\n",
            " [ 934.21967]\n",
            " [ 632.7543 ]\n",
            " [1139.0854 ]\n",
            " [ 755.2442 ]\n",
            " [1125.4244 ]\n",
            " [ 845.75836]\n",
            " [ 805.7056 ]\n",
            " [ 794.89655]\n",
            " [1139.5345 ]\n",
            " [ 978.4864 ]\n",
            " [1002.49677]\n",
            " [ 680.49194]\n",
            " [ 971.7656 ]\n",
            " [ 706.8839 ]\n",
            " [ 611.78345]\n",
            " [1100.6791 ]\n",
            " [ 984.40826]\n",
            " [1037.8632 ]\n",
            " [ 832.1044 ]\n",
            " [ 818.2845 ]\n",
            " [ 730.5094 ]\n",
            " [1052.9321 ]\n",
            " [ 871.4784 ]\n",
            " [ 731.03613]\n",
            " [ 807.9381 ]\n",
            " [1015.229  ]\n",
            " [ 683.1484 ]\n",
            " [ 936.00366]\n",
            " [ 836.2018 ]\n",
            " [ 724.0176 ]\n",
            " [ 759.0838 ]\n",
            " [ 594.6168 ]\n",
            " [ 851.11255]\n",
            " [1002.7692 ]\n",
            " [ 613.97516]\n",
            " [ 829.8951 ]\n",
            " [ 646.3758 ]\n",
            " [ 977.5596 ]\n",
            " [ 605.1199 ]\n",
            " [ 590.3807 ]\n",
            " [ 787.99365]\n",
            " [ 836.64   ]\n",
            " [ 992.06384]\n",
            " [ 709.69086]\n",
            " [ 974.6046 ]\n",
            " [ 772.9364 ]\n",
            " [1139.6908 ]\n",
            " [ 691.4205 ]\n",
            " [ 752.7003 ]\n",
            " [ 619.28876]\n",
            " [ 812.4501 ]\n",
            " [ 798.86194]\n",
            " [ 993.8173 ]\n",
            " [1005.0457 ]\n",
            " [ 889.25385]\n",
            " [ 613.7606 ]\n",
            " [ 729.18945]\n",
            " [ 854.20996]\n",
            " [ 756.61975]\n",
            " [1123.1069 ]\n",
            " [ 732.3536 ]\n",
            " [ 979.0502 ]\n",
            " [ 905.4333 ]\n",
            " [ 610.4507 ]\n",
            " [ 878.0483 ]\n",
            " [ 747.62695]\n",
            " [ 827.3969 ]\n",
            " [ 912.6108 ]\n",
            " [ 925.42285]\n",
            " [1027.5804 ]\n",
            " [ 813.899  ]\n",
            " [1011.83514]\n",
            " [ 843.5196 ]\n",
            " [ 625.21027]\n",
            " [1026.2454 ]\n",
            " [ 630.49506]\n",
            " [ 929.36926]\n",
            " [1103.3009 ]\n",
            " [ 986.42035]\n",
            " [1074.876  ]\n",
            " [ 660.2909 ]\n",
            " [ 852.6653 ]\n",
            " [ 857.06   ]\n",
            " [ 860.1183 ]\n",
            " [ 862.6797 ]\n",
            " [ 976.23584]\n",
            " [ 989.65826]\n",
            " [1018.37695]\n",
            " [ 707.256  ]\n",
            " [1001.25146]\n",
            " [ 707.82214]\n",
            " [1015.5306 ]\n",
            " [ 745.13464]\n",
            " [ 893.35345]\n",
            " [ 627.07117]\n",
            " [1031.5297 ]\n",
            " [ 761.1886 ]\n",
            " [ 821.3061 ]\n",
            " [ 772.95496]\n",
            " [1002.2182 ]\n",
            " [ 794.76514]\n",
            " [ 709.5623 ]\n",
            " [ 816.3948 ]\n",
            " [ 817.6718 ]\n",
            " [ 630.3051 ]\n",
            " [1117.8171 ]\n",
            " [1112.0782 ]\n",
            " [1140.2003 ]\n",
            " [1097.3013 ]\n",
            " [ 787.7349 ]\n",
            " [ 747.8236 ]\n",
            " [1107.3082 ]\n",
            " [ 883.0419 ]\n",
            " [1001.46985]\n",
            " [ 795.2372 ]\n",
            " [ 978.38983]\n",
            " [ 780.0245 ]\n",
            " [1118.771  ]\n",
            " [ 734.4819 ]\n",
            " [ 824.7396 ]\n",
            " [1100.5012 ]\n",
            " [ 716.929  ]\n",
            " [ 966.3392 ]\n",
            " [ 866.4517 ]\n",
            " [ 958.4951 ]\n",
            " [1133.5    ]]\n",
            "[[460.23087]\n",
            " [501.45413]\n",
            " [498.26434]\n",
            " [498.06448]\n",
            " [456.7249 ]\n",
            " [469.171  ]\n",
            " [423.1453 ]\n",
            " [459.33032]\n",
            " [479.33417]\n",
            " [415.5501 ]\n",
            " [468.5717 ]\n",
            " [533.05   ]\n",
            " [476.6421 ]\n",
            " [448.5484 ]\n",
            " [475.41208]\n",
            " [546.1976 ]\n",
            " [564.79297]\n",
            " [587.88104]\n",
            " [504.56055]\n",
            " [497.4526 ]\n",
            " [525.126  ]\n",
            " [441.15262]\n",
            " [514.34436]\n",
            " [555.45605]\n",
            " [577.21796]\n",
            " [547.0788 ]\n",
            " [473.44086]\n",
            " [488.62225]\n",
            " [445.91187]\n",
            " [491.79745]\n",
            " [546.8205 ]\n",
            " [469.6066 ]\n",
            " [439.50702]\n",
            " [432.36847]\n",
            " [536.5127 ]\n",
            " [507.74905]\n",
            " [529.5166 ]\n",
            " [503.27493]\n",
            " [526.5701 ]\n",
            " [482.7384 ]\n",
            " [535.1111 ]\n",
            " [485.31494]\n",
            " [454.02194]\n",
            " [532.4934 ]\n",
            " [496.72842]\n",
            " [469.99057]\n",
            " [521.7151 ]\n",
            " [502.85727]\n",
            " [537.65283]\n",
            " [585.9811 ]\n",
            " [518.5301 ]\n",
            " [463.6484 ]\n",
            " [465.35336]\n",
            " [460.23022]\n",
            " [537.55884]\n",
            " [460.10114]\n",
            " [526.26337]\n",
            " [575.7937 ]\n",
            " [488.82846]\n",
            " [532.73865]\n",
            " [524.714  ]\n",
            " [472.57916]\n",
            " [511.77545]\n",
            " [490.11   ]\n",
            " [496.67172]\n",
            " [458.3456 ]\n",
            " [561.4567 ]\n",
            " [515.5802 ]\n",
            " [529.45715]\n",
            " [473.3157 ]\n",
            " [499.93845]\n",
            " [461.3553 ]\n",
            " [521.5303 ]\n",
            " [519.04034]\n",
            " [460.6927 ]\n",
            " [541.8609 ]\n",
            " [431.48737]\n",
            " [452.0317 ]\n",
            " [487.77814]\n",
            " [503.9139 ]\n",
            " [442.29324]\n",
            " [471.64197]\n",
            " [480.85352]\n",
            " [542.1956 ]\n",
            " [449.51083]\n",
            " [554.5831 ]\n",
            " [521.82635]\n",
            " [470.66238]\n",
            " [530.9646 ]\n",
            " [454.00195]\n",
            " [526.81165]\n",
            " [446.12827]\n",
            " [514.81836]\n",
            " [436.2534 ]\n",
            " [503.23944]\n",
            " [553.0493 ]\n",
            " [529.4596 ]\n",
            " [532.10126]\n",
            " [501.90445]\n",
            " [472.94205]\n",
            " [499.6363 ]\n",
            " [486.25754]\n",
            " [544.45435]\n",
            " [420.88278]\n",
            " [515.916  ]\n",
            " [562.57745]\n",
            " [519.6686 ]\n",
            " [479.61725]\n",
            " [413.66528]\n",
            " [437.93118]\n",
            " [568.3335 ]\n",
            " [572.99884]\n",
            " [514.8467 ]\n",
            " [557.81757]\n",
            " [560.67004]\n",
            " [499.8285 ]\n",
            " [435.2653 ]\n",
            " [592.54926]\n",
            " [468.7731 ]\n",
            " [582.7818 ]\n",
            " [490.46945]\n",
            " [462.9208 ]\n",
            " [497.1517 ]\n",
            " [589.686  ]\n",
            " [531.05817]\n",
            " [547.598  ]\n",
            " [470.43015]\n",
            " [522.5005 ]\n",
            " [479.0839 ]\n",
            " [426.87476]\n",
            " [560.8044 ]\n",
            " [532.19867]\n",
            " [570.5882 ]\n",
            " [478.17468]\n",
            " [471.9961 ]\n",
            " [455.0897 ]\n",
            " [579.2909 ]\n",
            " [509.51443]\n",
            " [454.30624]\n",
            " [465.5776 ]\n",
            " [555.1988 ]\n",
            " [426.2147 ]\n",
            " [500.18918]\n",
            " [516.0503 ]\n",
            " [451.29062]\n",
            " [475.9456 ]\n",
            " [414.30133]\n",
            " [490.2533 ]\n",
            " [538.12695]\n",
            " [427.34094]\n",
            " [480.21286]\n",
            " [448.01093]\n",
            " [535.28784]\n",
            " [420.63568]\n",
            " [407.4282 ]\n",
            " [492.09982]\n",
            " [485.72025]\n",
            " [539.53955]\n",
            " [444.235  ]\n",
            " [521.87354]\n",
            " [487.24387]\n",
            " [584.73267]\n",
            " [470.6161 ]\n",
            " [466.60626]\n",
            " [427.9814 ]\n",
            " [508.49927]\n",
            " [503.62967]\n",
            " [528.75397]\n",
            " [540.01416]\n",
            " [519.8052 ]\n",
            " [423.0443 ]\n",
            " [454.99066]\n",
            " [496.24612]\n",
            " [474.20078]\n",
            " [582.6914 ]\n",
            " [453.58426]\n",
            " [532.1664 ]\n",
            " [529.3858 ]\n",
            " [422.91718]\n",
            " [510.1047 ]\n",
            " [468.67673]\n",
            " [477.94522]\n",
            " [489.30194]\n",
            " [501.17163]\n",
            " [565.0981 ]\n",
            " [509.73648]\n",
            " [555.0123 ]\n",
            " [487.8721 ]\n",
            " [434.56387]\n",
            " [517.6315 ]\n",
            " [437.8968 ]\n",
            " [499.02826]\n",
            " [570.1095 ]\n",
            " [535.1669 ]\n",
            " [550.70746]\n",
            " [455.8356 ]\n",
            " [496.30072]\n",
            " [500.19855]\n",
            " [501.02835]\n",
            " [500.94174]\n",
            " [538.2981 ]\n",
            " [538.0881 ]\n",
            " [554.62085]\n",
            " [441.95493]\n",
            " [544.3189 ]\n",
            " [486.96936]\n",
            " [547.1109 ]\n",
            " [476.81525]\n",
            " [477.8807 ]\n",
            " [436.53232]\n",
            " [565.2912 ]\n",
            " [474.76657]\n",
            " [472.93427]\n",
            " [476.14514]\n",
            " [547.73334]\n",
            " [499.78687]\n",
            " [487.61575]\n",
            " [511.1453 ]\n",
            " [514.24457]\n",
            " [439.17188]\n",
            " [571.174  ]\n",
            " [574.3462 ]\n",
            " [590.87756]\n",
            " [567.4306 ]\n",
            " [451.2955 ]\n",
            " [467.85086]\n",
            " [573.1198 ]\n",
            " [504.62933]\n",
            " [549.6208 ]\n",
            " [492.4433 ]\n",
            " [530.9176 ]\n",
            " [487.32272]\n",
            " [579.50806]\n",
            " [450.58536]\n",
            " [474.57736]\n",
            " [556.9799 ]\n",
            " [446.72726]\n",
            " [515.5792 ]\n",
            " [499.3059 ]\n",
            " [518.02527]\n",
            " [584.42316]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnq-cgMaeje3"
      },
      "source": [
        "# Baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8llYpvLN_Dm",
        "outputId": "644ebe24-f3c5-44be-e140-ae0d1bf6a94c"
      },
      "source": [
        "base_df = all_df.drop(['breakfast', 'lunch', 'dinner'], axis=1)\n",
        "b_train_df = base_df[:len(train_df)]\n",
        "b_test_df = base_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "print(b_train_df.shape, b_test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 12) (50, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImXwnP5-YC-c",
        "outputId": "1aa860d7-b7cf-41fb-be1b-8ce9d84a4e09"
      },
      "source": [
        "base_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1255 entries, 0 to 1254\n",
            "Data columns (total 12 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   lunch_y     1205 non-null   float64\n",
            " 1   dinner_y    1205 non-null   float64\n",
            " 2   vac_ratio   1255 non-null   float64\n",
            " 3   trip_ratio  1255 non-null   float64\n",
            " 4   home        1255 non-null   float64\n",
            " 5   extra       1255 non-null   float64\n",
            " 6   total       1255 non-null   float64\n",
            " 7   year        1255 non-null   int64  \n",
            " 8   month       1255 non-null   int64  \n",
            " 9   date        1255 non-null   int64  \n",
            " 10  week        1255 non-null   int64  \n",
            " 11  dayofweek   1255 non-null   int64  \n",
            "dtypes: float64(7), int64(5)\n",
            "memory usage: 167.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "CyxzG5YJX8S-",
        "outputId": "01dbe959-ba8e-4381-b1b8-b03a743006dd"
      },
      "source": [
        "base_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.00000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>890.334440</td>\n",
              "      <td>461.772614</td>\n",
              "      <td>0.055247</td>\n",
              "      <td>0.085630</td>\n",
              "      <td>0.017930</td>\n",
              "      <td>0.098451</td>\n",
              "      <td>0.841193</td>\n",
              "      <td>2018.169721</td>\n",
              "      <td>6.358566</td>\n",
              "      <td>15.89243</td>\n",
              "      <td>25.883665</td>\n",
              "      <td>2.007968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>209.505057</td>\n",
              "      <td>139.179202</td>\n",
              "      <td>0.049595</td>\n",
              "      <td>0.016669</td>\n",
              "      <td>0.039774</td>\n",
              "      <td>0.087486</td>\n",
              "      <td>0.056905</td>\n",
              "      <td>1.518847</td>\n",
              "      <td>3.470845</td>\n",
              "      <td>8.67904</td>\n",
              "      <td>15.164042</td>\n",
              "      <td>1.414191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008475</td>\n",
              "      <td>0.014576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520288</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>758.000000</td>\n",
              "      <td>406.000000</td>\n",
              "      <td>0.025727</td>\n",
              "      <td>0.076076</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001061</td>\n",
              "      <td>0.814270</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>879.000000</td>\n",
              "      <td>483.000000</td>\n",
              "      <td>0.037074</td>\n",
              "      <td>0.087205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.863602</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>16.00000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1032.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>0.065336</td>\n",
              "      <td>0.097917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164824</td>\n",
              "      <td>0.882132</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1459.000000</td>\n",
              "      <td>905.000000</td>\n",
              "      <td>0.464164</td>\n",
              "      <td>0.121115</td>\n",
              "      <td>0.180678</td>\n",
              "      <td>0.387640</td>\n",
              "      <td>0.934087</td>\n",
              "      <td>2021.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.00000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           lunch_y     dinner_y  ...         week    dayofweek\n",
              "count  1205.000000  1205.000000  ...  1255.000000  1255.000000\n",
              "mean    890.334440   461.772614  ...    25.883665     2.007968\n",
              "std     209.505057   139.179202  ...    15.164042     1.414191\n",
              "min     296.000000     0.000000  ...     1.000000     0.000000\n",
              "25%     758.000000   406.000000  ...    12.000000     1.000000\n",
              "50%     879.000000   483.000000  ...    26.000000     2.000000\n",
              "75%    1032.000000   545.000000  ...    39.000000     3.000000\n",
              "max    1459.000000   905.000000  ...    52.000000     4.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "28llXi8yOsix",
        "outputId": "946af01f-50bf-462e-cd2c-5e36d1261d30"
      },
      "source": [
        "b_train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lunch_y  dinner_y  vac_ratio  trip_ratio  ...  month  date  week  dayofweek\n",
              "0   1039.0     331.0   0.019223    0.057670  ...      2     1     5          0\n",
              "1    867.0     560.0   0.019223    0.066513  ...      2     2     5          1\n",
              "2   1017.0     573.0   0.021530    0.069204  ...      2     3     5          2\n",
              "3    978.0     525.0   0.039985    0.084583  ...      2     4     5          3\n",
              "4    925.0     330.0   0.106882    0.069589  ...      2     5     5          4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "yq3gPBCyOthV",
        "outputId": "b2d11856-c131-4cba-f160-34694c576788"
      },
      "source": [
        "b_test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>0.029501</td>\n",
              "      <td>0.061012</td>\n",
              "      <td>0.120013</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>0.034864</td>\n",
              "      <td>0.071069</td>\n",
              "      <td>0.116661</td>\n",
              "      <td>0.137110</td>\n",
              "      <td>0.777405</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>0.090513</td>\n",
              "      <td>0.083473</td>\n",
              "      <td>0.098558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727456</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>0.036936</td>\n",
              "      <td>0.052668</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.183995</td>\n",
              "      <td>0.800274</td>\n",
              "      <td>2021</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.063611</td>\n",
              "      <td>0.107387</td>\n",
              "      <td>0.155609</td>\n",
              "      <td>0.807798</td>\n",
              "      <td>2021</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      vac_ratio  trip_ratio      home     extra  ...  month  date  week  dayofweek\n",
              "1205   0.029501    0.061012  0.120013  0.001676  ...      1    27     4          2\n",
              "1206   0.034864    0.071069  0.116661  0.137110  ...      1    28     4          3\n",
              "1207   0.090513    0.083473  0.098558  0.000000  ...      1    29     4          4\n",
              "1208   0.036936    0.052668  0.110123  0.183995  ...      2     1     5          0\n",
              "1209   0.021204    0.063611  0.107387  0.155609  ...      2     2     5          1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgx-WqyF80Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2976ba-bc98-4007-88b7-a82a6a486baa"
      },
      "source": [
        "lunch_X = b_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "lunch_y = b_train_df['lunch_y']\n",
        "dinner_X = b_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "dinner_y = b_train_df['dinner_y']\n",
        "for col in (lunch_X, lunch_y, dinner_X, dinner_y):\n",
        "    print(col.head(1))\n",
        "# 점심\n",
        "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(lunch_X, lunch_y, test_size=0.2, random_state=2021)\n",
        "# 저녁\n",
        "d_X_train, d_X_test, d_y_train, d_y_test = train_test_split(dinner_X, dinner_y, test_size=0.2, random_state=2021)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   vac_ratio  trip_ratio  home     extra  ...  month  date  week  dayofweek\n",
            "0   0.019223     0.05767   0.0  0.091503  ...      2     1     5          0\n",
            "\n",
            "[1 rows x 10 columns]\n",
            "0    1039.0\n",
            "Name: lunch_y, dtype: float64\n",
            "   vac_ratio  trip_ratio  home     extra  ...  month  date  week  dayofweek\n",
            "0   0.019223     0.05767   0.0  0.091503  ...      2     1     5          0\n",
            "\n",
            "[1 rows x 10 columns]\n",
            "0    331.0\n",
            "Name: dinner_y, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8wltZXuVaNX",
        "outputId": "de911167-e660-4802-bdac-b36d2ac767d9"
      },
      "source": [
        "col1 = [l_X_train, l_X_test, l_y_train, l_y_test]\n",
        "col2 = [d_X_train, d_X_test, d_y_train, d_y_test]\n",
        "for i, j in zip(col1, col2):\n",
        "    print(i.shape)\n",
        "    print(j.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 10)\n",
            "(964, 10)\n",
            "(241, 10)\n",
            "(241, 10)\n",
            "(964,)\n",
            "(964,)\n",
            "(241,)\n",
            "(241,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcqfiTFxaG9c"
      },
      "source": [
        "## 점심 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnx4bk2WN4_",
        "outputId": "5c035d89-d46c-4e36-d074-06cfbf25d931"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=2021)\n",
        "n_repeats=3\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = xgb.DMatrix(l_X_train, label=l_y_train)\n",
        "    dtest = xgb.DMatrix(l_X_test, label=l_y_test)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror', # 회귀\n",
        "         'eval_metric': 'mae',\n",
        "         \"xgb_gpu_hist\": 1,\n",
        "         'verbosity': 0,\n",
        "         'booster': 'gbtree', # gradient boosting decision tree\n",
        "         'lambda': trial.suggest_loguniform('lambda', 1e-8, 1),\n",
        "         'alpha': trial.suggest_loguniform('alpha', 1e-8, 1),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
        "         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "         'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n",
        "         'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "    xgb2 = model.fit(l_X_train, l_y_train, eval_set=[(l_X_test, l_y_test)], verbose=0,\n",
        "                      eval_metric='mae')\n",
        "    mae = mean_absolute_error(l_y_test, xgb2.predict(l_X_test))\n",
        "\n",
        "    return mae\n",
        "        \n",
        "l_study_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_xgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:24:44,230]\u001b[0m A new study created in memory with name: no-name-a88e5a8f-534c-41e8-abf7-6b3d9a97a246\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:44,983]\u001b[0m Trial 0 finished with value: 918.3411489156272 and parameters: {'lambda': 0.0007044111641739534, 'alpha': 0.007361306311531573, 'max_depth': 3, 'eta': 3.1723761109634215e-06, 'gamma': 0.9504871519148276, 'n_estimators': 802, 'min_child_weight': 1, 'subsample': 0.7974053460591444}. Best is trial 0 with value: 918.3411489156272.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:46,062]\u001b[0m Trial 1 finished with value: 920.6297843038294 and parameters: {'lambda': 0.0019828237604565383, 'alpha': 0.01881399642343495, 'max_depth': 3, 'eta': 2.9415096718071926e-08, 'gamma': 0.5002279126949734, 'n_estimators': 1193, 'min_child_weight': 0, 'subsample': 0.6689793622007182}. Best is trial 0 with value: 918.3411489156272.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:47,542]\u001b[0m Trial 2 finished with value: 913.3117210736414 and parameters: {'lambda': 0.0008554559847076483, 'alpha': 0.5137409482657409, 'max_depth': 7, 'eta': 9.317229332510368e-06, 'gamma': 4.141540859021937e-05, 'n_estimators': 861, 'min_child_weight': 6, 'subsample': 0.47829570944696775}. Best is trial 2 with value: 913.3117210736414.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:48,768]\u001b[0m Trial 3 finished with value: 66.56477336962688 and parameters: {'lambda': 0.0004673391136992949, 'alpha': 6.464095867534913e-05, 'max_depth': 6, 'eta': 0.03844050387430893, 'gamma': 0.007207758310433094, 'n_estimators': 755, 'min_child_weight': 7, 'subsample': 0.7213206090997876}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:51,769]\u001b[0m Trial 4 finished with value: 273.61192290120107 and parameters: {'lambda': 0.042083801365359705, 'alpha': 4.322700584864719e-07, 'max_depth': 7, 'eta': 0.0008741945531044277, 'gamma': 2.5618220897682866e-06, 'n_estimators': 1398, 'min_child_weight': 6, 'subsample': 0.9834348413016252}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:53,821]\u001b[0m Trial 5 finished with value: 888.0750881685756 and parameters: {'lambda': 3.45030802333646e-05, 'alpha': 1.0245696441514804e-07, 'max_depth': 6, 'eta': 2.8463576586210582e-05, 'gamma': 0.2125771165026529, 'n_estimators': 1267, 'min_child_weight': 9, 'subsample': 0.6861216687720229}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:56,129]\u001b[0m Trial 6 finished with value: 918.4752982592681 and parameters: {'lambda': 0.0012434816947988851, 'alpha': 5.466023520987005e-06, 'max_depth': 8, 'eta': 2.761888724198144e-06, 'gamma': 2.88634156038091e-06, 'n_estimators': 861, 'min_child_weight': 2, 'subsample': 0.7262540977337992}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:58,183]\u001b[0m Trial 7 finished with value: 70.33486545926803 and parameters: {'lambda': 1.7255139207784372e-07, 'alpha': 1.2870516994090315e-05, 'max_depth': 7, 'eta': 0.061149501847645366, 'gamma': 3.241096716642312e-08, 'n_estimators': 1031, 'min_child_weight': 3, 'subsample': 0.774644544278894}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:59,356]\u001b[0m Trial 8 finished with value: 68.1853860562273 and parameters: {'lambda': 6.177011550458872e-05, 'alpha': 0.02449800360991601, 'max_depth': 3, 'eta': 0.09918695841159368, 'gamma': 0.016436710223451063, 'n_estimators': 1318, 'min_child_weight': 0, 'subsample': 0.6896215853214822}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:01,048]\u001b[0m Trial 9 finished with value: 67.28061470253338 and parameters: {'lambda': 0.02187549378501035, 'alpha': 1.5598018174190139e-06, 'max_depth': 5, 'eta': 0.06682151812048484, 'gamma': 0.002690489809534762, 'n_estimators': 1304, 'min_child_weight': 4, 'subsample': 0.536733171381199}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:02,781]\u001b[0m Trial 10 finished with value: 300.78902033255804 and parameters: {'lambda': 5.004452912467814e-07, 'alpha': 0.00022278607691920244, 'max_depth': 9, 'eta': 0.001592380784922668, 'gamma': 0.002099348519680594, 'n_estimators': 704, 'min_child_weight': 10, 'subsample': 0.9316994280483778}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:04,111]\u001b[0m Trial 11 finished with value: 111.3425189133007 and parameters: {'lambda': 0.8124300831619966, 'alpha': 1.0942499015468279e-08, 'max_depth': 5, 'eta': 0.8567161025170673, 'gamma': 0.003961951563814869, 'n_estimators': 1053, 'min_child_weight': 8, 'subsample': 0.5415362837471598}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:05,985]\u001b[0m Trial 12 finished with value: 65.47171881584705 and parameters: {'lambda': 0.2767127371994452, 'alpha': 0.0002842771489056246, 'max_depth': 5, 'eta': 0.009813918251814603, 'gamma': 0.000475114248083701, 'n_estimators': 1407, 'min_child_weight': 4, 'subsample': 0.5616611239461566}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:07,652]\u001b[0m Trial 13 finished with value: 69.28092950211521 and parameters: {'lambda': 0.6973871675442999, 'alpha': 0.000284448495246753, 'max_depth': 5, 'eta': 0.002862468962969005, 'gamma': 0.00012550778351316517, 'n_estimators': 1473, 'min_child_weight': 7, 'subsample': 0.40970483992774775}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:09,241]\u001b[0m Trial 14 finished with value: 123.82464042441974 and parameters: {'lambda': 3.893349981715994e-06, 'alpha': 0.0009338630713115014, 'max_depth': 4, 'eta': 0.9132508070880299, 'gamma': 0.00015807915824965108, 'n_estimators': 1492, 'min_child_weight': 5, 'subsample': 0.5487032621606267}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:10,775]\u001b[0m Trial 15 finished with value: 783.4060237457148 and parameters: {'lambda': 0.05012678061570556, 'alpha': 2.919160899996243e-05, 'max_depth': 6, 'eta': 0.00016910018811554884, 'gamma': 0.045075163473762385, 'n_estimators': 958, 'min_child_weight': 4, 'subsample': 0.6005481927728954}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:12,140]\u001b[0m Trial 16 finished with value: 64.20113527923205 and parameters: {'lambda': 0.2740768872902664, 'alpha': 0.0010646682248388827, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 1163, 'min_child_weight': 7, 'subsample': 0.8572080056927597}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:13,493]\u001b[0m Trial 17 finished with value: 67.40008760191098 and parameters: {'lambda': 0.9571509232692393, 'alpha': 0.32176538177297237, 'max_depth': 4, 'eta': 0.005376159201972576, 'gamma': 1.28114344075404e-05, 'n_estimators': 1160, 'min_child_weight': 5, 'subsample': 0.8751973272381632}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:14,941]\u001b[0m Trial 18 finished with value: 722.0406193396857 and parameters: {'lambda': 1.1919908806560655e-08, 'alpha': 0.0023069979929525183, 'max_depth': 4, 'eta': 0.00017392894544831955, 'gamma': 0.0005959691237442354, 'n_estimators': 1403, 'min_child_weight': 10, 'subsample': 0.4591840805254221}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:16,237]\u001b[0m Trial 19 finished with value: 65.34140153940288 and parameters: {'lambda': 0.18073547388026767, 'alpha': 0.06451499291835323, 'max_depth': 4, 'eta': 0.01786502548027726, 'gamma': 3.561841423988695e-08, 'n_estimators': 1172, 'min_child_weight': 3, 'subsample': 0.5933452151689637}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:17,570]\u001b[0m Trial 20 finished with value: 81.2812292328514 and parameters: {'lambda': 0.009409659062217815, 'alpha': 0.1590777309745813, 'max_depth': 4, 'eta': 0.3557242255687097, 'gamma': 2.3922179706674597e-08, 'n_estimators': 1137, 'min_child_weight': 2, 'subsample': 0.6169627695906035}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:19,215]\u001b[0m Trial 21 finished with value: 66.09441708133429 and parameters: {'lambda': 0.160756284633171, 'alpha': 0.0009663744947612753, 'max_depth': 5, 'eta': 0.010841969920209825, 'gamma': 1.965059027408609e-07, 'n_estimators': 1226, 'min_child_weight': 3, 'subsample': 0.583481689951347}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:20,314]\u001b[0m Trial 22 finished with value: 63.76083867876361 and parameters: {'lambda': 0.2071617183903141, 'alpha': 0.028389630078426337, 'max_depth': 4, 'eta': 0.01843924924522292, 'gamma': 0.0006187858956920169, 'n_estimators': 1057, 'min_child_weight': 4, 'subsample': 0.49937190739488835}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:21,216]\u001b[0m Trial 23 finished with value: 71.47218784949591 and parameters: {'lambda': 0.007627032299773406, 'alpha': 0.03057499913770234, 'max_depth': 3, 'eta': 0.24268756816628095, 'gamma': 1.1831896282470302e-05, 'n_estimators': 1071, 'min_child_weight': 6, 'subsample': 0.4799326516041161}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:22,193]\u001b[0m Trial 24 finished with value: 413.13437700073746 and parameters: {'lambda': 0.13068318019504035, 'alpha': 0.05527248630619152, 'max_depth': 4, 'eta': 0.000825402305546864, 'gamma': 6.465945239353549e-07, 'n_estimators': 980, 'min_child_weight': 3, 'subsample': 0.4104983193192014}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:23,332]\u001b[0m Trial 25 finished with value: 65.65550820758234 and parameters: {'lambda': 0.9372120867902318, 'alpha': 0.006049924902092124, 'max_depth': 4, 'eta': 0.019968607075283362, 'gamma': 0.000547702263480113, 'n_estimators': 1118, 'min_child_weight': 8, 'subsample': 0.5026674168411607}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:24,142]\u001b[0m Trial 26 finished with value: 630.3086509229731 and parameters: {'lambda': 0.0047267670742643245, 'alpha': 0.9433949814102942, 'max_depth': 3, 'eta': 0.00039486518044311346, 'gamma': 1.969825957042282e-05, 'n_estimators': 969, 'min_child_weight': 2, 'subsample': 0.44727861528246615}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:25,440]\u001b[0m Trial 27 finished with value: 79.17071748472348 and parameters: {'lambda': 0.12946761480821614, 'alpha': 0.07633072612236762, 'max_depth': 4, 'eta': 0.2188051451663559, 'gamma': 0.028004999588453865, 'n_estimators': 1226, 'min_child_weight': 5, 'subsample': 0.5110743451156794}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:26,774]\u001b[0m Trial 28 finished with value: 67.60952011678229 and parameters: {'lambda': 0.045651976278035765, 'alpha': 0.0027919745946494534, 'max_depth': 5, 'eta': 0.003791399704997058, 'gamma': 0.00011311956795561258, 'n_estimators': 1104, 'min_child_weight': 4, 'subsample': 0.43712371626449087}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:27,748]\u001b[0m Trial 29 finished with value: 920.4169202738777 and parameters: {'lambda': 0.3251467993745164, 'alpha': 0.011527281447922762, 'max_depth': 3, 'eta': 2.6598991453494786e-07, 'gamma': 0.09725359248861774, 'n_estimators': 1012, 'min_child_weight': 1, 'subsample': 0.8609625459069349}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:28,553]\u001b[0m Trial 30 finished with value: 891.1256005773901 and parameters: {'lambda': 0.026309010256652807, 'alpha': 0.0048158470784652125, 'max_depth': 3, 'eta': 3.6637203141230605e-05, 'gamma': 0.001350819781320405, 'n_estimators': 897, 'min_child_weight': 7, 'subsample': 0.6355155580215037}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:30,375]\u001b[0m Trial 31 finished with value: 65.66313886840314 and parameters: {'lambda': 0.21823113903857247, 'alpha': 0.0007674714125633175, 'max_depth': 5, 'eta': 0.012604206949792552, 'gamma': 0.0002800994353654845, 'n_estimators': 1364, 'min_child_weight': 4, 'subsample': 0.5821410853305904}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:31,710]\u001b[0m Trial 32 finished with value: 65.47880611182248 and parameters: {'lambda': 0.2875238410485435, 'alpha': 9.626458786645682e-05, 'max_depth': 4, 'eta': 0.01840068848363384, 'gamma': 0.0006983690521101405, 'n_estimators': 1203, 'min_child_weight': 3, 'subsample': 0.6376430109191562}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:33,286]\u001b[0m Trial 33 finished with value: 66.53877809136735 and parameters: {'lambda': 0.8766589057109917, 'alpha': 0.1647192179899387, 'max_depth': 5, 'eta': 0.006298866217442768, 'gamma': 3.605108553097131e-05, 'n_estimators': 1171, 'min_child_weight': 1, 'subsample': 0.5682265072290751}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:34,614]\u001b[0m Trial 34 finished with value: 67.1737475889847 and parameters: {'lambda': 0.00026800490142671974, 'alpha': 0.00023165926065790214, 'max_depth': 4, 'eta': 0.03163077809397883, 'gamma': 0.006960980040910539, 'n_estimators': 1272, 'min_child_weight': 6, 'subsample': 0.5040631702445691}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:36,215]\u001b[0m Trial 35 finished with value: 196.59272696467357 and parameters: {'lambda': 0.0033033834013924375, 'alpha': 0.0021798012566677364, 'max_depth': 6, 'eta': 0.001700104649425605, 'gamma': 5.262820093234687e-05, 'n_estimators': 917, 'min_child_weight': 4, 'subsample': 0.659609945507105}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:38,023]\u001b[0m Trial 36 finished with value: 70.69596881787312 and parameters: {'lambda': 0.07612852097134915, 'alpha': 0.013745161698255681, 'max_depth': 5, 'eta': 0.12118806005489595, 'gamma': 4.554880814638298e-06, 'n_estimators': 1423, 'min_child_weight': 6, 'subsample': 0.5308684849500519}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:39,016]\u001b[0m Trial 37 finished with value: 566.9749211988013 and parameters: {'lambda': 0.016001288641054264, 'alpha': 0.4848633782842135, 'max_depth': 3, 'eta': 0.00045437426136759945, 'gamma': 0.6648418476038375, 'n_estimators': 1078, 'min_child_weight': 5, 'subsample': 0.7501982494312628}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:40,454]\u001b[0m Trial 38 finished with value: 68.37319857648794 and parameters: {'lambda': 0.37830766337833766, 'alpha': 2.3875873223855133e-05, 'max_depth': 4, 'eta': 0.033572943847321284, 'gamma': 0.00027971978355721667, 'n_estimators': 1344, 'min_child_weight': 1, 'subsample': 0.48364960002910196}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:41,917]\u001b[0m Trial 39 finished with value: 920.6512656624881 and parameters: {'lambda': 0.0013083025082882734, 'alpha': 0.0005963194974817163, 'max_depth': 6, 'eta': 1.453365910950332e-08, 'gamma': 0.013795691188164573, 'n_estimators': 790, 'min_child_weight': 3, 'subsample': 0.8091926383702137}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:44,427]\u001b[0m Trial 40 finished with value: 92.21004729844722 and parameters: {'lambda': 0.10643828543223426, 'alpha': 0.048721427763492614, 'max_depth': 7, 'eta': 0.5264933954023195, 'gamma': 0.0013080549493276036, 'n_estimators': 1258, 'min_child_weight': 2, 'subsample': 0.568864027814022}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:45,782]\u001b[0m Trial 41 finished with value: 64.8624306833101 and parameters: {'lambda': 0.4078147902543462, 'alpha': 0.0001225110703385133, 'max_depth': 4, 'eta': 0.01258267098415013, 'gamma': 0.000676656126643668, 'n_estimators': 1197, 'min_child_weight': 3, 'subsample': 0.6433697540019185}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:47,131]\u001b[0m Trial 42 finished with value: 65.68355994006905 and parameters: {'lambda': 0.41469291313219897, 'alpha': 5.958593343648572e-06, 'max_depth': 4, 'eta': 0.0074743184319847, 'gamma': 0.00032037877226054296, 'n_estimators': 1165, 'min_child_weight': 4, 'subsample': 0.6696656009022517}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:48,582]\u001b[0m Trial 43 finished with value: 70.90660684039484 and parameters: {'lambda': 0.05934943626914697, 'alpha': 6.424451137568253e-05, 'max_depth': 5, 'eta': 0.10182282439510772, 'gamma': 0.004589266119230406, 'n_estimators': 1019, 'min_child_weight': 3, 'subsample': 0.7052555724607684}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:50,370]\u001b[0m Trial 44 finished with value: 93.12601594410496 and parameters: {'lambda': 0.01732043201454145, 'alpha': 0.00033675868455918033, 'max_depth': 5, 'eta': 0.0023021868361587515, 'gamma': 6.036845199256942e-05, 'n_estimators': 1118, 'min_child_weight': 2, 'subsample': 0.970397622865187}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:51,709]\u001b[0m Trial 45 finished with value: 66.96586463263421 and parameters: {'lambda': 1.6665751034731995e-05, 'alpha': 4.1268641761415764e-05, 'max_depth': 4, 'eta': 0.04561606792786469, 'gamma': 0.0012749949992720854, 'n_estimators': 1211, 'min_child_weight': 4, 'subsample': 0.6025443314376345}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:52,808]\u001b[0m Trial 46 finished with value: 223.5998911244246 and parameters: {'lambda': 0.4163754932794567, 'alpha': 0.00018078657901974128, 'max_depth': 3, 'eta': 0.0011224113425333613, 'gamma': 0.0026877259921942545, 'n_estimators': 1295, 'min_child_weight': 7, 'subsample': 0.5531604400526776}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:54,035]\u001b[0m Trial 47 finished with value: 64.35296073691974 and parameters: {'lambda': 0.0005191714251864224, 'alpha': 8.12733873663608e-06, 'max_depth': 4, 'eta': 0.017284203813064784, 'gamma': 0.0001863794283045143, 'n_estimators': 1078, 'min_child_weight': 5, 'subsample': 0.8050531631466846}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:55,043]\u001b[0m Trial 48 finished with value: 71.0621180870721 and parameters: {'lambda': 3.724610945081388e-06, 'alpha': 3.7984606442848577e-06, 'max_depth': 3, 'eta': 0.1436178588128073, 'gamma': 0.0002142191213028585, 'n_estimators': 1088, 'min_child_weight': 8, 'subsample': 0.8503096346810791}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:56,278]\u001b[0m Trial 49 finished with value: 66.52909021654564 and parameters: {'lambda': 0.000397333699416699, 'alpha': 1.5278081275894802e-06, 'max_depth': 4, 'eta': 0.05427246005429505, 'gamma': 8.298139675573555e-05, 'n_estimators': 1052, 'min_child_weight': 0, 'subsample': 0.8155844991352281}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdO9O4BxaMgy"
      },
      "source": [
        "## 저녁 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeopNUEEaKea",
        "outputId": "4f27fddd-a51f-433e-b5bf-45cecf31305e"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=2021)\n",
        "n_repeats=3\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = xgb.DMatrix(d_X_train, label=d_y_train)\n",
        "    dtest = xgb.DMatrix(d_X_test, label=d_y_test)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror', # 회귀\n",
        "         'eval_metric': 'mae',\n",
        "         \"xgb_gpu_hist\": 1,\n",
        "         'verbosity': 0,\n",
        "         'booster': 'gbtree', # gradient boosting decision tree\n",
        "         'lambda': trial.suggest_loguniform('lambda', 1e-8, 1),\n",
        "         'alpha': trial.suggest_loguniform('alpha', 1e-8, 1),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
        "         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "         'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n",
        "         'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "\n",
        "    xgb2 = model.fit(d_X_train, d_y_train, eval_set=[(d_X_test, d_y_test)], verbose=0,\n",
        "                      eval_metric='mae')\n",
        "    mae = mean_absolute_error(d_y_test, xgb2.predict(d_X_test))\n",
        "\n",
        "    return mae\n",
        "        \n",
        "d_study_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_xgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:25:56,311]\u001b[0m A new study created in memory with name: no-name-f426e753-abd1-4098-9403-ed9ac82358d3\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:57,075]\u001b[0m Trial 0 finished with value: 475.41611422913695 and parameters: {'lambda': 0.0007044111641739534, 'alpha': 0.007361306311531573, 'max_depth': 3, 'eta': 3.1723761109634215e-06, 'gamma': 0.9504871519148276, 'n_estimators': 802, 'min_child_weight': 1, 'subsample': 0.7974053460591444}. Best is trial 0 with value: 475.41611422913695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:58,167]\u001b[0m Trial 1 finished with value: 476.5668930421232 and parameters: {'lambda': 0.0019828237604565383, 'alpha': 0.01881399642343495, 'max_depth': 3, 'eta': 2.9415096718071926e-08, 'gamma': 0.5002279126949734, 'n_estimators': 1193, 'min_child_weight': 0, 'subsample': 0.6689793622007182}. Best is trial 0 with value: 475.41611422913695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:59,697]\u001b[0m Trial 2 finished with value: 472.89822147199226 and parameters: {'lambda': 0.0008554559847076483, 'alpha': 0.5137409482657409, 'max_depth': 7, 'eta': 9.317229332510368e-06, 'gamma': 4.141540859021937e-05, 'n_estimators': 861, 'min_child_weight': 6, 'subsample': 0.47829570944696775}. Best is trial 2 with value: 472.89822147199226.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:00,929]\u001b[0m Trial 3 finished with value: 52.80681936968411 and parameters: {'lambda': 0.0004673391136992949, 'alpha': 6.464095867534913e-05, 'max_depth': 6, 'eta': 0.03844050387430893, 'gamma': 0.007207758310433094, 'n_estimators': 755, 'min_child_weight': 7, 'subsample': 0.7213206090997876}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:04,050]\u001b[0m Trial 4 finished with value: 152.3267437562161 and parameters: {'lambda': 0.042083801365359705, 'alpha': 4.322700584864719e-07, 'max_depth': 7, 'eta': 0.0008741945531044277, 'gamma': 2.5618220897682866e-06, 'n_estimators': 1398, 'min_child_weight': 6, 'subsample': 0.9834348413016252}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:06,178]\u001b[0m Trial 5 finished with value: 460.2370487693929 and parameters: {'lambda': 3.45030802333646e-05, 'alpha': 1.0245696441514804e-07, 'max_depth': 6, 'eta': 2.8463576586210582e-05, 'gamma': 0.2125771165026529, 'n_estimators': 1267, 'min_child_weight': 9, 'subsample': 0.6861216687720229}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:08,688]\u001b[0m Trial 6 finished with value: 475.4849389205335 and parameters: {'lambda': 0.0012434816947988851, 'alpha': 5.466023520987005e-06, 'max_depth': 8, 'eta': 2.761888724198144e-06, 'gamma': 2.88634156038091e-06, 'n_estimators': 861, 'min_child_weight': 2, 'subsample': 0.7262540977337992}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:10,713]\u001b[0m Trial 7 finished with value: 53.12981206252862 and parameters: {'lambda': 1.7255139207784372e-07, 'alpha': 1.2870516994090315e-05, 'max_depth': 7, 'eta': 0.061149501847645366, 'gamma': 3.241096716642312e-08, 'n_estimators': 1031, 'min_child_weight': 3, 'subsample': 0.774644544278894}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:11,907]\u001b[0m Trial 8 finished with value: 59.22441621835796 and parameters: {'lambda': 6.177011550458872e-05, 'alpha': 0.02449800360991601, 'max_depth': 3, 'eta': 0.09918695841159368, 'gamma': 0.016436710223451063, 'n_estimators': 1318, 'min_child_weight': 0, 'subsample': 0.6896215853214822}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:13,595]\u001b[0m Trial 9 finished with value: 53.98322954217428 and parameters: {'lambda': 0.02187549378501035, 'alpha': 1.5598018174190139e-06, 'max_depth': 5, 'eta': 0.06682151812048484, 'gamma': 0.002690489809534762, 'n_estimators': 1304, 'min_child_weight': 4, 'subsample': 0.536733171381199}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:15,332]\u001b[0m Trial 10 finished with value: 166.63734709919734 and parameters: {'lambda': 5.004452912467814e-07, 'alpha': 0.00022278607691920244, 'max_depth': 9, 'eta': 0.001592380784922668, 'gamma': 0.002099348519680594, 'n_estimators': 704, 'min_child_weight': 10, 'subsample': 0.9316994280483778}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:16,325]\u001b[0m Trial 11 finished with value: 75.39252892173673 and parameters: {'lambda': 6.303067996914016e-08, 'alpha': 0.00011284590212347822, 'max_depth': 5, 'eta': 0.8540676182150262, 'gamma': 2.960389675838704e-08, 'n_estimators': 1022, 'min_child_weight': 8, 'subsample': 0.8212404197422466}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:17,720]\u001b[0m Trial 12 finished with value: 49.60530137224316 and parameters: {'lambda': 2.1115276911097155e-06, 'alpha': 1.053023456782512e-08, 'max_depth': 5, 'eta': 0.009329138801411624, 'gamma': 1.0428876644868658e-08, 'n_estimators': 1030, 'min_child_weight': 4, 'subsample': 0.5995868221527397}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:18,713]\u001b[0m Trial 13 finished with value: 85.74301532096388 and parameters: {'lambda': 3.029505671740337e-06, 'alpha': 2.3254850323359887e-08, 'max_depth': 5, 'eta': 0.002762356761921004, 'gamma': 0.00010187306410138822, 'n_estimators': 717, 'min_child_weight': 7, 'subsample': 0.565794121839103}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:19,673]\u001b[0m Trial 14 finished with value: 195.27811266673552 and parameters: {'lambda': 5.212926435362662e-06, 'alpha': 2.3226546685639463e-08, 'max_depth': 4, 'eta': 0.9132508070880299, 'gamma': 0.02286909713380436, 'n_estimators': 988, 'min_child_weight': 5, 'subsample': 0.4096051466204361}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:21,362]\u001b[0m Trial 15 finished with value: 395.96413413320835 and parameters: {'lambda': 0.3398163549712074, 'alpha': 0.0010321400334105644, 'max_depth': 6, 'eta': 0.00016910018811554884, 'gamma': 3.7500074859559315e-07, 'n_estimators': 1146, 'min_child_weight': 4, 'subsample': 0.5980303637521858}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:22,341]\u001b[0m Trial 16 finished with value: 48.37489075878349 and parameters: {'lambda': 4.277979133843391e-06, 'alpha': 0.7749760386934557, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 940, 'min_child_weight': 7, 'subsample': 0.5002956340798566}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:23,320]\u001b[0m Trial 17 finished with value: 49.59407719339078 and parameters: {'lambda': 1.804464586382735e-06, 'alpha': 0.06256584421430596, 'max_depth': 4, 'eta': 0.005376159201972576, 'gamma': 8.68993960210861e-05, 'n_estimators': 952, 'min_child_weight': 5, 'subsample': 0.468648006410138}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:24,245]\u001b[0m Trial 18 finished with value: 425.38179205661 and parameters: {'lambda': 1.1772216526969938e-08, 'alpha': 0.9994246856858706, 'max_depth': 4, 'eta': 0.00012458048704042218, 'gamma': 0.00016468352252101143, 'n_estimators': 948, 'min_child_weight': 10, 'subsample': 0.40332500922435083}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:25,217]\u001b[0m Trial 19 finished with value: 476.4907484974604 and parameters: {'lambda': 2.0556174559931543e-05, 'alpha': 0.21987538004955565, 'max_depth': 4, 'eta': 2.164831945499237e-07, 'gamma': 0.0003867070164004027, 'n_estimators': 926, 'min_child_weight': 8, 'subsample': 0.46844809354771166}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:26,335]\u001b[0m Trial 20 finished with value: 48.99136212455781 and parameters: {'lambda': 3.1778711344601074e-08, 'alpha': 0.1084228639083024, 'max_depth': 4, 'eta': 0.006989318214660817, 'gamma': 2.1496960796248377e-05, 'n_estimators': 1104, 'min_child_weight': 5, 'subsample': 0.4644635260242569}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:27,462]\u001b[0m Trial 21 finished with value: 48.56101706413807 and parameters: {'lambda': 2.555192037586075e-08, 'alpha': 0.11611550144786228, 'max_depth': 4, 'eta': 0.008392157449483425, 'gamma': 6.100470859500051e-06, 'n_estimators': 1113, 'min_child_weight': 6, 'subsample': 0.4595537856813319}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:28,404]\u001b[0m Trial 22 finished with value: 340.3084225634816 and parameters: {'lambda': 1.627341649627836e-08, 'alpha': 0.1177102169557382, 'max_depth': 3, 'eta': 0.0003212314759473525, 'gamma': 9.785938310693853e-06, 'n_estimators': 1099, 'min_child_weight': 6, 'subsample': 0.5165671428147879}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:29,469]\u001b[0m Trial 23 finished with value: 48.903642250789154 and parameters: {'lambda': 5.596019783535093e-08, 'alpha': 0.0024442335233036305, 'max_depth': 4, 'eta': 0.017411679188438785, 'gamma': 4.031547520455439e-07, 'n_estimators': 1093, 'min_child_weight': 7, 'subsample': 0.4322241697354785}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:30,650]\u001b[0m Trial 24 finished with value: 65.13898644902399 and parameters: {'lambda': 2.2871858625155397e-07, 'alpha': 0.005758707088677027, 'max_depth': 4, 'eta': 0.3226255305406646, 'gamma': 3.180815361349332e-07, 'n_estimators': 1200, 'min_child_weight': 8, 'subsample': 0.42788697226847766}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:31,903]\u001b[0m Trial 25 finished with value: 49.54024992048493 and parameters: {'lambda': 7.40953537192926e-08, 'alpha': 0.0014365396163047842, 'max_depth': 5, 'eta': 0.019211481493860153, 'gamma': 4.691084394211817e-07, 'n_estimators': 1090, 'min_child_weight': 7, 'subsample': 0.431195865004134}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:33,142]\u001b[0m Trial 26 finished with value: 146.68508325473897 and parameters: {'lambda': 4.594266046202505e-07, 'alpha': 0.9623633840490177, 'max_depth': 3, 'eta': 0.0008733896032352066, 'gamma': 3.251227982097295e-06, 'n_estimators': 1487, 'min_child_weight': 9, 'subsample': 0.5098840384760587}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:34,335]\u001b[0m Trial 27 finished with value: 58.87532625554508 and parameters: {'lambda': 9.994284609160695e-06, 'alpha': 0.001090472722604927, 'max_depth': 4, 'eta': 0.21387733672238712, 'gamma': 1.2423419921608941e-07, 'n_estimators': 1188, 'min_child_weight': 7, 'subsample': 0.43840925916290835}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:35,452]\u001b[0m Trial 28 finished with value: 49.43363564241971 and parameters: {'lambda': 1.2294703093211583e-08, 'alpha': 0.3484092225614428, 'max_depth': 5, 'eta': 0.017590487328147743, 'gamma': 7.81726112519595e-06, 'n_estimators': 909, 'min_child_weight': 9, 'subsample': 0.503717173109283}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:36,160]\u001b[0m Trial 29 finished with value: 464.9184888289677 and parameters: {'lambda': 0.0001678788920671415, 'alpha': 0.008556452942455495, 'max_depth': 3, 'eta': 3.163462015935103e-05, 'gamma': 0.0006751371908833001, 'n_estimators': 815, 'min_child_weight': 6, 'subsample': 0.5427612959082263}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:36,982]\u001b[0m Trial 30 finished with value: 60.99465909538427 and parameters: {'lambda': 8.372731083265067e-07, 'alpha': 0.003492132415257511, 'max_depth': 3, 'eta': 0.2952491655766468, 'gamma': 1.4361781910861084e-06, 'n_estimators': 1057, 'min_child_weight': 8, 'subsample': 0.4013294186985629}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:38,147]\u001b[0m Trial 31 finished with value: 49.33993293635578 and parameters: {'lambda': 2.9574094687528395e-08, 'alpha': 0.03869215134728838, 'max_depth': 4, 'eta': 0.005112175719078412, 'gamma': 1.3802264419738717e-05, 'n_estimators': 1125, 'min_child_weight': 5, 'subsample': 0.4634306813340733}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:39,364]\u001b[0m Trial 32 finished with value: 250.0575388516628 and parameters: {'lambda': 7.802292995602489e-08, 'alpha': 0.09997556901862417, 'max_depth': 4, 'eta': 0.0005846769356512174, 'gamma': 3.440850648280193e-05, 'n_estimators': 1161, 'min_child_weight': 6, 'subsample': 0.4375681970222544}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:40,390]\u001b[0m Trial 33 finished with value: 49.670251156779244 and parameters: {'lambda': 3.255731254954529e-08, 'alpha': 0.012212843239462944, 'max_depth': 3, 'eta': 0.0209632201501692, 'gamma': 2.3465932927534822e-05, 'n_estimators': 1239, 'min_child_weight': 7, 'subsample': 0.49658741547877433}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:41,575]\u001b[0m Trial 34 finished with value: 61.75128170662401 and parameters: {'lambda': 1.0759705215678392e-08, 'alpha': 0.4478520547259499, 'max_depth': 4, 'eta': 0.0025950936838975737, 'gamma': 0.0005296817883751048, 'n_estimators': 1090, 'min_child_weight': 3, 'subsample': 0.45413897170598644}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:42,673]\u001b[0m Trial 35 finished with value: 49.02350790174176 and parameters: {'lambda': 1.3027332017585647e-07, 'alpha': 0.1343377711437904, 'max_depth': 5, 'eta': 0.008998777660171096, 'gamma': 9.383901458376211e-07, 'n_estimators': 872, 'min_child_weight': 5, 'subsample': 0.48893273115365804}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:44,034]\u001b[0m Trial 36 finished with value: 57.26218447151026 and parameters: {'lambda': 8.740497286545499e-07, 'alpha': 0.00035320812458775925, 'max_depth': 6, 'eta': 0.11718765143468748, 'gamma': 1.142227914779116e-07, 'n_estimators': 1003, 'min_child_weight': 6, 'subsample': 0.4172387544628144}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:44,686]\u001b[0m Trial 37 finished with value: 50.276839398744194 and parameters: {'lambda': 2.6922923375677746e-07, 'alpha': 0.035489631897735026, 'max_depth': 3, 'eta': 0.027464144019768915, 'gamma': 3.999722208934755e-06, 'n_estimators': 803, 'min_child_weight': 7, 'subsample': 0.45019431970130136}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:46,071]\u001b[0m Trial 38 finished with value: 446.9351382473198 and parameters: {'lambda': 0.00016514171967801477, 'alpha': 0.002825919257073743, 'max_depth': 4, 'eta': 5.438287567409407e-05, 'gamma': 0.0001964783196314695, 'n_estimators': 1222, 'min_child_weight': 4, 'subsample': 0.543531607775182}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:47,567]\u001b[0m Trial 39 finished with value: 156.79775720018569 and parameters: {'lambda': 0.0039153034190586725, 'alpha': 0.9397978108444817, 'max_depth': 5, 'eta': 0.0011276857065002299, 'gamma': 3.932400627001717e-05, 'n_estimators': 1058, 'min_child_weight': 6, 'subsample': 0.5774449863411818}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:48,773]\u001b[0m Trial 40 finished with value: 52.90647470308043 and parameters: {'lambda': 2.997854377785043e-08, 'alpha': 0.01858963899216021, 'max_depth': 3, 'eta': 0.003327304777907329, 'gamma': 0.0013591387058649446, 'n_estimators': 1373, 'min_child_weight': 3, 'subsample': 0.6295840409473126}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:49,857]\u001b[0m Trial 41 finished with value: 49.24867121906201 and parameters: {'lambda': 7.157486855516702e-08, 'alpha': 0.19019780531786146, 'max_depth': 5, 'eta': 0.010481735637286502, 'gamma': 1.2937970173218866e-06, 'n_estimators': 861, 'min_child_weight': 5, 'subsample': 0.48499778414992245}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:50,779]\u001b[0m Trial 42 finished with value: 52.85353423549921 and parameters: {'lambda': 1.46238192508433e-07, 'alpha': 0.0682076897217432, 'max_depth': 4, 'eta': 0.04581872898973004, 'gamma': 9.358188987148226e-07, 'n_estimators': 878, 'min_child_weight': 5, 'subsample': 0.48074435143551575}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:52,028]\u001b[0m Trial 43 finished with value: 48.691231852250475 and parameters: {'lambda': 1.5201381415709392e-07, 'alpha': 2.014883142394282e-05, 'max_depth': 5, 'eta': 0.009086426929558045, 'gamma': 1.1224628174885833e-07, 'n_estimators': 974, 'min_child_weight': 7, 'subsample': 0.5212690606787962}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:53,128]\u001b[0m Trial 44 finished with value: 344.4506517782251 and parameters: {'lambda': 2.9824023272254985e-08, 'alpha': 2.1286662771300246e-05, 'max_depth': 4, 'eta': 0.0003447145451748578, 'gamma': 6.536232546011515e-08, 'n_estimators': 980, 'min_child_weight': 8, 'subsample': 0.5210138851516327}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:54,382]\u001b[0m Trial 45 finished with value: 56.27455974911258 and parameters: {'lambda': 8.723587117264894e-07, 'alpha': 3.5214876592102657e-06, 'max_depth': 5, 'eta': 0.09562654300179624, 'gamma': 1.1121742270173979e-08, 'n_estimators': 1058, 'min_child_weight': 7, 'subsample': 0.4489719837515521}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:55,578]\u001b[0m Trial 46 finished with value: 65.37667595004639 and parameters: {'lambda': 3.2504999691040626e-07, 'alpha': 1.1734207361172968e-06, 'max_depth': 4, 'eta': 0.0022904798811346377, 'gamma': 5.2261027173581985e-08, 'n_estimators': 1138, 'min_child_weight': 6, 'subsample': 0.5272594427998025}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:57,473]\u001b[0m Trial 47 finished with value: 473.86223707604705 and parameters: {'lambda': 1.3053754674255718e-05, 'alpha': 1.4948419293456199e-05, 'max_depth': 6, 'eta': 5.041522275900231e-06, 'gamma': 7.965606783698402e-06, 'n_estimators': 1173, 'min_child_weight': 7, 'subsample': 0.562156886304678}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:58,662]\u001b[0m Trial 48 finished with value: 48.588130460240535 and parameters: {'lambda': 6.154927864206695e-06, 'alpha': 4.600883546057284e-05, 'max_depth': 5, 'eta': 0.008250568532058423, 'gamma': 0.006812827202181092, 'n_estimators': 985, 'min_child_weight': 8, 'subsample': 0.4187504781088081}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:59,763]\u001b[0m Trial 49 finished with value: 52.877577271204274 and parameters: {'lambda': 6.0945618374501046e-05, 'alpha': 4.590801432439927e-05, 'max_depth': 5, 'eta': 0.04652959753438826, 'gamma': 0.0681698714929842, 'n_estimators': 982, 'min_child_weight': 8, 'subsample': 0.4148593553123528}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reaA8c3PYrdV",
        "outputId": "5699fd3b-503f-4f5a-def0-c2fb241eb741"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_xgb.best_trial.value, l_study_xgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_xgb.best_trial.value, d_study_xgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunch Best Trial: score 63.76083867876361,\n",
            "params {'lambda': 0.2071617183903141, 'alpha': 0.028389630078426337, 'max_depth': 4, 'eta': 0.01843924924522292, 'gamma': 0.0006187858956920169, 'n_estimators': 1057, 'min_child_weight': 4, 'subsample': 0.49937190739488835}\n",
            "Dinner Best Trial: score 48.37489075878349,\n",
            "params {'lambda': 4.277979133843391e-06, 'alpha': 0.7749760386934557, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 940, 'min_child_weight': 7, 'subsample': 0.5002956340798566}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHcWGWdrYwDq",
        "outputId": "c308153a-83af-41f6-9501-5b0c8ace3de7"
      },
      "source": [
        "l_trial = l_study_xgb.best_trial\n",
        "lunch_xgb_params = l_trial.params\n",
        "lunch_xgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.028389630078426337,\n",
              " 'eta': 0.01843924924522292,\n",
              " 'gamma': 0.0006187858956920169,\n",
              " 'lambda': 0.2071617183903141,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 4,\n",
              " 'n_estimators': 1057,\n",
              " 'subsample': 0.49937190739488835}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tanTBeVNaxJ7",
        "outputId": "c4d687c0-ae1f-4c7b-d8a5-4dec249cedb1"
      },
      "source": [
        "d_trial = d_study_xgb.best_trial\n",
        "dinner_xgb_params = d_trial.params\n",
        "dinner_xgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.7749760386934557,\n",
              " 'eta': 0.008152801312229872,\n",
              " 'gamma': 0.0004569100347069903,\n",
              " 'lambda': 4.277979133843391e-06,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 7,\n",
              " 'n_estimators': 940,\n",
              " 'subsample': 0.5002956340798566}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36jaPySDY0nv",
        "outputId": "062bab30-662b-4f73-802a-80269266d501"
      },
      "source": [
        "lunch_xgb_model = xgb.XGBRegressor(**lunch_xgb_params)\n",
        "lunch_xgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['lunch_y'], eval_metric='mae')\n",
        "lunch_xgb_pred = lunch_xgb_model.predict(b_test_df)\n",
        "\n",
        "dinner_xgb_model = xgb.XGBRegressor(**dinner_xgb_params)\n",
        "dinner_xgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['dinner_y'], eval_metric='mae')\n",
        "dinner_xgb_pred = dinner_xgb_model.predict(b_test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWohQ8qaZ9wL",
        "outputId": "f29a7a3e-de8b-46a9-8651-02338312d05c"
      },
      "source": [
        "lunch_xgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 994.9242 ,  919.6314 ,  605.23694, 1255.2684 ,  953.8549 ,\n",
              "        953.3689 ,  935.91516,  638.6148 , 1266.0553 , 1023.3267 ,\n",
              "        772.17834, 1308.999  , 1125.0316 , 1085.5706 ,  900.0972 ,\n",
              "        662.7512 , 1278.9653 , 1040.3416 ,  913.692  ,  841.9029 ,\n",
              "        606.52356, 1106.5292 ,  977.1059 ,  908.995  ,  634.20026,\n",
              "       1312.0895 , 1161.6604 , 1005.5013 ,  942.61676,  675.2395 ,\n",
              "       1290.7927 ,  987.2304 , 1046.5105 ,  902.4546 ,  636.1867 ,\n",
              "       1207.2196 ,  988.4212 ,  915.2831 ,  811.3775 ,  581.08905,\n",
              "       1183.7014 ,  968.84216,  920.5803 ,  814.6066 ,  592.08185,\n",
              "       1213.3978 , 1046.8319 ,  956.9798 ,  852.40784,  593.6707 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi8UttR0bMw9",
        "outputId": "10d98aa0-3500-4898-d8bd-4185454da8c5"
      },
      "source": [
        "dinner_xgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([217.5145 , 403.2052 , 246.3411 , 498.18445, 433.41296, 386.7222 ,\n",
              "       420.97272, 353.72974, 584.9701 , 487.35437, 195.0462 , 732.1324 ,\n",
              "       623.68756, 409.78995, 498.08823, 375.6728 , 644.32776, 605.3887 ,\n",
              "       329.30945, 496.8572 , 315.1558 , 645.8691 , 442.0772 , 549.3749 ,\n",
              "       387.9646 , 656.3688 , 643.18024, 424.5477 , 509.7587 , 332.6781 ,\n",
              "       731.80963, 560.68146, 424.51163, 471.8689 , 309.854  , 647.3817 ,\n",
              "       581.3698 , 311.83316, 445.98022, 273.98315, 629.8954 , 552.66876,\n",
              "       218.0934 , 407.56396, 311.27405, 612.31433, 538.4524 , 407.3398 ,\n",
              "       458.80402, 302.66708], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "bNcxNpW2eQSs",
        "outputId": "ddc0b811-d44e-41b6-9f72-3799b0e21511"
      },
      "source": [
        "plt.barh(lunch_X.columns, lunch_xgb_model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "NawDqo4omFV9",
        "outputId": "63f357c0-5a69-46e4-d8b0-94ccf42aa29e"
      },
      "source": [
        "submission_df = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "submission_df['중식계'] = lunch_xgb_pred\n",
        "submission_df['석식계'] = dinner_xgb_pred\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>994.924194</td>\n",
              "      <td>217.514496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>919.631409</td>\n",
              "      <td>403.205200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>605.236938</td>\n",
              "      <td>246.341095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>1255.268433</td>\n",
              "      <td>498.184448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>953.854919</td>\n",
              "      <td>433.412964</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자          중식계         석식계\n",
              "0  2021-01-27   994.924194  217.514496\n",
              "1  2021-01-28   919.631409  403.205200\n",
              "2  2021-01-29   605.236938  246.341095\n",
              "3  2021-02-01  1255.268433  498.184448\n",
              "4  2021-02-02   953.854919  433.412964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsmF9cMmg1M"
      },
      "source": [
        "submission_df.to_csv(PATH + 'xgb_base2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhHGixtouZye"
      },
      "source": [
        "# LightGBM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_OQA5Nlst9k",
        "outputId": "5243e89a-8b76-473a-a83e-070d5fc68ef0"
      },
      "source": [
        " sampler = TPESampler(seed=10)\n",
        " def objective(trial):\n",
        "\n",
        "     param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "     lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "     lgbm = lgbm_regr.fit(l_X_train, l_y_train , eval_set = [(l_X_train, l_y_train)], verbose=False)\n",
        "     mae = mean_absolute_error(l_y_test, lgbm.predict(l_X_test))\n",
        "     return mae\n",
        "        \n",
        "l_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:30,528]\u001b[0m A new study created in memory with name: no-name-59ec12cc-7867-4c2e-9c15-69635dc58dfe\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5348779873185086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5348779873185086\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4656004675652718e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4656004675652718e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5188377188557745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5188377188557745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.014810344004555135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014810344004555135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:31,890]\u001b[0m Trial 0 finished with value: 168.08836813627406 and parameters: {'lambda_l1': 0.014810344004555135, 'lambda_l2': 1.4656004675652718e-08, 'num_leaves': 254, 'max_depth': 8, 'n_estimators': 2844, 'feature_fraction': 0.5348779873185086, 'bagging_fraction': 0.5188377188557745, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 0 with value: 168.08836813627406.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8875725769912681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875725769912681\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003040034742832493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003040034742832493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7675156400976328, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675156400976328\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.090008568091192e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.090008568091192e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:32,646]\u001b[0m Trial 1 finished with value: 68.2245823893435 and parameters: {'lambda_l1': 5.090008568091192e-08, 'lambda_l2': 0.003040034742832493, 'num_leaves': 382, 'max_depth': 3, 'n_estimators': 2902, 'feature_fraction': 0.8875725769912681, 'bagging_fraction': 0.7675156400976328, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8044801690398071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8044801690398071\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005207224083783965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005207224083783965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6650999046537976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6650999046537976\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21988367156694333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21988367156694333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:33,185]\u001b[0m Trial 2 finished with value: 73.67051522366995 and parameters: {'lambda_l1': 0.21988367156694333, 'lambda_l2': 0.005207224083783965, 'num_leaves': 218, 'max_depth': 3, 'n_estimators': 2305, 'feature_fraction': 0.8044801690398071, 'bagging_fraction': 0.6650999046537976, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.945189328485201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.945189328485201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015965313667163816, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015965313667163816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5915416533931271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5915416533931271\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00012738137732610437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00012738137732610437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:34,549]\u001b[0m Trial 3 finished with value: 70.80919003939353 and parameters: {'lambda_l1': 0.00012738137732610437, 'lambda_l2': 0.0015965313667163816, 'num_leaves': 241, 'max_depth': 8, 'n_estimators': 2943, 'feature_fraction': 0.945189328485201, 'bagging_fraction': 0.5915416533931271, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8915721974020412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8915721974020412\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.042604022999246406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042604022999246406\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5193685238072874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5193685238072874\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.163471763379958e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.163471763379958e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:35,633]\u001b[0m Trial 4 finished with value: 78.27357533205227 and parameters: {'lambda_l1': 8.163471763379958e-08, 'lambda_l2': 0.042604022999246406, 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 3055, 'feature_fraction': 0.8915721974020412, 'bagging_fraction': 0.5193685238072874, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6355175463679523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6355175463679523\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3318126555538504e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3318126555538504e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4560762247351902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4560762247351902\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010893853540963833, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010893853540963833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:36,233]\u001b[0m Trial 5 finished with value: 167.7616691311999 and parameters: {'lambda_l1': 0.010893853540963833, 'lambda_l2': 2.3318126555538504e-06, 'num_leaves': 354, 'max_depth': 5, 'n_estimators': 1409, 'feature_fraction': 0.6355175463679523, 'bagging_fraction': 0.4560762247351902, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5508244805242356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508244805242356\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.3581671060741645, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3581671060741645\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7584229889385306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7584229889385306\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.1828116394242723e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1828116394242723e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:37,607]\u001b[0m Trial 6 finished with value: 80.8529806502653 and parameters: {'lambda_l1': 1.1828116394242723e-05, 'lambda_l2': 0.3581671060741645, 'num_leaves': 396, 'max_depth': 6, 'n_estimators': 4253, 'feature_fraction': 0.5508244805242356, 'bagging_fraction': 0.7584229889385306, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5984315871892792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5984315871892792\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0618360930258403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0618360930258403e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8642981777263575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8642981777263575\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005267577135346555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005267577135346555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:38,123]\u001b[0m Trial 7 finished with value: 168.088589155563 and parameters: {'lambda_l1': 0.0005267577135346555, 'lambda_l2': 2.0618360930258403e-08, 'num_leaves': 144, 'max_depth': 3, 'n_estimators': 2013, 'feature_fraction': 0.5984315871892792, 'bagging_fraction': 0.8642981777263575, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8579443522862087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8579443522862087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012357458041729475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012357458041729475\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.926857985634915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.926857985634915\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.3068536483753737e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3068536483753737e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:39,328]\u001b[0m Trial 8 finished with value: 73.11536522279569 and parameters: {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:45:39,519]\u001b[0m Trial 9 finished with value: 134.33553544821945 and parameters: {'lambda_l1': 0.0001281542517497079, 'lambda_l2': 0.0006063078395671604, 'num_leaves': 106, 'max_depth': 5, 'n_estimators': 809, 'feature_fraction': 0.5818375363906209, 'bagging_fraction': 0.5452455252421164, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5818375363906209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5818375363906209\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0006063078395671604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006063078395671604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5452455252421164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5452455252421164\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0001281542517497079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001281542517497079\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7649442484108072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7649442484108072\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.010479332494921e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.010479332494921e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7880669612015251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7880669612015251\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6785873892849563e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6785873892849563e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:40,422]\u001b[0m Trial 10 finished with value: 167.0844404823267 and parameters: {'lambda_l1': 1.6785873892849563e-08, 'lambda_l2': 3.010479332494921e-06, 'num_leaves': 341, 'max_depth': 4, 'n_estimators': 3558, 'feature_fraction': 0.7649442484108072, 'bagging_fraction': 0.7880669612015251, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9991122238129395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9991122238129395\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.61939793719469e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.61939793719469e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585514682875593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585514682875593\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.9826258759353e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.9826258759353e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:45,589]\u001b[0m Trial 11 finished with value: 156.59219682334364 and parameters: {'lambda_l1': 8.9826258759353e-07, 'lambda_l2': 2.61939793719469e-05, 'num_leaves': 287, 'max_depth': 9, 'n_estimators': 3632, 'feature_fraction': 0.9991122238129395, 'bagging_fraction': 0.6585514682875593, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9922869658927289, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9922869658927289\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.030766178350701442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030766178350701442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6307116556352568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6307116556352568\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0010032552297938406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010032552297938406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:46,945]\u001b[0m Trial 12 finished with value: 74.22269527381991 and parameters: {'lambda_l1': 0.0010032552297938406, 'lambda_l2': 0.030766178350701442, 'num_leaves': 311, 'max_depth': 9, 'n_estimators': 2453, 'feature_fraction': 0.9922869658927289, 'bagging_fraction': 0.6307116556352568, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.41844661211798795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41844661211798795\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00015468424548794194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00015468424548794194\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.995679260563783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995679260563783\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.9886276185414409e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9886276185414409e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:50,725]\u001b[0m Trial 13 finished with value: 127.29066396606996 and parameters: {'lambda_l1': 1.9886276185414409e-07, 'lambda_l2': 0.00015468424548794194, 'num_leaves': 387, 'max_depth': 7, 'n_estimators': 3556, 'feature_fraction': 0.41844661211798795, 'bagging_fraction': 0.995679260563783, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9290019894565231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9290019894565231\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9773722751809201, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9773722751809201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.750295356922126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750295356922126\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8821931552561775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8821931552561775e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:51,767]\u001b[0m Trial 14 finished with value: 99.66860342433343 and parameters: {'lambda_l1': 2.8821931552561775e-05, 'lambda_l2': 0.9773722751809201, 'num_leaves': 219, 'max_depth': 8, 'n_estimators': 1756, 'feature_fraction': 0.9290019894565231, 'bagging_fraction': 0.750295356922126, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7285367937084144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7285367937084144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.013133026541985783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013133026541985783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5989394570002292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5989394570002292\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0885522537644062e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0885522537644062e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:52,796]\u001b[0m Trial 15 finished with value: 70.82605705543644 and parameters: {'lambda_l1': 1.0885522537644062e-08, 'lambda_l2': 0.013133026541985783, 'num_leaves': 28, 'max_depth': 7, 'n_estimators': 3001, 'feature_fraction': 0.7285367937084144, 'bagging_fraction': 0.5989394570002292, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9592124084612702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9592124084612702\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4319355308173353e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4319355308173353e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4072835615446248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4072835615446248\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006757265265334436, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006757265265334436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:53,431]\u001b[0m Trial 16 finished with value: 160.12652768803702 and parameters: {'lambda_l1': 0.006757265265334436, 'lambda_l2': 3.4319355308173353e-05, 'num_leaves': 266, 'max_depth': 8, 'n_estimators': 2583, 'feature_fraction': 0.9592124084612702, 'bagging_fraction': 0.4072835615446248, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8133108831404763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8133108831404763\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.19063245323117958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19063245323117958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8359226382813782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8359226382813782\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4749952337893574, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4749952337893574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:55,146]\u001b[0m Trial 17 finished with value: 75.38167518057081 and parameters: {'lambda_l1': 0.4749952337893574, 'lambda_l2': 0.19063245323117958, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3778, 'feature_fraction': 0.8133108831404763, 'bagging_fraction': 0.8359226382813782, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9049229635967819, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049229635967819\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0038947940771188595, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0038947940771188595\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7133340635208179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7133340635208179\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.162473122054843e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.162473122054843e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:57,195]\u001b[0m Trial 18 finished with value: 68.25159573580302 and parameters: {'lambda_l1': 6.162473122054843e-05, 'lambda_l2': 0.0038947940771188595, 'num_leaves': 63, 'max_depth': 6, 'n_estimators': 4956, 'feature_fraction': 0.9049229635967819, 'bagging_fraction': 0.7133340635208179, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6694741937620116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694741937620116\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00017090105110919117, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017090105110919117\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7102315542302928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7102315542302928\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.558826272807897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.558826272807897e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:58,996]\u001b[0m Trial 19 finished with value: 112.40814959477449 and parameters: {'lambda_l1': 1.558826272807897e-06, 'lambda_l2': 0.00017090105110919117, 'num_leaves': 88, 'max_depth': 6, 'n_estimators': 4901, 'feature_fraction': 0.6694741937620116, 'bagging_fraction': 0.7102315542302928, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8830528000666321, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8830528000666321\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005399216065659898, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005399216065659898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981126396254016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981126396254016\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.577543141688918e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.577543141688918e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:00,363]\u001b[0m Trial 20 finished with value: 69.81787156647374 and parameters: {'lambda_l1': 8.577543141688918e-08, 'lambda_l2': 0.005399216065659898, 'num_leaves': 57, 'max_depth': 4, 'n_estimators': 4914, 'feature_fraction': 0.8830528000666321, 'bagging_fraction': 0.8981126396254016, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.857435008067406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.857435008067406\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007085955366616683, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007085955366616683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9541820918740274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9541820918740274\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.3637885278895198e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3637885278895198e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:01,715]\u001b[0m Trial 21 finished with value: 72.07557604930169 and parameters: {'lambda_l1': 1.3637885278895198e-07, 'lambda_l2': 0.007085955366616683, 'num_leaves': 64, 'max_depth': 4, 'n_estimators': 4860, 'feature_fraction': 0.857435008067406, 'bagging_fraction': 0.9541820918740274, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8896961138855114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8896961138855114\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1440306548213092, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1440306548213092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8719479103382188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8719479103382188\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.117885124030037e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.117885124030037e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:02,909]\u001b[0m Trial 22 finished with value: 79.82043715241834 and parameters: {'lambda_l1': 1.117885124030037e-08, 'lambda_l2': 0.1440306548213092, 'num_leaves': 49, 'max_depth': 4, 'n_estimators': 4443, 'feature_fraction': 0.8896961138855114, 'bagging_fraction': 0.8719479103382188, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.797585277438908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797585277438908\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00286882006173601, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00286882006173601\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8340528532958039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8340528532958039\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.4206330381302414e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4206330381302414e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:04,272]\u001b[0m Trial 23 finished with value: 70.4626573453293 and parameters: {'lambda_l1': 4.4206330381302414e-07, 'lambda_l2': 0.00286882006173601, 'num_leaves': 180, 'max_depth': 4, 'n_estimators': 4963, 'feature_fraction': 0.797585277438908, 'bagging_fraction': 0.8340528532958039, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9082255084550924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9082255084550924\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0004910285788460762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004910285788460762\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7131579822782704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7131579822782704\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3211789024334075e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3211789024334075e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:05,747]\u001b[0m Trial 24 finished with value: 83.35697281125313 and parameters: {'lambda_l1': 5.3211789024334075e-08, 'lambda_l2': 0.0004910285788460762, 'num_leaves': 114, 'max_depth': 5, 'n_estimators': 4092, 'feature_fraction': 0.9082255084550924, 'bagging_fraction': 0.7131579822782704, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8525645941267856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8525645941267856\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03461833732184834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03461833732184834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9186670114421646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9186670114421646\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.627153081826672e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.627153081826672e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:06,914]\u001b[0m Trial 25 finished with value: 73.17524387491486 and parameters: {'lambda_l1': 9.627153081826672e-06, 'lambda_l2': 0.03461833732184834, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4664, 'feature_fraction': 0.8525645941267856, 'bagging_fraction': 0.9186670114421646, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:46:07,080]\u001b[0m Trial 26 finished with value: 165.79104295387324 and parameters: {'lambda_l1': 3.617654385059622e-08, 'lambda_l2': 3.21018883782884e-05, 'num_leaves': 3, 'max_depth': 6, 'n_estimators': 922, 'feature_fraction': 0.7208616598347489, 'bagging_fraction': 0.8051944778854442, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7208616598347489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7208616598347489\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.21018883782884e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.21018883782884e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8051944778854442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8051944778854442\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.617654385059622e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.617654385059622e-08\n",
            "[LightGBM] [Warning] feature_fraction is set=0.978823807556182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.978823807556182\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007623884125877974, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007623884125877974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7586217334270403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7586217334270403\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.5202198902227952e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5202198902227952e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:08,380]\u001b[0m Trial 27 finished with value: 68.31447930080783 and parameters: {'lambda_l1': 3.5202198902227952e-06, 'lambda_l2': 0.007623884125877974, 'num_leaves': 37, 'max_depth': 4, 'n_estimators': 3928, 'feature_fraction': 0.978823807556182, 'bagging_fraction': 0.7586217334270403, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.983261850180457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.983261850180457\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.06153077564466302, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06153077564466302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7478638044077373, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7478638044077373\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.6713597683041026e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6713597683041026e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:10,110]\u001b[0m Trial 28 finished with value: 73.37228600318362 and parameters: {'lambda_l1': 2.6713597683041026e-05, 'lambda_l2': 0.06153077564466302, 'num_leaves': 30, 'max_depth': 5, 'n_estimators': 4001, 'feature_fraction': 0.983261850180457, 'bagging_fraction': 0.7478638044077373, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4467465826790745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4467465826790745\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00036096976564155053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00036096976564155053\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.672679532303821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672679532303821\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0008411698071306363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008411698071306363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:10,646]\u001b[0m Trial 29 finished with value: 118.29020494785748 and parameters: {'lambda_l1': 0.0008411698071306363, 'lambda_l2': 0.00036096976564155053, 'num_leaves': 3, 'max_depth': 7, 'n_estimators': 3251, 'feature_fraction': 0.4467465826790745, 'bagging_fraction': 0.672679532303821, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9485639040314328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9485639040314328\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9330264060741632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9330264060741632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7907252411951584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7907252411951584\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.238685512402491e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.238685512402491e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:11,503]\u001b[0m Trial 30 finished with value: 103.94130317065652 and parameters: {'lambda_l1': 5.238685512402491e-06, 'lambda_l2': 0.9330264060741632, 'num_leaves': 113, 'max_depth': 6, 'n_estimators': 3337, 'feature_fraction': 0.9485639040314328, 'bagging_fraction': 0.7907252411951584, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8456039224486642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456039224486642\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.011681208582494407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011681208582494407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.712747098225565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.712747098225565\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.1883465875895746e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.1883465875895746e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:12,701]\u001b[0m Trial 31 finished with value: 69.7380789666321 and parameters: {'lambda_l1': 4.1883465875895746e-07, 'lambda_l2': 0.011681208582494407, 'num_leaves': 48, 'max_depth': 4, 'n_estimators': 3929, 'feature_fraction': 0.8456039224486642, 'bagging_fraction': 0.712747098225565, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7753150238928894, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7753150238928894\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.009843900884763586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009843900884763586\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7033300787966946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7033300787966946\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.933439446112878e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.933439446112878e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:13,676]\u001b[0m Trial 32 finished with value: 67.77519885281583 and parameters: {'lambda_l1': 6.933439446112878e-07, 'lambda_l2': 0.009843900884763586, 'num_leaves': 95, 'max_depth': 3, 'n_estimators': 3908, 'feature_fraction': 0.7753150238928894, 'bagging_fraction': 0.7033300787966946, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.770900940963003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.770900940963003\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002349695193344987, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002349695193344987\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6634893230016086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6634893230016086\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.2412526223857976e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2412526223857976e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:14,367]\u001b[0m Trial 33 finished with value: 69.45398282377937 and parameters: {'lambda_l1': 1.2412526223857976e-06, 'lambda_l2': 0.002349695193344987, 'num_leaves': 83, 'max_depth': 3, 'n_estimators': 2728, 'feature_fraction': 0.770900940963003, 'bagging_fraction': 0.6634893230016086, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8109698082278238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8109698082278238\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012066704851500033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012066704851500033\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7483332174356776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7483332174356776\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.17692130190505e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.17692130190505e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:14,977]\u001b[0m Trial 34 finished with value: 83.75409302531094 and parameters: {'lambda_l1': 4.17692130190505e-05, 'lambda_l2': 0.0012066704851500033, 'num_leaves': 3, 'max_depth': 3, 'n_estimators': 3280, 'feature_fraction': 0.8109698082278238, 'bagging_fraction': 0.7483332174356776, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9242757612217026, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9242757612217026\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015967861745800383, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015967861745800383\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6201655597229148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6201655597229148\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.0925815695686164e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0925815695686164e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:16,094]\u001b[0m Trial 35 finished with value: 69.40967229893587 and parameters: {'lambda_l1': 3.0925815695686164e-06, 'lambda_l2': 0.015967861745800383, 'num_leaves': 125, 'max_depth': 3, 'n_estimators': 4367, 'feature_fraction': 0.9242757612217026, 'bagging_fraction': 0.6201655597229148, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9689976512076663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9689976512076663\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.07728059834779502, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07728059834779502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6801525970382309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6801525970382309\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023035809545990645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023035809545990645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:16,705]\u001b[0m Trial 36 finished with value: 73.53002867018955 and parameters: {'lambda_l1': 0.00023035809545990645, 'lambda_l2': 0.07728059834779502, 'num_leaves': 180, 'max_depth': 3, 'n_estimators': 2298, 'feature_fraction': 0.9689976512076663, 'bagging_fraction': 0.6801525970382309, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6799896576109249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6799896576109249\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00365564781783537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00365564781783537\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8187865503548556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8187865503548556\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.897285138402634e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.897285138402634e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:18,158]\u001b[0m Trial 37 finished with value: 65.47700831201462 and parameters: {'lambda_l1': 2.897285138402634e-07, 'lambda_l2': 0.00365564781783537, 'num_leaves': 89, 'max_depth': 4, 'n_estimators': 4170, 'feature_fraction': 0.6799896576109249, 'bagging_fraction': 0.8187865503548556, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6305292483774079, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305292483774079\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003988285558711171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003988285558711171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382605479138953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382605479138953\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.08103833153437869, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08103833153437869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:19,940]\u001b[0m Trial 38 finished with value: 66.5813999610059 and parameters: {'lambda_l1': 0.08103833153437869, 'lambda_l2': 0.003988285558711171, 'num_leaves': 92, 'max_depth': 5, 'n_estimators': 4176, 'feature_fraction': 0.6305292483774079, 'bagging_fraction': 0.8382605479138953, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6545599625224247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6545599625224247\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.001337440493169704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001337440493169704\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7917239084922874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7917239084922874\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.037113466772583696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.037113466772583696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:21,950]\u001b[0m Trial 39 finished with value: 68.12675992566635 and parameters: {'lambda_l1': 0.037113466772583696, 'lambda_l2': 0.001337440493169704, 'num_leaves': 88, 'max_depth': 5, 'n_estimators': 4235, 'feature_fraction': 0.6545599625224247, 'bagging_fraction': 0.7917239084922874, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6572490301121829, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6572490301121829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=6.147565815887788e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.147565815887788e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.843060285702147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.843060285702147\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1417946961934106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1417946961934106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:24,272]\u001b[0m Trial 40 finished with value: 143.37047718438484 and parameters: {'lambda_l1': 0.1417946961934106, 'lambda_l2': 6.147565815887788e-05, 'num_leaves': 94, 'max_depth': 5, 'n_estimators': 4189, 'feature_fraction': 0.6572490301121829, 'bagging_fraction': 0.843060285702147, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5008785352223447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5008785352223447\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0010207127649325268, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010207127649325268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8111461277730591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8111461277730591\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.08071802526324821, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08071802526324821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:26,367]\u001b[0m Trial 41 finished with value: 69.76879254295662 and parameters: {'lambda_l1': 0.08071802526324821, 'lambda_l2': 0.0010207127649325268, 'num_leaves': 137, 'max_depth': 5, 'n_estimators': 4541, 'feature_fraction': 0.5008785352223447, 'bagging_fraction': 0.8111461277730591, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6199850230421977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6199850230421977\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00029869339456754064, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029869339456754064\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.780120266936442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.780120266936442\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.045271139462990745, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.045271139462990745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:28,158]\u001b[0m Trial 42 finished with value: 91.99812603562292 and parameters: {'lambda_l1': 0.045271139462990745, 'lambda_l2': 0.00029869339456754064, 'num_leaves': 154, 'max_depth': 4, 'n_estimators': 4708, 'feature_fraction': 0.6199850230421977, 'bagging_fraction': 0.780120266936442, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6861358517564461, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861358517564461\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0024930661642714636, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024930661642714636\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8818295361642811, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8818295361642811\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.5816949305710215, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5816949305710215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:30,016]\u001b[0m Trial 43 finished with value: 65.95959291306336 and parameters: {'lambda_l1': 0.5816949305710215, 'lambda_l2': 0.0024930661642714636, 'num_leaves': 91, 'max_depth': 5, 'n_estimators': 3732, 'feature_fraction': 0.6861358517564461, 'bagging_fraction': 0.8818295361642811, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.694649336674864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.694649336674864\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015487656142613338, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015487656142613338\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8904034644477615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8904034644477615\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004451746482349735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004451746482349735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:32,242]\u001b[0m Trial 44 finished with value: 66.0828160805039 and parameters: {'lambda_l1': 0.004451746482349735, 'lambda_l2': 0.0015487656142613338, 'num_leaves': 94, 'max_depth': 5, 'n_estimators': 4296, 'feature_fraction': 0.694649336674864, 'bagging_fraction': 0.8904034644477615, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6912647996827558, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6912647996827558\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0022411177210349058, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022411177210349058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9692205317999674, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9692205317999674\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.97409057602456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.97409057602456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:34,298]\u001b[0m Trial 45 finished with value: 66.54621693719595 and parameters: {'lambda_l1': 0.97409057602456, 'lambda_l2': 0.0022411177210349058, 'num_leaves': 129, 'max_depth': 5, 'n_estimators': 3497, 'feature_fraction': 0.6912647996827558, 'bagging_fraction': 0.9692205317999674, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6907857835302649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6907857835302649\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002293955675468287, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002293955675468287\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9840748545936858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9840748545936858\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.911386313567701, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.911386313567701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:36,254]\u001b[0m Trial 46 finished with value: 65.73120733570985 and parameters: {'lambda_l1': 0.911386313567701, 'lambda_l2': 0.002293955675468287, 'num_leaves': 126, 'max_depth': 5, 'n_estimators': 3688, 'feature_fraction': 0.6907857835302649, 'bagging_fraction': 0.9840748545936858, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6894291505793495, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894291505793495\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.243222172966609e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.243222172966609e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9933142319078488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9933142319078488\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7723357260574077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723357260574077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:38,548]\u001b[0m Trial 47 finished with value: 164.691249318221 and parameters: {'lambda_l1': 0.7723357260574077, 'lambda_l2': 8.243222172966609e-06, 'num_leaves': 124, 'max_depth': 5, 'n_estimators': 3741, 'feature_fraction': 0.6894291505793495, 'bagging_fraction': 0.9933142319078488, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7077509504125293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077509504125293\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0007823504051765781, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007823504051765781\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9652566499690516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9652566499690516\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3077454896035705, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3077454896035705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:41,821]\u001b[0m Trial 48 finished with value: 72.76843848555889 and parameters: {'lambda_l1': 0.3077454896035705, 'lambda_l2': 0.0007823504051765781, 'num_leaves': 206, 'max_depth': 6, 'n_estimators': 3469, 'feature_fraction': 0.7077509504125293, 'bagging_fraction': 0.9652566499690516, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7369313686767585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369313686767585\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.7820979457059422e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7820979457059422e-07\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.958285045095513, subsample=1.0 will be ignored. Current value: bagging_fraction=0.958285045095513\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006696428249371957, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006696428249371957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:44,079]\u001b[0m Trial 49 finished with value: 168.01796158020093 and parameters: {'lambda_l1': 0.006696428249371957, 'lambda_l2': 1.7820979457059422e-07, 'num_leaves': 177, 'max_depth': 5, 'n_estimators': 3740, 'feature_fraction': 0.7369313686767585, 'bagging_fraction': 0.958285045095513, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_2eGQpfu4Ng",
        "outputId": "4607f217-6ce0-447c-c473-c7743b05ad0b"
      },
      "source": [
        " sampler = TPESampler(seed=10)\n",
        " def objective(trial):\n",
        "\n",
        "     param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "     lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "     lgbm = lgbm_regr.fit(d_X_train, d_y_train , eval_set = [(d_X_train, d_y_train)], verbose=False)\n",
        "     mae = mean_absolute_error(d_y_test, lgbm.predict(d_X_test))\n",
        "     return mae\n",
        "        \n",
        "d_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:44,107]\u001b[0m A new study created in memory with name: no-name-cd3128f2-f5f0-4590-9022-efe33303dc43\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5348779873185086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5348779873185086\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4656004675652718e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4656004675652718e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5188377188557745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5188377188557745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.014810344004555135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014810344004555135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:45,565]\u001b[0m Trial 0 finished with value: 102.27037999911656 and parameters: {'lambda_l1': 0.014810344004555135, 'lambda_l2': 1.4656004675652718e-08, 'num_leaves': 254, 'max_depth': 8, 'n_estimators': 2844, 'feature_fraction': 0.5348779873185086, 'bagging_fraction': 0.5188377188557745, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 0 with value: 102.27037999911656.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8875725769912681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875725769912681\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003040034742832493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003040034742832493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7675156400976328, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675156400976328\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.090008568091192e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.090008568091192e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:46,345]\u001b[0m Trial 1 finished with value: 50.88575106945658 and parameters: {'lambda_l1': 5.090008568091192e-08, 'lambda_l2': 0.003040034742832493, 'num_leaves': 382, 'max_depth': 3, 'n_estimators': 2902, 'feature_fraction': 0.8875725769912681, 'bagging_fraction': 0.7675156400976328, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8044801690398071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8044801690398071\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005207224083783965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005207224083783965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6650999046537976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6650999046537976\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21988367156694333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21988367156694333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:46,881]\u001b[0m Trial 2 finished with value: 56.39333400168846 and parameters: {'lambda_l1': 0.21988367156694333, 'lambda_l2': 0.005207224083783965, 'num_leaves': 218, 'max_depth': 3, 'n_estimators': 2305, 'feature_fraction': 0.8044801690398071, 'bagging_fraction': 0.6650999046537976, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.945189328485201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.945189328485201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015965313667163816, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015965313667163816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5915416533931271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5915416533931271\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00012738137732610437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00012738137732610437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:48,277]\u001b[0m Trial 3 finished with value: 52.97165045557678 and parameters: {'lambda_l1': 0.00012738137732610437, 'lambda_l2': 0.0015965313667163816, 'num_leaves': 241, 'max_depth': 8, 'n_estimators': 2943, 'feature_fraction': 0.945189328485201, 'bagging_fraction': 0.5915416533931271, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8915721974020412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8915721974020412\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.042604022999246406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042604022999246406\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5193685238072874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5193685238072874\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.163471763379958e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.163471763379958e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:49,387]\u001b[0m Trial 4 finished with value: 57.87950806994835 and parameters: {'lambda_l1': 8.163471763379958e-08, 'lambda_l2': 0.042604022999246406, 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 3055, 'feature_fraction': 0.8915721974020412, 'bagging_fraction': 0.5193685238072874, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6355175463679523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6355175463679523\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3318126555538504e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3318126555538504e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4560762247351902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4560762247351902\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010893853540963833, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010893853540963833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:50,003]\u001b[0m Trial 5 finished with value: 102.09636719794584 and parameters: {'lambda_l1': 0.010893853540963833, 'lambda_l2': 2.3318126555538504e-06, 'num_leaves': 354, 'max_depth': 5, 'n_estimators': 1409, 'feature_fraction': 0.6355175463679523, 'bagging_fraction': 0.4560762247351902, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5508244805242356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508244805242356\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.3581671060741645, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3581671060741645\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7584229889385306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7584229889385306\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.1828116394242723e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1828116394242723e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:51,413]\u001b[0m Trial 6 finished with value: 59.6568606510387 and parameters: {'lambda_l1': 1.1828116394242723e-05, 'lambda_l2': 0.3581671060741645, 'num_leaves': 396, 'max_depth': 6, 'n_estimators': 4253, 'feature_fraction': 0.5508244805242356, 'bagging_fraction': 0.7584229889385306, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5984315871892792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5984315871892792\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0618360930258403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0618360930258403e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8642981777263575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8642981777263575\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005267577135346555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005267577135346555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:51,920]\u001b[0m Trial 7 finished with value: 102.2706028172915 and parameters: {'lambda_l1': 0.0005267577135346555, 'lambda_l2': 2.0618360930258403e-08, 'num_leaves': 144, 'max_depth': 3, 'n_estimators': 2013, 'feature_fraction': 0.5984315871892792, 'bagging_fraction': 0.8642981777263575, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8579443522862087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8579443522862087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012357458041729475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012357458041729475\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.926857985634915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.926857985634915\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.3068536483753737e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3068536483753737e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:53,077]\u001b[0m Trial 8 finished with value: 56.0349205798433 and parameters: {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:46:53,281]\u001b[0m Trial 9 finished with value: 84.91992666873385 and parameters: {'lambda_l1': 0.0001281542517497079, 'lambda_l2': 0.0006063078395671604, 'num_leaves': 106, 'max_depth': 5, 'n_estimators': 809, 'feature_fraction': 0.5818375363906209, 'bagging_fraction': 0.5452455252421164, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5818375363906209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5818375363906209\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0006063078395671604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006063078395671604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5452455252421164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5452455252421164\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0001281542517497079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001281542517497079\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7649442484108072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7649442484108072\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.010479332494921e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.010479332494921e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7880669612015251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7880669612015251\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6785873892849563e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6785873892849563e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:54,255]\u001b[0m Trial 10 finished with value: 101.75072755084977 and parameters: {'lambda_l1': 1.6785873892849563e-08, 'lambda_l2': 3.010479332494921e-06, 'num_leaves': 341, 'max_depth': 4, 'n_estimators': 3558, 'feature_fraction': 0.7649442484108072, 'bagging_fraction': 0.7880669612015251, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9991122238129395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9991122238129395\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.61939793719469e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.61939793719469e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585514682875593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585514682875593\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.9826258759353e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.9826258759353e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:59,794]\u001b[0m Trial 11 finished with value: 95.91307094748466 and parameters: {'lambda_l1': 8.9826258759353e-07, 'lambda_l2': 2.61939793719469e-05, 'num_leaves': 287, 'max_depth': 9, 'n_estimators': 3632, 'feature_fraction': 0.9991122238129395, 'bagging_fraction': 0.6585514682875593, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9922869658927289, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9922869658927289\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.030766178350701442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030766178350701442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6307116556352568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6307116556352568\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0010032552297938406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010032552297938406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:01,190]\u001b[0m Trial 12 finished with value: 53.83919682450579 and parameters: {'lambda_l1': 0.0010032552297938406, 'lambda_l2': 0.030766178350701442, 'num_leaves': 311, 'max_depth': 9, 'n_estimators': 2453, 'feature_fraction': 0.9922869658927289, 'bagging_fraction': 0.6307116556352568, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.41844661211798795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41844661211798795\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00015468424548794194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00015468424548794194\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.995679260563783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995679260563783\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.9886276185414409e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9886276185414409e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:04,505]\u001b[0m Trial 13 finished with value: 77.94775249292114 and parameters: {'lambda_l1': 1.9886276185414409e-07, 'lambda_l2': 0.00015468424548794194, 'num_leaves': 387, 'max_depth': 7, 'n_estimators': 3556, 'feature_fraction': 0.41844661211798795, 'bagging_fraction': 0.995679260563783, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9290019894565231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9290019894565231\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9773722751809201, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9773722751809201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.750295356922126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750295356922126\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8821931552561775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8821931552561775e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:05,540]\u001b[0m Trial 14 finished with value: 72.58409443808755 and parameters: {'lambda_l1': 2.8821931552561775e-05, 'lambda_l2': 0.9773722751809201, 'num_leaves': 219, 'max_depth': 8, 'n_estimators': 1756, 'feature_fraction': 0.9290019894565231, 'bagging_fraction': 0.750295356922126, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7285367937084144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7285367937084144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.013133026541985783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013133026541985783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5989394570002292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5989394570002292\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0885522537644062e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0885522537644062e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:06,620]\u001b[0m Trial 15 finished with value: 54.25703202570445 and parameters: {'lambda_l1': 1.0885522537644062e-08, 'lambda_l2': 0.013133026541985783, 'num_leaves': 28, 'max_depth': 7, 'n_estimators': 3001, 'feature_fraction': 0.7285367937084144, 'bagging_fraction': 0.5989394570002292, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9592124084612702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9592124084612702\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4319355308173353e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4319355308173353e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4072835615446248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4072835615446248\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006757265265334436, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006757265265334436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:07,209]\u001b[0m Trial 16 finished with value: 98.04227709076831 and parameters: {'lambda_l1': 0.006757265265334436, 'lambda_l2': 3.4319355308173353e-05, 'num_leaves': 266, 'max_depth': 8, 'n_estimators': 2583, 'feature_fraction': 0.9592124084612702, 'bagging_fraction': 0.4072835615446248, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8133108831404763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8133108831404763\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.19063245323117958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19063245323117958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8359226382813782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8359226382813782\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4749952337893574, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4749952337893574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:08,922]\u001b[0m Trial 17 finished with value: 55.187261816113676 and parameters: {'lambda_l1': 0.4749952337893574, 'lambda_l2': 0.19063245323117958, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3778, 'feature_fraction': 0.8133108831404763, 'bagging_fraction': 0.8359226382813782, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9049229635967819, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049229635967819\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0038947940771188595, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0038947940771188595\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7133340635208179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7133340635208179\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.162473122054843e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.162473122054843e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:10,999]\u001b[0m Trial 18 finished with value: 51.788319311042265 and parameters: {'lambda_l1': 6.162473122054843e-05, 'lambda_l2': 0.0038947940771188595, 'num_leaves': 63, 'max_depth': 6, 'n_estimators': 4956, 'feature_fraction': 0.9049229635967819, 'bagging_fraction': 0.7133340635208179, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6694741937620116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694741937620116\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00017090105110919117, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017090105110919117\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7102315542302928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7102315542302928\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.558826272807897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.558826272807897e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:12,857]\u001b[0m Trial 19 finished with value: 74.03208675888746 and parameters: {'lambda_l1': 1.558826272807897e-06, 'lambda_l2': 0.00017090105110919117, 'num_leaves': 88, 'max_depth': 6, 'n_estimators': 4901, 'feature_fraction': 0.6694741937620116, 'bagging_fraction': 0.7102315542302928, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8830528000666321, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8830528000666321\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005399216065659898, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005399216065659898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981126396254016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981126396254016\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.577543141688918e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.577543141688918e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:14,264]\u001b[0m Trial 20 finished with value: 52.39016149622366 and parameters: {'lambda_l1': 8.577543141688918e-08, 'lambda_l2': 0.005399216065659898, 'num_leaves': 57, 'max_depth': 4, 'n_estimators': 4914, 'feature_fraction': 0.8830528000666321, 'bagging_fraction': 0.8981126396254016, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.857435008067406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.857435008067406\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007085955366616683, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007085955366616683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9541820918740274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9541820918740274\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.3637885278895198e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3637885278895198e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:15,644]\u001b[0m Trial 21 finished with value: 53.49626144822936 and parameters: {'lambda_l1': 1.3637885278895198e-07, 'lambda_l2': 0.007085955366616683, 'num_leaves': 64, 'max_depth': 4, 'n_estimators': 4860, 'feature_fraction': 0.857435008067406, 'bagging_fraction': 0.9541820918740274, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8896961138855114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8896961138855114\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1440306548213092, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1440306548213092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8719479103382188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8719479103382188\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.117885124030037e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.117885124030037e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:16,849]\u001b[0m Trial 22 finished with value: 62.680730159191256 and parameters: {'lambda_l1': 1.117885124030037e-08, 'lambda_l2': 0.1440306548213092, 'num_leaves': 49, 'max_depth': 4, 'n_estimators': 4443, 'feature_fraction': 0.8896961138855114, 'bagging_fraction': 0.8719479103382188, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.797585277438908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797585277438908\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00286882006173601, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00286882006173601\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8340528532958039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8340528532958039\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.4206330381302414e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4206330381302414e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:18,237]\u001b[0m Trial 23 finished with value: 54.03356394449385 and parameters: {'lambda_l1': 4.4206330381302414e-07, 'lambda_l2': 0.00286882006173601, 'num_leaves': 180, 'max_depth': 4, 'n_estimators': 4963, 'feature_fraction': 0.797585277438908, 'bagging_fraction': 0.8340528532958039, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9082255084550924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9082255084550924\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0004910285788460762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004910285788460762\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7131579822782704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7131579822782704\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3211789024334075e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3211789024334075e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:19,676]\u001b[0m Trial 24 finished with value: 61.29761142883199 and parameters: {'lambda_l1': 5.3211789024334075e-08, 'lambda_l2': 0.0004910285788460762, 'num_leaves': 114, 'max_depth': 5, 'n_estimators': 4092, 'feature_fraction': 0.9082255084550924, 'bagging_fraction': 0.7131579822782704, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8525645941267856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8525645941267856\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03461833732184834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03461833732184834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9186670114421646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9186670114421646\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.627153081826672e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.627153081826672e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:20,809]\u001b[0m Trial 25 finished with value: 55.19156434912255 and parameters: {'lambda_l1': 9.627153081826672e-06, 'lambda_l2': 0.03461833732184834, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4664, 'feature_fraction': 0.8525645941267856, 'bagging_fraction': 0.9186670114421646, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:47:20,963]\u001b[0m Trial 26 finished with value: 101.191347511389 and parameters: {'lambda_l1': 3.617654385059622e-08, 'lambda_l2': 3.21018883782884e-05, 'num_leaves': 3, 'max_depth': 6, 'n_estimators': 922, 'feature_fraction': 0.7208616598347489, 'bagging_fraction': 0.8051944778854442, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7208616598347489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7208616598347489\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.21018883782884e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.21018883782884e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8051944778854442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8051944778854442\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.617654385059622e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.617654385059622e-08\n",
            "[LightGBM] [Warning] feature_fraction is set=0.978823807556182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.978823807556182\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007623884125877974, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007623884125877974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7586217334270403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7586217334270403\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.5202198902227952e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5202198902227952e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:22,287]\u001b[0m Trial 27 finished with value: 51.10153192642099 and parameters: {'lambda_l1': 3.5202198902227952e-06, 'lambda_l2': 0.007623884125877974, 'num_leaves': 37, 'max_depth': 4, 'n_estimators': 3928, 'feature_fraction': 0.978823807556182, 'bagging_fraction': 0.7586217334270403, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.983261850180457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.983261850180457\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.06153077564466302, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06153077564466302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7478638044077373, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7478638044077373\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.6713597683041026e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6713597683041026e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:24,028]\u001b[0m Trial 28 finished with value: 57.35067831946532 and parameters: {'lambda_l1': 2.6713597683041026e-05, 'lambda_l2': 0.06153077564466302, 'num_leaves': 30, 'max_depth': 5, 'n_estimators': 4001, 'feature_fraction': 0.983261850180457, 'bagging_fraction': 0.7478638044077373, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4467465826790745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4467465826790745\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00036096976564155053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00036096976564155053\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.672679532303821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672679532303821\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0008411698071306363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008411698071306363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:24,566]\u001b[0m Trial 29 finished with value: 76.7237637130061 and parameters: {'lambda_l1': 0.0008411698071306363, 'lambda_l2': 0.00036096976564155053, 'num_leaves': 3, 'max_depth': 7, 'n_estimators': 3251, 'feature_fraction': 0.4467465826790745, 'bagging_fraction': 0.672679532303821, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9485639040314328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9485639040314328\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9330264060741632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9330264060741632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7907252411951584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7907252411951584\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.238685512402491e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.238685512402491e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:25,406]\u001b[0m Trial 30 finished with value: 76.44828364410473 and parameters: {'lambda_l1': 5.238685512402491e-06, 'lambda_l2': 0.9330264060741632, 'num_leaves': 113, 'max_depth': 6, 'n_estimators': 3337, 'feature_fraction': 0.9485639040314328, 'bagging_fraction': 0.7907252411951584, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8456039224486642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456039224486642\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.011681208582494407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011681208582494407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.712747098225565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.712747098225565\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.1883465875895746e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.1883465875895746e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:26,630]\u001b[0m Trial 31 finished with value: 52.72866096923458 and parameters: {'lambda_l1': 4.1883465875895746e-07, 'lambda_l2': 0.011681208582494407, 'num_leaves': 48, 'max_depth': 4, 'n_estimators': 3929, 'feature_fraction': 0.8456039224486642, 'bagging_fraction': 0.712747098225565, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9091986518238144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9091986518238144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0054097168626809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0054097168626809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8839408430846581, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8839408430846581\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.596942767846613e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.596942767846613e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:27,884]\u001b[0m Trial 32 finished with value: 50.38060695099718 and parameters: {'lambda_l1': 1.596942767846613e-06, 'lambda_l2': 0.0054097168626809, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4658, 'feature_fraction': 0.9091986518238144, 'bagging_fraction': 0.8839408430846581, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.925815425018322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.925815425018322\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015153033999916955, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015153033999916955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9969436914125568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9969436914125568\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.452436211789732e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.452436211789732e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:29,117]\u001b[0m Trial 33 finished with value: 50.41534563720781 and parameters: {'lambda_l1': 4.452436211789732e-05, 'lambda_l2': 0.0015153033999916955, 'num_leaves': 90, 'max_depth': 3, 'n_estimators': 4604, 'feature_fraction': 0.925815425018322, 'bagging_fraction': 0.9969436914125568, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9772738945928839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9772738945928839\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0009417066387537466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009417066387537466\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9738372773713918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9738372773713918\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8145929349246734e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8145929349246734e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:30,382]\u001b[0m Trial 34 finished with value: 52.72270755899047 and parameters: {'lambda_l1': 2.8145929349246734e-06, 'lambda_l2': 0.0009417066387537466, 'num_leaves': 91, 'max_depth': 3, 'n_estimators': 4314, 'feature_fraction': 0.9772738945928839, 'bagging_fraction': 0.9738372773713918, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9329972275586395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9329972275586395\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.01723918739867992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01723918739867992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.994399184996943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994399184996943\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.66760944400639e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.66760944400639e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:31,610]\u001b[0m Trial 35 finished with value: 53.05992678804438 and parameters: {'lambda_l1': 9.66760944400639e-07, 'lambda_l2': 0.01723918739867992, 'num_leaves': 8, 'max_depth': 3, 'n_estimators': 4616, 'feature_fraction': 0.9329972275586395, 'bagging_fraction': 0.994399184996943, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7960373470467561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7960373470467561\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0020104836009707154, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020104836009707154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8414620474837822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8414620474837822\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023035809545990645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023035809545990645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:32,345]\u001b[0m Trial 36 finished with value: 52.29180824018335 and parameters: {'lambda_l1': 0.00023035809545990645, 'lambda_l2': 0.0020104836009707154, 'num_leaves': 134, 'max_depth': 3, 'n_estimators': 2628, 'feature_fraction': 0.7960373470467561, 'bagging_fraction': 0.8414620474837822, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9569295052409753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9569295052409753\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.07680381735579632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07680381735579632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8923893102350151, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8923893102350151\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.7508875234874616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7508875234874616e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:33,572]\u001b[0m Trial 37 finished with value: 59.110562369032664 and parameters: {'lambda_l1': 1.7508875234874616e-05, 'lambda_l2': 0.07680381735579632, 'num_leaves': 190, 'max_depth': 3, 'n_estimators': 4187, 'feature_fraction': 0.9569295052409753, 'bagging_fraction': 0.8923893102350151, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9224306929229203, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224306929229203\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=6.448471114589394e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.448471114589394e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7702230586752068, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702230586752068\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3456114838540395e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3456114838540395e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:34,205]\u001b[0m Trial 38 finished with value: 95.4937556058898 and parameters: {'lambda_l1': 5.3456114838540395e-05, 'lambda_l2': 6.448471114589394e-05, 'num_leaves': 217, 'max_depth': 3, 'n_estimators': 2145, 'feature_fraction': 0.9224306929229203, 'bagging_fraction': 0.7702230586752068, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8305128192408078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8305128192408078\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0020915996062826334, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020915996062826334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9341455924632069, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9341455924632069\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.003372871572975594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003372871572975594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:35,651]\u001b[0m Trial 39 finished with value: 51.55403721335308 and parameters: {'lambda_l1': 0.003372871572975594, 'lambda_l2': 0.0020915996062826334, 'num_leaves': 86, 'max_depth': 4, 'n_estimators': 4660, 'feature_fraction': 0.8305128192408078, 'bagging_fraction': 0.9341455924632069, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7583684595501632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7583684595501632\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0757315797865286e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0757315797865286e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8591422753700104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8591422753700104\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.04442639526158807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04442639526158807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:36,563]\u001b[0m Trial 40 finished with value: 100.51243404763882 and parameters: {'lambda_l1': 0.04442639526158807, 'lambda_l2': 1.0757315797865286e-05, 'num_leaves': 36, 'max_depth': 3, 'n_estimators': 3326, 'feature_fraction': 0.7583684595501632, 'bagging_fraction': 0.8591422753700104, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8742791916342895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742791916342895\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00031443621280828615, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031443621280828615\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9500668175225292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500668175225292\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06235078593597233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06235078593597233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:38,268]\u001b[0m Trial 41 finished with value: 64.3468999129999 and parameters: {'lambda_l1': 0.06235078593597233, 'lambda_l2': 0.00031443621280828615, 'num_leaves': 92, 'max_depth': 4, 'n_estimators': 4660, 'feature_fraction': 0.8742791916342895, 'bagging_fraction': 0.9500668175225292, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8209938685648955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8209938685648955\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0013189876581934216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013189876581934216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.939671806615613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939671806615613\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0027795525571181335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027795525571181335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:39,836]\u001b[0m Trial 42 finished with value: 49.77502748346065 and parameters: {'lambda_l1': 0.0027795525571181335, 'lambda_l2': 0.0013189876581934216, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 4351, 'feature_fraction': 0.8209938685648955, 'bagging_fraction': 0.939671806615613, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7702893475226578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7702893475226578\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.001009919599141044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001009919599141044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8117396193748951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8117396193748951\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00025524993097192524, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00025524993097192524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:41,391]\u001b[0m Trial 43 finished with value: 50.82007911358183 and parameters: {'lambda_l1': 0.00025524993097192524, 'lambda_l2': 0.001009919599141044, 'num_leaves': 129, 'max_depth': 4, 'n_estimators': 4388, 'feature_fraction': 0.7702893475226578, 'bagging_fraction': 0.8117396193748951, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7636944615166064, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636944615166064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0011623154537011224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011623154537011224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8089946302785731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8089946302785731\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0002606276221696125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002606276221696125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:42,627]\u001b[0m Trial 44 finished with value: 51.403380263458004 and parameters: {'lambda_l1': 0.0002606276221696125, 'lambda_l2': 0.0011623154537011224, 'num_leaves': 130, 'max_depth': 3, 'n_estimators': 4439, 'feature_fraction': 0.7636944615166064, 'bagging_fraction': 0.8089946302785731, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8091728309057685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091728309057685\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0009459635443240914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009459635443240914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9014083135907872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9014083135907872\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.002311571813235472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002311571813235472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:44,562]\u001b[0m Trial 45 finished with value: 50.10231185723775 and parameters: {'lambda_l1': 0.002311571813235472, 'lambda_l2': 0.0009459635443240914, 'num_leaves': 161, 'max_depth': 5, 'n_estimators': 4281, 'feature_fraction': 0.8091728309057685, 'bagging_fraction': 0.9014083135907872, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6996250830317221, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6996250830317221\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.909532017600439e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.909532017600439e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8975574125196653, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8975574125196653\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.001701156943205884, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001701156943205884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:46,585]\u001b[0m Trial 46 finished with value: 83.38827099343189 and parameters: {'lambda_l1': 0.001701156943205884, 'lambda_l2': 8.909532017600439e-05, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 4304, 'feature_fraction': 0.6996250830317221, 'bagging_fraction': 0.8975574125196653, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7794039425160162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7794039425160162\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.6040343482308495e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.6040343482308495e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9805804236499959, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9805804236499959\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.023779343671537195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023779343671537195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:48,589]\u001b[0m Trial 47 finished with value: 102.2613583014618 and parameters: {'lambda_l1': 0.023779343671537195, 'lambda_l2': 4.6040343482308495e-08, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3760, 'feature_fraction': 0.7794039425160162, 'bagging_fraction': 0.9805804236499959, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8244817332234778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244817332234778\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00022137109133883102, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022137109133883102\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9165714675747751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9165714675747751\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004319517026608934, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004319517026608934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:51,737]\u001b[0m Trial 48 finished with value: 63.68962537603147 and parameters: {'lambda_l1': 0.004319517026608934, 'lambda_l2': 0.00022137109133883102, 'num_leaves': 121, 'max_depth': 5, 'n_estimators': 4758, 'feature_fraction': 0.8244817332234778, 'bagging_fraction': 0.9165714675747751, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7413065249357587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7413065249357587\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0007176014304748555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007176014304748555\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9526516526613242, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9526516526613242\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004954194531827444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004954194531827444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:53,587]\u001b[0m Trial 49 finished with value: 51.976929752416154 and parameters: {'lambda_l1': 0.0004954194531827444, 'lambda_l2': 0.0007176014304748555, 'num_leaves': 150, 'max_depth': 4, 'n_estimators': 4520, 'feature_fraction': 0.7413065249357587, 'bagging_fraction': 0.9526516526613242, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNFeBcx9tqur",
        "outputId": "3eb8e640-9c6f-427d-9160-894b9e8ce857"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_lgb.best_trial.value, l_study_lgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_lgb.best_trial.value, d_study_lgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunch Best Trial: score 65.47700831201462,\n",
            "params {'lambda_l1': 2.897285138402634e-07, 'lambda_l2': 0.00365564781783537, 'num_leaves': 89, 'max_depth': 4, 'n_estimators': 4170, 'feature_fraction': 0.6799896576109249, 'bagging_fraction': 0.8187865503548556, 'bagging_freq': 6, 'min_child_samples': 20}\n",
            "Dinner Best Trial: score 49.77502748346065,\n",
            "params {'lambda_l1': 0.0027795525571181335, 'lambda_l2': 0.0013189876581934216, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 4351, 'feature_fraction': 0.8209938685648955, 'bagging_fraction': 0.939671806615613, 'bagging_freq': 3, 'min_child_samples': 28}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP2wRgpNukp_",
        "outputId": "3b9e9876-3fa0-414a-805f-8ffea49d0501"
      },
      "source": [
        "l_trial_lgb = l_study_lgb.best_trial\n",
        "lunch_lgb_params = l_trial_lgb.params\n",
        "lunch_lgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.8187865503548556,\n",
              " 'bagging_freq': 6,\n",
              " 'feature_fraction': 0.6799896576109249,\n",
              " 'lambda_l1': 2.897285138402634e-07,\n",
              " 'lambda_l2': 0.00365564781783537,\n",
              " 'max_depth': 4,\n",
              " 'min_child_samples': 20,\n",
              " 'n_estimators': 4170,\n",
              " 'num_leaves': 89}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_4jdK6SvFPm",
        "outputId": "41781d9c-21f1-4cc1-df79-4f9cd9c99e64"
      },
      "source": [
        "d_trial_lgb = d_study_lgb.best_trial\n",
        "dinner_lgb_params = d_trial_lgb.params\n",
        "dinner_lgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.939671806615613,\n",
              " 'bagging_freq': 3,\n",
              " 'feature_fraction': 0.8209938685648955,\n",
              " 'lambda_l1': 0.0027795525571181335,\n",
              " 'lambda_l2': 0.0013189876581934216,\n",
              " 'max_depth': 4,\n",
              " 'min_child_samples': 28,\n",
              " 'n_estimators': 4351,\n",
              " 'num_leaves': 77}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3aUvzvEnnc_"
      },
      "source": [
        "#### Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLoo862Fuoyl",
        "outputId": "d8b48b29-1bc2-4bd3-cce1-7059c96b1107"
      },
      "source": [
        "lunch_lgb_model = lgb.LGBMRegressor(**lunch_lgb_params)\n",
        "lunch_lgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['lunch_y'], eval_metric='mae')\n",
        "lunch_lgb_pred = lunch_lgb_model.predict(b_test_df)\n",
        "\n",
        "dinner_lgb_model = lgb.LGBMRegressor(**dinner_lgb_params)\n",
        "dinner_lgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['dinner_y'], eval_metric='mae')\n",
        "dinner_lgb_pred = dinner_lgb_model.predict(b_test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6799896576109249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6799896576109249\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00365564781783537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00365564781783537\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.897285138402634e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.897285138402634e-07\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8187865503548556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8187865503548556\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8209938685648955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8209938685648955\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0013189876581934216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013189876581934216\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0027795525571181335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027795525571181335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.939671806615613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939671806615613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjEBjP-LutfL",
        "outputId": "2ff8339f-2c36-4eb9-c625-852ab21d6d0d"
      },
      "source": [
        "lunch_lgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1079.03310198,  924.10964866,  577.80795891, 1249.64290239,\n",
              "        895.40968667,  976.67085872,  932.21715732,  588.31314377,\n",
              "       1265.88372599, 1007.43627688,  753.3058041 , 1298.1315063 ,\n",
              "       1095.51476572, 1143.45021793,  904.39944554,  686.3541367 ,\n",
              "       1325.01370148, 1057.89940921,  963.60653005,  798.25491832,\n",
              "        642.38341296, 1102.81447347, 1014.60911754,  871.34047641,\n",
              "        586.9445266 , 1368.12620978, 1142.22587593,  987.52438831,\n",
              "        964.93036481,  753.91854802, 1305.10202639,  976.69937358,\n",
              "       1135.31632959,  951.21850548,  646.85876952, 1227.54952625,\n",
              "       1032.7836392 ,  980.65422895,  850.75414849,  558.01674131,\n",
              "       1197.43640734,  999.96037929, 1007.00921605,  824.95815502,\n",
              "        607.28509736, 1228.23824069, 1075.8525771 , 1064.4343903 ,\n",
              "        891.26183146,  622.11567044])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GuXL30svQN1",
        "outputId": "c4c62b15-c256-4280-a4b8-60ed9ddf3495"
      },
      "source": [
        "dinner_lgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([240.64583374, 395.31253185, 230.10808226, 536.22486105,\n",
              "       436.06674743, 435.43609076, 417.67914823, 316.7960654 ,\n",
              "       576.4247487 , 470.58059628,  64.61235642, 716.50671474,\n",
              "       532.11446787, 338.15984255, 468.82518124, 362.77551051,\n",
              "       644.14007198, 630.39492527, 370.51080814, 489.80303535,\n",
              "       345.26131363, 637.2045706 , 445.68363242, 499.00831437,\n",
              "       379.33171555, 615.08692761, 566.33144218, 395.44760439,\n",
              "       524.533477  , 285.36198195, 698.27470741, 500.0443474 ,\n",
              "       459.49348451, 482.87676549, 194.51826389, 663.76134889,\n",
              "       590.70957418, 318.86217704, 488.28828955, 217.18639504,\n",
              "       705.05824861, 604.94206022, 296.65494587, 408.72644953,\n",
              "       309.53007816, 655.41708784, 553.40894854, 527.76336813,\n",
              "       486.43570526, 339.27940083])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "JACfYxl9vl1U",
        "outputId": "65561fb1-d6e7-4ee1-fd1f-3a26ae8cfd59"
      },
      "source": [
        "lgb_submit = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "lgb_submit['중식계'] = lunch_lgb_pred\n",
        "lgb_submit['석식계'] = dinner_lgb_pred\n",
        "lgb_submit.to_csv(PATH + 'lgb_base.csv', index=False)\n",
        "lgb_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>1079.033102</td>\n",
              "      <td>240.645834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>924.109649</td>\n",
              "      <td>395.312532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>577.807959</td>\n",
              "      <td>230.108082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>1249.642902</td>\n",
              "      <td>536.224861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>895.409687</td>\n",
              "      <td>436.066747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자          중식계         석식계\n",
              "0  2021-01-27  1079.033102  240.645834\n",
              "1  2021-01-28   924.109649  395.312532\n",
              "2  2021-01-29   577.807959  230.108082\n",
              "3  2021-02-01  1249.642902  536.224861\n",
              "4  2021-02-02   895.409687  436.066747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWINF0jFglK"
      },
      "source": [
        "# regex = \"\\((.*?)\\)\"\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])\n",
        "\n",
        "\n",
        "# regex = '[/*,&+-><]'\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])\n",
        "\n",
        "# regex = 'D|BLT'\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ5lnAhdJXj4"
      },
      "source": [
        "# tfidf에 입력하는 코퍼스가 공백기준으로 단어를 인식해서 그냥 위의 all_df 사용\n",
        "\n",
        "# col = ['조식메뉴', '중식메뉴', '석식메뉴']\n",
        "# for i in col:\n",
        "#     all_df[i] = all_df[i].str.split()\n",
        "# all_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ftaXkjn1SE"
      },
      "source": [
        "- 메뉴 정리\n",
        "\n",
        "    - Tfidf로 단어를 임베딩\n",
        "    - 임베딩한 값이 특정 threshold 미만이면 없애기\n",
        "    - 예를 들어 계란후라이 tfidf 값이 0.1이면 threshold를 0.15정도로 지정해서 계란후라이 지우기\n",
        "    - 지우고 남아 있는 메뉴 리스트에서 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeIifxKohDTf"
      },
      "source": [
        "# def list_make(list, column):\n",
        "#     for i in all_df[column]:\n",
        "#         list.append(i)\n",
        "#     return list\n",
        "# breakfast_list = []\n",
        "# lunch_list = []\n",
        "# dinner_list = []\n",
        "\n",
        "# breakfast_list = list_make(breakfast_list, '조식메뉴')\n",
        "# lunch_list = list_make(lunch_list, '중식메뉴')\n",
        "# dinner_list = list_make(dinner_list, '석식메뉴')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5f7GtOjjk0a"
      },
      "source": [
        "# breakfast_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4RAOvfDq8zx"
      },
      "source": [
        "\n",
        "# non = []\n",
        "# def tfidf_view(sikdan):\n",
        "#     tfidf = TfidfVectorizer()\n",
        "#     sikdan_tfidf = tfidf.fit_transform(sikdan)\n",
        "#     word2id = defaultdict(lambda : 0)\n",
        "#     for idx, feature in enumerate(tfidf.get_feature_names()):\n",
        "#         word2id[feature] = idx\n",
        "#     for i, sent in enumerate(sikdan):\n",
        "#         print(' ===== document[%d] ====='%i)\n",
        "#         for token in sent.split():\n",
        "#             print([(token, sikdan_tfidf[i, word2id[token]])])\n",
        "#             if sikdan_tfidf[i, word2id[token]] < 0.001:\n",
        "#                 non.append(token)\n",
        "        \n",
        "\n",
        "# tfidf_view(breakfast_list)\n",
        "# non"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}