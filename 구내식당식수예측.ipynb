{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "구내식당식수예측.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1Zq0t1LDhgmlkJbZrlR8Oq05FmPV7QoYe",
      "authorship_tag": "ABX9TyNaALMjA2Po7jgj5ACrEQaA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Haebuk/Python_Machine_Learning/blob/master/%EA%B5%AC%EB%82%B4%EC%8B%9D%EB%8B%B9%EC%8B%9D%EC%88%98%EC%98%88%EC%B8%A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTW17ZhzhDvU"
      },
      "source": [
        "# 라이브러리\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maw3fEx49_Ol",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "395d4b21-7243-402f-bc0d-5eb47aacf522"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from tqdm import tqdm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
        "from copy import deepcopy\n",
        "# xgboost gpu in colab 런타임 변경\n",
        "!pip install https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl\n",
        "# lightgbm gpu in colab\n",
        "! git clone --recursive https://github.com/Microsoft/LightGBM\n",
        "! cd LightGBM && rm -rf build && mkdir build && cd build && cmake -DUSE_GPU=1 ../../LightGBM && make -j4 && cd ../python-package && python3 setup.py install --precompile --gpu;    \n",
        "from sklearn.metrics import mean_absolute_error\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "!pip install optuna -q\n",
        "import optuna\n",
        "from optuna.integration import XGBoostPruningCallback"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa\n",
            "\u001b[?25l  Downloading https://s3-us-west-2.amazonaws.com/xgboost-nightly-builds/xgboost-1.4.0_SNAPSHOT%2B4224c08cacceba3f83f90e387c07aa6205a83bfa-py3-none-manylinux2010_x86_64.whl (166.7MB)\n",
            "\u001b[K     |████████████████████████████████| 166.7MB 95kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.4.0-SNAPSHOT+4224c08cacceba3f83f90e387c07aa6205a83bfa) (1.19.5)\n",
            "Installing collected packages: xgboost\n",
            "  Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.4.0-SNAPSHOT\n",
            "Cloning into 'LightGBM'...\n",
            "remote: Enumerating objects: 22707, done.\u001b[K\n",
            "remote: Counting objects: 100% (320/320), done.\u001b[K\n",
            "remote: Compressing objects: 100% (179/179), done.\u001b[K\n",
            "remote: Total 22707 (delta 173), reused 221 (delta 134), pack-reused 22387\u001b[K\n",
            "Receiving objects: 100% (22707/22707), 17.80 MiB | 13.63 MiB/s, done.\n",
            "Resolving deltas: 100% (16614/16614), done.\n",
            "Submodule 'include/boost/compute' (https://github.com/boostorg/compute) registered for path 'external_libs/compute'\n",
            "Submodule 'eigen' (https://gitlab.com/libeigen/eigen.git) registered for path 'external_libs/eigen'\n",
            "Submodule 'external_libs/fast_double_parser' (https://github.com/lemire/fast_double_parser.git) registered for path 'external_libs/fast_double_parser'\n",
            "Submodule 'external_libs/fmt' (https://github.com/fmtlib/fmt.git) registered for path 'external_libs/fmt'\n",
            "Cloning into '/content/LightGBM/external_libs/compute'...\n",
            "remote: Enumerating objects: 21731, done.        \n",
            "remote: Counting objects: 100% (3/3), done.        \n",
            "remote: Compressing objects: 100% (3/3), done.        \n",
            "remote: Total 21731 (delta 0), reused 1 (delta 0), pack-reused 21728        \n",
            "Receiving objects: 100% (21731/21731), 8.51 MiB | 9.08 MiB/s, done.\n",
            "Resolving deltas: 100% (17566/17566), done.\n",
            "Cloning into '/content/LightGBM/external_libs/eigen'...\n",
            "remote: Enumerating objects: 110280, done.        \n",
            "remote: Counting objects: 100% (1646/1646), done.        \n",
            "remote: Compressing objects: 100% (563/563), done.        \n",
            "remote: Total 110280 (delta 1241), reused 1447 (delta 1075), pack-reused 108634        \n",
            "Receiving objects: 100% (110280/110280), 102.15 MiB | 16.08 MiB/s, done.\n",
            "Resolving deltas: 100% (90508/90508), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser'...\n",
            "remote: Enumerating objects: 689, done.        \n",
            "remote: Counting objects: 100% (189/189), done.        \n",
            "remote: Compressing objects: 100% (121/121), done.        \n",
            "remote: Total 689 (delta 93), reused 99 (delta 41), pack-reused 500        \n",
            "Receiving objects: 100% (689/689), 802.19 KiB | 1.53 MiB/s, done.\n",
            "Resolving deltas: 100% (347/347), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fmt'...\n",
            "remote: Enumerating objects: 26747, done.        \n",
            "remote: Counting objects: 100% (455/455), done.        \n",
            "remote: Compressing objects: 100% (178/178), done.        \n",
            "remote: Total 26747 (delta 261), reused 390 (delta 228), pack-reused 26292        \n",
            "Receiving objects: 100% (26747/26747), 13.27 MiB | 22.54 MiB/s, done.\n",
            "Resolving deltas: 100% (18060/18060), done.\n",
            "Submodule path 'external_libs/compute': checked out '36c89134d4013b2e5e45bc55656a18bd6141995a'\n",
            "Submodule path 'external_libs/eigen': checked out '8ba1b0f41a7950dc3e1d4ed75859e36c73311235'\n",
            "Submodule path 'external_libs/fast_double_parser': checked out 'ace60646c02dc54c57f19d644e49a61e7e7758ec'\n",
            "Submodule 'benchmark/dependencies/abseil-cpp' (https://github.com/abseil/abseil-cpp.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'\n",
            "Submodule 'benchmark/dependencies/double-conversion' (https://github.com/google/double-conversion.git) registered for path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp'...\n",
            "remote: Enumerating objects: 14762, done.        \n",
            "remote: Counting objects: 100% (769/769), done.        \n",
            "remote: Compressing objects: 100% (383/383), done.        \n",
            "remote: Total 14762 (delta 482), reused 620 (delta 386), pack-reused 13993        \n",
            "Receiving objects: 100% (14762/14762), 9.94 MiB | 14.06 MiB/s, done.\n",
            "Resolving deltas: 100% (11160/11160), done.\n",
            "Cloning into '/content/LightGBM/external_libs/fast_double_parser/benchmarks/dependencies/double-conversion'...\n",
            "remote: Enumerating objects: 1225, done.        \n",
            "remote: Counting objects: 100% (69/69), done.        \n",
            "remote: Compressing objects: 100% (50/50), done.        \n",
            "remote: Total 1225 (delta 38), reused 33 (delta 19), pack-reused 1156        \n",
            "Receiving objects: 100% (1225/1225), 7.08 MiB | 6.19 MiB/s, done.\n",
            "Resolving deltas: 100% (810/810), done.\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/abseil-cpp': checked out 'd936052d32a5b7ca08b0199a6724724aea432309'\n",
            "Submodule path 'external_libs/fast_double_parser/benchmarks/dependencies/double-conversion': checked out 'f4cb2384efa55dee0e6652f8674b05763441ab09'\n",
            "Submodule path 'external_libs/fmt': checked out 'cc09f1a6798c085c325569ef466bcdcffdc266d4'\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Check for working C compiler: /usr/bin/cc\n",
            "-- Check for working C compiler: /usr/bin/cc -- works\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++\n",
            "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Found OpenMP_C: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP_CXX: -fopenmp (found version \"4.5\") \n",
            "-- Found OpenMP: TRUE (found version \"4.5\")  \n",
            "-- Looking for CL_VERSION_2_2\n",
            "-- Looking for CL_VERSION_2_2 - found\n",
            "-- Found OpenCL: /usr/lib/x86_64-linux-gnu/libOpenCL.so (found version \"2.2\") \n",
            "-- OpenCL include directory: /usr/include\n",
            "-- Boost version: 1.65.1\n",
            "-- Found the following Boost libraries:\n",
            "--   filesystem\n",
            "--   system\n",
            "-- Performing Test MM_PREFETCH\n",
            "-- Performing Test MM_PREFETCH - Success\n",
            "-- Using _mm_prefetch\n",
            "-- Performing Test MM_MALLOC\n",
            "-- Performing Test MM_MALLOC - Success\n",
            "-- Using _mm_malloc\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/LightGBM/build\n",
            "\u001b[35m\u001b[1mScanning dependencies of target _lightgbm\u001b[0m\n",
            "\u001b[35m\u001b[1mScanning dependencies of target lightgbm\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[  4%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/main.cpp.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/application/application.cpp.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/boosting.cpp.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 14%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt.cpp.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_model_text.cpp.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/gbdt_prediction.cpp.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/boosting/prediction_early_stop.cpp.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/bin.cpp.o\u001b[0m\n",
            "[ 24%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config.cpp.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/config_auto.cpp.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset.cpp.o\u001b[0m\n",
            "[ 34%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 39%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/dataset_loader.cpp.o\u001b[0m\n",
            "[ 40%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/file_io.cpp.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 44%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/json11.cpp.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/metadata.cpp.o\u001b[0m\n",
            "[ 49%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/parser.cpp.o\u001b[0m\n",
            "[ 50%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/train_share_states.cpp.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/io/tree.cpp.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/dcg_calculator.cpp.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 57%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 59%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/metric/metric.cpp.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/ifaddrs_patch.cpp.o\u001b[0m\n",
            "[ 69%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linker_topo.cpp.o\u001b[0m\n",
            "[ 71%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_mpi.cpp.o\u001b[0m\n",
            "[ 72%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/linkers_socket.cpp.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/network/network.cpp.o\u001b[0m\n",
            "[ 75%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 76%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/objective/objective_function.cpp.o\u001b[0m\n",
            "[ 78%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/cuda_tree_learner.cpp.o\u001b[0m\n",
            "[ 79%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/data_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/feature_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 84%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/gpu_tree_learner.cpp.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/linear_tree_learner.cpp.o\u001b[0m\n",
            "[ 88%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 89%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 91%] \u001b[32mBuilding CXX object CMakeFiles/lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 92%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/serial_tree_learner.cpp.o\u001b[0m\n",
            "[ 94%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/tree_learner.cpp.o\u001b[0m\n",
            "[ 95%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/treelearner/voting_parallel_tree_learner.cpp.o\u001b[0m\n",
            "[ 97%] \u001b[32mBuilding CXX object CMakeFiles/_lightgbm.dir/src/c_api.cpp.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../lightgbm\u001b[0m\n",
            "[ 98%] Built target lightgbm\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX shared library ../lib_lightgbm.so\u001b[0m\n",
            "[100%] Built target _lightgbm\n",
            "running install\n",
            "running build\n",
            "running build_py\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/Grammar.txt\n",
            "INFO:root:Generating grammar tables from /usr/lib/python3.7/lib2to3/PatternGrammar.txt\n",
            "creating build\n",
            "creating build/lib\n",
            "creating build/lib/lightgbm\n",
            "copying lightgbm/plotting.py -> build/lib/lightgbm\n",
            "copying lightgbm/libpath.py -> build/lib/lightgbm\n",
            "copying lightgbm/basic.py -> build/lib/lightgbm\n",
            "copying lightgbm/callback.py -> build/lib/lightgbm\n",
            "copying lightgbm/__init__.py -> build/lib/lightgbm\n",
            "copying lightgbm/sklearn.py -> build/lib/lightgbm\n",
            "copying lightgbm/engine.py -> build/lib/lightgbm\n",
            "copying lightgbm/dask.py -> build/lib/lightgbm\n",
            "copying lightgbm/compat.py -> build/lib/lightgbm\n",
            "running egg_info\n",
            "creating lightgbm.egg-info\n",
            "writing lightgbm.egg-info/PKG-INFO\n",
            "writing dependency_links to lightgbm.egg-info/dependency_links.txt\n",
            "writing requirements to lightgbm.egg-info/requires.txt\n",
            "writing top-level names to lightgbm.egg-info/top_level.txt\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "reading manifest template 'MANIFEST.in'\n",
            "no previously-included directories found matching 'build'\n",
            "warning: no files found matching 'LICENSE'\n",
            "warning: no files found matching '*.txt'\n",
            "warning: no files found matching '*.so' under directory 'lightgbm'\n",
            "warning: no files found matching 'compile/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/cmake/IntegratedOpenCL.cmake'\n",
            "warning: no files found matching '*.so' under directory 'compile'\n",
            "warning: no files found matching '*.dll' under directory 'compile/Release'\n",
            "warning: no files found matching 'compile/external_libs/compute/CMakeLists.txt'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/cmake'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/include'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/compute/meta'\n",
            "warning: no files found matching 'compile/external_libs/eigen/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Cholesky'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Core'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Dense'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Eigenvalues'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Geometry'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Householder'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/Jacobi'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/LU'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/QR'\n",
            "warning: no files found matching 'compile/external_libs/eigen/Eigen/SVD'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Cholesky'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Core'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Eigenvalues'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Geometry'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Householder'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/Jacobi'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/LU'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/misc'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/plugins'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/QR'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/eigen/Eigen/src/SVD'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE'\n",
            "warning: no files found matching 'compile/external_libs/fast_double_parser/LICENSE.BSL'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fast_double_parser/include'\n",
            "warning: no files found matching 'compile/external_libs/fmt/CMakeLists.txt'\n",
            "warning: no files found matching 'compile/external_libs/fmt/LICENSE.rst'\n",
            "warning: no files found matching '*' under directory 'compile/external_libs/fmt/include'\n",
            "warning: no files found matching '*' under directory 'compile/include'\n",
            "warning: no files found matching '*' under directory 'compile/src'\n",
            "warning: no files found matching 'LightGBM.sln' under directory 'compile/windows'\n",
            "warning: no files found matching 'LightGBM.vcxproj' under directory 'compile/windows'\n",
            "warning: no files found matching '*.dll' under directory 'compile/windows/x64/DLL'\n",
            "warning: no previously-included files matching '*.py[co]' found anywhere in distribution\n",
            "warning: no previously-included files found matching 'compile/external_libs/compute/.git'\n",
            "writing manifest file 'lightgbm.egg-info/SOURCES.txt'\n",
            "copying lightgbm/VERSION.txt -> build/lib/lightgbm\n",
            "running install_lib\n",
            "copying build/lib/lightgbm/plotting.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/libpath.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/basic.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/callback.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/__init__.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/VERSION.txt -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/sklearn.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/engine.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/dask.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "copying build/lib/lightgbm/compat.py -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "INFO:LightGBM:Installing lib_lightgbm from: ['../lib_lightgbm.so']\n",
            "copying ../lib_lightgbm.so -> /usr/local/lib/python3.7/dist-packages/lightgbm\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/plotting.py to plotting.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/libpath.py to libpath.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/basic.py to basic.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/callback.py to callback.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/__init__.py to __init__.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/sklearn.py to sklearn.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/engine.py to engine.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/dask.py to dask.cpython-37.pyc\n",
            "byte-compiling /usr/local/lib/python3.7/dist-packages/lightgbm/compat.py to compat.cpython-37.pyc\n",
            "running install_egg_info\n",
            "Copying lightgbm.egg-info to /usr/local/lib/python3.7/dist-packages/lightgbm-3.2.1.99-py3.7.egg-info\n",
            "running install_scripts\n",
            "\u001b[K     |████████████████████████████████| 307kB 4.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 7.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 174kB 15.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 143kB 18.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 15.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25h  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fq5HFK3L-QWR"
      },
      "source": [
        "PATH = '/content/drive/MyDrive/input/235743_구내식당 식사 인원 예측 AI 경진대회_data/'\n",
        "train_df = pd.read_csv(PATH + 'train.csv')\n",
        "test_df = pd.read_csv(PATH + 'test.csv')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "yVVZGTl3-4RC",
        "outputId": "47352b81-ddaa-44a8-eb30-8a102fda4921"
      },
      "source": [
        "train_df.head(10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>요일</th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2016-02-01</td>\n",
              "      <td>월</td>\n",
              "      <td>2601</td>\n",
              "      <td>50</td>\n",
              "      <td>150</td>\n",
              "      <td>238</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 오징어찌개  쇠불고기 (쇠고기:호주산) 계란찜 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 육개장  자반고등어구이  두부조림  건파래무침 ...</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2016-02-02</td>\n",
              "      <td>화</td>\n",
              "      <td>2601</td>\n",
              "      <td>50</td>\n",
              "      <td>173</td>\n",
              "      <td>319</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치찌개  가자미튀김  모둠소세지구이  마늘쫑무...</td>\n",
              "      <td>콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무...</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2016-02-03</td>\n",
              "      <td>수</td>\n",
              "      <td>2601</td>\n",
              "      <td>56</td>\n",
              "      <td>180</td>\n",
              "      <td>111</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...</td>\n",
              "      <td>카레덮밥 (쌀,현미흑미:국내산) 팽이장국  치킨핑거 (닭고기:국내산) 쫄면야채무침 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 청국장찌개  황태양념구이 (황태:러시아산) 고기...</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2016-02-04</td>\n",
              "      <td>목</td>\n",
              "      <td>2601</td>\n",
              "      <td>104</td>\n",
              "      <td>220</td>\n",
              "      <td>355</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 쇠고기무국  주꾸미볶음  부추전  시금치나물  ...</td>\n",
              "      <td>미니김밥*겨자장 (쌀,현미흑미:국내산) 우동  멕시칸샐러드  군고구마  무피클  포...</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-02-05</td>\n",
              "      <td>금</td>\n",
              "      <td>2601</td>\n",
              "      <td>278</td>\n",
              "      <td>181</td>\n",
              "      <td>34</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 떡국  돈육씨앗강정 (돼지고기:국내산) 우엉잡채...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 차돌박이찌개 (쇠고기:호주산) 닭갈비 (닭고기:...</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2016-02-11</td>\n",
              "      <td>목</td>\n",
              "      <td>2601</td>\n",
              "      <td>383</td>\n",
              "      <td>143</td>\n",
              "      <td>417</td>\n",
              "      <td>0.0</td>\n",
              "      <td>팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 시래기국  훈제오리구이  도토리묵무침  쌈무/양...</td>\n",
              "      <td>참치회덮밥 (쌀,현미흑미:국내산) 맑은국  군만두  과일샐러드  락교  포기김치 (...</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2016-02-12</td>\n",
              "      <td>금</td>\n",
              "      <td>2601</td>\n",
              "      <td>389</td>\n",
              "      <td>156</td>\n",
              "      <td>93</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 꽃게탕  돈육굴소스볶음  옥수수전  유채나물  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치콩나물국  미니함박  어묵볶음  물파래무침 ...</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2016-02-15</td>\n",
              "      <td>월</td>\n",
              "      <td>2601</td>\n",
              "      <td>87</td>\n",
              "      <td>204</td>\n",
              "      <td>482</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 시금치국  닭감자조림 (닭고기:국내산) 연두부*양념장  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 홍합미역국  등갈비김치찜 (돼지고기,김치:국내산) 임연수...</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2016-02-16</td>\n",
              "      <td>화</td>\n",
              "      <td>2601</td>\n",
              "      <td>72</td>\n",
              "      <td>236</td>\n",
              "      <td>526</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 쇠고기무국 (쇠고기:호주산) 탕수어 (동태:러시아산) 오...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 된장찌개  쇠불고기 (쇠고기:호주산) 해파리겨자채  봄동...</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>2016-02-17</td>\n",
              "      <td>수</td>\n",
              "      <td>2601</td>\n",
              "      <td>78</td>\n",
              "      <td>250</td>\n",
              "      <td>23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 냉이된장국  쇠고기장조림 (쇠고기:호주산) 통도라지구이 ...</td>\n",
              "      <td>볶음밥*자장소스 (쌀:국내산) 맑은국  새우또띠아  쨔샤이무침  요플레  포기김치 ...</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자 요일  ...     중식계    석식계\n",
              "0  2016-02-01  월  ...  1039.0  331.0\n",
              "1  2016-02-02  화  ...   867.0  560.0\n",
              "2  2016-02-03  수  ...  1017.0  573.0\n",
              "3  2016-02-04  목  ...   978.0  525.0\n",
              "4  2016-02-05  금  ...   925.0  330.0\n",
              "5  2016-02-11  목  ...  1045.0  550.0\n",
              "6  2016-02-12  금  ...   909.0  598.0\n",
              "7  2016-02-15  월  ...  1268.0  672.0\n",
              "8  2016-02-16  화  ...  1014.0  523.0\n",
              "9  2016-02-17  수  ...   916.0  588.0\n",
              "\n",
              "[10 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "kgSYY8gz_AuO",
        "outputId": "464ea441-3124-4584-91c5-a7d745fbb30b"
      },
      "source": [
        "test_df.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>요일</th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>수</td>\n",
              "      <td>2983</td>\n",
              "      <td>88</td>\n",
              "      <td>182</td>\n",
              "      <td>5</td>\n",
              "      <td>358.0</td>\n",
              "      <td>모닝롤/연유버터베이글 우유/주스 계란후라이/찐계란 단호박죽/흑미밥 우거지국 고기완자...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 대구지리 매운돈갈비찜 오꼬노미계란말이 상추무침 포기김치 양상추...</td>\n",
              "      <td>흑미밥 얼큰순두부찌개 쇠고기우엉볶음 버섯햄볶음 (New)아삭이고추무절임 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>목</td>\n",
              "      <td>2983</td>\n",
              "      <td>104</td>\n",
              "      <td>212</td>\n",
              "      <td>409</td>\n",
              "      <td>348.0</td>\n",
              "      <td>모닝롤/대만샌드위치 우유/주스 계란후라이/찐계란 누룽지탕/흑미밥 황태국 시래기지짐 ...</td>\n",
              "      <td>쌀밥/보리밥/찰현미밥 우렁된장찌개 오리주물럭 청양부추전 수제삼색무쌈 겉절이김치 양상...</td>\n",
              "      <td>충무김밥 우동국물 오징어무침 꽃맛살샐러드 얼갈이쌈장무침 석박지</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>금</td>\n",
              "      <td>2983</td>\n",
              "      <td>270</td>\n",
              "      <td>249</td>\n",
              "      <td>0</td>\n",
              "      <td>294.0</td>\n",
              "      <td>모닝롤/핫케익 우유/주스 계란후라이/찐계란 오곡죽/흑미밥 매생이굴국 고구마순볶음 양...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 팽이장국 수제돈까스*소스 가자미조림 동초나물무침 포기김치 양상...</td>\n",
              "      <td>흑미밥 물만둣국 카레찜닭 숯불양념꼬지어묵 꼬시래기무침 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>월</td>\n",
              "      <td>2924</td>\n",
              "      <td>108</td>\n",
              "      <td>154</td>\n",
              "      <td>538</td>\n",
              "      <td>322.0</td>\n",
              "      <td>모닝롤/촉촉한치즈케익 우유/주스 계란후라이/찐계란 누룽지탕/흑미밥 두부김칫국 새우완...</td>\n",
              "      <td>쌀밥/흑미밥/찰현미밥 배추들깨국 오리대패불고기 시금치프리타타 부추고추장무침 포기김치...</td>\n",
              "      <td>흑미밥 동태탕 돈육꽈리고추장조림 당면채소무침 모자반무침 포기김치</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>화</td>\n",
              "      <td>2924</td>\n",
              "      <td>62</td>\n",
              "      <td>186</td>\n",
              "      <td>455</td>\n",
              "      <td>314.0</td>\n",
              "      <td>모닝롤/토마토샌드 우유/주스 계란후라이/찐계란 채소죽/흑미밥 호박맑은국 오이생채 양...</td>\n",
              "      <td>쌀밥/팥밥/찰현미밥 부대찌개 닭살데리야끼조림 버섯탕수 세발나물무침 알타리김치/사과푸...</td>\n",
              "      <td>흑미밥 바지락살국 쇠고기청경채볶음 두부구이*볶은김치 머위된장무침 백김치</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자  ...                                           석식메뉴\n",
              "0  2021-01-27  ...  흑미밥 얼큰순두부찌개 쇠고기우엉볶음 버섯햄볶음 (New)아삭이고추무절임 포기김치 \n",
              "1  2021-01-28  ...            충무김밥 우동국물 오징어무침 꽃맛살샐러드 얼갈이쌈장무침 석박지 \n",
              "2  2021-01-29  ...            흑미밥 물만둣국 카레찜닭 숯불양념꼬지어묵 꼬시래기무침 포기김치 \n",
              "3  2021-02-01  ...           흑미밥 동태탕 돈육꽈리고추장조림 당면채소무침 모자반무침 포기김치 \n",
              "4  2021-02-02  ...       흑미밥 바지락살국 쇠고기청경채볶음 두부구이*볶은김치 머위된장무침 백김치 \n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxe-kkV6AlNF",
        "outputId": "4140eff2-96b1-4721-b7cf-eaaa5c8092ea"
      },
      "source": [
        "print(train_df.shape, test_df.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 12) (50, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "SasndXbCF8MZ",
        "outputId": "09f857cd-2bd0-4bac-efd5-2a1fbe956418"
      },
      "source": [
        "train_df.describe()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>본사정원수</th>\n",
              "      <th>본사휴가자수</th>\n",
              "      <th>본사출장자수</th>\n",
              "      <th>본사시간외근무명령서승인건수</th>\n",
              "      <th>현본사소속재택근무자수</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>2807.815768</td>\n",
              "      <td>157.913693</td>\n",
              "      <td>241.142739</td>\n",
              "      <td>274.117012</td>\n",
              "      <td>43.506224</td>\n",
              "      <td>890.334440</td>\n",
              "      <td>461.772614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>171.264404</td>\n",
              "      <td>144.190572</td>\n",
              "      <td>43.532298</td>\n",
              "      <td>246.239651</td>\n",
              "      <td>109.937400</td>\n",
              "      <td>209.505057</td>\n",
              "      <td>139.179202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>2601.000000</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>2645.000000</td>\n",
              "      <td>71.000000</td>\n",
              "      <td>217.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>758.000000</td>\n",
              "      <td>406.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>2760.000000</td>\n",
              "      <td>105.000000</td>\n",
              "      <td>245.000000</td>\n",
              "      <td>299.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>879.000000</td>\n",
              "      <td>483.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>2962.000000</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>272.000000</td>\n",
              "      <td>452.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1032.000000</td>\n",
              "      <td>545.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3305.000000</td>\n",
              "      <td>1224.000000</td>\n",
              "      <td>378.000000</td>\n",
              "      <td>1044.000000</td>\n",
              "      <td>533.000000</td>\n",
              "      <td>1459.000000</td>\n",
              "      <td>905.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             본사정원수       본사휴가자수  ...          중식계          석식계\n",
              "count  1205.000000  1205.000000  ...  1205.000000  1205.000000\n",
              "mean   2807.815768   157.913693  ...   890.334440   461.772614\n",
              "std     171.264404   144.190572  ...   209.505057   139.179202\n",
              "min    2601.000000    23.000000  ...   296.000000     0.000000\n",
              "25%    2645.000000    71.000000  ...   758.000000   406.000000\n",
              "50%    2760.000000   105.000000  ...   879.000000   483.000000\n",
              "75%    2962.000000   185.000000  ...  1032.000000   545.000000\n",
              "max    3305.000000  1224.000000  ...  1459.000000   905.000000\n",
              "\n",
              "[8 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 705
        },
        "id": "dhg1YrRaBq9N",
        "outputId": "53ddc59b-118f-4627-aa59-e7acb4d118ac"
      },
      "source": [
        "all_df = pd.concat([train_df, test_df], axis=0).reset_index(drop=True)\n",
        "\n",
        "\n",
        "all_df['vac_ratio'] = all_df['본사휴가자수'] / all_df['본사정원수']\n",
        "all_df['trip_ratio'] = all_df['본사출장자수'] / all_df['본사정원수']\n",
        "all_df['home'] = all_df['현본사소속재택근무자수'] / all_df['본사정원수']\n",
        "all_df['extra'] = all_df['본사시간외근무명령서승인건수'] / all_df['본사정원수']\n",
        "all_df['total'] = (all_df['본사정원수'] - all_df['본사휴가자수'] \n",
        "                   - all_df['본사출장자수'] - all_df['현본사소속재택근무자수']) / all_df['본사정원수']\n",
        "\n",
        "all_df['일자'] = pd.to_datetime(all_df['일자'])\n",
        "\n",
        "all_df['year'] = all_df['일자'].dt.year\n",
        "all_df['month'] = all_df['일자'].dt.month\n",
        "all_df['date'] = all_df['일자'].dt.day\n",
        "all_df['week'] = all_df['일자'].dt.isocalendar().week\n",
        "all_df['dayofweek'] = all_df['일자'].dt.weekday\n",
        "\n",
        "all_df.drop(['본사휴가자수', '본사출장자수', '현본사소속재택근무자수', \n",
        "             '본사시간외근무명령서승인건수', '본사정원수', '일자', '요일'], axis=1, inplace=True)\n",
        "all_df['week'] = all_df['week'].astype(np.int64)\n",
        "all_df.rename({'조식메뉴':'breakfast', '중식메뉴':'lunch', '석식메뉴':'dinner', '중식계':'lunch_y', '석식계':'dinner_y'}, inplace=True)\n",
        "\n",
        "all_df.head(10)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>조식메뉴</th>\n",
              "      <th>중식메뉴</th>\n",
              "      <th>석식메뉴</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 오징어찌개  쇠불고기 (쇠고기:호주산) 계란찜 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 육개장  자반고등어구이  두부조림  건파래무침 ...</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치찌개  가자미튀김  모둠소세지구이  마늘쫑무...</td>\n",
              "      <td>콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무...</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...</td>\n",
              "      <td>카레덮밥 (쌀,현미흑미:국내산) 팽이장국  치킨핑거 (닭고기:국내산) 쫄면야채무침 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 청국장찌개  황태양념구이 (황태:러시아산) 고기...</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 쇠고기무국  주꾸미볶음  부추전  시금치나물  ...</td>\n",
              "      <td>미니김밥*겨자장 (쌀,현미흑미:국내산) 우동  멕시칸샐러드  군고구마  무피클  포...</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 떡국  돈육씨앗강정 (돼지고기:국내산) 우엉잡채...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 차돌박이찌개 (쇠고기:호주산) 닭갈비 (닭고기:...</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 시래기국  훈제오리구이  도토리묵무침  쌈무/양...</td>\n",
              "      <td>참치회덮밥 (쌀,현미흑미:국내산) 맑은국  군만두  과일샐러드  락교  포기김치 (...</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>0.147251</td>\n",
              "      <td>0.054979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160323</td>\n",
              "      <td>0.797770</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 꽃게탕  돈육굴소스볶음  옥수수전  유채나물  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀,현미흑미:국내산) 김치콩나물국  미니함박  어묵볶음  물파래무침 ...</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>0.149558</td>\n",
              "      <td>0.059977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.790465</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 시금치국  닭감자조림 (닭고기:국내산) 연두부*양념장  ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 홍합미역국  등갈비김치찜 (돼지고기,김치:국내산) 임연수...</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>0.033449</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185313</td>\n",
              "      <td>0.888120</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 쇠고기무국 (쇠고기:호주산) 탕수어 (동태:러시아산) 오...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 된장찌개  쇠불고기 (쇠고기:호주산) 해파리겨자채  봄동...</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.090734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.202230</td>\n",
              "      <td>0.881584</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...</td>\n",
              "      <td>쌀밥/잡곡밥 (쌀:국내산) 냉이된장국  쇠고기장조림 (쇠고기:호주산) 통도라지구이 ...</td>\n",
              "      <td>볶음밥*자장소스 (쌀:국내산) 맑은국  새우또띠아  쨔샤이무침  요플레  포기김치 ...</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.096117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008843</td>\n",
              "      <td>0.873895</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                조식메뉴  ... dayofweek\n",
              "0  모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐...  ...         0\n",
              "1  모닝롤/단호박샌드  우유/두유/주스 계란후라이  팥죽/쌀밥 (쌀:국내산) 호박젓국찌...  ...         1\n",
              "2  모닝롤/베이글  우유/두유/주스 계란후라이  표고버섯죽/쌀밥 (쌀:국내산) 콩나물국...  ...         2\n",
              "3  모닝롤/토마토샌드  우유/두유/주스 계란후라이  닭죽/쌀밥 (쌀,닭:국내산) 근대국...  ...         3\n",
              "4  모닝롤/와플  우유/두유/주스 계란후라이  쇠고기죽/쌀밥 (쌀:국내산) 재첩국  방...  ...         4\n",
              "5  팬케익/찐빵  우유/두유/주스  계란후라이  견과류죽/쌀밥 (쌀:국내산) 감자찌개 ...  ...         3\n",
              "6  모닝롤/야채샌드  우유/두유/주스  계란후라이  고구마죽/쌀밥 (쌀:국내산) 봄동된...  ...         4\n",
              "7  모닝롤/치즈프레즐  우유/두유/주스  계란후라이  잣죽/쌀밥 (쌀:국내산) 민물새우...  ...         0\n",
              "8  모닝롤/마늘빵  우유/두유/주스  계란후라이  단호박죽/쌀밥 (쌀:국내산) 어묵국 ...  ...         1\n",
              "9  모닝롤/참치샌드  우유/두유/주스  계란후라이  흑임자죽/쌀밥 (쌀:국내산) 북어계...  ...         2\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "fDMBD9vNzrmU",
        "outputId": "bc80b2e9-3873-4233-f5b9-221b8f5a3f1f"
      },
      "source": [
        "f, ax = plt.subplots(1, 2,figsize=(10,6))\n",
        "ax[0].hist(all_df['중식계'], bins=100)\n",
        "ax[0].set_title('Lunch')\n",
        "ax[1].hist(all_df['석식계'], bins=100)\n",
        "ax[1].set_title('Dinner')\n",
        "plt.show()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "S4arTTbM--GL",
        "outputId": "165dc7b6-a8ed-4628-a4f5-78489886d798"
      },
      "source": [
        "regex = '\\*.*'\n",
        "re.sub(regex, '', '마늘*새우젓')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'마늘'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkp67IZOwBOu"
      },
      "source": [
        "def split_process(x):\n",
        "    regex = '\\*.*|\\((.*?)\\)|[+%><]|\\&.*' \n",
        "    x_ = []\n",
        "    x = x.split(' ')\n",
        "    for i in x:\n",
        "        if '(' in i or ':' in i or ')' in i:\n",
        "            continue\n",
        "        if '/' in i:\n",
        "            x_.extend(i.split('/'))\n",
        "        elif ',' in i:\n",
        "            x_.extend(i.split(','))\n",
        "        elif '-' in i:\n",
        "            x_.extend(i.split('-'))\n",
        "        else:\n",
        "            x_.append(re.sub(regex, '', i))\n",
        "        \n",
        "    x_ = list(set(x_)) # 가끔 중복되는 메뉴 제거(계란후라이가 두번 들어있는 식단도 있음)\n",
        "    x_.remove('')\n",
        "    return x_\n",
        "\n",
        "breakfast_list = []\n",
        "lunch_list = []\n",
        "dinner_list = []\n",
        "\n",
        "breakfast_list += all_df['조식메뉴'].apply(lambda x: split_process(x)).to_list()\n",
        "lunch_list += all_df['중식메뉴'].apply(lambda x: split_process(x)).to_list()\n",
        "dinner_list += all_df['석식메뉴'].apply(lambda x: split_process(x)).to_list()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDTZW_YEGaJs",
        "outputId": "ef53127a-70a5-49a2-d63c-dbf1fa544231"
      },
      "source": [
        "print(all_df['조식메뉴'][0])\n",
        "print(breakfast_list[0])\n",
        "print(all_df['석식메뉴'][1])\n",
        "print(dinner_list[1])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "모닝롤/찐빵  우유/두유/주스 계란후라이  호두죽/쌀밥 (쌀:국내산) 된장찌개  쥐어채무침  포기김치 (배추,고추가루:국내산) \n",
            "['계란후라이', '된장찌개', '포기김치', '우유', '주스', '모닝롤', '쌀밥', '두유', '쥐어채무침', '찐빵', '호두죽']\n",
            "콩나물밥*양념장 (쌀,현미흑미:국내산) 어묵국  유산슬 (쇠고기:호주산) 아삭고추무침  바나나  포기김치 (배추,고추가루:국내산) \n",
            "['아삭고추무침', '바나나', '포기김치', '어묵국', '콩나물밥', '유산슬']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhH6XUDmwkSt",
        "outputId": "4a973fdd-3211-408c-db6b-2520f45f02a4"
      },
      "source": [
        "def make_set(list):\n",
        "    menu_set = set()\n",
        "    for row in list:\n",
        "        menu_set.update(row)\n",
        "    return menu_set\n",
        "\n",
        "breakfast_set = make_set(breakfast_list)\n",
        "lunch_set = make_set(lunch_list)\n",
        "dinner_set = make_set(dinner_list)\n",
        "\n",
        "# 조중석식 메뉴 중복 제거 리스트\n",
        "print(breakfast_set)\n",
        "print(lunch_set)\n",
        "print(dinner_set)\n",
        "\n",
        "# 조중석식 메뉴 개수\n",
        "print(len(breakfast_set), len(breakfast_set), len(breakfast_set))\n",
        "# 겹치는 메뉴 개수\n",
        "print(len(breakfast_set & lunch_set & dinner_set))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'열무김치', '배추맑은국', '매생이떡국', '아귀채무침', '팥죽', '쑥갓나물', '배추시래기국', '사골우거지국', '어묵고추장무침', '매운감자양파국', '고르곤졸라', '진미채무침', '사과오이초무침', '소고기채소죽', '스크램블에그', '유부김치국', '구운어묵볶음', '북어채국', '모듬묵샐러드', '우엉땅콩조림', '흑미밥', '카스테라', '도라지나물', '맑은버섯국', '콩나물국', '바나나시나몬토스트', '우거지해장국', '순두부탕', '브로컬리두부무침', '연유후레쉬', '갈릭파이', '냉이바지락국', '맑은만두육개장', '모시조개시금치국', '모둠사태조림', '들깨시래기국', '파운드케익', '두부김칫국', '해물동그랑땡전', '토마토샌드', '김치죽', '오렌지빵', '올갱이아욱국', '호박맑은국', '연두부찌개', '에그맥모닝', '두부브로컬리무침', '참치채소죽', '미역죽', '비름나물', '깻잎순나물볶음', '대구매운탕', '두부구이', '피자샌드', '어묵토마토조림', '무채나물', '느타리버섯국', '크림누룽지탕', '김치황태국', '비엔나채소볶음', '쇠고기샤브국', '느타리버섯볶음', '삶은계란', '블루베리프렌치토스트', '들깨감자국', '컵케익', '생크림단팥빵', '대만식연유샌드위치', '인기가요샌드', '피바지락배추국', '절편', '양념깻잎지', '참나물땅콩무침', '양상추샐러드', '매콤사태찜', '베이컨숙주볶음', '매운버섯국', '멸치크랜베리볶음', '게살모닝샌드위치', '감자고추장찌개', '바지락콩나물국', '토스트', '곤약어묵볶음', '120명', '미나리나물', '채소새우죽', '블루베리사과샌드', '콩나물간장조림', '순두부국', '달래된장찌개', '영양닭죽', '비엔나구이', '두부젓국찌개', '고구마죽', '베이글', '쇠고기무국', '소고기죽', '생깻잎지', '브로콜리감자볶음', '크림롤케익', '꽁치김치조림', '멸치고추장볶음', '삼겹살김치볶음', '크림치즈와플', '모닝사라다빵', '브로콜리맛살볶음', '김가루잔파무침', '들깨버섯국', '샐러드', '순두부된장국', '감자조림', '도라지생채', '취나물된장무침', '피자빵', '메추리알곤약조림', '오이보트샐러드', '아욱국', '매운어묵국', '우렁살된장국', '오색떡국', '마계토스트', '참치야채죽', '브로컬리들깨찜', '두부양념찜', '청포묵무침', '시금치국', '어묵볶음', '크래미미역줄기볶음', '조각케익', '시금치팬케익', '취나물볶음', '미역줄기볶음', '수제동그랑땡전', '브로컬리된장무침', '오이맛살냉채', '지리멸치볶음', '동태찌개', '황태두부국', '단호박죽', '머핀', '증편', '해물죽', '애호박건새우볶음', '토란국', '미역나물', '찐빵', '가지양파나물', '커피', '미니새송이볶음', '맑은조개탕', '톳무침', '사골파국', '쪽파숙회', '버섯들깨탕', '마늘종호두조림', '대추채멸치볶음', '햄치즈샌드위치', '와플&생크림', '청양콩나물국', '건파래볶음', '모둠묵', '고기완자전', '콩비지찌개', '베이컨샌드위치', '단호박피자빵', '인절미토스트', '우엉간장조림', '참치김치찌개', '명엽체고추장볶음', '김치콩나물국', '모닝에그빵', '미역레몬초무침', '떡국', '배추국', '팥호빵', '브로컬리들깨무침', '땅콩죽', '참나물두부샐러드', '봄동나물', '에그타르트', '콩자반', '새송이버섯곤약장조림', '카스텔라', '애호박볶음', '호박숙', '마늘쫑새우볶음', '마늘바게트', '사과샌드위치', '팬케익', '수박', '감자햄볶음', '콩나물해장국', '알탕', '가지양파무침', '베이컨치즈베이글', '건파래무침', '후르츠팬케익', '두부조림', '시금치나물', '햄야채볶음', '해물완자전', '진미채볶음', '호빵', '들깨무채국', '베이컨숙주굴소스볶음', '건새우아욱국', '에그샌드', '비타민샐러드', '사과베이비샐러드', '얼갈이국', '냉이된장국', '옥수수스프', '파게트', '고들빼기무침', '콩가루배추국', '계란찜', '땅콩샌드', '해물순두부찌개', '마늘쫑햄볶음', '열무된장나물', '참나물생채', '느타리애호박볶음', '브로컬리초장', '섭산적구이', '단호박찐빵', '감자채피망볶음', '맑은순두부국', '무생채', '애호박나물', '바나나팬케익', '상추양념장', '홍합죽', '버섯햄볶음', '오이생채', '어묵꽈리고추볶음', '꽈리고추멸치볶음', 'BLT샌드위치', '핫도그', '비트무생채', '멸치아몬드볶음', '콩나물오징어국', '아귀지리', '호박채나물', '크로아상샌드위치', '유부김칫국', '두부동그랑땡', '대만샌드위치', '가지두반장볶음', '참치죽', '우엉조림', '호박새우젓찌개', '고구마순나물', '도토리묵무침', '우유', '홍루이젠', '바나나베이비샐러드', '크래미숙주무침', '시래기조림', '연두부국', '김자반', '홍합살미역국', '브라우니', '김치순두부찌개', '콩죽', '배추된장국', '조랭이미역국', '촉촉한치즈케익', '북어계란국', '파래무침', '시금치두부무침', '피자토스트', '아삭고추무침', '북어국', '자반김', '숙주미나리나물', '황태채국', '메추리알조림', '명엽채볶음', '에그갈릭토스트', '단배추나물', '크로와상', '프레즐', '남친샌드위치', '마늘종숙회', '해물땡굴소스볶음', '모듬묵', '쇠고기매운국', '애호박새우젓볶음', '동전문어조림', '근대된장국', '참치샌드', '참나물무침', '포기김치', '감자양파국', '통마늘너비아니조림', '사과잼쿠키', '길거리토스트', '머위대나물', '새우살미역국', '홍초콩나물국', '얼갈이된장국', '무비트생채', '게살채소죽', '가자미양념찜', '양송이죽', '꽃게된장찌개', '어묵국', '김실파무침', '새우완자국', '시금치프리타타', '연두부', '핫케이크', '두부고기조림', '피홍합탕', '땅콩멸치볶음', '매생이굴국', '시래기나물', '두부양념조림', '견과류죽', '토란탕', '애플파이', '참나물', '우엉채조림', '감자샌드', '카레감자볶음', '사과롤케익', '오이맛살볶음', '두부쑥갓무침', '새알미역국', '토마토샐러드', '양배추샐러드', '겨울초나물', '초코핫케익', '마늘쫑무침', '치즈베이글', '치즈볼', '검정콩조림', '깍두기', '아메리카노', '베이컨에그슬럿', '쥐어채무침', '브로컬리무침', '햄에그샌드', '치즈프레즐', '북어해장국', '조랭이떡국', '계란빵', '새알만두국', '아삭고추된장무침', '커피콩빵', '참나물땅콩가루무침', '두유', '쇠고기해장국', '섭산적조림', '열무된장국', '멸치호두볶음', '배추겉절이', '알타리김치', '마늘쫑건새우볶음', '봄동겉절이', '계란장조림', '페스츄리', '어묵고추장볶음', '모둠장조림', '동전쥐포무침', '느타리팽이볶음', '샌드위치', '동초나물무침', '버섯비엔나조림', '소고기국', '찐계란', '호박고구마오븐구이', '고르곤졸라피자', '동태탕', '누룽지탕', '구이김', '단호박크림스프', '오렌지케익빵', '시금치된장국', '건새우무국', '닭살해장국', '두부김치국', '매콤부들어묵볶음', '건새우무조림', '병아리', '버섯들깨죽', '방울토마토', '김잔파무침', '땅콩아몬드조림', '새송이버섯볶음', '치즈팡샌드', '비엔나곤약조림', '땅콩조림', '베이컨샌드', '냉이국', '소고기미역국', '고구마샌드', '감자국', '새우완자전', '브로컬리들깨소스', '쌀밥', '버섯매운탕', '크루통크림스프', '수삼닭죽', '두부새우젓국', '미나리숙주무침', '매운사태조림', '토마토리코타치즈샐러드', '홍합살무국', '황태해장국', '청경채무침', '맑은연두부탕', '메론롤케익', '에그포테이토샌드위치', '알감자조림', '자반무침', '애호박나물볶음', '야채모닝샌드', '옛날소시지전', '돈육장조림', '소라살죽', '콘스프', '사각어묵볶음', '진미채간장조림', '연근조림', '야채소시지전', '양념깻잎지찜', '군대리아', '주스', '모닝롤', '햄에그샌드위치', '쇠고기버섯국', 'BLT샌드', '들기름무채볶음', '옹심이만두국', '오징어국', '보리누룽지탕', '낙지김치죽', '바나나팬케이크', '과일샐러드', '모닝샌드', '깻순나물', '칠리소스두부브로컬리볶음', '실곤약흑임자무침', '크랜베리멸치볶음', '민물새우찌개', '순두부백탕', '소보로빵', '시금치나물무침', '딤섬', '치커리무침', '모닝샌드위치', '햄야채샌드', '황태국', '바지락죽', '마늘쫑메추리알장조림', '모카카스테라', '두부들깨탕', '홍합탕', '롤케이크', '녹차호떡', '호밧젓국찌개', '콩나물된장국', '대구탕', '구구마순나물', '쇠고기마늘죽', '유채된장무침', '크렌베리멸치볶음', '새알팥죽', '오이사과무침', '흑미쌀찐빵', '치커리사과무침', '참치야채', '두부계란전', '양념깻잎찜', '호떡맥모닝', '콩가루된장국', '아귀지리탕', '김구이', '연두부샐러드', '페퍼로니피자', '근대감자국', '감자채햄볶음', '옹심이국', '고구마순볶음', '조갯살근대국', '치커리오이무침', '그린샐러드', '마늘빵', '오징어콩나물국', '맑은만두국', '아오리사과', '바지락무국', '비엘티샌드위치', '고구마파이', '햄에그치즈토스트', '고구마오븐구이', '명엽채고추장볶음', '계란후라이', '야채샌드위치', '채소죽', '두반장가지볶음', '오곡죽', '얼갈이나물', '시래기지짐', '두부떡국', '크로와상샌드위치', '감자맛살볶음', '오이무침', '삼색샌드위치', '쇠고기꽈리고추장조림', '바나나샌드', '콩가루배춧국', '고추장찌개', '감자찌개', '도토리묵', '전주식콩나물국해장국', '콩나물김치국', '시금치핫케익', '영양부추생채', '호박새우젓국', '마늘쫑볶음', '꽃게탕', '우거지올갱이국', '매운감자조림', '롤케익', '스크램블', '닭곰탕', '땅콩크림빵', '녹차카스테라', '고사리들깨나물', '새우살죽', '순두부찌개', '조랭이떡미역국', '대구찌개', '후르츠산도', '야채햄샌드', '인절미샌드', '시래기국', '맑은콩나물국', '얼큰낙지죽', '크림치즈프레즐', '브로콜리스프', '시금치죽', '베이컨맥모닝', '야채호빵', '치커리유자무침', '게살모닝샌드', '브리또', '프렌치토스트', '맑은꽃게탕', '열무나물', '카레감자채볶음', '호박채볶음', '단팥빵', '잣죽', '건포도머핀', '시금치샐러드', '미역국', '새송이볶음', '참치채소볶음', '닭죽', '취나물무침', '연근땅콩조림', '해초무침', '쑥갓무침', '마늘쫑맛살볶음', '깨찰빵', '버섯맑은국', '두부양념구이', '대구지리탕', '취나물', '버섯국', '단팥죽', '매운소고기국', '고사리들깨볶음', '시금치고추장국', '김칫국', '닭개장', '북엇국', '바나나', '캔꽁치무조림', '비엔나브로콜리볶음', '옹심이만둣국', '도라지볶음', '버섯굴죽', '오징어무국', '쥐포무침', '새우살야채죽', '연근호두조림', '더덕무침', '참치새드', '애플샌드', '쿠키', '미역소고기죽', '바지락살국', '사각어묵무침', '마샐러드', '사과파이', '메론빵', '스콘', '토마토', '새송이조림', '호박나물', '흑임자죽', '북어콩나물국', '멸치볶음', '방울양배추베이컨볶음', '돈사태찜', '무청된장국', '쑥갓겉절이', '촉촉한치즈빵', '오이도라지무침', '카야잼샌드', '허니브레드', '가지볶음', '노각무침', '옥수수샌드', '대구지리', '아욱된장국', '방풍나물무침', '꽃맛살볶음', '콩나물김칫국', '애호박새우젓국', '어묵탕', '치즈케익', '문어꽈리초조림', '흑미두부죽', '감자스프', '시래기된장국', '유부장국', '얼갈이겉절이', '김가루실파무침', '크로와상샌드', '사과', '버섯죽', '올챙이만두국', '꽃게된장국', '스태프핫도그', '블루베리크림치즈베이글', '오징어젓갈무침', '우거지국', '감자된장찌개', '에그단호박샌드', '밤죽', '연두부탕', '통아몬드멸치볶음', '돈육마늘장조림', '김치어묵국', '가지쇠고기볶음', '야채죽', '어묵매운국', '치아바타샌드', '몽골식돈육볶음', '브로컬리', '숙주나물무침', '베이비샐러드', '매생이국', '새송이버섯죽', '느타리버섯장조림', '바지락쑥국', '호박죽', '쑥국', '골뱅이무침', '콩조림', '소시지감자볶음', '마늘쫑건새우무침', '호박볶음', '섭산적채소조림', '시나몬페스츄리', '누룽지', '무나물', '앙버터모닝빵', '꿀호떡', '겨울초겉절이', '크래미샌드', '된장찌개', '봄동된장국', '스팸구이', '버섯볶음', '볼어묵조림', '건새우무채국', '핫케익', '브로컬리죽', '근대국', '멸치캐슈넛볶음', '소시지볶음', '깻잎순볶음', '스틱치즈케익', '라즈베리빵', '단배추들깨무침', '베이컨감자볶음', '느타리볶음', '느타리호박볶음', '차돌박이찌개', '건새우마늘쫑볶음', '맑은버섯육개장', '동태매운탕', '케익', '비엔나야채볶음', '식빵피자', '북어무우국', '리코타치즈샐러드', '토마토샌드위치', '숙주나물', '새송이죽', '근대나물무침', '콩나물무침', '멸치마늘종볶음', '고구마스프', '시금치초무침', '녹두죽', '가지나물', '감자채볶음', '호박잎찌개', '바지락국', '재래김', '햄치즈샌드', '물파래무침', '소고기스프', '미니햄버거', '게살죽', '소고기무우국', '북어맑은국', '생크림와플', '낙지죽', '순두부계란국', '피바지락국', '불고기브리또', '꽈리고추찜', '유채나물무침', '머위나물무침', '톳두부무침', '연유버터베이글', '소보루빵', '유채나물', '볼어묵볶음', '치커리유자청무침', '양념김', '소고기샤브국', '민물새우찌깨', '아귀매운탕', '수제어묵볶음', '홍게살죽', '들깨미역국', '명엽채무침', '씨크립샌드', '단호박샌드', '멸치고추장무침', '곰피초장', '얼큰소고기국', '호떡', '늙은호박죽', '달래오이무침', '소고기무국', '딸기파이', '김치두부국', '표고버섯죽', '쇠고기미역국', '김치국', '양송이스프', '키위드레싱샐러드', '구운계란', '김치도토리묵무침', '분홍소세지구이', '호두죽', '누룽지탕죽', '방풍나물', '애플잼쿠키', '매운감자국', '쇠고기우거지국', '시래기들깨탕', '재첩국', '옹심이만두떡국', '참치모닝샌드', '보코치니샐러드', '부추김무침', '죽순버섯볶음', '파래김', '고구마줄기볶음', '만두국', '호박젓국찌개', '우엉어묵볶음', '콥샐러드', '참치김치볶음', '차돌박이된장찌개', '무채국', '새우야채죽', '쇠고기죽', '미니케익', '비엔나소세지볶음', '맑은감자국', '야채샌드', '살라미샌드위치', '매운콩나물국', '트위스터버거', '수제비국', '치킨샌드', '버섯매운국', '크로크무슈', '호박된장국', '선지해장국', '쑥갓두부무침', '와플', '마약토스트'}\n",
            "{'미역초무침', '감자샐러드', '돈육고추장불고기', '참나물생채무침', '볼어묵굴소스볶음', '미트볼케찹조림', '미니우동', '고추', '모듬묵샐러드', '치킨샐러드', '주꾸미야채무침', '비엔나볶음', '도라지나물', '찹쌀밥', '도토리묵야채무침', '미니핫도그', '도라지나물볶음', '우거지해장국', '깻잎무쌈', '훈제오리냉채', '깐풍육', '새싹샐러드', '마파두부덮밥', '스프링롤', '탱크보이', '김치전', '청경채나물', '비엔나채소볶음', '돈육떡강정', '콩나물제육볶음', '돈수육', '닭볶음', '양념깻잎지', '닭살카레라이스', '어묵매운탕', '양상추샐러드', '건새우미역국', '나가사끼짬뽕국', '매운버섯국', '스위트칠리미트볼', '감자고추장찌개', '감자치즈구이', '두릅소고기샐러드', '쇠고기낙지볶음', '왕갈비탕', '삼겹살김치볶음', '달래된장국', '단호박물김치', '양장피', '꽃게찌개', '프로바이오틱', '얼갈이된장무침', '시금치고추장나물', '계란파국', '물만두국', '어묵볶음', '조각케익', '소세지피망볶음', '올방개묵무침', '동태찌개', '만두탕수육', '물파래전', '찐햇감자', '연어스테이크', '브로콜리땅콩소스무침', '메밀전', '버섯들깨탕', '비엔나감자볶음', '오향장육', '해물수제비국', '귤', '곤약야채무침', '단호박카레라이스', '쑥된장국', '레몬유린기', '꽈배기도넛', '해물잡채', '감자비엔나볶음', '콩가루배추된장국', '파닭', '명란계란말이', '파인애플', '파프리카감자채볶음', '꼬시래기무초무침', '오이달래무침', '블랙페퍼쉬림프', '적어구이', '누룽지탕수육', '간장두부조림', '한방소갈비찜', '오징어초무침', '간장파닭', '얼갈이국', '메밀부추전', '김치볶음밥', '청경채사과생채', '모둠양채쌈', '풋마늘대무침', '브로컬리초장', '구운채소', '김치빈대떡', '오이지무침', '돈육잡채', '닭양념조림', '돈육버섯고추장덮밥', '애호박나물', '고춧잎볶음', '수제삼색무쌈', '김치제육볶음', '오이나물볶음', '히레카츠', '머위된장나물', '맑은떡국', '꽁치구이', '조갯살아욱국', '아귀콩나물찜', '참치야채샐러드', '매실짱아찌', '망고푸딩', '메추리알짜장떡볶이', '닭다리살스테이크', '부추만두', '봉추찜닭', '매생이전', '생강채*쌈장', '고추지', '북어계란국', '북어국', '메추리알조림', '간장마늘치킨', '삼색묵무침', '꽁치레몬구이', '삼치된장구이', '포기김치', '사과고구마그라탕', '비엔나케찹조림', '참치야채전', '꽃게된장찌개', '궁중떡볶음', '시금치프리타타', '연두부', '땅콩멸치볶음', '시래기나물', '토란탕', '모듬채소', '상추파무침', '오꼬노미계란말이', '유채나물된장무침', '배즙', '펜네파스타샐러드', '물만두', '마늘*새우젓', '치즈함박스테이크', '토마토샐러드', '안동찜닭', '쭈삼불고기', '오이냉국', '나물비빔밥', '열대과일', '돈육고추장볶음', '닭데리야끼조림', '오미자주스', '참나물땅콩가루무침', '햇고구마오븐구이', '가자미무조림', '열무된장국', '청량된장찌개', '알타리김치', '보름나물', '오렌지', '고등어김치말이찜', '요거트푸딩', '쇠고기모듬장조림', '동초나물무침', '상추파채무침', '두부스테이크', '표고돈육탕수', '구이김', '호박부추전', '시금치된장국', '치즈닭갈비', '감자채카레볶음', '두릅새송이초무침', '콩나물냉국', '수수부꾸미', '와사비무쌈*쌈장', '방울토마토', '미소시루', '어묵꽈리고추조림', '무쌈', '꽃맛살햄볶음', '차돌된장찌개', '쭈꾸미삼겹살볶음', '파프리카해초무침', '우묵냉국', '맛살겨자초무침', '깍둑오이초무침', '갈치양념조림', '홍합살무국', '청경채무침', '코다리조림', '곰취', '스팸계란전', '상추부추생채', '도라지오이무침', '매운쇠고기국', '사각어묵볶음', '곤약메추리알조림', '녹두김치전', '버섯초장무침', '코다리양념조림', '토마토스크램블', '닭다리바베큐오븐구이', '훈제오리단호박볶음', '녹두전', '부추고추장무침', '콩나물맑은국', '매콤낙지볶음', '깻순나물', '고등어김치말이', '실곤약흑임자무침', '찰떡떡갈비조림', '돼지김치찌개', '순두부백탕', '오징어야채무침', '치커리무침', '수제석박지', '호박전', '마파무조림', '홍합탕', '청양부추전', '검은깨올방개묵무침', '홍어미나리초무침', '치커리만다린샐러드', '냉모밀국수', '치자밥', '매운콩나물무침', '쫄면채소무침', '장어강정', '삼겹살김치찜', '모듬장조림', '두부계란전', '크림새우', '김구이', '들깨버섯탕', '참나물두부무침', '옹심이국', '새싹두부구이', '짜장소스', '신김치도토리묵', '소불고기', '양상추*쌈장', '강된장찌개', '계란후라이', '간장찜닭', '시래기지짐', '팽이장국', '군고구마', '콩나물김치국', '깐풍두부', '고추잡채', '개성감자만두', '콩나물잡채', '콩나물불고기', '통계란꼬치어묵탕', '목살스테이크', '맑은콩나물국', '돈육칠리강정', '버섯불고기', '강된장', '오이도라지생채', '푸딩', '오꼬노미야끼계란말이', '사과맛살초무침', '해물김치전', '모둠버섯구이', '치커리유자무침', '계란', '깻잎*쌈장', '열무나물', '비엔나컬리플라워조림', '요플레', '미역국', '굴미역국', '취나물무침', '연근땅콩조림', '매운쇠고기버섯볶음', '양파짱아찌', '돼지간장불고기', '곤약흑임자무침', '애기새송이버섯볶음', '동태전', '대구지리탕', '취나물', '버섯국', '냉이된장찌개', '오이소박이', '마늘', '매운소고기국', '동태무조림', '동파육', '바지락냉이국', '닭개장', '도라지볶음', '떡갈비조림', '상추무침', '깻잎완자전', '순살깐풍기', '수제돈까스', '열무보리비빔밥', '돈갈비찜', '해물겨자냉채', '깻잎지', '감자채파프리카볶음', '황태양념구이', '비빔메밀국수', '호박나물', '해물섞어찜', '봄동된장무침', '우엉잡채', '멸치볶음', '가지찜', '애호박전', '오이도라지무침', '찰보리밥', '크루통샐러드', '가자미튀김', '꽃맛살볶음', '돈사태김치찜', '콩나물김칫국', '돈육보쌈', '찐옥수수', '부추겉절이', '삼겹살더덕고추장구이', '김말이강정', '모히토과일샐러드', '꼬막미나리초무침', '오이미역냉국', '팽이된장국', '수육', '양념두부조림', '오징어브로컬리숙회', '타코야끼', '버섯잡채', '단호박장조림', '햄계란말이', '돈육씨앗강정', '모듬소시지구이', '김치고기전', '닭오븐구이', '두부새싹구이', '꿀호떡', '명태엿장조림', '소고기매운무국', '우무묵냉국', '너비아니구이', '꽁치오븐구이', '토마토계란볶음', '후르츠탕수육', '비름나물고추장무침', '근대국', '어묵꽈리볶음', '감자볶음', '강낭콩밥', '베이컨감자볶음', '동태매운탕', '보쌈', '부추고추전', '배도라지주스', '볶음김치', '요거트드링킹', '치킨핑거', '호박잎찌개', '쇠불고기', '콩나물겨자채', '명태조림', '양념찜닭', '과일그라탕', '야채비빔만두', '매운돼지갈비찜', '짜장닭볶음', '버섯숙회*초장', '완자전', '유자청제육볶음', '얼큰소고기국', '검정콩밥', '순대볶음', '감자채전', '버섯들깨국', '옹심이만두떡국', '한식잡채', '가지나물무침', '삼색만두채소무침', '콩나물부추무침', '콥샐러드', '영양모듬견과', '채소계란말이', '골뱅이야채무침', '부추샐러드', '무채국', '수떡수떡화채', '쑥갓쌈&쌈장', '수제비국', '오리불고기', '쌈추겉절이', '비타민흑임자샐러드', '인절미', '순대국밥', '쑥갓나물', '사골우거지국', '부추양파무침', '오지치즈후라이', '오징어', '류산슬', '상추*쌈장', '사과오이초무침', '콘슬로우', '하와이언함박스테이크', '장각허브오븐구이', '맛살계란말이', '비빔냉면', '고추장고구마순무침', '삼겹보쌈', '깻잎통닭', '꽈리고추찹쌀무침', '온두부', '돈육두루치기', '당면채소무침', '쇠고기단호박조림', '모듬야채쌈', '솎음열무나물', '청경채생채', '꽃상추겉절이', '칠리새우', '알리오올리오파스타', '라면땅', '수제과일잼샌드', '명이나물-장아찌', '새송이*가지구이', '감자고구마샐러드', '미니함박조림', '치커리들깨무침', '대구매운탕', '두부구이', '베추겉절이', '브로콜리버섯볶음', '느타리버섯볶음', '유부주머니국', '카레덮밥', '수제두부까스', '시리얼', '참나물땅콩무침', '사골우거지탕', '수제탕수육', '곤약어묵볶음', '미나리나물', '케일숙쌈*양념간장', '고등어카레구이', '굴김치두부국', '해물전', '옥수수계란찜', '꼬들빼기김치', '복숭아아이스티', '두부맛전', '들깨버섯국', '도라지생채', '배추깻잎', '아욱국', '파채상추무침', '브로컬리들깨찜', '모듬묵양념장', '매운소불고기', '기장밥', '콩나물파채절이', '새송이전', '오징어볶음', '오렌지자몽샐러드', '묵은지닭찜', '고추*쌈장', '황태포무침', '망고', '만두찜', '깻잎', '훈제오리', '진미채오이무침', '그린샐러드*키위D', '고추장불고기', '대패삼겹살볶음', '모둠묵', '콩비지찌개', '카레닭찜', '참치김치찌개', '미역레몬초무침', '미나리초장무침', '실곤약냉채', '마늘바게트', '돈육굴소스볶음', '닭볶음탕', '두부오꼬노미야끼', '얼갈이생채', '맑은계란국', '한방갈비탕', '건파래무침', '콩나물두루치기', '쌈추', '홍합국', '해물완자전', '청경채', '바지락살무국', '피클', '소고기당면국', '연근깨소스무침', '오이지냉국', '홍어채무침', '콩가루배추국', '쌈배추', '열무된장나물', '삼겹살오븐구이', '맑은순두부국', '무생채', '궁중떡볶이', '날치알계란찜', '두부참치조림', '갈치구이', '닭데리야끼구이', '해물동그랑땡채소볶음', '두부커틀렛', '우엉불고기', '돌나물무침', '반달호박나물', '홍어무침', '가지두반장볶음', '새송이너비아니구이', '아이스슈', '야채볶음밥', '락교', '고구마함박스테이크', '미소국', '베리베리샐러드', '견과류마카로니범벅', '매운쇠고기샤브샤브', '근대나물', '견과류조림', '삼계탕', '배추된장국', '황태채국', '청경채깨장나물', '초복특식', '아삭고추무침', '김치어묵탕', '소세지구이', '딸기드레싱샐러드', '청', '매콤소갈비찜', '꼬들단무지무침', '솎음열무나물무침', '치킨텐더샐러드', '매운동태찜', '맛살냉채', '간장돼지갈비찜', '새우살미역국', '소고기숙주볶음', '병아리콩', '무비트생채', '콩나물파채불고기', '참나물겉절이', '대패삽겹숙주볶음', '순살파닭', '코다리강정', '쇠고기장조림', '찰현미밥', '오삼불고기', 'LA갈비구이', '동태포전', '가자미엿장구이', '참나물', '가자미조림', '깻잎전', '치커리만다린무침', '양배추샐러드', '오프룻요거트', '팽이버섯국', '검정콩조림', '깍두기', '생야채', '다슬기아욱국', '쇠고기버섯볶음', '소세지오븐구이', '봄나물비빔밥', '크란치바', '요거트D', '유부채소겨자무침', '매운소고기낙지볶음', '갈비만두', '봄동겉절이', '해물부추전', '두부강정', '갈릭버섯탕수', '계란장조림', '고기전', '군만두', '팽이무국', '오징어브로컬리', '비빔밥', '소고기국', '매운주꾸미볶음', '버섯영양밥', '꼬시래기무침', '두부', '상추', '호박잎된장찌개', '마카로니샐러드', '치커리유자생채', '두부김치국', '돈육콩나물불고기', '청경채만다린생채', '치킨까스', '고구마고로케', '갈치조림', '소고기미역국', '수박화채', '돈육도라지고추장볶음', '쌀밥', '닭살겨자채', '비트무피클', '모듬소시지볶음', '브로콜리깨소스무침', '야채스틱', '연근유자피클', '파채콩나물무침', '매운어묵무침', '봄동달래무침', '떡잡채', '도라지오이생채', '꽈리고추감자조림', '무쌈말이', '돈육꽈리고추볶음', '호박잎', '계란국', '모닝샌드', '훈제오리마늘볶음', '새송이버섯조림', '콜리샐러드', '쫄면야채무침', '견과류멸치볶음', '모듬양채쌈', '파프리카계란말이', '전주식콩나물해장국', '모듬버섯볶음', '오징어링', '물미역', '콩나물밥', '미니버거', '오미산적', '두부까스', '골뱅이채소무침', '치커리오이무침', '수제돈가스', '불고기비빔밥', '메추리알떡볶이', '콩나물동태찜', '돼지고기유자청볶음', '버섯초무침', '고구마오븐구이', '얼갈이나물', '마늘쫑볶음', '꽃게탕', '가쯔오국', '도라지무침', '과일요거트샐러드', '오리대패불고기', '떡만두국', '상추초무침', '보쌈김치', '감자그라탕', '고추장감자조림', '시래기국', '쌈채소', '요거닭', '삼색꼬지전', '건다래순볶음', '닭찜', '도토리묵냉국', '모둠쌈', '계란채소볶음밥', '쨔샤이무침', '멕시칸샐러드', '부대찌개', '수제찹쌀꿔바로우', '모둠채소무침', '물미역초장', '쌈다시마초장', '영양부추무침', '단무지무침', '우묵콩국', '불고기덮밥', '오징어숙회무침', '쇠고기매운버섯국', '타워함박스테이크', '김칫국', '북엇국', '바나나', '브로콜리숙회', '파스타샐러드', '쇠고기두부찜', '고등어조림', '매콤해물볶음', '감자수제비국', '크레미계란말이', '콩나물냉채', '매운호박볶음', '유채겉절이', '식혜', '청국장찌개', '꼬지삼색전', '고추간장지', '멸치국수', '닭가슴살냉채', '깻잎순무침', '치커리생채', '더덕구이', '매콤함박스테이크', '전복장각삼계탕', '탕수육', '돈육간장불고기', '양파링카레튀김', '우동국', '닭매운찜', '춘권튀김', '얼갈이겉절이', '양배추', '꽃게된장국', '채소스틱&쌈장', '삼겹살수육', '삼겹살구이', '콩나물맛살냉채', '오리들깨탕', '해물탕', '단무지', '풋고추양파쌈장무침', '꽁치와사비구이', '숙주나물무침', '양파호박채나물', '눈꽃치즈샐러드', '콩조림', '버섯탕수', '냉메밀소바', '비엔나감자조림', '부추깻잎전', '꽈리고추어묵볶음', '모듬튀김', '비빔야채만두', '닭강정', '연근', '돈육김치볶음', '돌나물유자청무침', '차돌박이찌개', '건새우마늘쫑볶음', '사과즙', '통도라지고추장구이', '사과고구마그라탱', '치킨텐더', '버블샐러드', '데리야끼파닭', '부추호박전', '표고버섯탕수육', '수제함박스테이크', '오이무초무침', '청포묵', '톳두부무침', '치커리유자청무침', '양념김', '마파두부', '양장피잡채', '짜글이돼지찌개', '호박잎된장국', '마늘간장치킨', '계란말이', '쭈꾸미볶음', '단호박어묵탕수', '김치두부국', '쇠고기미역국', '김치국', '새송이버섯전', '바베큐폭립', '목살데리야끼', '방풍나물', '우무콩국', '소세지감자조림', '꽃맛살오리엔탈샐러드', '모둠버섯볶음', '야채고로케', '파래김', '유채나물겉절이', '숙주미나리무침', '고구마줄기볶음', '갈릭돈가스', '단무지락교무침', '소고기장조림', '감자만두', '매운콩나물국', '두부커틀릿', '단감', '명태코다리조림', '호박된장국', '쑥갓두부무침', '주꾸미세비체샐러드', '미나리초무침', '삼치구이', '열무김치', '파프리카잡채', '양파치킨', '수완왕갈비맛통닭', '옥수수밥', '할라피뇨채소피클', '수제보쌈김치', '나쵸콥샐러드', '미역오이냉국', '진미채무침', '유기농식혜', '언양식불고기', '고추지무침', '취나물쌈장무침', '훈제오리볶음', '흑미밥', '황태맑은국', '순두부탕', '브로컬리두부무침', '츄러스', '문어꽈리고추조림', '옥수수콘치즈구이', '쥬시쿨', '사과오이냉국', '오이스틱', '볶은김치', '호박맑은국', '고추장누들떡볶이', '쫑상추무침', '장각삼계탕', '불닭볶음', '후라이드', '삼치무조림', '쇠고기샤브국', '춘권', '닭갈비', '김치제육덮밥', '호두견과류강정', '닭다리튀김', '깐풍연근', '멸치크랜베리볶음', '등갈비김치말이', '꽃맛살과일샐러드', '묵은지닭볶음탕', '생깻잎지', '부추무침', '건강비빔밥', '비엔나컬리플라워볶음', '푸실리파스타샐러드', '와사비무쌈', '유린기', '가자미구이', '늙은호박전', '감자조림', '부들어묵볶음', '조기구이', '이벤트행사', '쫄면', '보리밥', '주꾸미떡볶음', '청포묵무침', '채소스틱', '고등어구이', '토마토프리타타', '해물파전', '실곤약무침', '소고기된장찌개', '오이양파무침', '소고기잡채', '매운계란파국', '오이', '토란국', '허니버터치킨', '장어구이', '양잡피잡채', '오이소배기', '홍시', '두부고기양념찜', '달래두부무침', '양념', '톳무침', '돼지고추장불고기', '무쌈채소말이', '우거지된장국', '양념파닭', '하와이안샐러드', '미나리오이무침', '머위된장무침', '떡국', '옥수수전', '겉절이김치', '고추튀김', '순남시래기국', '참치회덮밥', '수박', '호박채나물볶음', '알탕', '참나물상추겉절이', '장각백숙', '음료', '두부조림', '시금치나물', '햄감자채볶음', '메밀전병', '나쵸', '냉이나물무침', '단호박영양밥', '영양부추', '크래미해초무침', '옥수수스프', '토마토스파게티', '대패삼겹', '참나물생채', '미역장국', '송편', '주꾸미브로콜리숙회', '꽈리고추메추리알조림', '단호박범벅', '요구르트', '모둠소시지구이', '갈치감자조림', '해초샐러드', '오이생채', '꽈리고추멸치볶음', '오징어젓무침', '간장치킨', '멸치아몬드볶음', '살살치킨', '양념장', '청포도', '도토리묵무침', '고구마순나물', '제첩두부국', '갓김치', '목살찹스테이크', '시래기조림', '연두부국', '사천식탕수육', '홍합살미역국', '오므라이스', '콩나물파채', '쇠고기불고기', '만가닥버섯불고기', '돌나물초장무침', '명엽채볶음', '두부계란구이', '오렌지주스', '사과푸딩', '차돌박이구이', '모듬묵', '미소장국', '쇠고기매운국', '풋고추', '씨앗쌈장', '짜파치킨', '참나물무침', '갈비통통만두', '양배추쌈', '해물동그랑땡', '다시마쌈', '치즈불닭', '치즈계란찜', '귀리밥', '어묵국', '동파삼겹수육', '모듬어묵볶음', '어묵잡채', '만다린샐러드', '동그랑땡', '오복지무침', '콩나물볶음', '고기듬뿍카레라이스', '어묵고추장떡', '하루나겉절이', '매콤떡갈비조림', '쇠고기당면볶음', '꽁치김치말이찜', '콘치즈오븐구이', '육개장', '북어해장국', '조랭이떡국', '새알만두국', '김밥볶음밥', '아삭고추된장무침', '김치필라프', '홍삼', '마늘쫑건새우볶음', '오복지', '가래떡구이', '실곤약야채무침', '브로콜리쌈장무침', '어묵고추장볶음', '제육고추장불고기', '나쵸칩', '베이비크랩강정', '김말이튀김', '맛살겨자채', '유부주머니된장국', '총각김치', '새송이버섯볶음', '호박된장찌개', '땅콩조림', '물만둣국', '냉이국', '치킨무', '버섯매운탕', '씨리얼과일샐러드', '적포도', '낙지비빔밥', '가쯔오장국', '오리주물럭', '브로컬리맛살볶음', '가자미유린기', '풍기샐러드', '메추리알탕수', '버섯들깨찌개', '마카로니치즈범벅', '연근조림', '황도샐러드', '복숭아미역냉국', '산채비빔밥', '레몬미역초무침', '유부된장국', '소고기브로컬리볶음', '오징어국', '해파리냉채', '과일샐러드', '야채계란말이', '감자프리타타', '잡곡밥', '부추전', '오이사과무침', '매운닭찜', '춘천닭갈비', '생선가스', '가지완자튀김', '차돌박이숙주볶음', '머위나물', '수제고기육전', '봄새싹비빔밥', '호박잎쌈', '열무비빔밥', '닭간장조림', '순살양념치킨', '불낙찌개', '생선커틀릿', '옛날돈까스', '오징어튀김', '목살구이', '상추쑥갓생채', '채소프리타타', '돈간장불고기', '오이무침', '치킨커틀렛', '매콤볼어묵볶음', '콩가루배춧국', '삼색콜리', '치킨너겟', '세발나물무침', '갈릭순살치킨', '영양부추생채', '건새우호박채전', '잡채', '야채계란찜', '곤드레밥', '매콤어묵볶음', '삼색유자청무침', '무말랭이', '미트볼칠리조림', '견과류샐러드', '시저샐러드', '순살닭갈비', '아귀순살찜', '허니순살치킨', '연복풍덮밥', '요거트파르페', '웨지감자오븐구이', '오이사과생채', '꽃상추무침', '메밀전병만두', '오이볶음', '양파절임', '깻잎찜', '치커리유자샐러드', '제육미나리볶음', '계란버섯장조림', '오이맛살초무침', '등심돈까스', '닭살냉채', '쭈꾸미삼겹고추장볶음', '통오이고추무침', '조갯살무국', '더덕무침', '봄동전', '황태채마늘쫑무침', '비엔나케찹볶음', '사각어묵무침', '동그랑땡구이', '토마토', '천도복숭아', '사과나무주스', '꽈리고추어묵조림', '도라지초무침', '산고추지무침', '나주곰탕', '주꾸미볶음', '노각무침', '무채와사비무침', '아삭이고추된장무침', '가지무침', '아욱된장국', '임연수구이', '어묵탕', '오이미역무침', '두부된장찌개', '마시는요거트', '유부장국', '두부카프레제', '도라지오이초무침', '사과', '돈육피망볶음', '올챙이만두국', '더덕양념구이', '우거지국', '연두부탕', '돈육춘장볶음', '돈갈비양념구이', '오이사과냉국', '브로컬리', '돌나물', '모듬쌈', '골뱅이무침', '굴비구이', '전주비빔밥', '김치찌개', '봄동된장국', '완두콩밥', '오이쑥갓생채', '감자범벅', '건새우무채국', '맛살떡샐러드', '해물된장찌개', '바베큐장각오븐구이', '오징어찌개', '굴떡국', '가지고추장무침', '매운족발볶음', '맑은버섯육개장', '청양고추계란말이', '한방설렁탕', '콩나물무침', '가지나물', '콩샐러드', '탕수만두', '크림스프', '가자미카레튀김', '꽈리고추찜', '유채나물무침', '시금치초생채', '유산슬', '노각생채', '통들깨부추무침', '호박꼬지', '볼어묵볶음', '미니쌀국수', '소고기샤브국', '시금치고추장무침', '고구마범벅', '아삭고추쌈장무침', '들깨미역국', '소고기무국', '유부채소겨자냉채', '삼색물만두무침', '미니짬뽕', '사골떡국', '양배추채무침', '고구마튀김', '알배기', '참치김치볶음', '떡갈비', '미역미소시루', '들깨시락국', '미니케익', '비엔나피망볶음', '순살닭강정', '양념치킨', '해물굴소스볶음', '매실주스', '동태', '깻잎양념지', '돈나물유자청무침', '호박고추장찌개', '임연수찜', '양념돼지갈비찜', '쇠고기느타리국', '유니짜장밥', '축하떡', '북어채국', '열기어구이', '꽁치한마리구이', '더덕오이생채', '모듬소세지볶음', '콩나물국', '샐러드파스타', '수원왕갈비', '들깨시래기국', '훈제오리구이', '과일탕수육', '야채튀김', '카프레제샐러드', '올갱이아욱국', '상추겉절이', '모듬버섯구이', '시리얼샐러드', '낙지볶음', '단호박채소전', '비름나물', '닭살겨자냉채', '바질페스토스파게티', '들깨수제비', '궁중떡찜', '느타리버섯국', '고구마치즈구이', '백김치', '자몽에이드', '시금치고추장나물무침', '주꾸미초무침', '연어훈제샐러드', '오이초무침', '해물볶음우동', '삼치데리야끼', '버섯메추리알장조림', '봄동숙', '부추생채', '통감자오븐구이', '갈비탕', '쇠고기무국', '햄피망볶음', '청경채사과무침', '수제피클', '로스트치킨샐러드', '돈육볶음', '비름나물된장무침', '메추리알곤약조림', '소갈비찜', '매운어묵국', '석박지', '불미나리무침', '콘샐러드', '소고기숙주나물볶음', '해물청경채볶음', '김치우동', '레몬탕수육', '경상도식소고기국', '시금치국', '흑임자연근샐러드', '미역줄기볶음', '팥밥', '김치찐만두', '과일', '쪽파무침', '얼큰순두부찌개', '또띠아칩', '마카로니콘샐러드', '쇠고기볶음', '모둠소세지구이', '가자미엿장조림', '사과푸딩샐러드', '시금치부침개', '고기완자전', '동그랑땡부침', '팝콘치킨', '가래떡돼지갈비찜', '김치콩나물국', '배추국', '배추들깨국', '무피클', '모듬소세지구이', '돼지갈비찜', '봄동나물', '콩자반', '호박숙', '토마토두부카프레제', '고구마순무침', '오곡밥', '다시마', '크리스마스케익', '떡볶이', '콩나물파채무침', '두반장감자볶음', '들깨무채국', '건새우아욱국', '미트볼채소볶음', '상추쌈', '견과류연근조림', '실곤약초무침', '냉이된장국', '지중해샐러드', '계란찜', '해물순두부찌개', '매실음료', '순대채소볶음', '돈육간장강정', '비엔나떡조림', '치커리유자청생채', '브로콜리새송이메추리알조림', '해파리겨자채', '렌틸콩밥', '어묵꽈리고추볶음', '핫도그', '비트무생채', '함박스테이크', '호박채나물', '유부김칫국', '돈삼겹보쌈', '교촌간장치킨', '우엉조림', '닭가슴살장조림', '꼬지어묵탕', '크래미숙주무침', '생선까스', '세발나물생채', '양배추숙쌈', '대파육개장', '다시마쌈*씨앗쌈장', '단호박견과류구이', '쇠고기숙주볶음', '단호박', '짬뽕국', '단배추나물', '마늘종숙회', '근대된장국', '부럼', '감자양파국', '황태콩나물해장국', '건새우호박볶음', '머위대나물', '홍초콩나물국', '얼갈이된장국', '가자미양념찜', '냉이콩나물국', '머위대들깨볶음', '부추와사비무침', '두부양념조림', '셀프무쌈말이', '두부맑은국', '새알미역국', '달래무침', '청양된장찌개', '수수밥', '명태코다리강정', '마늘쫑무침', '쫄면무침', '쌈무', '브로컬리무침', '치커리사과생채', '미역미소시루국', '짬뽕불고기', '살구복숭아주스', '쇠고기해장국', '멸치호두볶음', '배추겉절이', '목살데리야끼구이', '단호박계란찜', '오꼬노미야끼', '생선커틀렛', '베이컨김치볶음밥', '개성식메밀부침개', '닭살데리야끼조림', '모둠장조림', '배추쌈', '타래과', '분홍소시지전', '매운쇠고기샤브샤브국', '소고기버섯볶음', '이연복의', '채소전', '탕평채', '꽁치한마리레몬구이', '동태탕', '비엔케찹볶음', '브로컬리오징어숙회', '건새우무국', '파김치', '치즈계란말이', '들깨버섯무침', '매콤콩나물국', '문어오이미역초무침', '바지락미역국', '감자국', '마늘치킨', '뼈없는감자탕', '감자전', '물미역초고추장무침', '새우튀김', '고구마그라탕', '임연수무조림', '돈육장조림', '새송이떡갈비구이', '매운소고기무국', '어묵간장조림', '동태알탕', '짜장덮밥', '쇠고기납작당면볶음', '옹심이만두국', '시금치무침', '수제오미산적', '바싹불고기', '민물새우찌개', '맛살콩나물냉채', '고사리육개장', '소고기콩나물밥', '떡밤초', '다시마*초장', '쌈', '황태국', '오리고추장볶음', '메밀버섯전', '비엔나간장볶음', '대구탕', '새알팥죽', '깐풍기', '닭감자조림', '차돌비빔국수', '부추팽이겉절이', '파인애플볶음밥', '해물까스', '치커리사과무침', '매콤돼지갈비찜', '쭈꾸미숙회무침', '수원왕갈비통닭', '고구마순볶음', '매운어묵볶음', '그린샐러드', '우렁된장찌개', '찹쌀호떡', '등갈비김치찜', '꽃맛살샐러드', '두반장가지볶음', '풋마늘초무침', '해파리무침', '고추장찌개', '새우까스', '도토리묵', '황태미역국', '탕수어', '콩나물겨자채무침', '갈치무조림', '돈육강정', '닭곰탕', '배추김치', '병아리콩밥', '맛살계란찜', '갈릭돈까스', '순두부찌개', '조랭이떡미역국', '알로에주스', '호박새우젓볶음', '대구찌개', '그린샐러드*오렌지드레싱', '탄두리치킨', '딸기푸딩', '해물누룽지탕', '동그랑땡전', '쇠고기잡채', '제육볶음', '인절미츄러스맛탕', '타꼬야끼', '오징어굴소스볶음', '칠리탕수육', '케일*우렁쌈장', '카레감자채볶음', '소고기불고기', '오리훈제고추장볶음', '세발나물', '시금치샐러드', '참치채소볶음', '해물돼지갈비찜', '유자청돈육볶음', '고구마치즈빵', '해초무침', '청포도주스', '미니채소떡갈비', '붕어빵', '꽁치김치말이', '오리양념불고기', '짜장밥', '자반고등어구이', '비엔나브로콜리볶음', '미역오이초무침', '옹심이만둣국', '매콤미니함박', '돈육김치찌개', '양배추피클', '또띠아피자', '삼겹살고추장구이', '낙지볶음밥', '마약계란장조림', '모듬묵흑임자샐러드', '골뱅이소면무침', '청경채겉절이', '가래떡츄러스', '북어콩나물국', '맑은국', '무청된장국', '가지볶음', '대구지리', '오징어돈육볶음', '방풍나물무침', '치커리사과유자청무침', '깻잎쌈', '명이절임', '청경채찜', '소고기낙지볶음', '시래기된장국', '잔치국수', '차조밥', '장어고추장양념구이', '통도라지구이', '미역무침', '매운돈갈비찜', '찜닭', '쑥국', '새우날치알볶음밥', '오이부추무침', '청경채새송이볶음', '무나물', '버섯구이', '명태양념조림', '건취나물볶음', '된장찌개', '버섯볶음', '김치볶음', '열무나물무침', '무말랭이무침', '꽁치캔김치조림', '아욱수제비국', '돈육간장볶음', '물미역무침', '카레라이스', '미트볼조림', '숙주나물', '시금치초무침', '맛탕', '감자채볶음', '물파래무침', '연두부찜', '맛살전', '고구마치즈돈까스', '아몬드멸치볶음', '카레닭볶음', '새우완자탕', '포도주스', '소고기떡국', '냉족발야채무침', '주꾸미굴소스볶음', '열무물국수', '적어양념장구이', '해물콩나물찜', '유채나물', '설렁탕', '츄러스채소맛탕', '두부계란부침', '모듬소세지버섯구이', '곰피초장', '쪽파국', '멸치크렌베리볶음', '콩비지김치찌개', '버섯메밀전', '시래기들깨탕', '간장깻잎지', '차돌박이된장찌개', '삼치양념구이', '고추잎나물', '짜요짜요', '오리고추장불고기', '육전', '훈제오리고추장볶음', '비빔메밀면', '소불고기덮밥', '알감자버터구이'}\n",
            "{'미역초무침', '감자샐러드', '단호박달걀찜', '새송이고추장구이', '미니팥칼국수', '도넛츠', '땅콩멸치조림', '돈육고추장불고기', '참나물생채무침', '장국', '미트볼케찹조림', '미니우동', '무쌈깻잎', '모듬버섯탕수육', '모듬묵샐러드', '치킨샐러드', '백종원의', '비엔나볶음', '도라지나물', '도토리묵야채무침', '찹쌀밥', '낙지덮밥', '우거지해장국', '상추치커리무침', '훈제오리냉채', '깐풍육', '가지된장무침', '유산슬덮밥', '삼치조림', '해물동그랑땡전', '황태무채국', '쌈추전', '청경채김치', '마파두부덮밥', '펜네베이컨샐러드', '연두부찌개', '김치전', '납작군만두', '볼어묵곤약볶음', '우동장국', '계란김밥', '청경채나물', '미더덕콩나물찜', '치커리배생채', '비엔나채소볶음', '열무김치볶음', '돈수육', '양념깻잎지', '닭볶음', '어묵매운탕', '양상추샐러드', '나가사끼짬뽕국', '부추생채무침', '매운버섯국', '감자고추장찌개', '감자치즈구이', '단호박조림', '쇠고기낙지볶음', '바지락수제비', '달래된장국', '쇠고기우엉볶음', '오이지', '얼갈이된장무침', '로제찜닭', '빌소세지구이', '시리얼과일샐러드', '섬초무침', '계란파국', '물만두국', '어묵볶음', '올방개묵무침', '동태찌개', '찐햇감자', '물파래전', '비빔만두채소무침', '쇠고기국', '오이쑥갓겉절이', '도토리묵채소무침', '메밀전', '우육비빔냉면', '사골파국', '버섯들깨탕', '삼치양념찜', '비엔나감자볶음', '건파래볶음', '귤', '단호박카레라이스', '쑥된장국', '브로컬리꽃맛살샐러드', '두부매콤조림', '해물떡볶이', '오이선', '김치수제비국', '모둠과일', '감자비엔나볶음', '파닭', '동그랑땡계란부침', '오이달래무침', '삼계국밥', '누룽지탕수육', '흑임자시금치샐러드', '오징어초무침', '채소볶음밥', '얼갈이국', '참치마요덮밥', '김치볶음밥', '주꾸미채소볶음', '잡채말이어묵국', '해물칼국수', '브로컬리초장', '풋마늘대무침', '구운채소', '치킨마요덮밥', '오이지무침', '돈육잡채', '사과양상추샐러드', '애호박나물', '연근흑임자샐러드', '옥수수샐러드', '순대찜', '채소쌈', '미트볼피망볶음', '시금치초고추장무침', '달래오이생채', '삼겹살볶음밥', '오이나물볶음', '마제소바', '매콤호박볶음', '꽁치구이', '조갯살아욱국', '아귀콩나물찜', '푸실리샐러드', '부추만두', '김치순두부찌개', '매생이전', '북어계란국', '북어국', '유부우동', '메추리알조림', '간장마늘치킨', '상추부추무침', '애호박새우젓볶음', '뼈해장국', '삼치된장구이', '포기김치', '치커리깨소스무침', '참치야채전', '궁중떡볶음', '온메밀소바', '시금치프리타타', '연두부', '토란탕', '상추파무침', '오꼬노미계란말이', '유채나물된장무침', '대패삼겹숙주볶음', '치즈함박스테이크', '후리가케덮밥', '안동찜닭', '유부주머니우동국', '소떡소떡', '돈육고추장볶음', '미니함박', '닭데리야끼조림', '채소피클', '참나물초장무침', '참나물땅콩가루무침', '전주식콩나물국', '해물볶음', '열무된장국', '알타리김치', '오렌지', '내사랑포도', '쇠고기탕수', '다시마채무초무침', '고구마맛탕', '루꼴라샐러드', '두부스테이크', '춘전닭갈비', '제육김치덮밥', '해초배무침', '구이김', '시금치된장국', '치즈닭갈비', '호박부추전', '닭가슴살겨자무침', '감자채카레볶음', '콩나물냉국', '수수부꾸미', '김말이', '방울토마토', '미소시루', '무쌈', '새우살호박볶음', '단호박두부탕수', '차돌된장찌개', '통새우또띠아', '파프리카해초무침', '깍둑오이초무침', '갈치양념조림', '황태해장국', '청경채무침', '코다리조림', '스팸김치찌개', '옛날소시지전', '도라지오이무침', '매운쇠고기국', '흑임자샐러드', '파인애플주스', '고구마연근맛탕', '돈까스김치나베', '코다리양념조림', '굴소스파인볶음밥', '녹두전', '깻순나물', '고등어김치말이', '실곤약흑임자무침', '찰떡떡갈비조림', '순두부백탕', '오징어야채무침', '부추팽이무침', '치커리무침', '우동', '양파*쌈장', '꽃빵튀김', '홍합탕', '양파초절임', '냉모밀국수', '소고기퀘사디아', '매운콩나물무침', '쫄면채소무침', '오징어어묵무침', '장어강정', '베이컨계란말이', '두부계란전', '크림새우', '김구이', '중국식볶음밥', '들깨버섯탕', '옹심이국', '꼬치어묵매운탕', '새싹두부구이', '짜장소스', '신김치도토리묵', '소불고기', '쇠고기퀘사디아', '계란후라이', '간장찜닭', '콘치즈', '시래기지짐', '해물가스', '팽이장국', '컵주스', '채소튀김', '군고구마', '콩나물김치국', '목살필라프', '개성감자만두', '고추잡채', '연근샐러드', '오징어무침', '수제등심찹쌀꿔바로우', '토마토시금치달걀볶음', '콩나물불고기', '불고기필라프', '목살스테이크', '맑은콩나물국', '돈육칠리강정', '메추리알곤약장조림', '버섯불고기', '오이도라지생채', '푸딩', '오꼬노미야끼계란말이', '사과맛살초무침', '해물김치전', '모둠버섯구이', '치커리유자무침', '계란', '맑은버섯닭개장', '국물떡볶이', '열무나물', '꼬들단무지', '요플레', '미역국', '굴미역국', '취나물무침', '연근땅콩조림', '수제두부동그랑땡', '갈치튀김', '동태전', '만두튀김', '취나물', '교자만두', '유부우동국물', '냉이된장찌개', '오이소박이', '콘치즈구이', '홍시드레싱샐러드', '마늘쫑메추리알조림', '매운소고기국', '어묵무침', '동파육', '닭개장', '메추리알치즈떡볶이', '오징어무국', '떡갈비조림', '상추무침', '맑은장국', '순살깐풍기', '오징어채소볶음', '수제돈까스', '돈갈비찜', '해물겨자냉채', '깻잎지', '햄감자볶음', '감자채파프리카볶음', '황태양념구이', '비빔메밀국수', '호박나물', '사천탕수육', '우엉잡채', '멸치볶음', '오이도라지무침', '등갈비바베큐조림', '짜장잡채밥', '가자미튀김', '꽃맛살볶음', '봄동무침', '낙지미나리볶음', '참치야채비빔밥', '찐옥수수', '무채맑은국', '쇠고기모둠장조림', '부추겉절이', '소고기콜라비조림', '김말이강정', '오징어젓갈무침', '제육춘장볶음', '얼갈이쌈장무침', '생선초밥', '타코야끼', '버섯잡채', '몽골식돈육볶음', '햄계란말이', '돈육씨앗강정', '볶음우동', '호박반달나물', '모듬소시지구이', '김치고기전', '애호박새우젓나물', '닭오븐구이', '콩나물굴소스볶음', '꼬시래기초무침', '두부새싹구이', '쇠고기들깨소스무침', '크랜베리단호박샐러드', '채소볶음우동', '소고기매운무국', '꼬막채소무침', '사과청경채무침', '꽁치오븐구이', '후르츠탕수육', '근대국', '동태매운탕', '샤워크림새우', '숯불양념꼬치어묵', '팽이가쯔오장국', '작은밥', '구슬떡볶이', '치킨핑거', '굴소스해물볶음밥', '호박잎찌개', '케찹', '쇠불고기', '콩나물겨자채', '우불고기볶음', '주꾸미삼겹살볶음', '초계국수', '명태조림', '소시지오븐구이', '참나물들깨무침', '야채비빔만두', '짜사이채무침', '매운돼지갈비찜', '오뗄햄김밥', '수제어묵볶음', '유자청제육볶음', '나가사키면', '버섯맛살볶음', '케일숙쌈*쌈장', '순대볶음', '흑임자곤약샐러드', '추가밥', '감자채전', '과일주스', '만두', '꽁치양파조림', '한식잡채', '고갈비구이', '비트채소절임', '콥샐러드', '무채국', '수제비국', '오리불고기', '고등어김치찜', '비타민흑임자샐러드', '소고기모듬장조림', '수제오이피클', '쑥갓나물', '사골우거지국', '오징어', '류산슬', '꽁보리밥', '콘슬로우', '멸치주먹밥', '로제파스타', '맑은버섯국', '삼겹보쌈', '머위순나물', '꽈리고추찹쌀무침', '장아찌', '온두부', '떡꼬지', '온모밀국수', '돈육두루치기', '당면채소무침', '솎음열무나물', '청경채생채', '등갈비묵은지찜', '알리오올리오파스타', '어묵곤약볶음', '무나물들깨볶음', '멸치견과류볶음', '미니함박조림', '뼈감자탕', '우거지탕', '비빔칼국수', '돈육청경채볶음', '대구매운탕', '미역줄기', '두부구이', '김치녹두전', '해물굴소스볶음밥', '느타리버섯볶음', '더덕고추장불고기', '유부주머니국', '카레덮밥', '야채전', '참나물땅콩무침', '베이컨숙주볶음', '오이양배추피클', '가지탕수', '매쉬드포테이토', '고등어카레구이', '달래된장찌개', '해물전', '옥수수계란찜', '닭칼국수', '치커리단감무침', '들깨버섯국', '도라지생채', '취나물된장무침', '아욱국', '스팸', '삼선짬뽕국', '매운소불고기', '오징어볶음', '취나물볶음', '통새우김밥', '순대오징어볶음', '묵은지닭찜', '쇠미역쌈', '무초절이', '오이맛살냉채', '만두찜', '유부초밥', '까르보나라떡볶이', '꿔바로우탕수육', '삼치데리야끼구이', '훈제오리', '진미채오이무침', '씨앗콩자반', '양파장아찌', '단배추겉절이', '고추장불고기', '찹쌀순대볶음', '꽁치감자조림', '무우짱아찌', '청양콩나물국', '모둠묵', '콩비지찌개', '쇠고기볶음밥', '참치김치찌개', '양상추', '고추장멸치볶음', '미역레몬초무침', '마늘바게트', '돈육굴소스볶음', '닭볶음탕', '두부오꼬노미야끼', '얼갈이생채', '멘보샤', '등뼈묵은지찜', '취나물땅콩무침', '옛날왕돈가스', '건파래무침', '그린빈베이컨볶음', '스팸볶음밥', '피클', '연근깨소스무침', '홍어채무침', '콩가루배추국', '열무된장나물', '당면계란만두', '섭산적표고굴소스볶음', '무생채', '궁중떡볶이', '날치알계란찜', '갈치구이', '사과주스', '닭데리야끼구이', '나가사끼짬뽕', '새송이너비아니구이', '옥수수감자범벅', '적어양념구이', '아이스슈', '야채볶음밥', '락교', '스팸계란말이', '물미역초무침', '김자반', '고춧잎무침', '시래기들개탕', '견과류조림', '배추된장국', '김치어묵탕', '아삭고추무침', '돌나물오이무침', '딸기드레싱샐러드', '짜사이볶음', '돈육매콤조림', '옛날돈가스', '꼬들단무지무침', '돈나물오리엔탈무침', '돈육고추장찌개', '돈까스', '맛살냉채', '소고기숙주볶음', '무비트생채', '참나물겉절이', '순살파닭', '코다리강정', '쇠고기장조림', '두부고기조림', '오삼불고기', '모듬소세지', '동태포전', '가자미엿장구이', '참나물', '깻잎전', '양념고추지무침', '얼큰소고기무국', '오징어불고기', '양배추샐러드', '팽이버섯국', '검정콩조림', '깍두기', '비빔국수', '청포묵야채무침', '생야채', '다슬기아욱국', '모둠튀김', '팽이버섯장국', '날＞', '잡채밥', '돈육고구마강정', '갈비만두', '봄동겉절이', '해물부추전', '칠리미트볼조림', '계란장조림', '고기전', '군만두', '오징어브로컬리', '비빔밥', '버섯영양밥', '꼬시래기무침', '두부', '비프스파게티', '호박잎된장찌개', '상추', '쇠고기숙주규동덮밥', '두부김치국', '꽃삼겹김치찜', '해물순두부국', '그린요거트샐러드', '순대들깨볶음', '치킨까스', '갈치조림', '소고기미역국', '손수제비국', '메밀국수', '쌀밥', '닭살겨자채', '비트무피클', '매운사태조림', '브로콜리깨소스무침', '맑은연두부탕', '야채스틱', '김치두루치기', '어묵잡채볶음', '오리훈제마늘볶음', '도라지오이생채', '열무비빔국수', '주스', '머위대초무침', '무쌈말이', '사과오이무침', '계란국', '새송이버섯조림', '크랜베리멸치볶음', '깻잎양념찜', '참외', '돈육두릅장조림', '연유꽃빵튀김', '시금치나물무침', '짠지오이무침', '쫄면야채무침', '스파게티', '쫄면비빔만두', '냉이김칫국', '모듬양채쌈', '새싹피자', '콩나물밥', '미니버거', '감자채햄볶음', '양상추메추리알샐러드', '라볶이', '골뱅이채소무침', '수제돈가스', '짬뽕수제비국', '고구마오븐구이', '풋고추튀김', '왕만두', '얼갈이나물', '땡초주먹밥', '마늘쫑볶음', '꽃게탕', '가쯔오국', '도라지무침', '과일요거트샐러드', '옥수수콘치즈', '떡만두국', '홍합짬뽕국', '매운감자조림', '상추초무침', '볼어묵고추장볶음', '돈까스김밥', '간장계란장', '시래기국', '훈제오리불고기', '케이준샐러드', '컵라면', '마파두부소스', '미니국수', '도토리묵냉국', '바지락된장찌개', '쨔샤이무침', '멕시칸샐러드', '부대찌개', '수제찹쌀꿔바로우', '모둠채소무침', '달래새우전', '망고주스', '삼치엿장구이', '쑥갓무침', '영양부추무침', '해물볶음밥', '단무지무침', '깨찰빵', '오징어숙회무침', '타워함박스테이크', '김칫국', '바나나', '브로콜리숙회', '파스타샐러드', '쇠고기두부찜', '고등어조림', '콩나물냉채', '식혜', '해라피겨자채', '청국장찌개', '닭가슴살냉채', '망고드레싱샐러드', '쑥갓겉절이', '매운등뼈조림', '치커리생채', '탕수육', '돈육간장불고기', '애호박새우젓국', '닭매운찜', '얼갈이겉절이', '실곤약채소무침', '김주먹밥', '컬리플라워샐러드', '두부부침', '감자만두국', '삼겹살구이', '김치어묵국', '닭살채소굴소스볶음', '굴소스볶음밥', '회오리감자', '매운순대국', '단무지', '절인고추', '미니야채떡갈비', '수제무말랭이무침', '콩조림', '버섯탕수', '냉메밀소바', '비엔나감자조림', '숙주미나리잡채', '얼갈이열무겉절이', '야채쫄면무침', '꽈리고추어묵볶음', '부추팽이버섯생채무침', '모듬튀김', '비빔야채만두', '볼어묵조림', '닭강정', '연근', '돈육김치볶음', '오렌지쥬스', '돌나물유자청무침', '차돌박이찌개', '건새우마늘쫑볶음', '느타리호박볶음', '비엔나야채볶음', '치킨텐더', '데리야끼파닭', '완두콩스프', '부추호박전', '청양멸치주먹밥', '미니햄버거', '표고버섯탕수육', '단호박스프', '포테이토오븐구이', '근대고추장무침', '왕만두찜', '시금치초장무침', '숯불양념꼬지어묵', '미니돈까스', '톳두부무침', '미니떡갈비조림', '건도토리묵파프리카볶음', '치커리유자청무침', '마파두부', '매운닭개장', '양장피잡채', '돈육모듬장조림', '옛날왕돈까스', '마늘간장치킨', '계란말이', '쭈꾸미볶음', '김치두부국', '쇠고기미역국', '김치국', '키위드레싱샐러드', '새송이버섯전', '꼬마김밥', '방풍나물', '매운감자국', '건새우무나물', '해물우동볶음', '모둠버섯볶음', '파래김', '숙주미나리무침', '만두국', '사과오이생채', '찐감자', '야채샐러드', '소고기장조림', '감자만두', '두부커틀릿', '매운콩나물국', '김치주먹밥', '갈릭파닭', '야채쫄면', '후난식볶음밥', '쑥갓두부무침', '열무김치국수', '삼치구이', '열무김치', '녹두빈대떡', '양파치킨', '고사리볶음', '찹쌀도너츠', '계란야채말이', '수제보쌈김치', '진미채무침', '고등어양념구이', '취나물된장볶음', '참치주먹밥', '언양식불고기', '포도', '고추지무침', '훈제오리볶음', '흑미밥', '모둠묵샐러드', '충무김밥', '찐만두', '츄러스', '해물짜장면', '사과오이냉국', '숙주나물당근무침', '브로콜리', '쫑상추무침', '뉴욕핫도그', '미니잔치국수', '매운순대국밥', '쇠고기샤브국', '춘권', '새송이버섯장조림', '닭갈비', '콤비네이션피자', '삼치튀김', '페퍼로니치즈피자', '깐풍연근', '부채살오므라이스', '나가사키짬뽕국', '마늘베이컨볶음밥', '물만두찜', '묵은지닭볶음탕', '부추오이생채', '닭갈비볶음밥', '생깻잎지', '부추무침', '마늘쫑건새우', '비엔나컬리플라워볶음', '파채*소스', '유린기', '가자미구이', '늙은호박전', '부들어묵볶음', '계발의', '오이보트샐러드', '조기구이', '감자햄조림', '쫄면', '슈크림', '주꾸미떡볶음', '방어양념장구이', '청포묵무침', '채소스틱', '고등어구이', '꼬치어묵국', '해물파전', '소고기된장찌개', '오이양파무침', '햄치즈또띠아', '돈채표고버섯볶음', '김치미나리전', '매운계란파국', '비엔나감자구이', '부추오리엔탈무침', '블루베리드레싱샐러드', '고구마순들깨볶음', '자몽샐러드', '황태국수', '카레홍합찜', '칠리베이비크랩', '우거지된장국', '하와이안샐러드', '등심찹쌀꿔바로우', '낙지젓무침', '머위된장무침', '떡국', '옥수수전', '겉절이김치', '복주머니딤섬', '마늘쫑장아찌', '오리훈제볶음밥', '고추튀김', '참치회덮밥', '바베큐함박찹스테이크', '수박', '왕새우튀김', '알탕', '음료', '두부조림', '시금치나물', '햄감자채볶음', '주꾸미무침', '햄맛살볶음', '옥수수스프', '토마토스파게티', '대패삼겹', '참나물생채', '미역장국', '물파래초무침', '단호박범벅', '코다리엿장조림', '요구르트', '모둠소시지구이', '해물짬뽕', '미트볼파스타', '오이생채', '오징어젓무침', '간장치킨', '멸치아몬드볶음', '멸치마늘종조림', '통고추쌈장무침', '바게뜨', '삼색귤소스무침', '청양해물파전', '청포도', '애플망고두유', '도토리묵무침', '고구마순나물', '돈육가지두반장볶음', '갓김치', '시래기조림', '사천식탕수육', '양파', '쇠고기규동덮밥', '오므라이스', '미트볼떡조림', '단무지양념무침', '폭탄주먹밥', '만가닥버섯불고기', '명엽채볶음', '두부계란구이', '오렌지주스', '사과푸딩', '모듬묵', '미소장국', '쇠고기매운국', '얼갈이나물된장무침', '풋고추', '감자양념조림', '참나물무침', '물냉면', '＜자기', '메추리알풋고추조림', '채소계란찜', '양배추쌈', '해물동그랑땡', '비트피클', '치즈계란찜', '어묵국', '동파삼겹수육', '버섯들깨나물', '고구마떡볶이', '어묵잡채', '수제고로케', '쇠고기육전', '오복지무침', '짬뽕', '고추짜장', '콩나물볶음', '훈제오리떡볶음', '계란떡볶이', '콘치즈오븐구이', '햄볶음밥', '육개장', '치킨퀘사디야', '북어해장국', '참치샐러드', '김밥볶음밥', '새알만두국', '아삭고추된장무침', '감자소세지볶음', '나초콥샐러드', '김치필라프', '홍합무우국', '마늘쫑건새우볶음', '오복지', '실곤약야채무침', '어묵피망볶음', '수제연근유자피클', '김말이튀김', '해물손수제비', '꽁치김치찜', '유부주머니된장국', '백종원의사라다빵', '새송이버섯볶음', '팽이버섯부추무침', '땅콩조림', '물만둣국', '고추,양파', '냉이국', '치킨무', '진미채무말랭이무침', '모짜렐라핫도그', '씨리얼과일샐러드', '낙지비빔밥', '가쯔오장국', '브로컬리맛살볶음', '가자미유린기', '목살간장조림', '참치파개장', '카레찜닭', '풍기샐러드', '자장소스', '닭겨자냉채', '마카로니치즈범벅', '연근조림', '옹심이감자국', '산채비빔밥', '가자미양념조림', '유부된장국', '오징어국', '해파리냉채', '과일샐러드', '감자프리타타', '퀘사디아', '풋고추양파무침', '잡곡밥', '부추전', '어묵깻잎전', '고기짬뽕국', '오이사과무침', '매운닭찜', '춘천닭갈비', '생선가스', '수제고기육전', '고추잡채덮밥', '닭간장조림', '사골옹심이만둣국', '생선커틀릿', '옛날돈까스', '청포도피클', '양배추숙', '오징어튀김', '제육간장불고기', '어묵우동', '메밀비빔국수', '오이무침', '감자찌개', '계란볶음밥', '오이무피클', '세발나물무침', '영양부추생채', '호박새우젓국', '새우미역초무침', '꼬지어묵우동', '건새우호박채전', '야채계란찜', '잡채', '곤드레밥', '매콤어묵볶음', '무말랭이', '섭산적고추장구이', '떡갈비주먹밥', '시저샐러드', '순살닭갈비', '닭윙강정튀김', '가래떡오븐구이', '김자반볶음', '채소라면', '오이사과생채', '꽃상추무침', '메밀전병만두', '오이볶음', '생과일플레인샐러드', '양파절임', '깻잎찜', '하루야채주스', '야채부케', '얼큰동태탕', '닭간장볶음', '주먹밥', '오이맛살초무침', '옥수수맛살전', '등심돈까스', '닭살냉채', '날치알김치볶음밥', '단무지채무침', '더덕무침', '비엔나케찹볶음', '바지락살국', '메추리알장조림', '케이준치킨샐러드', '꼬치어묵떡볶이', '우삼겹부대찌개', '소고기주먹밥', '토마토', '천도복숭아', '꽈리고추어묵조림', '도라지초무침', '소고기메추리알장조림', '산고추지무침', '주꾸미볶음', '샐러드김밥', '노각무침', '가지무침', '양념고추지', '임연수구이', '오이미역무침', '두부된장찌개', '유부장국', '두부카프레제', '마늘바게뜨', '근대두부된장국', '로제스파게티', '도라지오이초무침', '사과', '올챙이만두국', '돈육피망볶음', '우거지국', '명란계란찜', '연두부탕', '스팸주먹밥', '브로컬리', '돌나물', '모듬쌈', '스프', '골뱅이무침', '굴비구이', '김치찌개', '겨울초겉절이', '오징어떡볶음', '봄동된장국', '연두부계란찜', '감자범벅', '햄전', '오이맛살무침', '소세지볶음', '해물된장찌개', '매운족발볶음', '치즈시즈닝치킨', '팽이버섯채소전', '근대나물무침', '콩나물무침', '낙지볶음덮밥', '가지나물', '브로컬리새우전', '탕수만두', '크림스프', '해쉬포테이토', '가자미카레튀김', '가지마파두부', '만둣국', '꽈리고추찜', '유채나물무침', '유산슬', '섭산적데리야끼조림', '미니쌀국수', '새우로제파스타', '미나리전', '매운사태찜', '아귀매운탕', '고구마범벅', '딸기생크림와플', '들깨미역국', '소고기무국', '목살김치찌개', '유부채소겨자냉채', '애플카레라이스', '모자반무침', '돈육꽈리고추장조림', '해물누룽지', '감자튀김', '미니짬뽕', '돈까스또띠아', '버섯육개장', '양념갈비찜', '수제미니햄버거', '비트무절임', '자기개발의날', '고구마튀김', '너비아니', '호박젓국찌개', '단감치커리무침', '세발나물오리엔탈무침', '알배기', '브로컬리초회', '참치김치볶음', '숙주고기짬뽕', '김치참치주먹밥', '토마토계란찜', '순살닭강정', '매콤시래기된장지짐', '양념치킨', '두반장가지나물', '시래기삼치조림', '매실주스', '홍합미역국', '배추흑임자무침', '임연수찜', '꽁치한마리구이', '모듬소세지볶음', '자반고등어찜', '콩나물국', '샐러드파스타', '얼큰감자국', '수제칠리핫도그', '수제핫도그', '해초레몬무침', '들깨시래기국', '수제마늘바게트', '훈제오리구이', '과일탕수육', '깻잎고기전', '야채튀김', '감귤쥬스', '올갱이아욱국', '고구마샐러드', '상추겉절이', '미니쫄우동', '삼겹살마늘볶음밥', '낙지볶음', '비름나물', '닭살겨자냉채', '궁중떡찜', '새우볶음밥', '코다리무조림', '느타리버섯국', '고구마치즈구이', '백김치', '오징어땅콩조림', '쇠고기가지조림', '매운떡볶이', '콩국수', '주꾸미초무침', '미나리나물무침', '오이초무침', '해물볶음우동', '과일플레인샐러드', '삼치데리야끼', '김치국수', '짜장면', '쫑상추새콤무침', '부추생채', '매실쥬스', '도라지채무침', '쇠고기무국', '청경채사과무침', '수제피클', '양배추비트피클', '김가루잔파무침', '샐러드', '갈치카레구이', '돈육볶음', '메추리알곤약조림', '쑥갓생무침', '딸기와플', '매운어묵국', '닭불고기', '석박지', '콘샐러드', '해물청경채볶음', '김치우동', '두부양념찜', '레몬탕수육', '볶음쌀국수', '시금치국', '두부카프레제샐러드', '우동국물', '등뼈김치찜', '소고기계란장조림', '미역줄기볶음', '과일', '아쿠아돈까스', '새우만두', '쪽파무침', '얼큰순두부찌개', '또띠아칩', '우불고기', '김밥', '크림카레우동', '감자버터구이', '미니김밥', '허니슈스트링감자', '팝콘치킨', '메쉬드포테이토', '김치콩나물국', '배추국', '무피클', '모듬소세지구이', '돼지갈비찜', '카레돈까스정식', '두부찜', '나박물김치', '수제오징어튀김', '콩자반', '꽈배기도너츠', '감자카레볶음', '단호박팥찜', '언양식바싹불고기', '떡볶이', '콩나물파채무침', '호빵', '들깨무채국', '돼지고기장조림', '건새우아욱국', '미트볼채소볶음', '상추쌈', '실곤약초무침', '냉이된장국', '고들빼기무침', '계란찜', '해물순두부찌개', '순대채소볶음', '돈육간장강정', '미나리무침', '꽁채캔김치조림', '모듬떡볶이', '쌈장', '해파리겨자채', '버섯햄볶음', '어묵꽈리고추볶음', '핫도그', '조각티라미수', '비트무생채', '함박스테이크', '시금치흑임자샐러드', '호박채나물', '돈삼겹보쌈', '우엉조림', '닭가슴살장조림', '볶음밥', '동그랑땡강정', '꼬지어묵탕', '생선까스', '모닝빵', '돈채호박볶음', '쌀국수', '참치덮밥', '쇠고기숙주볶음', '숙주미나리나물', '단호박', '짬뽕국', '단배추나물', '근대된장국', '통마늘너비아니조림', '감자양파국', '머위대나물', '쇠고기덮밥', '자기계발의날', '물만두탕수', '마늘종멸치볶음', '얼갈이된장국', '가자미양념찜', '치커리귤무침', '닭봉오븐구이', '매생이굴국', '두부양념조림', '셀프무쌈말이', '돈사태떡찜', '새우튀김우동', '쇠고기청경채볶음', '새알미역국', '마늘쫑무침', '무초절임', '쫄면무침', '쌈무', '매콤돈육메추리알장조림', '치커리사과생채', '짬뽕불고기', '가쓰오장국', '멸치호두볶음', '배추겉절이', '단호박계란찜', '봄나물튀김', '오꼬노미야끼', '베이컨김치볶음밥', '베이컨볶음밥', '모둠장조림', '또띠아견과칩', '소고기버섯볶음', '탕평채', '연근튀김', '닭카레볶음', '고르곤졸라피자', '동태탕', '감자치즈오븐구이', '브로컬리오징어숙회', '고구마까스', '짜샤이볶음', '돌나물초장', '순대야채볶음', '파김치', '치즈계란말이', '들깨버섯무침', '해물짬뽕국', '감자국', '마늘치킨', '김계란말이', '감자간장조림', '꼬막찜', '뼈없는감자탕', '감자전', '메추리알꽈리고추조림', '새우튀김', '고등어자반찜', '셀프충무김밥', '고구마그라탕', '돈육장조림', '돈가스또띠아', '매운소고기무국', '동태알탕', '짜장덮밥', '우엉곤약조림', '옹심이만두국', '시금치무침', '민물새우찌개', '코코뱅', '딤섬', '새우또띠아', '황태국', '장각닭죽', '꽁치허브구이', '잔멸치볶음', '알리오올리오', '대구탕', '깐풍기', '차돌비빔국수', '부추팽이겉절이', '반반치킨', '파인애플볶음밥', '해물까스', '치커리사과무침', '노가리고추조림', '쌈만두', '하루나무침', '수원왕갈비통닭', '토마토설탕절인', '고구마순볶음', '매운어묵볶음', '마늘빵', '아오리사과', '등갈비김치찜', '비빔만두', '가자미찜', '꽃맛살샐러드', '두반장가지볶음', '코코넛새우튀김', '풋마늘초무침', '새우까스', '고추장찌개', '새우살볶음밥', '도토리묵', '스틱단무지', '황태미역국', '탕수어', '배', '갈치무조림', '돈육강정', '닭곰탕', '배추김치', '순두부찌개', '조랭이떡미역국', '대구찌개', '소고기매운국', '북어짬뽕국', '모둠채소전', '탄두리치킨', '삼겹살야채비빔면', '해물누룽지탕', '동그랑땡전', '제육볶음', '타꼬야끼', '오징어굴소스볶음', '돈육계란장조림', '웨지감자', '카레감자채볶음', '소고기불고기', '세발나물', '시금치샐러드', '콩나물간장볶음', '유자청돈육볶음', '해초무침', '미니채소떡갈비', '꽁치김치말이', '꼬지어묵국', '짜장밥', '자반고등어구이', '등갈비오븐구이', '쪽파김무침', '옹심이만둣국', '무채유자무침', '돈육김치찌개', '샐러리샐러드', '양배추피클', '또띠아피자', '옥수수맛탕', '모듬어묵탕', '조각사과', '청경채겉절이', '간장불고기', '맑은국', '치킨까스김치나베', '춘장돈육볶음', '무청된장국', '키위그린샐러드', '대구지리', '돼지국밥', '오이피클', '꼬치어묵탕', '투움바스파게티', '깻잎쌈', '날치알볶음밥', '청경채찜', '소고기낙지볶음', '매운오징어국', '잔치국수', '스태프핫도그', '칼국수', '비빔채소만두', '통도라지구이', '미역무침', '허니버터옥수수', '매운돈갈비찜', '찜닭', '크래미오이보트샐러드', '옥수수볼맛탕', '짜장잡채덮밥', '피크닉', '가정의날', '무나물', '쇠고기야채볶음', '묵은지삼겹살찜', '된장찌개', '김치볶음', '쭈꾸미불고기', '무말랭이무침', '열무나물무침', '돈육간장볶음', '카레라이스', '통배추겉절이', '미트볼조림', '숙주나물', '시금치초무침', '생파김치', '맛탕', '감자채볶음', '재래김', '수제치킨까스', '짬뽕수제비', '물파래무침', '맛살전', '고구마치즈돈까스', '아몬드멸치볶음', '포도주스', '김치말이국수', '밀떡볶이', '야채주먹밥', '임연수엿장조림', '주꾸미굴소스볶음', '브로컬리크림스프', '열무물국수', '봄동쌈', '짬뽕순두부찌개', '유채나물', '설렁탕', '깐쇼새우', '미소된장국', '열대과일샐러드', '오징어순대볶음', '두부계란부침', '수제맛쵸킹탕수육', '미나리숙주나물', '두부미소된장국', '양송이스프', '버섯메밀전', '해물수제비', '모둠버섯초무침', '시래기들깨탕', '동태콩나물찜', '간장깻잎지', '하와이안필라프', '차돌박이된장찌개', '조갯살미역국', '삼치양념구이', '베리베리퐁당요플레', '버섯매운국', '바나나와플', '건새우아욱된장국', '빠에야'}\n",
            "805 805 805\n",
            "228\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj7_EReTyz1C"
      },
      "source": [
        "def tfidf_transform(list, set):\n",
        "    word2id = defaultdict(lambda: 0) # 메뉴 이름 담을 딕셔너리\n",
        "    list_contents = [] # 리스트로 저장된 식단을 코퍼스 단위로 바꿔 저장하는 리스트\n",
        "    list_transformed = [] # tfidf 변환된 값을 저장하는 리스트\n",
        "    emb = TfidfVectorizer(vocabulary=set, lowercase=False)\n",
        "    for row in list:\n",
        "        list_contents.append(' '.join(row)) # 코퍼스 단위로 변환\n",
        "    emb_list = emb.fit_transform(list_contents) # tfidf 변환\n",
        "    for idx, feature in enumerate(emb.get_feature_names()):\n",
        "        word2id[feature] = idx # 딕셔너리에 메뉴 이름 저장\n",
        "    for i, sent in enumerate(list_contents):\n",
        "        list_transformed.append([(token, emb_list[i, word2id[token]])for token in sent.split()])\n",
        "\n",
        "            \n",
        "    return list_transformed\n",
        "\n",
        "breakfast_tfidf = tfidf_transform(breakfast_list, breakfast_set)\n",
        "lunch_tfidf = tfidf_transform(lunch_list, lunch_set)\n",
        "dinner_tfidf = tfidf_transform(dinner_list, dinner_set)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9BsdF2eTFf4"
      },
      "source": [
        "### 자주 나오는 메뉴 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERR-GViJ88Ro",
        "outputId": "e06c0831-c680-4f8a-a167-3cd7d0fd3265"
      },
      "source": [
        "THRESHOLD = 0.20\n",
        "def delete_menu(THRESHOLD, list):\n",
        "    useless = []\n",
        "    for i, d in enumerate(list):\n",
        "        for idx, m in enumerate(d):\n",
        "            if m[1] < THRESHOLD:\n",
        "                useless.append(m[0])\n",
        "    return set(useless)\n",
        "brkfst_del = list(delete_menu(THRESHOLD, breakfast_tfidf))\n",
        "lunch_del = list(delete_menu(THRESHOLD, lunch_tfidf))\n",
        "dinner_del = list(delete_menu(THRESHOLD, dinner_tfidf))\n",
        "print(brkfst_del)\n",
        "print(lunch_del)\n",
        "print(dinner_del)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['계란후라이', '포기김치', '주스', '우유', '모닝롤', '스크램블에그', '쌀밥', '양상추샐러드', '와플&생크림', '누룽지탕', '흑미밥']\n",
            "['다시마*초장', '명이나물-장아찌', '쌈', '새송이*가지구이', '포기김치', '쌀밥', '케일*우렁쌈장', '그린샐러드*키위D', '깻잎*쌈장', '배추겉절이', '상추*쌈장', '잡곡밥', '찰현미밥', '흑미밥', '귤', '마늘*새우젓', '양상추샐러드', '생강채*쌈장', '다시마쌈*씨앗쌈장', '쑥갓쌈&쌈장', '그린샐러드*오렌지드레싱', '버섯숙회*초장', '고추*쌈장', '와사비무쌈*쌈장', '채소스틱&쌈장', '청', '케일숙쌈*양념간장', '양상추*쌈장']\n",
            "['잡곡밥', '배', '고추,양파', '포기김치', '케일숙쌈*쌈장', '＜자기', '쌀밥', '양파*쌈장', '날＞', '파채*소스', '흑미밥', '귤']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOmZCqSbY4HG",
        "outputId": "d97b73b6-5dc1-43f5-bcfb-fcb3b9e8f02c"
      },
      "source": [
        "for i in range(5):\n",
        "    print(breakfast_list[i])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['계란후라이', '된장찌개', '포기김치', '우유', '주스', '모닝롤', '쌀밥', '두유', '쥐어채무침', '찐빵', '호두죽']\n",
            "['계란후라이', '포기김치', '우유', '주스', '호박젓국찌개', '모닝롤', '팥죽', '쌀밥', '두유', '단호박샌드', '시래기조림']\n",
            "['계란후라이', '콩나물국', '포기김치', '우유', '주스', '표고버섯죽', '모닝롤', '느타리호박볶음', '쌀밥', '베이글', '두유']\n",
            "['계란후라이', '포기김치', '우유', '주스', '닭죽', '모닝롤', '멸치볶음', '쌀밥', '두유', '근대국', '토마토샌드']\n",
            "['계란후라이', '방풍나물', '포기김치', '우유', '주스', '모닝롤', '쌀밥', '재첩국', '두유', '와플', '쇠고기죽']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3hqu1HVR9rb",
        "outputId": "60a4bfe7-dc0f-4828-c25a-e9cb5206e671"
      },
      "source": [
        "del_col = [brkfst_del, lunch_del, dinner_del]\n",
        "B = deepcopy(breakfast_list)\n",
        "L = deepcopy(lunch_list)\n",
        "D = deepcopy(dinner_list)\n",
        "menu_list = [B, L, D]\n",
        "\n",
        "def menu_processing(del_list, menu_list):\n",
        "    list = []\n",
        "    for d in del_list:\n",
        "        for i in menu_list:\n",
        "            if d in i:\n",
        "                i.remove(d)\n",
        "\n",
        "for i, j in zip(del_col,[B, L, D]):\n",
        "    menu_processing(i, j)\n",
        "\n",
        "B[:5]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['된장찌개', '두유', '쥐어채무침', '찐빵', '호두죽'],\n",
              " ['호박젓국찌개', '팥죽', '두유', '단호박샌드', '시래기조림'],\n",
              " ['콩나물국', '표고버섯죽', '느타리호박볶음', '베이글', '두유'],\n",
              " ['닭죽', '멸치볶음', '두유', '근대국', '토마토샌드'],\n",
              " ['방풍나물', '재첩국', '두유', '와플', '쇠고기죽']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "Cq4X45tCz7js",
        "outputId": "87c70fa3-a4e1-4add-cc72-2bf914aa10a2"
      },
      "source": [
        "for i in range(len(all_df)):\n",
        "    all_df['조식메뉴'][i] = B[i]\n",
        "    all_df['중식메뉴'][i] = L[i]\n",
        "    all_df['석식메뉴'][i] = D[i]\n",
        "all_df.rename(columns={'조식메뉴':'breakfast', '중식메뉴':'lunch', '석식메뉴':'dinner', '중식계':'lunch_y', '석식계':'dinner_y'}, inplace=True)\n",
        "all_df.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>breakfast</th>\n",
              "      <th>lunch</th>\n",
              "      <th>dinner</th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[된장찌개, 두유, 쥐어채무침, 찐빵, 호두죽]</td>\n",
              "      <td>[쇠불고기, 계란찜, 요구르트, 청포묵무침, 오징어찌개]</td>\n",
              "      <td>[건파래무침, 두부조림, 자반고등어구이, 육개장]</td>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[호박젓국찌개, 팥죽, 두유, 단호박샌드, 시래기조림]</td>\n",
              "      <td>[마늘쫑무침, 요구르트, 모둠소세지구이, 김치찌개, 가자미튀김]</td>\n",
              "      <td>[아삭고추무침, 바나나, 어묵국, 콩나물밥, 유산슬]</td>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[콩나물국, 표고버섯죽, 느타리호박볶음, 베이글, 두유]</td>\n",
              "      <td>[쫄면야채무침, 치킨핑거, 견과류조림, 팽이장국, 카레덮밥, 요구르트]</td>\n",
              "      <td>[고기전, 황태양념구이, 청국장찌개, 새송이버섯볶음]</td>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[닭죽, 멸치볶음, 두유, 근대국, 토마토샌드]</td>\n",
              "      <td>[부추전, 주꾸미볶음, 시금치나물, 쇠고기무국, 요구르트]</td>\n",
              "      <td>[군고구마, 미니김밥, 무피클, 우동, 멕시칸샐러드]</td>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[방풍나물, 재첩국, 두유, 와플, 쇠고기죽]</td>\n",
              "      <td>[우엉잡채, 요구르트, 떡국, 돈육씨앗강정, 청경채무침]</td>\n",
              "      <td>[차돌박이찌개, 콩나물무침, 감자소세지볶음, 닭갈비]</td>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>[두유, 팬케익, 명엽채무침, 찐빵, 감자찌개, 견과류죽]</td>\n",
              "      <td>[도토리묵무침, 시래기국, 양파절임, 훈제오리구이, 요구르트, 쌈무]</td>\n",
              "      <td>[과일샐러드, 맑은국, 참치회덮밥, 락교, 군만두]</td>\n",
              "      <td>1045.0</td>\n",
              "      <td>550.0</td>\n",
              "      <td>0.147251</td>\n",
              "      <td>0.054979</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.160323</td>\n",
              "      <td>0.797770</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>[야채샌드, 봄동된장국, 숙주나물, 고구마죽, 두유]</td>\n",
              "      <td>[요구르트, 돈육굴소스볶음, 꽃게탕, 유채나물, 옥수수전]</td>\n",
              "      <td>[미니함박, 깍두기, 김치콩나물국, 물파래무침, 어묵볶음]</td>\n",
              "      <td>909.0</td>\n",
              "      <td>598.0</td>\n",
              "      <td>0.149558</td>\n",
              "      <td>0.059977</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.035755</td>\n",
              "      <td>0.790465</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>[콩조림, 잣죽, 두유, 민물새우찌개, 치즈프레즐]</td>\n",
              "      <td>[콩나물무침, 요구르트, 연두부, 닭감자조림, 시금치국]</td>\n",
              "      <td>[등갈비김치찜, 임연수구이, 브로컬리초장, 홍합미역국]</td>\n",
              "      <td>1268.0</td>\n",
              "      <td>672.0</td>\n",
              "      <td>0.033449</td>\n",
              "      <td>0.078431</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.185313</td>\n",
              "      <td>0.888120</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>[마늘빵, 어묵국, 김구이, 두유, 단호박죽]</td>\n",
              "      <td>[오징어숙회무침, 취나물, 요구르트, 쇠고기무국, 탕수어]</td>\n",
              "      <td>[된장찌개, 쇠불고기, 봄동무침, 해파리겨자채]</td>\n",
              "      <td>1014.0</td>\n",
              "      <td>523.0</td>\n",
              "      <td>0.027682</td>\n",
              "      <td>0.090734</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.202230</td>\n",
              "      <td>0.881584</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>[흑임자죽, 무생채, 참치샌드, 두유, 북어계란국]</td>\n",
              "      <td>[통도라지구이, 치커리무침, 쇠고기장조림, 요구르트, 냉이된장국]</td>\n",
              "      <td>[요플레, 맑은국, 볶음밥, 새우또띠아, 쨔샤이무침]</td>\n",
              "      <td>916.0</td>\n",
              "      <td>588.0</td>\n",
              "      <td>0.029988</td>\n",
              "      <td>0.096117</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008843</td>\n",
              "      <td>0.873895</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          breakfast  ... dayofweek\n",
              "0        [된장찌개, 두유, 쥐어채무침, 찐빵, 호두죽]  ...         0\n",
              "1    [호박젓국찌개, 팥죽, 두유, 단호박샌드, 시래기조림]  ...         1\n",
              "2   [콩나물국, 표고버섯죽, 느타리호박볶음, 베이글, 두유]  ...         2\n",
              "3        [닭죽, 멸치볶음, 두유, 근대국, 토마토샌드]  ...         3\n",
              "4         [방풍나물, 재첩국, 두유, 와플, 쇠고기죽]  ...         4\n",
              "5  [두유, 팬케익, 명엽채무침, 찐빵, 감자찌개, 견과류죽]  ...         3\n",
              "6     [야채샌드, 봄동된장국, 숙주나물, 고구마죽, 두유]  ...         4\n",
              "7      [콩조림, 잣죽, 두유, 민물새우찌개, 치즈프레즐]  ...         0\n",
              "8         [마늘빵, 어묵국, 김구이, 두유, 단호박죽]  ...         1\n",
              "9      [흑임자죽, 무생채, 참치샌드, 두유, 북어계란국]  ...         2\n",
              "\n",
              "[10 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9jpcLHYOo41",
        "outputId": "830c36fa-e809-498d-f3aa-2af7c0aeeef6"
      },
      "source": [
        "all_df.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1255, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZOTPOgQz5zN"
      },
      "source": [
        "all_df.to_csv(PATH + 'all_df_processing.csv', index=False)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U8llYpvLN_Dm",
        "outputId": "644ebe24-f3c5-44be-e140-ae0d1bf6a94c"
      },
      "source": [
        "base_df = all_df.drop(['breakfast', 'lunch', 'dinner'], axis=1)\n",
        "b_train_df = base_df[:len(train_df)]\n",
        "b_test_df = base_df[len(train_df):].drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "print(b_train_df.shape, b_test_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1205, 12) (50, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImXwnP5-YC-c",
        "outputId": "1aa860d7-b7cf-41fb-be1b-8ce9d84a4e09"
      },
      "source": [
        "base_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1255 entries, 0 to 1254\n",
            "Data columns (total 12 columns):\n",
            " #   Column      Non-Null Count  Dtype  \n",
            "---  ------      --------------  -----  \n",
            " 0   lunch_y     1205 non-null   float64\n",
            " 1   dinner_y    1205 non-null   float64\n",
            " 2   vac_ratio   1255 non-null   float64\n",
            " 3   trip_ratio  1255 non-null   float64\n",
            " 4   home        1255 non-null   float64\n",
            " 5   extra       1255 non-null   float64\n",
            " 6   total       1255 non-null   float64\n",
            " 7   year        1255 non-null   int64  \n",
            " 8   month       1255 non-null   int64  \n",
            " 9   date        1255 non-null   int64  \n",
            " 10  week        1255 non-null   int64  \n",
            " 11  dayofweek   1255 non-null   int64  \n",
            "dtypes: float64(7), int64(5)\n",
            "memory usage: 167.5 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "CyxzG5YJX8S-",
        "outputId": "01dbe959-ba8e-4381-b1b8-b03a743006dd"
      },
      "source": [
        "base_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1205.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.00000</td>\n",
              "      <td>1255.000000</td>\n",
              "      <td>1255.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>890.334440</td>\n",
              "      <td>461.772614</td>\n",
              "      <td>0.055247</td>\n",
              "      <td>0.085630</td>\n",
              "      <td>0.017930</td>\n",
              "      <td>0.098451</td>\n",
              "      <td>0.841193</td>\n",
              "      <td>2018.169721</td>\n",
              "      <td>6.358566</td>\n",
              "      <td>15.89243</td>\n",
              "      <td>25.883665</td>\n",
              "      <td>2.007968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>209.505057</td>\n",
              "      <td>139.179202</td>\n",
              "      <td>0.049595</td>\n",
              "      <td>0.016669</td>\n",
              "      <td>0.039774</td>\n",
              "      <td>0.087486</td>\n",
              "      <td>0.056905</td>\n",
              "      <td>1.518847</td>\n",
              "      <td>3.470845</td>\n",
              "      <td>8.67904</td>\n",
              "      <td>15.164042</td>\n",
              "      <td>1.414191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>296.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008475</td>\n",
              "      <td>0.014576</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520288</td>\n",
              "      <td>2016.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>758.000000</td>\n",
              "      <td>406.000000</td>\n",
              "      <td>0.025727</td>\n",
              "      <td>0.076076</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001061</td>\n",
              "      <td>0.814270</td>\n",
              "      <td>2017.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>8.00000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>879.000000</td>\n",
              "      <td>483.000000</td>\n",
              "      <td>0.037074</td>\n",
              "      <td>0.087205</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.863602</td>\n",
              "      <td>2018.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>16.00000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1032.000000</td>\n",
              "      <td>545.000000</td>\n",
              "      <td>0.065336</td>\n",
              "      <td>0.097917</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.164824</td>\n",
              "      <td>0.882132</td>\n",
              "      <td>2019.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>23.00000</td>\n",
              "      <td>39.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1459.000000</td>\n",
              "      <td>905.000000</td>\n",
              "      <td>0.464164</td>\n",
              "      <td>0.121115</td>\n",
              "      <td>0.180678</td>\n",
              "      <td>0.387640</td>\n",
              "      <td>0.934087</td>\n",
              "      <td>2021.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>31.00000</td>\n",
              "      <td>52.000000</td>\n",
              "      <td>4.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           lunch_y     dinner_y  ...         week    dayofweek\n",
              "count  1205.000000  1205.000000  ...  1255.000000  1255.000000\n",
              "mean    890.334440   461.772614  ...    25.883665     2.007968\n",
              "std     209.505057   139.179202  ...    15.164042     1.414191\n",
              "min     296.000000     0.000000  ...     1.000000     0.000000\n",
              "25%     758.000000   406.000000  ...    12.000000     1.000000\n",
              "50%     879.000000   483.000000  ...    26.000000     2.000000\n",
              "75%    1032.000000   545.000000  ...    39.000000     3.000000\n",
              "max    1459.000000   905.000000  ...    52.000000     4.000000\n",
              "\n",
              "[8 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "28llXi8yOsix",
        "outputId": "946af01f-50bf-462e-cd2c-5e36d1261d30"
      },
      "source": [
        "b_train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>lunch_y</th>\n",
              "      <th>dinner_y</th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1039.0</td>\n",
              "      <td>331.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.057670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.091503</td>\n",
              "      <td>0.923106</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>867.0</td>\n",
              "      <td>560.0</td>\n",
              "      <td>0.019223</td>\n",
              "      <td>0.066513</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122645</td>\n",
              "      <td>0.914264</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1017.0</td>\n",
              "      <td>573.0</td>\n",
              "      <td>0.021530</td>\n",
              "      <td>0.069204</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.042676</td>\n",
              "      <td>0.909266</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>978.0</td>\n",
              "      <td>525.0</td>\n",
              "      <td>0.039985</td>\n",
              "      <td>0.084583</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.136486</td>\n",
              "      <td>0.875433</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>925.0</td>\n",
              "      <td>330.0</td>\n",
              "      <td>0.106882</td>\n",
              "      <td>0.069589</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.013072</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>2016</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   lunch_y  dinner_y  vac_ratio  trip_ratio  ...  month  date  week  dayofweek\n",
              "0   1039.0     331.0   0.019223    0.057670  ...      2     1     5          0\n",
              "1    867.0     560.0   0.019223    0.066513  ...      2     2     5          1\n",
              "2   1017.0     573.0   0.021530    0.069204  ...      2     3     5          2\n",
              "3    978.0     525.0   0.039985    0.084583  ...      2     4     5          3\n",
              "4    925.0     330.0   0.106882    0.069589  ...      2     5     5          4\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "yq3gPBCyOthV",
        "outputId": "b2d11856-c131-4cba-f160-34694c576788"
      },
      "source": [
        "b_test_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>vac_ratio</th>\n",
              "      <th>trip_ratio</th>\n",
              "      <th>home</th>\n",
              "      <th>extra</th>\n",
              "      <th>total</th>\n",
              "      <th>year</th>\n",
              "      <th>month</th>\n",
              "      <th>date</th>\n",
              "      <th>week</th>\n",
              "      <th>dayofweek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1205</th>\n",
              "      <td>0.029501</td>\n",
              "      <td>0.061012</td>\n",
              "      <td>0.120013</td>\n",
              "      <td>0.001676</td>\n",
              "      <td>0.789474</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>27</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1206</th>\n",
              "      <td>0.034864</td>\n",
              "      <td>0.071069</td>\n",
              "      <td>0.116661</td>\n",
              "      <td>0.137110</td>\n",
              "      <td>0.777405</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1207</th>\n",
              "      <td>0.090513</td>\n",
              "      <td>0.083473</td>\n",
              "      <td>0.098558</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.727456</td>\n",
              "      <td>2021</td>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>0.036936</td>\n",
              "      <td>0.052668</td>\n",
              "      <td>0.110123</td>\n",
              "      <td>0.183995</td>\n",
              "      <td>0.800274</td>\n",
              "      <td>2021</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1209</th>\n",
              "      <td>0.021204</td>\n",
              "      <td>0.063611</td>\n",
              "      <td>0.107387</td>\n",
              "      <td>0.155609</td>\n",
              "      <td>0.807798</td>\n",
              "      <td>2021</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      vac_ratio  trip_ratio      home     extra  ...  month  date  week  dayofweek\n",
              "1205   0.029501    0.061012  0.120013  0.001676  ...      1    27     4          2\n",
              "1206   0.034864    0.071069  0.116661  0.137110  ...      1    28     4          3\n",
              "1207   0.090513    0.083473  0.098558  0.000000  ...      1    29     4          4\n",
              "1208   0.036936    0.052668  0.110123  0.183995  ...      2     1     5          0\n",
              "1209   0.021204    0.063611  0.107387  0.155609  ...      2     2     5          1\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgx-WqyF80Vf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2976ba-bc98-4007-88b7-a82a6a486baa"
      },
      "source": [
        "lunch_X = b_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "lunch_y = b_train_df['lunch_y']\n",
        "dinner_X = b_train_df.drop(['lunch_y', 'dinner_y'], axis=1)\n",
        "dinner_y = b_train_df['dinner_y']\n",
        "for col in (lunch_X, lunch_y, dinner_X, dinner_y):\n",
        "    print(col.head(1))\n",
        "# 점심\n",
        "l_X_train, l_X_test, l_y_train, l_y_test = train_test_split(lunch_X, lunch_y, test_size=0.2, random_state=2021)\n",
        "# 저녁\n",
        "d_X_train, d_X_test, d_y_train, d_y_test = train_test_split(dinner_X, dinner_y, test_size=0.2, random_state=2021)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   vac_ratio  trip_ratio  home     extra  ...  month  date  week  dayofweek\n",
            "0   0.019223     0.05767   0.0  0.091503  ...      2     1     5          0\n",
            "\n",
            "[1 rows x 10 columns]\n",
            "0    1039.0\n",
            "Name: lunch_y, dtype: float64\n",
            "   vac_ratio  trip_ratio  home     extra  ...  month  date  week  dayofweek\n",
            "0   0.019223     0.05767   0.0  0.091503  ...      2     1     5          0\n",
            "\n",
            "[1 rows x 10 columns]\n",
            "0    331.0\n",
            "Name: dinner_y, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8wltZXuVaNX",
        "outputId": "de911167-e660-4802-bdac-b36d2ac767d9"
      },
      "source": [
        "col1 = [l_X_train, l_X_test, l_y_train, l_y_test]\n",
        "col2 = [d_X_train, d_X_test, d_y_train, d_y_test]\n",
        "for i, j in zip(col1, col2):\n",
        "    print(i.shape)\n",
        "    print(j.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(964, 10)\n",
            "(964, 10)\n",
            "(241, 10)\n",
            "(241, 10)\n",
            "(964,)\n",
            "(964,)\n",
            "(241,)\n",
            "(241,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BcqfiTFxaG9c"
      },
      "source": [
        "## 점심 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWnx4bk2WN4_",
        "outputId": "5c035d89-d46c-4e36-d074-06cfbf25d931"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=2021)\n",
        "n_repeats=3\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = xgb.DMatrix(l_X_train, label=l_y_train)\n",
        "    dtest = xgb.DMatrix(l_X_test, label=l_y_test)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror', # 회귀\n",
        "         'eval_metric': 'mae',\n",
        "         \"xgb_gpu_hist\": 1,\n",
        "         'verbosity': 0,\n",
        "         'booster': 'gbtree', # gradient boosting decision tree\n",
        "         'lambda': trial.suggest_loguniform('lambda', 1e-8, 1),\n",
        "         'alpha': trial.suggest_loguniform('alpha', 1e-8, 1),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
        "         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "         'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n",
        "         'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "    xgb2 = model.fit(l_X_train, l_y_train, eval_set=[(l_X_test, l_y_test)], verbose=0,\n",
        "                      eval_metric='mae')\n",
        "    mae = mean_absolute_error(l_y_test, xgb2.predict(l_X_test))\n",
        "\n",
        "    return mae\n",
        "        \n",
        "l_study_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_xgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:24:44,230]\u001b[0m A new study created in memory with name: no-name-a88e5a8f-534c-41e8-abf7-6b3d9a97a246\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:44,983]\u001b[0m Trial 0 finished with value: 918.3411489156272 and parameters: {'lambda': 0.0007044111641739534, 'alpha': 0.007361306311531573, 'max_depth': 3, 'eta': 3.1723761109634215e-06, 'gamma': 0.9504871519148276, 'n_estimators': 802, 'min_child_weight': 1, 'subsample': 0.7974053460591444}. Best is trial 0 with value: 918.3411489156272.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:46,062]\u001b[0m Trial 1 finished with value: 920.6297843038294 and parameters: {'lambda': 0.0019828237604565383, 'alpha': 0.01881399642343495, 'max_depth': 3, 'eta': 2.9415096718071926e-08, 'gamma': 0.5002279126949734, 'n_estimators': 1193, 'min_child_weight': 0, 'subsample': 0.6689793622007182}. Best is trial 0 with value: 918.3411489156272.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:47,542]\u001b[0m Trial 2 finished with value: 913.3117210736414 and parameters: {'lambda': 0.0008554559847076483, 'alpha': 0.5137409482657409, 'max_depth': 7, 'eta': 9.317229332510368e-06, 'gamma': 4.141540859021937e-05, 'n_estimators': 861, 'min_child_weight': 6, 'subsample': 0.47829570944696775}. Best is trial 2 with value: 913.3117210736414.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:48,768]\u001b[0m Trial 3 finished with value: 66.56477336962688 and parameters: {'lambda': 0.0004673391136992949, 'alpha': 6.464095867534913e-05, 'max_depth': 6, 'eta': 0.03844050387430893, 'gamma': 0.007207758310433094, 'n_estimators': 755, 'min_child_weight': 7, 'subsample': 0.7213206090997876}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:51,769]\u001b[0m Trial 4 finished with value: 273.61192290120107 and parameters: {'lambda': 0.042083801365359705, 'alpha': 4.322700584864719e-07, 'max_depth': 7, 'eta': 0.0008741945531044277, 'gamma': 2.5618220897682866e-06, 'n_estimators': 1398, 'min_child_weight': 6, 'subsample': 0.9834348413016252}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:53,821]\u001b[0m Trial 5 finished with value: 888.0750881685756 and parameters: {'lambda': 3.45030802333646e-05, 'alpha': 1.0245696441514804e-07, 'max_depth': 6, 'eta': 2.8463576586210582e-05, 'gamma': 0.2125771165026529, 'n_estimators': 1267, 'min_child_weight': 9, 'subsample': 0.6861216687720229}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:56,129]\u001b[0m Trial 6 finished with value: 918.4752982592681 and parameters: {'lambda': 0.0012434816947988851, 'alpha': 5.466023520987005e-06, 'max_depth': 8, 'eta': 2.761888724198144e-06, 'gamma': 2.88634156038091e-06, 'n_estimators': 861, 'min_child_weight': 2, 'subsample': 0.7262540977337992}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:58,183]\u001b[0m Trial 7 finished with value: 70.33486545926803 and parameters: {'lambda': 1.7255139207784372e-07, 'alpha': 1.2870516994090315e-05, 'max_depth': 7, 'eta': 0.061149501847645366, 'gamma': 3.241096716642312e-08, 'n_estimators': 1031, 'min_child_weight': 3, 'subsample': 0.774644544278894}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:24:59,356]\u001b[0m Trial 8 finished with value: 68.1853860562273 and parameters: {'lambda': 6.177011550458872e-05, 'alpha': 0.02449800360991601, 'max_depth': 3, 'eta': 0.09918695841159368, 'gamma': 0.016436710223451063, 'n_estimators': 1318, 'min_child_weight': 0, 'subsample': 0.6896215853214822}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:01,048]\u001b[0m Trial 9 finished with value: 67.28061470253338 and parameters: {'lambda': 0.02187549378501035, 'alpha': 1.5598018174190139e-06, 'max_depth': 5, 'eta': 0.06682151812048484, 'gamma': 0.002690489809534762, 'n_estimators': 1304, 'min_child_weight': 4, 'subsample': 0.536733171381199}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:02,781]\u001b[0m Trial 10 finished with value: 300.78902033255804 and parameters: {'lambda': 5.004452912467814e-07, 'alpha': 0.00022278607691920244, 'max_depth': 9, 'eta': 0.001592380784922668, 'gamma': 0.002099348519680594, 'n_estimators': 704, 'min_child_weight': 10, 'subsample': 0.9316994280483778}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:04,111]\u001b[0m Trial 11 finished with value: 111.3425189133007 and parameters: {'lambda': 0.8124300831619966, 'alpha': 1.0942499015468279e-08, 'max_depth': 5, 'eta': 0.8567161025170673, 'gamma': 0.003961951563814869, 'n_estimators': 1053, 'min_child_weight': 8, 'subsample': 0.5415362837471598}. Best is trial 3 with value: 66.56477336962688.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:05,985]\u001b[0m Trial 12 finished with value: 65.47171881584705 and parameters: {'lambda': 0.2767127371994452, 'alpha': 0.0002842771489056246, 'max_depth': 5, 'eta': 0.009813918251814603, 'gamma': 0.000475114248083701, 'n_estimators': 1407, 'min_child_weight': 4, 'subsample': 0.5616611239461566}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:07,652]\u001b[0m Trial 13 finished with value: 69.28092950211521 and parameters: {'lambda': 0.6973871675442999, 'alpha': 0.000284448495246753, 'max_depth': 5, 'eta': 0.002862468962969005, 'gamma': 0.00012550778351316517, 'n_estimators': 1473, 'min_child_weight': 7, 'subsample': 0.40970483992774775}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:09,241]\u001b[0m Trial 14 finished with value: 123.82464042441974 and parameters: {'lambda': 3.893349981715994e-06, 'alpha': 0.0009338630713115014, 'max_depth': 4, 'eta': 0.9132508070880299, 'gamma': 0.00015807915824965108, 'n_estimators': 1492, 'min_child_weight': 5, 'subsample': 0.5487032621606267}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:10,775]\u001b[0m Trial 15 finished with value: 783.4060237457148 and parameters: {'lambda': 0.05012678061570556, 'alpha': 2.919160899996243e-05, 'max_depth': 6, 'eta': 0.00016910018811554884, 'gamma': 0.045075163473762385, 'n_estimators': 958, 'min_child_weight': 4, 'subsample': 0.6005481927728954}. Best is trial 12 with value: 65.47171881584705.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:12,140]\u001b[0m Trial 16 finished with value: 64.20113527923205 and parameters: {'lambda': 0.2740768872902664, 'alpha': 0.0010646682248388827, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 1163, 'min_child_weight': 7, 'subsample': 0.8572080056927597}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:13,493]\u001b[0m Trial 17 finished with value: 67.40008760191098 and parameters: {'lambda': 0.9571509232692393, 'alpha': 0.32176538177297237, 'max_depth': 4, 'eta': 0.005376159201972576, 'gamma': 1.28114344075404e-05, 'n_estimators': 1160, 'min_child_weight': 5, 'subsample': 0.8751973272381632}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:14,941]\u001b[0m Trial 18 finished with value: 722.0406193396857 and parameters: {'lambda': 1.1919908806560655e-08, 'alpha': 0.0023069979929525183, 'max_depth': 4, 'eta': 0.00017392894544831955, 'gamma': 0.0005959691237442354, 'n_estimators': 1403, 'min_child_weight': 10, 'subsample': 0.4591840805254221}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:16,237]\u001b[0m Trial 19 finished with value: 65.34140153940288 and parameters: {'lambda': 0.18073547388026767, 'alpha': 0.06451499291835323, 'max_depth': 4, 'eta': 0.01786502548027726, 'gamma': 3.561841423988695e-08, 'n_estimators': 1172, 'min_child_weight': 3, 'subsample': 0.5933452151689637}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:17,570]\u001b[0m Trial 20 finished with value: 81.2812292328514 and parameters: {'lambda': 0.009409659062217815, 'alpha': 0.1590777309745813, 'max_depth': 4, 'eta': 0.3557242255687097, 'gamma': 2.3922179706674597e-08, 'n_estimators': 1137, 'min_child_weight': 2, 'subsample': 0.6169627695906035}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:19,215]\u001b[0m Trial 21 finished with value: 66.09441708133429 and parameters: {'lambda': 0.160756284633171, 'alpha': 0.0009663744947612753, 'max_depth': 5, 'eta': 0.010841969920209825, 'gamma': 1.965059027408609e-07, 'n_estimators': 1226, 'min_child_weight': 3, 'subsample': 0.583481689951347}. Best is trial 16 with value: 64.20113527923205.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:20,314]\u001b[0m Trial 22 finished with value: 63.76083867876361 and parameters: {'lambda': 0.2071617183903141, 'alpha': 0.028389630078426337, 'max_depth': 4, 'eta': 0.01843924924522292, 'gamma': 0.0006187858956920169, 'n_estimators': 1057, 'min_child_weight': 4, 'subsample': 0.49937190739488835}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:21,216]\u001b[0m Trial 23 finished with value: 71.47218784949591 and parameters: {'lambda': 0.007627032299773406, 'alpha': 0.03057499913770234, 'max_depth': 3, 'eta': 0.24268756816628095, 'gamma': 1.1831896282470302e-05, 'n_estimators': 1071, 'min_child_weight': 6, 'subsample': 0.4799326516041161}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:22,193]\u001b[0m Trial 24 finished with value: 413.13437700073746 and parameters: {'lambda': 0.13068318019504035, 'alpha': 0.05527248630619152, 'max_depth': 4, 'eta': 0.000825402305546864, 'gamma': 6.465945239353549e-07, 'n_estimators': 980, 'min_child_weight': 3, 'subsample': 0.4104983193192014}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:23,332]\u001b[0m Trial 25 finished with value: 65.65550820758234 and parameters: {'lambda': 0.9372120867902318, 'alpha': 0.006049924902092124, 'max_depth': 4, 'eta': 0.019968607075283362, 'gamma': 0.000547702263480113, 'n_estimators': 1118, 'min_child_weight': 8, 'subsample': 0.5026674168411607}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:24,142]\u001b[0m Trial 26 finished with value: 630.3086509229731 and parameters: {'lambda': 0.0047267670742643245, 'alpha': 0.9433949814102942, 'max_depth': 3, 'eta': 0.00039486518044311346, 'gamma': 1.969825957042282e-05, 'n_estimators': 969, 'min_child_weight': 2, 'subsample': 0.44727861528246615}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:25,440]\u001b[0m Trial 27 finished with value: 79.17071748472348 and parameters: {'lambda': 0.12946761480821614, 'alpha': 0.07633072612236762, 'max_depth': 4, 'eta': 0.2188051451663559, 'gamma': 0.028004999588453865, 'n_estimators': 1226, 'min_child_weight': 5, 'subsample': 0.5110743451156794}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:26,774]\u001b[0m Trial 28 finished with value: 67.60952011678229 and parameters: {'lambda': 0.045651976278035765, 'alpha': 0.0027919745946494534, 'max_depth': 5, 'eta': 0.003791399704997058, 'gamma': 0.00011311956795561258, 'n_estimators': 1104, 'min_child_weight': 4, 'subsample': 0.43712371626449087}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:27,748]\u001b[0m Trial 29 finished with value: 920.4169202738777 and parameters: {'lambda': 0.3251467993745164, 'alpha': 0.011527281447922762, 'max_depth': 3, 'eta': 2.6598991453494786e-07, 'gamma': 0.09725359248861774, 'n_estimators': 1012, 'min_child_weight': 1, 'subsample': 0.8609625459069349}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:28,553]\u001b[0m Trial 30 finished with value: 891.1256005773901 and parameters: {'lambda': 0.026309010256652807, 'alpha': 0.0048158470784652125, 'max_depth': 3, 'eta': 3.6637203141230605e-05, 'gamma': 0.001350819781320405, 'n_estimators': 897, 'min_child_weight': 7, 'subsample': 0.6355155580215037}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:30,375]\u001b[0m Trial 31 finished with value: 65.66313886840314 and parameters: {'lambda': 0.21823113903857247, 'alpha': 0.0007674714125633175, 'max_depth': 5, 'eta': 0.012604206949792552, 'gamma': 0.0002800994353654845, 'n_estimators': 1364, 'min_child_weight': 4, 'subsample': 0.5821410853305904}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:31,710]\u001b[0m Trial 32 finished with value: 65.47880611182248 and parameters: {'lambda': 0.2875238410485435, 'alpha': 9.626458786645682e-05, 'max_depth': 4, 'eta': 0.01840068848363384, 'gamma': 0.0006983690521101405, 'n_estimators': 1203, 'min_child_weight': 3, 'subsample': 0.6376430109191562}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:33,286]\u001b[0m Trial 33 finished with value: 66.53877809136735 and parameters: {'lambda': 0.8766589057109917, 'alpha': 0.1647192179899387, 'max_depth': 5, 'eta': 0.006298866217442768, 'gamma': 3.605108553097131e-05, 'n_estimators': 1171, 'min_child_weight': 1, 'subsample': 0.5682265072290751}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:34,614]\u001b[0m Trial 34 finished with value: 67.1737475889847 and parameters: {'lambda': 0.00026800490142671974, 'alpha': 0.00023165926065790214, 'max_depth': 4, 'eta': 0.03163077809397883, 'gamma': 0.006960980040910539, 'n_estimators': 1272, 'min_child_weight': 6, 'subsample': 0.5040631702445691}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:36,215]\u001b[0m Trial 35 finished with value: 196.59272696467357 and parameters: {'lambda': 0.0033033834013924375, 'alpha': 0.0021798012566677364, 'max_depth': 6, 'eta': 0.001700104649425605, 'gamma': 5.262820093234687e-05, 'n_estimators': 917, 'min_child_weight': 4, 'subsample': 0.659609945507105}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:38,023]\u001b[0m Trial 36 finished with value: 70.69596881787312 and parameters: {'lambda': 0.07612852097134915, 'alpha': 0.013745161698255681, 'max_depth': 5, 'eta': 0.12118806005489595, 'gamma': 4.554880814638298e-06, 'n_estimators': 1423, 'min_child_weight': 6, 'subsample': 0.5308684849500519}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:39,016]\u001b[0m Trial 37 finished with value: 566.9749211988013 and parameters: {'lambda': 0.016001288641054264, 'alpha': 0.4848633782842135, 'max_depth': 3, 'eta': 0.00045437426136759945, 'gamma': 0.6648418476038375, 'n_estimators': 1078, 'min_child_weight': 5, 'subsample': 0.7501982494312628}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:40,454]\u001b[0m Trial 38 finished with value: 68.37319857648794 and parameters: {'lambda': 0.37830766337833766, 'alpha': 2.3875873223855133e-05, 'max_depth': 4, 'eta': 0.033572943847321284, 'gamma': 0.00027971978355721667, 'n_estimators': 1344, 'min_child_weight': 1, 'subsample': 0.48364960002910196}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:41,917]\u001b[0m Trial 39 finished with value: 920.6512656624881 and parameters: {'lambda': 0.0013083025082882734, 'alpha': 0.0005963194974817163, 'max_depth': 6, 'eta': 1.453365910950332e-08, 'gamma': 0.013795691188164573, 'n_estimators': 790, 'min_child_weight': 3, 'subsample': 0.8091926383702137}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:44,427]\u001b[0m Trial 40 finished with value: 92.21004729844722 and parameters: {'lambda': 0.10643828543223426, 'alpha': 0.048721427763492614, 'max_depth': 7, 'eta': 0.5264933954023195, 'gamma': 0.0013080549493276036, 'n_estimators': 1258, 'min_child_weight': 2, 'subsample': 0.568864027814022}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:45,782]\u001b[0m Trial 41 finished with value: 64.8624306833101 and parameters: {'lambda': 0.4078147902543462, 'alpha': 0.0001225110703385133, 'max_depth': 4, 'eta': 0.01258267098415013, 'gamma': 0.000676656126643668, 'n_estimators': 1197, 'min_child_weight': 3, 'subsample': 0.6433697540019185}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:47,131]\u001b[0m Trial 42 finished with value: 65.68355994006905 and parameters: {'lambda': 0.41469291313219897, 'alpha': 5.958593343648572e-06, 'max_depth': 4, 'eta': 0.0074743184319847, 'gamma': 0.00032037877226054296, 'n_estimators': 1165, 'min_child_weight': 4, 'subsample': 0.6696656009022517}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:48,582]\u001b[0m Trial 43 finished with value: 70.90660684039484 and parameters: {'lambda': 0.05934943626914697, 'alpha': 6.424451137568253e-05, 'max_depth': 5, 'eta': 0.10182282439510772, 'gamma': 0.004589266119230406, 'n_estimators': 1019, 'min_child_weight': 3, 'subsample': 0.7052555724607684}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:50,370]\u001b[0m Trial 44 finished with value: 93.12601594410496 and parameters: {'lambda': 0.01732043201454145, 'alpha': 0.00033675868455918033, 'max_depth': 5, 'eta': 0.0023021868361587515, 'gamma': 6.036845199256942e-05, 'n_estimators': 1118, 'min_child_weight': 2, 'subsample': 0.970397622865187}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:51,709]\u001b[0m Trial 45 finished with value: 66.96586463263421 and parameters: {'lambda': 1.6665751034731995e-05, 'alpha': 4.1268641761415764e-05, 'max_depth': 4, 'eta': 0.04561606792786469, 'gamma': 0.0012749949992720854, 'n_estimators': 1211, 'min_child_weight': 4, 'subsample': 0.6025443314376345}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:52,808]\u001b[0m Trial 46 finished with value: 223.5998911244246 and parameters: {'lambda': 0.4163754932794567, 'alpha': 0.00018078657901974128, 'max_depth': 3, 'eta': 0.0011224113425333613, 'gamma': 0.0026877259921942545, 'n_estimators': 1295, 'min_child_weight': 7, 'subsample': 0.5531604400526776}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:54,035]\u001b[0m Trial 47 finished with value: 64.35296073691974 and parameters: {'lambda': 0.0005191714251864224, 'alpha': 8.12733873663608e-06, 'max_depth': 4, 'eta': 0.017284203813064784, 'gamma': 0.0001863794283045143, 'n_estimators': 1078, 'min_child_weight': 5, 'subsample': 0.8050531631466846}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:55,043]\u001b[0m Trial 48 finished with value: 71.0621180870721 and parameters: {'lambda': 3.724610945081388e-06, 'alpha': 3.7984606442848577e-06, 'max_depth': 3, 'eta': 0.1436178588128073, 'gamma': 0.0002142191213028585, 'n_estimators': 1088, 'min_child_weight': 8, 'subsample': 0.8503096346810791}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:56,278]\u001b[0m Trial 49 finished with value: 66.52909021654564 and parameters: {'lambda': 0.000397333699416699, 'alpha': 1.5278081275894802e-06, 'max_depth': 4, 'eta': 0.05427246005429505, 'gamma': 8.298139675573555e-05, 'n_estimators': 1052, 'min_child_weight': 0, 'subsample': 0.8155844991352281}. Best is trial 22 with value: 63.76083867876361.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdO9O4BxaMgy"
      },
      "source": [
        "## 저녁 튜닝"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeopNUEEaKea",
        "outputId": "4f27fddd-a51f-433e-b5bf-45cecf31305e"
      },
      "source": [
        "from optuna.samplers import TPESampler\n",
        "\n",
        "sampler = TPESampler(seed=2021)\n",
        "n_repeats=3\n",
        "\n",
        "def objective(trial):\n",
        "    dtrain = xgb.DMatrix(d_X_train, label=d_y_train)\n",
        "    dtest = xgb.DMatrix(d_X_test, label=d_y_test)\n",
        "\n",
        "    param = {\n",
        "        'objective': 'reg:squarederror', # 회귀\n",
        "         'eval_metric': 'mae',\n",
        "         \"xgb_gpu_hist\": 1,\n",
        "         'verbosity': 0,\n",
        "         'booster': 'gbtree', # gradient boosting decision tree\n",
        "         'lambda': trial.suggest_loguniform('lambda', 1e-8, 1),\n",
        "         'alpha': trial.suggest_loguniform('alpha', 1e-8, 1),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         \"eta\": trial.suggest_loguniform(\"eta\", 1e-8, 1.0),\n",
        "         \"gamma\": trial.suggest_loguniform(\"gamma\", 1e-8, 1.0),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 1500),\n",
        "         'min_child_weight': trial.suggest_int('min_child_weight', 0, 10),\n",
        "         'subsample': trial.suggest_loguniform('subsample', 0.4, 1)\n",
        "    }\n",
        "\n",
        "    model = xgb.XGBRegressor(**param)\n",
        "\n",
        "    xgb2 = model.fit(d_X_train, d_y_train, eval_set=[(d_X_test, d_y_test)], verbose=0,\n",
        "                      eval_metric='mae')\n",
        "    mae = mean_absolute_error(d_y_test, xgb2.predict(d_X_test))\n",
        "\n",
        "    return mae\n",
        "        \n",
        "d_study_xgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_xgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:25:56,311]\u001b[0m A new study created in memory with name: no-name-f426e753-abd1-4098-9403-ed9ac82358d3\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:57,075]\u001b[0m Trial 0 finished with value: 475.41611422913695 and parameters: {'lambda': 0.0007044111641739534, 'alpha': 0.007361306311531573, 'max_depth': 3, 'eta': 3.1723761109634215e-06, 'gamma': 0.9504871519148276, 'n_estimators': 802, 'min_child_weight': 1, 'subsample': 0.7974053460591444}. Best is trial 0 with value: 475.41611422913695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:58,167]\u001b[0m Trial 1 finished with value: 476.5668930421232 and parameters: {'lambda': 0.0019828237604565383, 'alpha': 0.01881399642343495, 'max_depth': 3, 'eta': 2.9415096718071926e-08, 'gamma': 0.5002279126949734, 'n_estimators': 1193, 'min_child_weight': 0, 'subsample': 0.6689793622007182}. Best is trial 0 with value: 475.41611422913695.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:25:59,697]\u001b[0m Trial 2 finished with value: 472.89822147199226 and parameters: {'lambda': 0.0008554559847076483, 'alpha': 0.5137409482657409, 'max_depth': 7, 'eta': 9.317229332510368e-06, 'gamma': 4.141540859021937e-05, 'n_estimators': 861, 'min_child_weight': 6, 'subsample': 0.47829570944696775}. Best is trial 2 with value: 472.89822147199226.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:00,929]\u001b[0m Trial 3 finished with value: 52.80681936968411 and parameters: {'lambda': 0.0004673391136992949, 'alpha': 6.464095867534913e-05, 'max_depth': 6, 'eta': 0.03844050387430893, 'gamma': 0.007207758310433094, 'n_estimators': 755, 'min_child_weight': 7, 'subsample': 0.7213206090997876}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:04,050]\u001b[0m Trial 4 finished with value: 152.3267437562161 and parameters: {'lambda': 0.042083801365359705, 'alpha': 4.322700584864719e-07, 'max_depth': 7, 'eta': 0.0008741945531044277, 'gamma': 2.5618220897682866e-06, 'n_estimators': 1398, 'min_child_weight': 6, 'subsample': 0.9834348413016252}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:06,178]\u001b[0m Trial 5 finished with value: 460.2370487693929 and parameters: {'lambda': 3.45030802333646e-05, 'alpha': 1.0245696441514804e-07, 'max_depth': 6, 'eta': 2.8463576586210582e-05, 'gamma': 0.2125771165026529, 'n_estimators': 1267, 'min_child_weight': 9, 'subsample': 0.6861216687720229}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:08,688]\u001b[0m Trial 6 finished with value: 475.4849389205335 and parameters: {'lambda': 0.0012434816947988851, 'alpha': 5.466023520987005e-06, 'max_depth': 8, 'eta': 2.761888724198144e-06, 'gamma': 2.88634156038091e-06, 'n_estimators': 861, 'min_child_weight': 2, 'subsample': 0.7262540977337992}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:10,713]\u001b[0m Trial 7 finished with value: 53.12981206252862 and parameters: {'lambda': 1.7255139207784372e-07, 'alpha': 1.2870516994090315e-05, 'max_depth': 7, 'eta': 0.061149501847645366, 'gamma': 3.241096716642312e-08, 'n_estimators': 1031, 'min_child_weight': 3, 'subsample': 0.774644544278894}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:11,907]\u001b[0m Trial 8 finished with value: 59.22441621835796 and parameters: {'lambda': 6.177011550458872e-05, 'alpha': 0.02449800360991601, 'max_depth': 3, 'eta': 0.09918695841159368, 'gamma': 0.016436710223451063, 'n_estimators': 1318, 'min_child_weight': 0, 'subsample': 0.6896215853214822}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:13,595]\u001b[0m Trial 9 finished with value: 53.98322954217428 and parameters: {'lambda': 0.02187549378501035, 'alpha': 1.5598018174190139e-06, 'max_depth': 5, 'eta': 0.06682151812048484, 'gamma': 0.002690489809534762, 'n_estimators': 1304, 'min_child_weight': 4, 'subsample': 0.536733171381199}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:15,332]\u001b[0m Trial 10 finished with value: 166.63734709919734 and parameters: {'lambda': 5.004452912467814e-07, 'alpha': 0.00022278607691920244, 'max_depth': 9, 'eta': 0.001592380784922668, 'gamma': 0.002099348519680594, 'n_estimators': 704, 'min_child_weight': 10, 'subsample': 0.9316994280483778}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:16,325]\u001b[0m Trial 11 finished with value: 75.39252892173673 and parameters: {'lambda': 6.303067996914016e-08, 'alpha': 0.00011284590212347822, 'max_depth': 5, 'eta': 0.8540676182150262, 'gamma': 2.960389675838704e-08, 'n_estimators': 1022, 'min_child_weight': 8, 'subsample': 0.8212404197422466}. Best is trial 3 with value: 52.80681936968411.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:17,720]\u001b[0m Trial 12 finished with value: 49.60530137224316 and parameters: {'lambda': 2.1115276911097155e-06, 'alpha': 1.053023456782512e-08, 'max_depth': 5, 'eta': 0.009329138801411624, 'gamma': 1.0428876644868658e-08, 'n_estimators': 1030, 'min_child_weight': 4, 'subsample': 0.5995868221527397}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:18,713]\u001b[0m Trial 13 finished with value: 85.74301532096388 and parameters: {'lambda': 3.029505671740337e-06, 'alpha': 2.3254850323359887e-08, 'max_depth': 5, 'eta': 0.002762356761921004, 'gamma': 0.00010187306410138822, 'n_estimators': 717, 'min_child_weight': 7, 'subsample': 0.565794121839103}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:19,673]\u001b[0m Trial 14 finished with value: 195.27811266673552 and parameters: {'lambda': 5.212926435362662e-06, 'alpha': 2.3226546685639463e-08, 'max_depth': 4, 'eta': 0.9132508070880299, 'gamma': 0.02286909713380436, 'n_estimators': 988, 'min_child_weight': 5, 'subsample': 0.4096051466204361}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:21,362]\u001b[0m Trial 15 finished with value: 395.96413413320835 and parameters: {'lambda': 0.3398163549712074, 'alpha': 0.0010321400334105644, 'max_depth': 6, 'eta': 0.00016910018811554884, 'gamma': 3.7500074859559315e-07, 'n_estimators': 1146, 'min_child_weight': 4, 'subsample': 0.5980303637521858}. Best is trial 12 with value: 49.60530137224316.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:22,341]\u001b[0m Trial 16 finished with value: 48.37489075878349 and parameters: {'lambda': 4.277979133843391e-06, 'alpha': 0.7749760386934557, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 940, 'min_child_weight': 7, 'subsample': 0.5002956340798566}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:23,320]\u001b[0m Trial 17 finished with value: 49.59407719339078 and parameters: {'lambda': 1.804464586382735e-06, 'alpha': 0.06256584421430596, 'max_depth': 4, 'eta': 0.005376159201972576, 'gamma': 8.68993960210861e-05, 'n_estimators': 952, 'min_child_weight': 5, 'subsample': 0.468648006410138}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:24,245]\u001b[0m Trial 18 finished with value: 425.38179205661 and parameters: {'lambda': 1.1772216526969938e-08, 'alpha': 0.9994246856858706, 'max_depth': 4, 'eta': 0.00012458048704042218, 'gamma': 0.00016468352252101143, 'n_estimators': 948, 'min_child_weight': 10, 'subsample': 0.40332500922435083}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:25,217]\u001b[0m Trial 19 finished with value: 476.4907484974604 and parameters: {'lambda': 2.0556174559931543e-05, 'alpha': 0.21987538004955565, 'max_depth': 4, 'eta': 2.164831945499237e-07, 'gamma': 0.0003867070164004027, 'n_estimators': 926, 'min_child_weight': 8, 'subsample': 0.46844809354771166}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:26,335]\u001b[0m Trial 20 finished with value: 48.99136212455781 and parameters: {'lambda': 3.1778711344601074e-08, 'alpha': 0.1084228639083024, 'max_depth': 4, 'eta': 0.006989318214660817, 'gamma': 2.1496960796248377e-05, 'n_estimators': 1104, 'min_child_weight': 5, 'subsample': 0.4644635260242569}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:27,462]\u001b[0m Trial 21 finished with value: 48.56101706413807 and parameters: {'lambda': 2.555192037586075e-08, 'alpha': 0.11611550144786228, 'max_depth': 4, 'eta': 0.008392157449483425, 'gamma': 6.100470859500051e-06, 'n_estimators': 1113, 'min_child_weight': 6, 'subsample': 0.4595537856813319}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:28,404]\u001b[0m Trial 22 finished with value: 340.3084225634816 and parameters: {'lambda': 1.627341649627836e-08, 'alpha': 0.1177102169557382, 'max_depth': 3, 'eta': 0.0003212314759473525, 'gamma': 9.785938310693853e-06, 'n_estimators': 1099, 'min_child_weight': 6, 'subsample': 0.5165671428147879}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:29,469]\u001b[0m Trial 23 finished with value: 48.903642250789154 and parameters: {'lambda': 5.596019783535093e-08, 'alpha': 0.0024442335233036305, 'max_depth': 4, 'eta': 0.017411679188438785, 'gamma': 4.031547520455439e-07, 'n_estimators': 1093, 'min_child_weight': 7, 'subsample': 0.4322241697354785}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:30,650]\u001b[0m Trial 24 finished with value: 65.13898644902399 and parameters: {'lambda': 2.2871858625155397e-07, 'alpha': 0.005758707088677027, 'max_depth': 4, 'eta': 0.3226255305406646, 'gamma': 3.180815361349332e-07, 'n_estimators': 1200, 'min_child_weight': 8, 'subsample': 0.42788697226847766}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:31,903]\u001b[0m Trial 25 finished with value: 49.54024992048493 and parameters: {'lambda': 7.40953537192926e-08, 'alpha': 0.0014365396163047842, 'max_depth': 5, 'eta': 0.019211481493860153, 'gamma': 4.691084394211817e-07, 'n_estimators': 1090, 'min_child_weight': 7, 'subsample': 0.431195865004134}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:33,142]\u001b[0m Trial 26 finished with value: 146.68508325473897 and parameters: {'lambda': 4.594266046202505e-07, 'alpha': 0.9623633840490177, 'max_depth': 3, 'eta': 0.0008733896032352066, 'gamma': 3.251227982097295e-06, 'n_estimators': 1487, 'min_child_weight': 9, 'subsample': 0.5098840384760587}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:34,335]\u001b[0m Trial 27 finished with value: 58.87532625554508 and parameters: {'lambda': 9.994284609160695e-06, 'alpha': 0.001090472722604927, 'max_depth': 4, 'eta': 0.21387733672238712, 'gamma': 1.2423419921608941e-07, 'n_estimators': 1188, 'min_child_weight': 7, 'subsample': 0.43840925916290835}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:35,452]\u001b[0m Trial 28 finished with value: 49.43363564241971 and parameters: {'lambda': 1.2294703093211583e-08, 'alpha': 0.3484092225614428, 'max_depth': 5, 'eta': 0.017590487328147743, 'gamma': 7.81726112519595e-06, 'n_estimators': 909, 'min_child_weight': 9, 'subsample': 0.503717173109283}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:36,160]\u001b[0m Trial 29 finished with value: 464.9184888289677 and parameters: {'lambda': 0.0001678788920671415, 'alpha': 0.008556452942455495, 'max_depth': 3, 'eta': 3.163462015935103e-05, 'gamma': 0.0006751371908833001, 'n_estimators': 815, 'min_child_weight': 6, 'subsample': 0.5427612959082263}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:36,982]\u001b[0m Trial 30 finished with value: 60.99465909538427 and parameters: {'lambda': 8.372731083265067e-07, 'alpha': 0.003492132415257511, 'max_depth': 3, 'eta': 0.2952491655766468, 'gamma': 1.4361781910861084e-06, 'n_estimators': 1057, 'min_child_weight': 8, 'subsample': 0.4013294186985629}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:38,147]\u001b[0m Trial 31 finished with value: 49.33993293635578 and parameters: {'lambda': 2.9574094687528395e-08, 'alpha': 0.03869215134728838, 'max_depth': 4, 'eta': 0.005112175719078412, 'gamma': 1.3802264419738717e-05, 'n_estimators': 1125, 'min_child_weight': 5, 'subsample': 0.4634306813340733}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:39,364]\u001b[0m Trial 32 finished with value: 250.0575388516628 and parameters: {'lambda': 7.802292995602489e-08, 'alpha': 0.09997556901862417, 'max_depth': 4, 'eta': 0.0005846769356512174, 'gamma': 3.440850648280193e-05, 'n_estimators': 1161, 'min_child_weight': 6, 'subsample': 0.4375681970222544}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:40,390]\u001b[0m Trial 33 finished with value: 49.670251156779244 and parameters: {'lambda': 3.255731254954529e-08, 'alpha': 0.012212843239462944, 'max_depth': 3, 'eta': 0.0209632201501692, 'gamma': 2.3465932927534822e-05, 'n_estimators': 1239, 'min_child_weight': 7, 'subsample': 0.49658741547877433}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:41,575]\u001b[0m Trial 34 finished with value: 61.75128170662401 and parameters: {'lambda': 1.0759705215678392e-08, 'alpha': 0.4478520547259499, 'max_depth': 4, 'eta': 0.0025950936838975737, 'gamma': 0.0005296817883751048, 'n_estimators': 1090, 'min_child_weight': 3, 'subsample': 0.45413897170598644}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:42,673]\u001b[0m Trial 35 finished with value: 49.02350790174176 and parameters: {'lambda': 1.3027332017585647e-07, 'alpha': 0.1343377711437904, 'max_depth': 5, 'eta': 0.008998777660171096, 'gamma': 9.383901458376211e-07, 'n_estimators': 872, 'min_child_weight': 5, 'subsample': 0.48893273115365804}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:44,034]\u001b[0m Trial 36 finished with value: 57.26218447151026 and parameters: {'lambda': 8.740497286545499e-07, 'alpha': 0.00035320812458775925, 'max_depth': 6, 'eta': 0.11718765143468748, 'gamma': 1.142227914779116e-07, 'n_estimators': 1003, 'min_child_weight': 6, 'subsample': 0.4172387544628144}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:44,686]\u001b[0m Trial 37 finished with value: 50.276839398744194 and parameters: {'lambda': 2.6922923375677746e-07, 'alpha': 0.035489631897735026, 'max_depth': 3, 'eta': 0.027464144019768915, 'gamma': 3.999722208934755e-06, 'n_estimators': 803, 'min_child_weight': 7, 'subsample': 0.45019431970130136}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:46,071]\u001b[0m Trial 38 finished with value: 446.9351382473198 and parameters: {'lambda': 0.00016514171967801477, 'alpha': 0.002825919257073743, 'max_depth': 4, 'eta': 5.438287567409407e-05, 'gamma': 0.0001964783196314695, 'n_estimators': 1222, 'min_child_weight': 4, 'subsample': 0.543531607775182}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:47,567]\u001b[0m Trial 39 finished with value: 156.79775720018569 and parameters: {'lambda': 0.0039153034190586725, 'alpha': 0.9397978108444817, 'max_depth': 5, 'eta': 0.0011276857065002299, 'gamma': 3.932400627001717e-05, 'n_estimators': 1058, 'min_child_weight': 6, 'subsample': 0.5774449863411818}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:48,773]\u001b[0m Trial 40 finished with value: 52.90647470308043 and parameters: {'lambda': 2.997854377785043e-08, 'alpha': 0.01858963899216021, 'max_depth': 3, 'eta': 0.003327304777907329, 'gamma': 0.0013591387058649446, 'n_estimators': 1373, 'min_child_weight': 3, 'subsample': 0.6295840409473126}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:49,857]\u001b[0m Trial 41 finished with value: 49.24867121906201 and parameters: {'lambda': 7.157486855516702e-08, 'alpha': 0.19019780531786146, 'max_depth': 5, 'eta': 0.010481735637286502, 'gamma': 1.2937970173218866e-06, 'n_estimators': 861, 'min_child_weight': 5, 'subsample': 0.48499778414992245}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:50,779]\u001b[0m Trial 42 finished with value: 52.85353423549921 and parameters: {'lambda': 1.46238192508433e-07, 'alpha': 0.0682076897217432, 'max_depth': 4, 'eta': 0.04581872898973004, 'gamma': 9.358188987148226e-07, 'n_estimators': 878, 'min_child_weight': 5, 'subsample': 0.48074435143551575}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:52,028]\u001b[0m Trial 43 finished with value: 48.691231852250475 and parameters: {'lambda': 1.5201381415709392e-07, 'alpha': 2.014883142394282e-05, 'max_depth': 5, 'eta': 0.009086426929558045, 'gamma': 1.1224628174885833e-07, 'n_estimators': 974, 'min_child_weight': 7, 'subsample': 0.5212690606787962}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:53,128]\u001b[0m Trial 44 finished with value: 344.4506517782251 and parameters: {'lambda': 2.9824023272254985e-08, 'alpha': 2.1286662771300246e-05, 'max_depth': 4, 'eta': 0.0003447145451748578, 'gamma': 6.536232546011515e-08, 'n_estimators': 980, 'min_child_weight': 8, 'subsample': 0.5210138851516327}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:54,382]\u001b[0m Trial 45 finished with value: 56.27455974911258 and parameters: {'lambda': 8.723587117264894e-07, 'alpha': 3.5214876592102657e-06, 'max_depth': 5, 'eta': 0.09562654300179624, 'gamma': 1.1121742270173979e-08, 'n_estimators': 1058, 'min_child_weight': 7, 'subsample': 0.4489719837515521}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:55,578]\u001b[0m Trial 46 finished with value: 65.37667595004639 and parameters: {'lambda': 3.2504999691040626e-07, 'alpha': 1.1734207361172968e-06, 'max_depth': 4, 'eta': 0.0022904798811346377, 'gamma': 5.2261027173581985e-08, 'n_estimators': 1138, 'min_child_weight': 6, 'subsample': 0.5272594427998025}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:57,473]\u001b[0m Trial 47 finished with value: 473.86223707604705 and parameters: {'lambda': 1.3053754674255718e-05, 'alpha': 1.4948419293456199e-05, 'max_depth': 6, 'eta': 5.041522275900231e-06, 'gamma': 7.965606783698402e-06, 'n_estimators': 1173, 'min_child_weight': 7, 'subsample': 0.562156886304678}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:58,662]\u001b[0m Trial 48 finished with value: 48.588130460240535 and parameters: {'lambda': 6.154927864206695e-06, 'alpha': 4.600883546057284e-05, 'max_depth': 5, 'eta': 0.008250568532058423, 'gamma': 0.006812827202181092, 'n_estimators': 985, 'min_child_weight': 8, 'subsample': 0.4187504781088081}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n",
            "\u001b[32m[I 2021-07-03 09:26:59,763]\u001b[0m Trial 49 finished with value: 52.877577271204274 and parameters: {'lambda': 6.0945618374501046e-05, 'alpha': 4.590801432439927e-05, 'max_depth': 5, 'eta': 0.04652959753438826, 'gamma': 0.0681698714929842, 'n_estimators': 982, 'min_child_weight': 8, 'subsample': 0.4148593553123528}. Best is trial 16 with value: 48.37489075878349.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reaA8c3PYrdV",
        "outputId": "5699fd3b-503f-4f5a-def0-c2fb241eb741"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_xgb.best_trial.value, l_study_xgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_xgb.best_trial.value, d_study_xgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunch Best Trial: score 63.76083867876361,\n",
            "params {'lambda': 0.2071617183903141, 'alpha': 0.028389630078426337, 'max_depth': 4, 'eta': 0.01843924924522292, 'gamma': 0.0006187858956920169, 'n_estimators': 1057, 'min_child_weight': 4, 'subsample': 0.49937190739488835}\n",
            "Dinner Best Trial: score 48.37489075878349,\n",
            "params {'lambda': 4.277979133843391e-06, 'alpha': 0.7749760386934557, 'max_depth': 4, 'eta': 0.008152801312229872, 'gamma': 0.0004569100347069903, 'n_estimators': 940, 'min_child_weight': 7, 'subsample': 0.5002956340798566}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHcWGWdrYwDq",
        "outputId": "c308153a-83af-41f6-9501-5b0c8ace3de7"
      },
      "source": [
        "l_trial = l_study_xgb.best_trial\n",
        "lunch_xgb_params = l_trial.params\n",
        "lunch_xgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.028389630078426337,\n",
              " 'eta': 0.01843924924522292,\n",
              " 'gamma': 0.0006187858956920169,\n",
              " 'lambda': 0.2071617183903141,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 4,\n",
              " 'n_estimators': 1057,\n",
              " 'subsample': 0.49937190739488835}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tanTBeVNaxJ7",
        "outputId": "c4d687c0-ae1f-4c7b-d8a5-4dec249cedb1"
      },
      "source": [
        "d_trial = d_study_xgb.best_trial\n",
        "dinner_xgb_params = d_trial.params\n",
        "dinner_xgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'alpha': 0.7749760386934557,\n",
              " 'eta': 0.008152801312229872,\n",
              " 'gamma': 0.0004569100347069903,\n",
              " 'lambda': 4.277979133843391e-06,\n",
              " 'max_depth': 4,\n",
              " 'min_child_weight': 7,\n",
              " 'n_estimators': 940,\n",
              " 'subsample': 0.5002956340798566}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "36jaPySDY0nv",
        "outputId": "062bab30-662b-4f73-802a-80269266d501"
      },
      "source": [
        "lunch_xgb_model = xgb.XGBRegressor(**lunch_xgb_params)\n",
        "lunch_xgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['lunch_y'], eval_metric='mae')\n",
        "lunch_xgb_pred = lunch_xgb_model.predict(b_test_df)\n",
        "\n",
        "dinner_xgb_model = xgb.XGBRegressor(**dinner_xgb_params)\n",
        "dinner_xgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['dinner_y'], eval_metric='mae')\n",
        "dinner_xgb_pred = dinner_xgb_model.predict(b_test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/xgboost/data.py:114: UserWarning:\n",
            "\n",
            "Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWohQ8qaZ9wL",
        "outputId": "f29a7a3e-de8b-46a9-8651-02338312d05c"
      },
      "source": [
        "lunch_xgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 994.9242 ,  919.6314 ,  605.23694, 1255.2684 ,  953.8549 ,\n",
              "        953.3689 ,  935.91516,  638.6148 , 1266.0553 , 1023.3267 ,\n",
              "        772.17834, 1308.999  , 1125.0316 , 1085.5706 ,  900.0972 ,\n",
              "        662.7512 , 1278.9653 , 1040.3416 ,  913.692  ,  841.9029 ,\n",
              "        606.52356, 1106.5292 ,  977.1059 ,  908.995  ,  634.20026,\n",
              "       1312.0895 , 1161.6604 , 1005.5013 ,  942.61676,  675.2395 ,\n",
              "       1290.7927 ,  987.2304 , 1046.5105 ,  902.4546 ,  636.1867 ,\n",
              "       1207.2196 ,  988.4212 ,  915.2831 ,  811.3775 ,  581.08905,\n",
              "       1183.7014 ,  968.84216,  920.5803 ,  814.6066 ,  592.08185,\n",
              "       1213.3978 , 1046.8319 ,  956.9798 ,  852.40784,  593.6707 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mi8UttR0bMw9",
        "outputId": "10d98aa0-3500-4898-d8bd-4185454da8c5"
      },
      "source": [
        "dinner_xgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([217.5145 , 403.2052 , 246.3411 , 498.18445, 433.41296, 386.7222 ,\n",
              "       420.97272, 353.72974, 584.9701 , 487.35437, 195.0462 , 732.1324 ,\n",
              "       623.68756, 409.78995, 498.08823, 375.6728 , 644.32776, 605.3887 ,\n",
              "       329.30945, 496.8572 , 315.1558 , 645.8691 , 442.0772 , 549.3749 ,\n",
              "       387.9646 , 656.3688 , 643.18024, 424.5477 , 509.7587 , 332.6781 ,\n",
              "       731.80963, 560.68146, 424.51163, 471.8689 , 309.854  , 647.3817 ,\n",
              "       581.3698 , 311.83316, 445.98022, 273.98315, 629.8954 , 552.66876,\n",
              "       218.0934 , 407.56396, 311.27405, 612.31433, 538.4524 , 407.3398 ,\n",
              "       458.80402, 302.66708], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "bNcxNpW2eQSs",
        "outputId": "ddc0b811-d44e-41b6-9f72-3799b0e21511"
      },
      "source": [
        "plt.barh(lunch_X.columns, lunch_xgb_model.feature_importances_)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 10 artists>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 148
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "NawDqo4omFV9",
        "outputId": "63f357c0-5a69-46e4-d8b0-94ccf42aa29e"
      },
      "source": [
        "submission_df = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "submission_df['중식계'] = lunch_xgb_pred\n",
        "submission_df['석식계'] = dinner_xgb_pred\n",
        "submission_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>994.924194</td>\n",
              "      <td>217.514496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>919.631409</td>\n",
              "      <td>403.205200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>605.236938</td>\n",
              "      <td>246.341095</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>1255.268433</td>\n",
              "      <td>498.184448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>953.854919</td>\n",
              "      <td>433.412964</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자          중식계         석식계\n",
              "0  2021-01-27   994.924194  217.514496\n",
              "1  2021-01-28   919.631409  403.205200\n",
              "2  2021-01-29   605.236938  246.341095\n",
              "3  2021-02-01  1255.268433  498.184448\n",
              "4  2021-02-02   953.854919  433.412964"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZsmF9cMmg1M"
      },
      "source": [
        "submission_df.to_csv(PATH + 'xgb_base2.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VhHGixtouZye"
      },
      "source": [
        "# LightGBM\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_OQA5Nlst9k",
        "outputId": "5243e89a-8b76-473a-a83e-070d5fc68ef0"
      },
      "source": [
        " sampler = TPESampler(seed=10)\n",
        " def objective(trial):\n",
        "\n",
        "     param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "     lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "     lgbm = lgbm_regr.fit(l_X_train, l_y_train , eval_set = [(l_X_train, l_y_train)], verbose=False)\n",
        "     mae = mean_absolute_error(l_y_test, lgbm.predict(l_X_test))\n",
        "     return mae\n",
        "        \n",
        "l_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "l_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:30,528]\u001b[0m A new study created in memory with name: no-name-59ec12cc-7867-4c2e-9c15-69635dc58dfe\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5348779873185086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5348779873185086\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4656004675652718e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4656004675652718e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5188377188557745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5188377188557745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.014810344004555135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014810344004555135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:31,890]\u001b[0m Trial 0 finished with value: 168.08836813627406 and parameters: {'lambda_l1': 0.014810344004555135, 'lambda_l2': 1.4656004675652718e-08, 'num_leaves': 254, 'max_depth': 8, 'n_estimators': 2844, 'feature_fraction': 0.5348779873185086, 'bagging_fraction': 0.5188377188557745, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 0 with value: 168.08836813627406.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8875725769912681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875725769912681\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003040034742832493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003040034742832493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7675156400976328, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675156400976328\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.090008568091192e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.090008568091192e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:32,646]\u001b[0m Trial 1 finished with value: 68.2245823893435 and parameters: {'lambda_l1': 5.090008568091192e-08, 'lambda_l2': 0.003040034742832493, 'num_leaves': 382, 'max_depth': 3, 'n_estimators': 2902, 'feature_fraction': 0.8875725769912681, 'bagging_fraction': 0.7675156400976328, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8044801690398071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8044801690398071\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005207224083783965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005207224083783965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6650999046537976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6650999046537976\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21988367156694333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21988367156694333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:33,185]\u001b[0m Trial 2 finished with value: 73.67051522366995 and parameters: {'lambda_l1': 0.21988367156694333, 'lambda_l2': 0.005207224083783965, 'num_leaves': 218, 'max_depth': 3, 'n_estimators': 2305, 'feature_fraction': 0.8044801690398071, 'bagging_fraction': 0.6650999046537976, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.945189328485201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.945189328485201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015965313667163816, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015965313667163816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5915416533931271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5915416533931271\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00012738137732610437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00012738137732610437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:34,549]\u001b[0m Trial 3 finished with value: 70.80919003939353 and parameters: {'lambda_l1': 0.00012738137732610437, 'lambda_l2': 0.0015965313667163816, 'num_leaves': 241, 'max_depth': 8, 'n_estimators': 2943, 'feature_fraction': 0.945189328485201, 'bagging_fraction': 0.5915416533931271, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8915721974020412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8915721974020412\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.042604022999246406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042604022999246406\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5193685238072874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5193685238072874\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.163471763379958e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.163471763379958e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:35,633]\u001b[0m Trial 4 finished with value: 78.27357533205227 and parameters: {'lambda_l1': 8.163471763379958e-08, 'lambda_l2': 0.042604022999246406, 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 3055, 'feature_fraction': 0.8915721974020412, 'bagging_fraction': 0.5193685238072874, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6355175463679523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6355175463679523\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3318126555538504e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3318126555538504e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4560762247351902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4560762247351902\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010893853540963833, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010893853540963833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:36,233]\u001b[0m Trial 5 finished with value: 167.7616691311999 and parameters: {'lambda_l1': 0.010893853540963833, 'lambda_l2': 2.3318126555538504e-06, 'num_leaves': 354, 'max_depth': 5, 'n_estimators': 1409, 'feature_fraction': 0.6355175463679523, 'bagging_fraction': 0.4560762247351902, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5508244805242356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508244805242356\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.3581671060741645, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3581671060741645\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7584229889385306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7584229889385306\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.1828116394242723e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1828116394242723e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:37,607]\u001b[0m Trial 6 finished with value: 80.8529806502653 and parameters: {'lambda_l1': 1.1828116394242723e-05, 'lambda_l2': 0.3581671060741645, 'num_leaves': 396, 'max_depth': 6, 'n_estimators': 4253, 'feature_fraction': 0.5508244805242356, 'bagging_fraction': 0.7584229889385306, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5984315871892792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5984315871892792\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0618360930258403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0618360930258403e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8642981777263575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8642981777263575\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005267577135346555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005267577135346555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:38,123]\u001b[0m Trial 7 finished with value: 168.088589155563 and parameters: {'lambda_l1': 0.0005267577135346555, 'lambda_l2': 2.0618360930258403e-08, 'num_leaves': 144, 'max_depth': 3, 'n_estimators': 2013, 'feature_fraction': 0.5984315871892792, 'bagging_fraction': 0.8642981777263575, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8579443522862087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8579443522862087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012357458041729475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012357458041729475\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.926857985634915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.926857985634915\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.3068536483753737e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3068536483753737e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:39,328]\u001b[0m Trial 8 finished with value: 73.11536522279569 and parameters: {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:45:39,519]\u001b[0m Trial 9 finished with value: 134.33553544821945 and parameters: {'lambda_l1': 0.0001281542517497079, 'lambda_l2': 0.0006063078395671604, 'num_leaves': 106, 'max_depth': 5, 'n_estimators': 809, 'feature_fraction': 0.5818375363906209, 'bagging_fraction': 0.5452455252421164, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5818375363906209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5818375363906209\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0006063078395671604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006063078395671604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5452455252421164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5452455252421164\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0001281542517497079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001281542517497079\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7649442484108072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7649442484108072\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.010479332494921e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.010479332494921e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7880669612015251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7880669612015251\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6785873892849563e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6785873892849563e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:40,422]\u001b[0m Trial 10 finished with value: 167.0844404823267 and parameters: {'lambda_l1': 1.6785873892849563e-08, 'lambda_l2': 3.010479332494921e-06, 'num_leaves': 341, 'max_depth': 4, 'n_estimators': 3558, 'feature_fraction': 0.7649442484108072, 'bagging_fraction': 0.7880669612015251, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9991122238129395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9991122238129395\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.61939793719469e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.61939793719469e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585514682875593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585514682875593\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.9826258759353e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.9826258759353e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:45,589]\u001b[0m Trial 11 finished with value: 156.59219682334364 and parameters: {'lambda_l1': 8.9826258759353e-07, 'lambda_l2': 2.61939793719469e-05, 'num_leaves': 287, 'max_depth': 9, 'n_estimators': 3632, 'feature_fraction': 0.9991122238129395, 'bagging_fraction': 0.6585514682875593, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9922869658927289, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9922869658927289\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.030766178350701442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030766178350701442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6307116556352568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6307116556352568\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0010032552297938406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010032552297938406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:46,945]\u001b[0m Trial 12 finished with value: 74.22269527381991 and parameters: {'lambda_l1': 0.0010032552297938406, 'lambda_l2': 0.030766178350701442, 'num_leaves': 311, 'max_depth': 9, 'n_estimators': 2453, 'feature_fraction': 0.9922869658927289, 'bagging_fraction': 0.6307116556352568, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.41844661211798795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41844661211798795\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00015468424548794194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00015468424548794194\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.995679260563783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995679260563783\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.9886276185414409e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9886276185414409e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:50,725]\u001b[0m Trial 13 finished with value: 127.29066396606996 and parameters: {'lambda_l1': 1.9886276185414409e-07, 'lambda_l2': 0.00015468424548794194, 'num_leaves': 387, 'max_depth': 7, 'n_estimators': 3556, 'feature_fraction': 0.41844661211798795, 'bagging_fraction': 0.995679260563783, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9290019894565231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9290019894565231\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9773722751809201, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9773722751809201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.750295356922126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750295356922126\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8821931552561775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8821931552561775e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:51,767]\u001b[0m Trial 14 finished with value: 99.66860342433343 and parameters: {'lambda_l1': 2.8821931552561775e-05, 'lambda_l2': 0.9773722751809201, 'num_leaves': 219, 'max_depth': 8, 'n_estimators': 1756, 'feature_fraction': 0.9290019894565231, 'bagging_fraction': 0.750295356922126, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7285367937084144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7285367937084144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.013133026541985783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013133026541985783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5989394570002292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5989394570002292\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0885522537644062e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0885522537644062e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:52,796]\u001b[0m Trial 15 finished with value: 70.82605705543644 and parameters: {'lambda_l1': 1.0885522537644062e-08, 'lambda_l2': 0.013133026541985783, 'num_leaves': 28, 'max_depth': 7, 'n_estimators': 3001, 'feature_fraction': 0.7285367937084144, 'bagging_fraction': 0.5989394570002292, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9592124084612702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9592124084612702\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4319355308173353e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4319355308173353e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4072835615446248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4072835615446248\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006757265265334436, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006757265265334436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:53,431]\u001b[0m Trial 16 finished with value: 160.12652768803702 and parameters: {'lambda_l1': 0.006757265265334436, 'lambda_l2': 3.4319355308173353e-05, 'num_leaves': 266, 'max_depth': 8, 'n_estimators': 2583, 'feature_fraction': 0.9592124084612702, 'bagging_fraction': 0.4072835615446248, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8133108831404763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8133108831404763\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.19063245323117958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19063245323117958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8359226382813782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8359226382813782\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4749952337893574, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4749952337893574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:55,146]\u001b[0m Trial 17 finished with value: 75.38167518057081 and parameters: {'lambda_l1': 0.4749952337893574, 'lambda_l2': 0.19063245323117958, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3778, 'feature_fraction': 0.8133108831404763, 'bagging_fraction': 0.8359226382813782, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9049229635967819, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049229635967819\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0038947940771188595, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0038947940771188595\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7133340635208179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7133340635208179\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.162473122054843e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.162473122054843e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:57,195]\u001b[0m Trial 18 finished with value: 68.25159573580302 and parameters: {'lambda_l1': 6.162473122054843e-05, 'lambda_l2': 0.0038947940771188595, 'num_leaves': 63, 'max_depth': 6, 'n_estimators': 4956, 'feature_fraction': 0.9049229635967819, 'bagging_fraction': 0.7133340635208179, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6694741937620116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694741937620116\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00017090105110919117, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017090105110919117\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7102315542302928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7102315542302928\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.558826272807897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.558826272807897e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:45:58,996]\u001b[0m Trial 19 finished with value: 112.40814959477449 and parameters: {'lambda_l1': 1.558826272807897e-06, 'lambda_l2': 0.00017090105110919117, 'num_leaves': 88, 'max_depth': 6, 'n_estimators': 4901, 'feature_fraction': 0.6694741937620116, 'bagging_fraction': 0.7102315542302928, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8830528000666321, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8830528000666321\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005399216065659898, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005399216065659898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981126396254016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981126396254016\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.577543141688918e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.577543141688918e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:00,363]\u001b[0m Trial 20 finished with value: 69.81787156647374 and parameters: {'lambda_l1': 8.577543141688918e-08, 'lambda_l2': 0.005399216065659898, 'num_leaves': 57, 'max_depth': 4, 'n_estimators': 4914, 'feature_fraction': 0.8830528000666321, 'bagging_fraction': 0.8981126396254016, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.857435008067406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.857435008067406\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007085955366616683, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007085955366616683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9541820918740274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9541820918740274\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.3637885278895198e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3637885278895198e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:01,715]\u001b[0m Trial 21 finished with value: 72.07557604930169 and parameters: {'lambda_l1': 1.3637885278895198e-07, 'lambda_l2': 0.007085955366616683, 'num_leaves': 64, 'max_depth': 4, 'n_estimators': 4860, 'feature_fraction': 0.857435008067406, 'bagging_fraction': 0.9541820918740274, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8896961138855114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8896961138855114\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1440306548213092, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1440306548213092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8719479103382188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8719479103382188\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.117885124030037e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.117885124030037e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:02,909]\u001b[0m Trial 22 finished with value: 79.82043715241834 and parameters: {'lambda_l1': 1.117885124030037e-08, 'lambda_l2': 0.1440306548213092, 'num_leaves': 49, 'max_depth': 4, 'n_estimators': 4443, 'feature_fraction': 0.8896961138855114, 'bagging_fraction': 0.8719479103382188, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.797585277438908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797585277438908\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00286882006173601, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00286882006173601\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8340528532958039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8340528532958039\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.4206330381302414e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4206330381302414e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:04,272]\u001b[0m Trial 23 finished with value: 70.4626573453293 and parameters: {'lambda_l1': 4.4206330381302414e-07, 'lambda_l2': 0.00286882006173601, 'num_leaves': 180, 'max_depth': 4, 'n_estimators': 4963, 'feature_fraction': 0.797585277438908, 'bagging_fraction': 0.8340528532958039, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9082255084550924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9082255084550924\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0004910285788460762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004910285788460762\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7131579822782704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7131579822782704\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3211789024334075e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3211789024334075e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:05,747]\u001b[0m Trial 24 finished with value: 83.35697281125313 and parameters: {'lambda_l1': 5.3211789024334075e-08, 'lambda_l2': 0.0004910285788460762, 'num_leaves': 114, 'max_depth': 5, 'n_estimators': 4092, 'feature_fraction': 0.9082255084550924, 'bagging_fraction': 0.7131579822782704, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8525645941267856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8525645941267856\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03461833732184834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03461833732184834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9186670114421646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9186670114421646\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.627153081826672e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.627153081826672e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:06,914]\u001b[0m Trial 25 finished with value: 73.17524387491486 and parameters: {'lambda_l1': 9.627153081826672e-06, 'lambda_l2': 0.03461833732184834, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4664, 'feature_fraction': 0.8525645941267856, 'bagging_fraction': 0.9186670114421646, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:46:07,080]\u001b[0m Trial 26 finished with value: 165.79104295387324 and parameters: {'lambda_l1': 3.617654385059622e-08, 'lambda_l2': 3.21018883782884e-05, 'num_leaves': 3, 'max_depth': 6, 'n_estimators': 922, 'feature_fraction': 0.7208616598347489, 'bagging_fraction': 0.8051944778854442, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7208616598347489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7208616598347489\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.21018883782884e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.21018883782884e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8051944778854442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8051944778854442\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.617654385059622e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.617654385059622e-08\n",
            "[LightGBM] [Warning] feature_fraction is set=0.978823807556182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.978823807556182\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007623884125877974, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007623884125877974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7586217334270403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7586217334270403\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.5202198902227952e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5202198902227952e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:08,380]\u001b[0m Trial 27 finished with value: 68.31447930080783 and parameters: {'lambda_l1': 3.5202198902227952e-06, 'lambda_l2': 0.007623884125877974, 'num_leaves': 37, 'max_depth': 4, 'n_estimators': 3928, 'feature_fraction': 0.978823807556182, 'bagging_fraction': 0.7586217334270403, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.983261850180457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.983261850180457\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.06153077564466302, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06153077564466302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7478638044077373, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7478638044077373\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.6713597683041026e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6713597683041026e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:10,110]\u001b[0m Trial 28 finished with value: 73.37228600318362 and parameters: {'lambda_l1': 2.6713597683041026e-05, 'lambda_l2': 0.06153077564466302, 'num_leaves': 30, 'max_depth': 5, 'n_estimators': 4001, 'feature_fraction': 0.983261850180457, 'bagging_fraction': 0.7478638044077373, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4467465826790745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4467465826790745\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00036096976564155053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00036096976564155053\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.672679532303821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672679532303821\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0008411698071306363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008411698071306363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:10,646]\u001b[0m Trial 29 finished with value: 118.29020494785748 and parameters: {'lambda_l1': 0.0008411698071306363, 'lambda_l2': 0.00036096976564155053, 'num_leaves': 3, 'max_depth': 7, 'n_estimators': 3251, 'feature_fraction': 0.4467465826790745, 'bagging_fraction': 0.672679532303821, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9485639040314328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9485639040314328\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9330264060741632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9330264060741632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7907252411951584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7907252411951584\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.238685512402491e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.238685512402491e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:11,503]\u001b[0m Trial 30 finished with value: 103.94130317065652 and parameters: {'lambda_l1': 5.238685512402491e-06, 'lambda_l2': 0.9330264060741632, 'num_leaves': 113, 'max_depth': 6, 'n_estimators': 3337, 'feature_fraction': 0.9485639040314328, 'bagging_fraction': 0.7907252411951584, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8456039224486642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456039224486642\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.011681208582494407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011681208582494407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.712747098225565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.712747098225565\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.1883465875895746e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.1883465875895746e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:12,701]\u001b[0m Trial 31 finished with value: 69.7380789666321 and parameters: {'lambda_l1': 4.1883465875895746e-07, 'lambda_l2': 0.011681208582494407, 'num_leaves': 48, 'max_depth': 4, 'n_estimators': 3929, 'feature_fraction': 0.8456039224486642, 'bagging_fraction': 0.712747098225565, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 1 with value: 68.2245823893435.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7753150238928894, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7753150238928894\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.009843900884763586, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.009843900884763586\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7033300787966946, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7033300787966946\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.933439446112878e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.933439446112878e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:13,676]\u001b[0m Trial 32 finished with value: 67.77519885281583 and parameters: {'lambda_l1': 6.933439446112878e-07, 'lambda_l2': 0.009843900884763586, 'num_leaves': 95, 'max_depth': 3, 'n_estimators': 3908, 'feature_fraction': 0.7753150238928894, 'bagging_fraction': 0.7033300787966946, 'bagging_freq': 5, 'min_child_samples': 38}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.770900940963003, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.770900940963003\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002349695193344987, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002349695193344987\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6634893230016086, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6634893230016086\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.2412526223857976e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.2412526223857976e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:14,367]\u001b[0m Trial 33 finished with value: 69.45398282377937 and parameters: {'lambda_l1': 1.2412526223857976e-06, 'lambda_l2': 0.002349695193344987, 'num_leaves': 83, 'max_depth': 3, 'n_estimators': 2728, 'feature_fraction': 0.770900940963003, 'bagging_fraction': 0.6634893230016086, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8109698082278238, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8109698082278238\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012066704851500033, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012066704851500033\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7483332174356776, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7483332174356776\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.17692130190505e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.17692130190505e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:14,977]\u001b[0m Trial 34 finished with value: 83.75409302531094 and parameters: {'lambda_l1': 4.17692130190505e-05, 'lambda_l2': 0.0012066704851500033, 'num_leaves': 3, 'max_depth': 3, 'n_estimators': 3280, 'feature_fraction': 0.8109698082278238, 'bagging_fraction': 0.7483332174356776, 'bagging_freq': 4, 'min_child_samples': 39}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9242757612217026, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9242757612217026\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.015967861745800383, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.015967861745800383\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6201655597229148, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6201655597229148\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.0925815695686164e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.0925815695686164e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:16,094]\u001b[0m Trial 35 finished with value: 69.40967229893587 and parameters: {'lambda_l1': 3.0925815695686164e-06, 'lambda_l2': 0.015967861745800383, 'num_leaves': 125, 'max_depth': 3, 'n_estimators': 4367, 'feature_fraction': 0.9242757612217026, 'bagging_fraction': 0.6201655597229148, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9689976512076663, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9689976512076663\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.07728059834779502, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07728059834779502\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6801525970382309, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6801525970382309\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023035809545990645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023035809545990645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:16,705]\u001b[0m Trial 36 finished with value: 73.53002867018955 and parameters: {'lambda_l1': 0.00023035809545990645, 'lambda_l2': 0.07728059834779502, 'num_leaves': 180, 'max_depth': 3, 'n_estimators': 2298, 'feature_fraction': 0.9689976512076663, 'bagging_fraction': 0.6801525970382309, 'bagging_freq': 7, 'min_child_samples': 49}. Best is trial 32 with value: 67.77519885281583.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6799896576109249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6799896576109249\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00365564781783537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00365564781783537\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8187865503548556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8187865503548556\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.897285138402634e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.897285138402634e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:18,158]\u001b[0m Trial 37 finished with value: 65.47700831201462 and parameters: {'lambda_l1': 2.897285138402634e-07, 'lambda_l2': 0.00365564781783537, 'num_leaves': 89, 'max_depth': 4, 'n_estimators': 4170, 'feature_fraction': 0.6799896576109249, 'bagging_fraction': 0.8187865503548556, 'bagging_freq': 6, 'min_child_samples': 20}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6305292483774079, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6305292483774079\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003988285558711171, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003988285558711171\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8382605479138953, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8382605479138953\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.08103833153437869, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08103833153437869\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:19,940]\u001b[0m Trial 38 finished with value: 66.5813999610059 and parameters: {'lambda_l1': 0.08103833153437869, 'lambda_l2': 0.003988285558711171, 'num_leaves': 92, 'max_depth': 5, 'n_estimators': 4176, 'feature_fraction': 0.6305292483774079, 'bagging_fraction': 0.8382605479138953, 'bagging_freq': 4, 'min_child_samples': 16}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6545599625224247, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6545599625224247\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.001337440493169704, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001337440493169704\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7917239084922874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7917239084922874\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.037113466772583696, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.037113466772583696\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:21,950]\u001b[0m Trial 39 finished with value: 68.12675992566635 and parameters: {'lambda_l1': 0.037113466772583696, 'lambda_l2': 0.001337440493169704, 'num_leaves': 88, 'max_depth': 5, 'n_estimators': 4235, 'feature_fraction': 0.6545599625224247, 'bagging_fraction': 0.7917239084922874, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6572490301121829, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6572490301121829\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=6.147565815887788e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.147565815887788e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.843060285702147, subsample=1.0 will be ignored. Current value: bagging_fraction=0.843060285702147\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.1417946961934106, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.1417946961934106\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:24,272]\u001b[0m Trial 40 finished with value: 143.37047718438484 and parameters: {'lambda_l1': 0.1417946961934106, 'lambda_l2': 6.147565815887788e-05, 'num_leaves': 94, 'max_depth': 5, 'n_estimators': 4189, 'feature_fraction': 0.6572490301121829, 'bagging_fraction': 0.843060285702147, 'bagging_freq': 3, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5008785352223447, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5008785352223447\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0010207127649325268, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0010207127649325268\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8111461277730591, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8111461277730591\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.08071802526324821, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.08071802526324821\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:26,367]\u001b[0m Trial 41 finished with value: 69.76879254295662 and parameters: {'lambda_l1': 0.08071802526324821, 'lambda_l2': 0.0010207127649325268, 'num_leaves': 137, 'max_depth': 5, 'n_estimators': 4541, 'feature_fraction': 0.5008785352223447, 'bagging_fraction': 0.8111461277730591, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6199850230421977, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6199850230421977\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00029869339456754064, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00029869339456754064\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.780120266936442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.780120266936442\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.045271139462990745, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.045271139462990745\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:28,158]\u001b[0m Trial 42 finished with value: 91.99812603562292 and parameters: {'lambda_l1': 0.045271139462990745, 'lambda_l2': 0.00029869339456754064, 'num_leaves': 154, 'max_depth': 4, 'n_estimators': 4708, 'feature_fraction': 0.6199850230421977, 'bagging_fraction': 0.780120266936442, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6861358517564461, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6861358517564461\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0024930661642714636, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0024930661642714636\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8818295361642811, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8818295361642811\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.5816949305710215, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.5816949305710215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:30,016]\u001b[0m Trial 43 finished with value: 65.95959291306336 and parameters: {'lambda_l1': 0.5816949305710215, 'lambda_l2': 0.0024930661642714636, 'num_leaves': 91, 'max_depth': 5, 'n_estimators': 3732, 'feature_fraction': 0.6861358517564461, 'bagging_fraction': 0.8818295361642811, 'bagging_freq': 5, 'min_child_samples': 12}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.694649336674864, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.694649336674864\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015487656142613338, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015487656142613338\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8904034644477615, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8904034644477615\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004451746482349735, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004451746482349735\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:32,242]\u001b[0m Trial 44 finished with value: 66.0828160805039 and parameters: {'lambda_l1': 0.004451746482349735, 'lambda_l2': 0.0015487656142613338, 'num_leaves': 94, 'max_depth': 5, 'n_estimators': 4296, 'feature_fraction': 0.694649336674864, 'bagging_fraction': 0.8904034644477615, 'bagging_freq': 4, 'min_child_samples': 10}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6912647996827558, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6912647996827558\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0022411177210349058, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0022411177210349058\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9692205317999674, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9692205317999674\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.97409057602456, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.97409057602456\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:34,298]\u001b[0m Trial 45 finished with value: 66.54621693719595 and parameters: {'lambda_l1': 0.97409057602456, 'lambda_l2': 0.0022411177210349058, 'num_leaves': 129, 'max_depth': 5, 'n_estimators': 3497, 'feature_fraction': 0.6912647996827558, 'bagging_fraction': 0.9692205317999674, 'bagging_freq': 3, 'min_child_samples': 5}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6907857835302649, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6907857835302649\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.002293955675468287, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.002293955675468287\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9840748545936858, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9840748545936858\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.911386313567701, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.911386313567701\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:36,254]\u001b[0m Trial 46 finished with value: 65.73120733570985 and parameters: {'lambda_l1': 0.911386313567701, 'lambda_l2': 0.002293955675468287, 'num_leaves': 126, 'max_depth': 5, 'n_estimators': 3688, 'feature_fraction': 0.6907857835302649, 'bagging_fraction': 0.9840748545936858, 'bagging_freq': 3, 'min_child_samples': 9}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6894291505793495, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6894291505793495\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.243222172966609e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.243222172966609e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9933142319078488, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9933142319078488\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.7723357260574077, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.7723357260574077\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:38,548]\u001b[0m Trial 47 finished with value: 164.691249318221 and parameters: {'lambda_l1': 0.7723357260574077, 'lambda_l2': 8.243222172966609e-06, 'num_leaves': 124, 'max_depth': 5, 'n_estimators': 3741, 'feature_fraction': 0.6894291505793495, 'bagging_fraction': 0.9933142319078488, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7077509504125293, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7077509504125293\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0007823504051765781, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007823504051765781\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9652566499690516, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9652566499690516\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.3077454896035705, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.3077454896035705\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:41,821]\u001b[0m Trial 48 finished with value: 72.76843848555889 and parameters: {'lambda_l1': 0.3077454896035705, 'lambda_l2': 0.0007823504051765781, 'num_leaves': 206, 'max_depth': 6, 'n_estimators': 3469, 'feature_fraction': 0.7077509504125293, 'bagging_fraction': 0.9652566499690516, 'bagging_freq': 2, 'min_child_samples': 5}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7369313686767585, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7369313686767585\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.7820979457059422e-07, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.7820979457059422e-07\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.958285045095513, subsample=1.0 will be ignored. Current value: bagging_fraction=0.958285045095513\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006696428249371957, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006696428249371957\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:44,079]\u001b[0m Trial 49 finished with value: 168.01796158020093 and parameters: {'lambda_l1': 0.006696428249371957, 'lambda_l2': 1.7820979457059422e-07, 'num_leaves': 177, 'max_depth': 5, 'n_estimators': 3740, 'feature_fraction': 0.7369313686767585, 'bagging_fraction': 0.958285045095513, 'bagging_freq': 2, 'min_child_samples': 11}. Best is trial 37 with value: 65.47700831201462.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_2eGQpfu4Ng",
        "outputId": "4607f217-6ce0-447c-c473-c7743b05ad0b"
      },
      "source": [
        " sampler = TPESampler(seed=10)\n",
        " def objective(trial):\n",
        "\n",
        "     param = {\n",
        "         'objective': 'regression', # 회귀\n",
        "         'metric': 'mae', \n",
        "         'verbosity': -1,\n",
        "         'boosting_type': 'gbdt', # gradient boosting decision tree\n",
        "         'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 1),\n",
        "         'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'num_leaves': trial.suggest_int('num_leaves', 2, 400),\n",
        "         'max_depth': trial.suggest_int('max_depth',3, 9),\n",
        "         'learning_rate': trial.suggest_loguniform('lambda_l2', 1e-8, 1),\n",
        "         'n_estimators': trial.suggest_int('n_estimators', 700, 5000),\n",
        "         'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
        "         'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
        "         'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
        "         'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
        "     }\n",
        "\n",
        "     lgbm_regr = lgb.LGBMRegressor(**param)\n",
        "     lgbm = lgbm_regr.fit(d_X_train, d_y_train , eval_set = [(d_X_train, d_y_train)], verbose=False)\n",
        "     mae = mean_absolute_error(d_y_test, lgbm.predict(d_X_test))\n",
        "     return mae\n",
        "        \n",
        "d_study_lgb = optuna.create_study(direction='minimize', sampler=sampler)\n",
        "d_study_lgb.optimize(objective, n_trials=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:44,107]\u001b[0m A new study created in memory with name: no-name-cd3128f2-f5f0-4590-9022-efe33303dc43\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5348779873185086, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5348779873185086\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.4656004675652718e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.4656004675652718e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5188377188557745, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5188377188557745\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.014810344004555135, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.014810344004555135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:45,565]\u001b[0m Trial 0 finished with value: 102.27037999911656 and parameters: {'lambda_l1': 0.014810344004555135, 'lambda_l2': 1.4656004675652718e-08, 'num_leaves': 254, 'max_depth': 8, 'n_estimators': 2844, 'feature_fraction': 0.5348779873185086, 'bagging_fraction': 0.5188377188557745, 'bagging_freq': 6, 'min_child_samples': 21}. Best is trial 0 with value: 102.27037999911656.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8875725769912681, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8875725769912681\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.003040034742832493, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.003040034742832493\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7675156400976328, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7675156400976328\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.090008568091192e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.090008568091192e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:46,345]\u001b[0m Trial 1 finished with value: 50.88575106945658 and parameters: {'lambda_l1': 5.090008568091192e-08, 'lambda_l2': 0.003040034742832493, 'num_leaves': 382, 'max_depth': 3, 'n_estimators': 2902, 'feature_fraction': 0.8875725769912681, 'bagging_fraction': 0.7675156400976328, 'bagging_freq': 6, 'min_child_samples': 33}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8044801690398071, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8044801690398071\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005207224083783965, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005207224083783965\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6650999046537976, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6650999046537976\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.21988367156694333, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.21988367156694333\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:46,881]\u001b[0m Trial 2 finished with value: 56.39333400168846 and parameters: {'lambda_l1': 0.21988367156694333, 'lambda_l2': 0.005207224083783965, 'num_leaves': 218, 'max_depth': 3, 'n_estimators': 2305, 'feature_fraction': 0.8044801690398071, 'bagging_fraction': 0.6650999046537976, 'bagging_freq': 4, 'min_child_samples': 64}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.945189328485201, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.945189328485201\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015965313667163816, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015965313667163816\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5915416533931271, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5915416533931271\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00012738137732610437, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00012738137732610437\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:48,277]\u001b[0m Trial 3 finished with value: 52.97165045557678 and parameters: {'lambda_l1': 0.00012738137732610437, 'lambda_l2': 0.0015965313667163816, 'num_leaves': 241, 'max_depth': 8, 'n_estimators': 2943, 'feature_fraction': 0.945189328485201, 'bagging_fraction': 0.5915416533931271, 'bagging_freq': 1, 'min_child_samples': 33}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8915721974020412, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8915721974020412\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.042604022999246406, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.042604022999246406\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5193685238072874, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5193685238072874\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.163471763379958e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.163471763379958e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:49,387]\u001b[0m Trial 4 finished with value: 57.87950806994835 and parameters: {'lambda_l1': 8.163471763379958e-08, 'lambda_l2': 0.042604022999246406, 'num_leaves': 20, 'max_depth': 7, 'n_estimators': 3055, 'feature_fraction': 0.8915721974020412, 'bagging_fraction': 0.5193685238072874, 'bagging_freq': 6, 'min_child_samples': 38}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6355175463679523, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6355175463679523\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.3318126555538504e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.3318126555538504e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4560762247351902, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4560762247351902\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.010893853540963833, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.010893853540963833\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:50,003]\u001b[0m Trial 5 finished with value: 102.09636719794584 and parameters: {'lambda_l1': 0.010893853540963833, 'lambda_l2': 2.3318126555538504e-06, 'num_leaves': 354, 'max_depth': 5, 'n_estimators': 1409, 'feature_fraction': 0.6355175463679523, 'bagging_fraction': 0.4560762247351902, 'bagging_freq': 6, 'min_child_samples': 19}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5508244805242356, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5508244805242356\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.3581671060741645, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.3581671060741645\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7584229889385306, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7584229889385306\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.1828116394242723e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.1828116394242723e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:51,413]\u001b[0m Trial 6 finished with value: 59.6568606510387 and parameters: {'lambda_l1': 1.1828116394242723e-05, 'lambda_l2': 0.3581671060741645, 'num_leaves': 396, 'max_depth': 6, 'n_estimators': 4253, 'feature_fraction': 0.5508244805242356, 'bagging_fraction': 0.7584229889385306, 'bagging_freq': 7, 'min_child_samples': 56}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5984315871892792, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5984315871892792\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.0618360930258403e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.0618360930258403e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8642981777263575, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8642981777263575\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0005267577135346555, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0005267577135346555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:51,920]\u001b[0m Trial 7 finished with value: 102.2706028172915 and parameters: {'lambda_l1': 0.0005267577135346555, 'lambda_l2': 2.0618360930258403e-08, 'num_leaves': 144, 'max_depth': 3, 'n_estimators': 2013, 'feature_fraction': 0.5984315871892792, 'bagging_fraction': 0.8642981777263575, 'bagging_freq': 1, 'min_child_samples': 46}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8579443522862087, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8579443522862087\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0012357458041729475, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0012357458041729475\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.926857985634915, subsample=1.0 will be ignored. Current value: bagging_fraction=0.926857985634915\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.3068536483753737e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.3068536483753737e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:53,077]\u001b[0m Trial 8 finished with value: 56.0349205798433 and parameters: {'lambda_l1': 3.3068536483753737e-06, 'lambda_l2': 0.0012357458041729475, 'num_leaves': 140, 'max_depth': 3, 'n_estimators': 4484, 'feature_fraction': 0.8579443522862087, 'bagging_fraction': 0.926857985634915, 'bagging_freq': 3, 'min_child_samples': 63}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:46:53,281]\u001b[0m Trial 9 finished with value: 84.91992666873385 and parameters: {'lambda_l1': 0.0001281542517497079, 'lambda_l2': 0.0006063078395671604, 'num_leaves': 106, 'max_depth': 5, 'n_estimators': 809, 'feature_fraction': 0.5818375363906209, 'bagging_fraction': 0.5452455252421164, 'bagging_freq': 4, 'min_child_samples': 59}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.5818375363906209, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5818375363906209\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0006063078395671604, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0006063078395671604\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5452455252421164, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5452455252421164\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0001281542517497079, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0001281542517497079\n",
            "[LightGBM] [Warning] feature_fraction is set=0.7649442484108072, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7649442484108072\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.010479332494921e-06, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.010479332494921e-06\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7880669612015251, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7880669612015251\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.6785873892849563e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.6785873892849563e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:54,255]\u001b[0m Trial 10 finished with value: 101.75072755084977 and parameters: {'lambda_l1': 1.6785873892849563e-08, 'lambda_l2': 3.010479332494921e-06, 'num_leaves': 341, 'max_depth': 4, 'n_estimators': 3558, 'feature_fraction': 0.7649442484108072, 'bagging_fraction': 0.7880669612015251, 'bagging_freq': 5, 'min_child_samples': 90}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9991122238129395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9991122238129395\n",
            "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
            "[LightGBM] [Warning] lambda_l2 is set=2.61939793719469e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=2.61939793719469e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6585514682875593, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6585514682875593\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.9826258759353e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.9826258759353e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:46:59,794]\u001b[0m Trial 11 finished with value: 95.91307094748466 and parameters: {'lambda_l1': 8.9826258759353e-07, 'lambda_l2': 2.61939793719469e-05, 'num_leaves': 287, 'max_depth': 9, 'n_estimators': 3632, 'feature_fraction': 0.9991122238129395, 'bagging_fraction': 0.6585514682875593, 'bagging_freq': 1, 'min_child_samples': 7}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9922869658927289, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9922869658927289\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.030766178350701442, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.030766178350701442\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.6307116556352568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6307116556352568\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0010032552297938406, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0010032552297938406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:01,190]\u001b[0m Trial 12 finished with value: 53.83919682450579 and parameters: {'lambda_l1': 0.0010032552297938406, 'lambda_l2': 0.030766178350701442, 'num_leaves': 311, 'max_depth': 9, 'n_estimators': 2453, 'feature_fraction': 0.9922869658927289, 'bagging_fraction': 0.6307116556352568, 'bagging_freq': 2, 'min_child_samples': 31}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.41844661211798795, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.41844661211798795\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00015468424548794194, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00015468424548794194\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.995679260563783, subsample=1.0 will be ignored. Current value: bagging_fraction=0.995679260563783\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.9886276185414409e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.9886276185414409e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:04,505]\u001b[0m Trial 13 finished with value: 77.94775249292114 and parameters: {'lambda_l1': 1.9886276185414409e-07, 'lambda_l2': 0.00015468424548794194, 'num_leaves': 387, 'max_depth': 7, 'n_estimators': 3556, 'feature_fraction': 0.41844661211798795, 'bagging_fraction': 0.995679260563783, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9290019894565231, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9290019894565231\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9773722751809201, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9773722751809201\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.750295356922126, subsample=1.0 will be ignored. Current value: bagging_fraction=0.750295356922126\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8821931552561775e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8821931552561775e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:05,540]\u001b[0m Trial 14 finished with value: 72.58409443808755 and parameters: {'lambda_l1': 2.8821931552561775e-05, 'lambda_l2': 0.9773722751809201, 'num_leaves': 219, 'max_depth': 8, 'n_estimators': 1756, 'feature_fraction': 0.9290019894565231, 'bagging_fraction': 0.750295356922126, 'bagging_freq': 7, 'min_child_samples': 28}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7285367937084144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7285367937084144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.013133026541985783, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.013133026541985783\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.5989394570002292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.5989394570002292\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.0885522537644062e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.0885522537644062e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:06,620]\u001b[0m Trial 15 finished with value: 54.25703202570445 and parameters: {'lambda_l1': 1.0885522537644062e-08, 'lambda_l2': 0.013133026541985783, 'num_leaves': 28, 'max_depth': 7, 'n_estimators': 3001, 'feature_fraction': 0.7285367937084144, 'bagging_fraction': 0.5989394570002292, 'bagging_freq': 5, 'min_child_samples': 44}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9592124084612702, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9592124084612702\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.4319355308173353e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.4319355308173353e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.4072835615446248, subsample=1.0 will be ignored. Current value: bagging_fraction=0.4072835615446248\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.006757265265334436, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.006757265265334436\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:07,209]\u001b[0m Trial 16 finished with value: 98.04227709076831 and parameters: {'lambda_l1': 0.006757265265334436, 'lambda_l2': 3.4319355308173353e-05, 'num_leaves': 266, 'max_depth': 8, 'n_estimators': 2583, 'feature_fraction': 0.9592124084612702, 'bagging_fraction': 0.4072835615446248, 'bagging_freq': 2, 'min_child_samples': 73}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8133108831404763, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8133108831404763\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.19063245323117958, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.19063245323117958\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8359226382813782, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8359226382813782\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.4749952337893574, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.4749952337893574\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:08,922]\u001b[0m Trial 17 finished with value: 55.187261816113676 and parameters: {'lambda_l1': 0.4749952337893574, 'lambda_l2': 0.19063245323117958, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3778, 'feature_fraction': 0.8133108831404763, 'bagging_fraction': 0.8359226382813782, 'bagging_freq': 5, 'min_child_samples': 19}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9049229635967819, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9049229635967819\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0038947940771188595, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0038947940771188595\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7133340635208179, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7133340635208179\n",
            "[LightGBM] [Warning] lambda_l1 is set=6.162473122054843e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=6.162473122054843e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:10,999]\u001b[0m Trial 18 finished with value: 51.788319311042265 and parameters: {'lambda_l1': 6.162473122054843e-05, 'lambda_l2': 0.0038947940771188595, 'num_leaves': 63, 'max_depth': 6, 'n_estimators': 4956, 'feature_fraction': 0.9049229635967819, 'bagging_fraction': 0.7133340635208179, 'bagging_freq': 7, 'min_child_samples': 35}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6694741937620116, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6694741937620116\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00017090105110919117, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00017090105110919117\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7102315542302928, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7102315542302928\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.558826272807897e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.558826272807897e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:12,857]\u001b[0m Trial 19 finished with value: 74.03208675888746 and parameters: {'lambda_l1': 1.558826272807897e-06, 'lambda_l2': 0.00017090105110919117, 'num_leaves': 88, 'max_depth': 6, 'n_estimators': 4901, 'feature_fraction': 0.6694741937620116, 'bagging_fraction': 0.7102315542302928, 'bagging_freq': 7, 'min_child_samples': 44}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8830528000666321, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8830528000666321\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.005399216065659898, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.005399216065659898\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8981126396254016, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8981126396254016\n",
            "[LightGBM] [Warning] lambda_l1 is set=8.577543141688918e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=8.577543141688918e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:14,264]\u001b[0m Trial 20 finished with value: 52.39016149622366 and parameters: {'lambda_l1': 8.577543141688918e-08, 'lambda_l2': 0.005399216065659898, 'num_leaves': 57, 'max_depth': 4, 'n_estimators': 4914, 'feature_fraction': 0.8830528000666321, 'bagging_fraction': 0.8981126396254016, 'bagging_freq': 6, 'min_child_samples': 75}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.857435008067406, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.857435008067406\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007085955366616683, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007085955366616683\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9541820918740274, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9541820918740274\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.3637885278895198e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.3637885278895198e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:15,644]\u001b[0m Trial 21 finished with value: 53.49626144822936 and parameters: {'lambda_l1': 1.3637885278895198e-07, 'lambda_l2': 0.007085955366616683, 'num_leaves': 64, 'max_depth': 4, 'n_estimators': 4860, 'feature_fraction': 0.857435008067406, 'bagging_fraction': 0.9541820918740274, 'bagging_freq': 6, 'min_child_samples': 89}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8896961138855114, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8896961138855114\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.1440306548213092, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.1440306548213092\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8719479103382188, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8719479103382188\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.117885124030037e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.117885124030037e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:16,849]\u001b[0m Trial 22 finished with value: 62.680730159191256 and parameters: {'lambda_l1': 1.117885124030037e-08, 'lambda_l2': 0.1440306548213092, 'num_leaves': 49, 'max_depth': 4, 'n_estimators': 4443, 'feature_fraction': 0.8896961138855114, 'bagging_fraction': 0.8719479103382188, 'bagging_freq': 7, 'min_child_samples': 99}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.797585277438908, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.797585277438908\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00286882006173601, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00286882006173601\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8340528532958039, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8340528532958039\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.4206330381302414e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.4206330381302414e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:18,237]\u001b[0m Trial 23 finished with value: 54.03356394449385 and parameters: {'lambda_l1': 4.4206330381302414e-07, 'lambda_l2': 0.00286882006173601, 'num_leaves': 180, 'max_depth': 4, 'n_estimators': 4963, 'feature_fraction': 0.797585277438908, 'bagging_fraction': 0.8340528532958039, 'bagging_freq': 6, 'min_child_samples': 74}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9082255084550924, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9082255084550924\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0004910285788460762, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0004910285788460762\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7131579822782704, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7131579822782704\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3211789024334075e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3211789024334075e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:19,676]\u001b[0m Trial 24 finished with value: 61.29761142883199 and parameters: {'lambda_l1': 5.3211789024334075e-08, 'lambda_l2': 0.0004910285788460762, 'num_leaves': 114, 'max_depth': 5, 'n_estimators': 4092, 'feature_fraction': 0.9082255084550924, 'bagging_fraction': 0.7131579822782704, 'bagging_freq': 5, 'min_child_samples': 50}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8525645941267856, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8525645941267856\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.03461833732184834, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.03461833732184834\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9186670114421646, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9186670114421646\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.627153081826672e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.627153081826672e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:20,809]\u001b[0m Trial 25 finished with value: 55.19156434912255 and parameters: {'lambda_l1': 9.627153081826672e-06, 'lambda_l2': 0.03461833732184834, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4664, 'feature_fraction': 0.8525645941267856, 'bagging_fraction': 0.9186670114421646, 'bagging_freq': 7, 'min_child_samples': 71}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n",
            "\u001b[32m[I 2021-07-03 09:47:20,963]\u001b[0m Trial 26 finished with value: 101.191347511389 and parameters: {'lambda_l1': 3.617654385059622e-08, 'lambda_l2': 3.21018883782884e-05, 'num_leaves': 3, 'max_depth': 6, 'n_estimators': 922, 'feature_fraction': 0.7208616598347489, 'bagging_fraction': 0.8051944778854442, 'bagging_freq': 6, 'min_child_samples': 84}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7208616598347489, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7208616598347489\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=3.21018883782884e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=3.21018883782884e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8051944778854442, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8051944778854442\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.617654385059622e-08, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.617654385059622e-08\n",
            "[LightGBM] [Warning] feature_fraction is set=0.978823807556182, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.978823807556182\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.007623884125877974, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.007623884125877974\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7586217334270403, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7586217334270403\n",
            "[LightGBM] [Warning] lambda_l1 is set=3.5202198902227952e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=3.5202198902227952e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:22,287]\u001b[0m Trial 27 finished with value: 51.10153192642099 and parameters: {'lambda_l1': 3.5202198902227952e-06, 'lambda_l2': 0.007623884125877974, 'num_leaves': 37, 'max_depth': 4, 'n_estimators': 3928, 'feature_fraction': 0.978823807556182, 'bagging_fraction': 0.7586217334270403, 'bagging_freq': 7, 'min_child_samples': 38}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.983261850180457, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.983261850180457\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.06153077564466302, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.06153077564466302\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7478638044077373, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7478638044077373\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.6713597683041026e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.6713597683041026e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:24,028]\u001b[0m Trial 28 finished with value: 57.35067831946532 and parameters: {'lambda_l1': 2.6713597683041026e-05, 'lambda_l2': 0.06153077564466302, 'num_leaves': 30, 'max_depth': 5, 'n_estimators': 4001, 'feature_fraction': 0.983261850180457, 'bagging_fraction': 0.7478638044077373, 'bagging_freq': 7, 'min_child_samples': 24}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.4467465826790745, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4467465826790745\n",
            "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00036096976564155053, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00036096976564155053\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.672679532303821, subsample=1.0 will be ignored. Current value: bagging_fraction=0.672679532303821\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0008411698071306363, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0008411698071306363\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:24,566]\u001b[0m Trial 29 finished with value: 76.7237637130061 and parameters: {'lambda_l1': 0.0008411698071306363, 'lambda_l2': 0.00036096976564155053, 'num_leaves': 3, 'max_depth': 7, 'n_estimators': 3251, 'feature_fraction': 0.4467465826790745, 'bagging_fraction': 0.672679532303821, 'bagging_freq': 7, 'min_child_samples': 37}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9485639040314328, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9485639040314328\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.9330264060741632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.9330264060741632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7907252411951584, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7907252411951584\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.238685512402491e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.238685512402491e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:25,406]\u001b[0m Trial 30 finished with value: 76.44828364410473 and parameters: {'lambda_l1': 5.238685512402491e-06, 'lambda_l2': 0.9330264060741632, 'num_leaves': 113, 'max_depth': 6, 'n_estimators': 3337, 'feature_fraction': 0.9485639040314328, 'bagging_fraction': 0.7907252411951584, 'bagging_freq': 6, 'min_child_samples': 13}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8456039224486642, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8456039224486642\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.011681208582494407, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.011681208582494407\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.712747098225565, subsample=1.0 will be ignored. Current value: bagging_fraction=0.712747098225565\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.1883465875895746e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.1883465875895746e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:26,630]\u001b[0m Trial 31 finished with value: 52.72866096923458 and parameters: {'lambda_l1': 4.1883465875895746e-07, 'lambda_l2': 0.011681208582494407, 'num_leaves': 48, 'max_depth': 4, 'n_estimators': 3929, 'feature_fraction': 0.8456039224486642, 'bagging_fraction': 0.712747098225565, 'bagging_freq': 6, 'min_child_samples': 37}. Best is trial 1 with value: 50.88575106945658.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9091986518238144, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9091986518238144\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0054097168626809, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0054097168626809\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8839408430846581, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8839408430846581\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.596942767846613e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.596942767846613e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:27,884]\u001b[0m Trial 32 finished with value: 50.38060695099718 and parameters: {'lambda_l1': 1.596942767846613e-06, 'lambda_l2': 0.0054097168626809, 'num_leaves': 70, 'max_depth': 3, 'n_estimators': 4658, 'feature_fraction': 0.9091986518238144, 'bagging_fraction': 0.8839408430846581, 'bagging_freq': 5, 'min_child_samples': 27}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.925815425018322, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.925815425018322\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0015153033999916955, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0015153033999916955\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9969436914125568, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9969436914125568\n",
            "[LightGBM] [Warning] lambda_l1 is set=4.452436211789732e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=4.452436211789732e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:29,117]\u001b[0m Trial 33 finished with value: 50.41534563720781 and parameters: {'lambda_l1': 4.452436211789732e-05, 'lambda_l2': 0.0015153033999916955, 'num_leaves': 90, 'max_depth': 3, 'n_estimators': 4604, 'feature_fraction': 0.925815425018322, 'bagging_fraction': 0.9969436914125568, 'bagging_freq': 5, 'min_child_samples': 26}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9772738945928839, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9772738945928839\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0009417066387537466, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009417066387537466\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9738372773713918, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9738372773713918\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.8145929349246734e-06, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.8145929349246734e-06\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:30,382]\u001b[0m Trial 34 finished with value: 52.72270755899047 and parameters: {'lambda_l1': 2.8145929349246734e-06, 'lambda_l2': 0.0009417066387537466, 'num_leaves': 91, 'max_depth': 3, 'n_estimators': 4314, 'feature_fraction': 0.9772738945928839, 'bagging_fraction': 0.9738372773713918, 'bagging_freq': 5, 'min_child_samples': 25}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9329972275586395, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9329972275586395\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.01723918739867992, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.01723918739867992\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.994399184996943, subsample=1.0 will be ignored. Current value: bagging_fraction=0.994399184996943\n",
            "[LightGBM] [Warning] lambda_l1 is set=9.66760944400639e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=9.66760944400639e-07\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:31,610]\u001b[0m Trial 35 finished with value: 53.05992678804438 and parameters: {'lambda_l1': 9.66760944400639e-07, 'lambda_l2': 0.01723918739867992, 'num_leaves': 8, 'max_depth': 3, 'n_estimators': 4616, 'feature_fraction': 0.9329972275586395, 'bagging_fraction': 0.994399184996943, 'bagging_freq': 4, 'min_child_samples': 15}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7960373470467561, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7960373470467561\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0020104836009707154, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020104836009707154\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8414620474837822, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8414620474837822\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00023035809545990645, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00023035809545990645\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:32,345]\u001b[0m Trial 36 finished with value: 52.29180824018335 and parameters: {'lambda_l1': 0.00023035809545990645, 'lambda_l2': 0.0020104836009707154, 'num_leaves': 134, 'max_depth': 3, 'n_estimators': 2628, 'feature_fraction': 0.7960373470467561, 'bagging_fraction': 0.8414620474837822, 'bagging_freq': 5, 'min_child_samples': 31}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9569295052409753, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9569295052409753\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.07680381735579632, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.07680381735579632\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8923893102350151, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8923893102350151\n",
            "[LightGBM] [Warning] lambda_l1 is set=1.7508875234874616e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1.7508875234874616e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:33,572]\u001b[0m Trial 37 finished with value: 59.110562369032664 and parameters: {'lambda_l1': 1.7508875234874616e-05, 'lambda_l2': 0.07680381735579632, 'num_leaves': 190, 'max_depth': 3, 'n_estimators': 4187, 'feature_fraction': 0.9569295052409753, 'bagging_fraction': 0.8923893102350151, 'bagging_freq': 4, 'min_child_samples': 22}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.9224306929229203, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.9224306929229203\n",
            "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
            "[LightGBM] [Warning] lambda_l2 is set=6.448471114589394e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=6.448471114589394e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.7702230586752068, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7702230586752068\n",
            "[LightGBM] [Warning] lambda_l1 is set=5.3456114838540395e-05, reg_alpha=0.0 will be ignored. Current value: lambda_l1=5.3456114838540395e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:34,205]\u001b[0m Trial 38 finished with value: 95.4937556058898 and parameters: {'lambda_l1': 5.3456114838540395e-05, 'lambda_l2': 6.448471114589394e-05, 'num_leaves': 217, 'max_depth': 3, 'n_estimators': 2145, 'feature_fraction': 0.9224306929229203, 'bagging_fraction': 0.7702230586752068, 'bagging_freq': 5, 'min_child_samples': 41}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8305128192408078, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8305128192408078\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0020915996062826334, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0020915996062826334\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9341455924632069, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9341455924632069\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.003372871572975594, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.003372871572975594\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:35,651]\u001b[0m Trial 39 finished with value: 51.55403721335308 and parameters: {'lambda_l1': 0.003372871572975594, 'lambda_l2': 0.0020915996062826334, 'num_leaves': 86, 'max_depth': 4, 'n_estimators': 4660, 'feature_fraction': 0.8305128192408078, 'bagging_fraction': 0.9341455924632069, 'bagging_freq': 4, 'min_child_samples': 48}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7583684595501632, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7583684595501632\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=1.0757315797865286e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=1.0757315797865286e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8591422753700104, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8591422753700104\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.04442639526158807, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.04442639526158807\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:36,563]\u001b[0m Trial 40 finished with value: 100.51243404763882 and parameters: {'lambda_l1': 0.04442639526158807, 'lambda_l2': 1.0757315797865286e-05, 'num_leaves': 36, 'max_depth': 3, 'n_estimators': 3326, 'feature_fraction': 0.7583684595501632, 'bagging_fraction': 0.8591422753700104, 'bagging_freq': 6, 'min_child_samples': 53}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8742791916342895, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8742791916342895\n",
            "[LightGBM] [Warning] bagging_freq is set=4, subsample_freq=0 will be ignored. Current value: bagging_freq=4\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00031443621280828615, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00031443621280828615\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9500668175225292, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9500668175225292\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.06235078593597233, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.06235078593597233\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:38,268]\u001b[0m Trial 41 finished with value: 64.3468999129999 and parameters: {'lambda_l1': 0.06235078593597233, 'lambda_l2': 0.00031443621280828615, 'num_leaves': 92, 'max_depth': 4, 'n_estimators': 4660, 'feature_fraction': 0.8742791916342895, 'bagging_fraction': 0.9500668175225292, 'bagging_freq': 4, 'min_child_samples': 49}. Best is trial 32 with value: 50.38060695099718.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8209938685648955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8209938685648955\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0013189876581934216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013189876581934216\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.939671806615613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939671806615613\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0027795525571181335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027795525571181335\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:39,836]\u001b[0m Trial 42 finished with value: 49.77502748346065 and parameters: {'lambda_l1': 0.0027795525571181335, 'lambda_l2': 0.0013189876581934216, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 4351, 'feature_fraction': 0.8209938685648955, 'bagging_fraction': 0.939671806615613, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7702893475226578, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7702893475226578\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.001009919599141044, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.001009919599141044\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8117396193748951, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8117396193748951\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.00025524993097192524, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.00025524993097192524\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:41,391]\u001b[0m Trial 43 finished with value: 50.82007911358183 and parameters: {'lambda_l1': 0.00025524993097192524, 'lambda_l2': 0.001009919599141044, 'num_leaves': 129, 'max_depth': 4, 'n_estimators': 4388, 'feature_fraction': 0.7702893475226578, 'bagging_fraction': 0.8117396193748951, 'bagging_freq': 3, 'min_child_samples': 27}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7636944615166064, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7636944615166064\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0011623154537011224, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0011623154537011224\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8089946302785731, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8089946302785731\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0002606276221696125, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0002606276221696125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:42,627]\u001b[0m Trial 44 finished with value: 51.403380263458004 and parameters: {'lambda_l1': 0.0002606276221696125, 'lambda_l2': 0.0011623154537011224, 'num_leaves': 130, 'max_depth': 3, 'n_estimators': 4439, 'feature_fraction': 0.7636944615166064, 'bagging_fraction': 0.8089946302785731, 'bagging_freq': 3, 'min_child_samples': 16}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8091728309057685, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8091728309057685\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0009459635443240914, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0009459635443240914\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9014083135907872, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9014083135907872\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.002311571813235472, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.002311571813235472\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:44,562]\u001b[0m Trial 45 finished with value: 50.10231185723775 and parameters: {'lambda_l1': 0.002311571813235472, 'lambda_l2': 0.0009459635443240914, 'num_leaves': 161, 'max_depth': 5, 'n_estimators': 4281, 'feature_fraction': 0.8091728309057685, 'bagging_fraction': 0.9014083135907872, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6996250830317221, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6996250830317221\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=8.909532017600439e-05, reg_lambda=0.0 will be ignored. Current value: lambda_l2=8.909532017600439e-05\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8975574125196653, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8975574125196653\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.001701156943205884, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.001701156943205884\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:46,585]\u001b[0m Trial 46 finished with value: 83.38827099343189 and parameters: {'lambda_l1': 0.001701156943205884, 'lambda_l2': 8.909532017600439e-05, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 4304, 'feature_fraction': 0.6996250830317221, 'bagging_fraction': 0.8975574125196653, 'bagging_freq': 3, 'min_child_samples': 28}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7794039425160162, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7794039425160162\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=4.6040343482308495e-08, reg_lambda=0.0 will be ignored. Current value: lambda_l2=4.6040343482308495e-08\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9805804236499959, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9805804236499959\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.023779343671537195, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.023779343671537195\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:48,589]\u001b[0m Trial 47 finished with value: 102.2613583014618 and parameters: {'lambda_l1': 0.023779343671537195, 'lambda_l2': 4.6040343482308495e-08, 'num_leaves': 163, 'max_depth': 5, 'n_estimators': 3760, 'feature_fraction': 0.7794039425160162, 'bagging_fraction': 0.9805804236499959, 'bagging_freq': 2, 'min_child_samples': 27}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.8244817332234778, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8244817332234778\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00022137109133883102, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00022137109133883102\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9165714675747751, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9165714675747751\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.004319517026608934, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.004319517026608934\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:51,737]\u001b[0m Trial 48 finished with value: 63.68962537603147 and parameters: {'lambda_l1': 0.004319517026608934, 'lambda_l2': 0.00022137109133883102, 'num_leaves': 121, 'max_depth': 5, 'n_estimators': 4758, 'feature_fraction': 0.8244817332234778, 'bagging_fraction': 0.9165714675747751, 'bagging_freq': 3, 'min_child_samples': 8}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.7413065249357587, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.7413065249357587\n",
            "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0007176014304748555, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0007176014304748555\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.9526516526613242, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9526516526613242\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0004954194531827444, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0004954194531827444\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-07-03 09:47:53,587]\u001b[0m Trial 49 finished with value: 51.976929752416154 and parameters: {'lambda_l1': 0.0004954194531827444, 'lambda_l2': 0.0007176014304748555, 'num_leaves': 150, 'max_depth': 4, 'n_estimators': 4520, 'feature_fraction': 0.7413065249357587, 'bagging_fraction': 0.9526516526613242, 'bagging_freq': 2, 'min_child_samples': 12}. Best is trial 42 with value: 49.77502748346065.\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNFeBcx9tqur",
        "outputId": "3eb8e640-9c6f-427d-9160-894b9e8ce857"
      },
      "source": [
        "print('Lunch Best Trial: score {},\\nparams {}'.format(l_study_lgb.best_trial.value, l_study_lgb.best_trial.params))\n",
        "print('Dinner Best Trial: score {},\\nparams {}'.format(d_study_lgb.best_trial.value, d_study_lgb.best_trial.params))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lunch Best Trial: score 65.47700831201462,\n",
            "params {'lambda_l1': 2.897285138402634e-07, 'lambda_l2': 0.00365564781783537, 'num_leaves': 89, 'max_depth': 4, 'n_estimators': 4170, 'feature_fraction': 0.6799896576109249, 'bagging_fraction': 0.8187865503548556, 'bagging_freq': 6, 'min_child_samples': 20}\n",
            "Dinner Best Trial: score 49.77502748346065,\n",
            "params {'lambda_l1': 0.0027795525571181335, 'lambda_l2': 0.0013189876581934216, 'num_leaves': 77, 'max_depth': 4, 'n_estimators': 4351, 'feature_fraction': 0.8209938685648955, 'bagging_fraction': 0.939671806615613, 'bagging_freq': 3, 'min_child_samples': 28}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP2wRgpNukp_",
        "outputId": "3b9e9876-3fa0-414a-805f-8ffea49d0501"
      },
      "source": [
        "l_trial_lgb = l_study_lgb.best_trial\n",
        "lunch_lgb_params = l_trial_lgb.params\n",
        "lunch_lgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.8187865503548556,\n",
              " 'bagging_freq': 6,\n",
              " 'feature_fraction': 0.6799896576109249,\n",
              " 'lambda_l1': 2.897285138402634e-07,\n",
              " 'lambda_l2': 0.00365564781783537,\n",
              " 'max_depth': 4,\n",
              " 'min_child_samples': 20,\n",
              " 'n_estimators': 4170,\n",
              " 'num_leaves': 89}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_4jdK6SvFPm",
        "outputId": "41781d9c-21f1-4cc1-df79-4f9cd9c99e64"
      },
      "source": [
        "d_trial_lgb = d_study_lgb.best_trial\n",
        "dinner_lgb_params = d_trial_lgb.params\n",
        "dinner_lgb_params"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bagging_fraction': 0.939671806615613,\n",
              " 'bagging_freq': 3,\n",
              " 'feature_fraction': 0.8209938685648955,\n",
              " 'lambda_l1': 0.0027795525571181335,\n",
              " 'lambda_l2': 0.0013189876581934216,\n",
              " 'max_depth': 4,\n",
              " 'min_child_samples': 28,\n",
              " 'n_estimators': 4351,\n",
              " 'num_leaves': 77}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLoo862Fuoyl",
        "outputId": "d8b48b29-1bc2-4bd3-cce1-7059c96b1107"
      },
      "source": [
        "lunch_lgb_model = lgb.LGBMRegressor(**lunch_lgb_params)\n",
        "lunch_lgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['lunch_y'], eval_metric='mae')\n",
        "lunch_lgb_pred = lunch_lgb_model.predict(b_test_df)\n",
        "\n",
        "dinner_lgb_model = lgb.LGBMRegressor(**dinner_lgb_params)\n",
        "dinner_lgb_model.fit(b_train_df.drop(['lunch_y', 'dinner_y'], axis=1), b_train_df['dinner_y'], eval_metric='mae')\n",
        "dinner_lgb_pred = dinner_lgb_model.predict(b_test_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[LightGBM] [Warning] feature_fraction is set=0.6799896576109249, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.6799896576109249\n",
            "[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.00365564781783537, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.00365564781783537\n",
            "[LightGBM] [Warning] lambda_l1 is set=2.897285138402634e-07, reg_alpha=0.0 will be ignored. Current value: lambda_l1=2.897285138402634e-07\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.8187865503548556, subsample=1.0 will be ignored. Current value: bagging_fraction=0.8187865503548556\n",
            "[LightGBM] [Warning] feature_fraction is set=0.8209938685648955, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8209938685648955\n",
            "[LightGBM] [Warning] bagging_freq is set=3, subsample_freq=0 will be ignored. Current value: bagging_freq=3\n",
            "[LightGBM] [Warning] lambda_l2 is set=0.0013189876581934216, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0013189876581934216\n",
            "[LightGBM] [Warning] lambda_l1 is set=0.0027795525571181335, reg_alpha=0.0 will be ignored. Current value: lambda_l1=0.0027795525571181335\n",
            "[LightGBM] [Warning] bagging_fraction is set=0.939671806615613, subsample=1.0 will be ignored. Current value: bagging_fraction=0.939671806615613\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjEBjP-LutfL",
        "outputId": "2ff8339f-2c36-4eb9-c625-852ab21d6d0d"
      },
      "source": [
        "lunch_lgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1079.03310198,  924.10964866,  577.80795891, 1249.64290239,\n",
              "        895.40968667,  976.67085872,  932.21715732,  588.31314377,\n",
              "       1265.88372599, 1007.43627688,  753.3058041 , 1298.1315063 ,\n",
              "       1095.51476572, 1143.45021793,  904.39944554,  686.3541367 ,\n",
              "       1325.01370148, 1057.89940921,  963.60653005,  798.25491832,\n",
              "        642.38341296, 1102.81447347, 1014.60911754,  871.34047641,\n",
              "        586.9445266 , 1368.12620978, 1142.22587593,  987.52438831,\n",
              "        964.93036481,  753.91854802, 1305.10202639,  976.69937358,\n",
              "       1135.31632959,  951.21850548,  646.85876952, 1227.54952625,\n",
              "       1032.7836392 ,  980.65422895,  850.75414849,  558.01674131,\n",
              "       1197.43640734,  999.96037929, 1007.00921605,  824.95815502,\n",
              "        607.28509736, 1228.23824069, 1075.8525771 , 1064.4343903 ,\n",
              "        891.26183146,  622.11567044])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4GuXL30svQN1",
        "outputId": "c4c62b15-c256-4280-a4b8-60ed9ddf3495"
      },
      "source": [
        "dinner_lgb_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([240.64583374, 395.31253185, 230.10808226, 536.22486105,\n",
              "       436.06674743, 435.43609076, 417.67914823, 316.7960654 ,\n",
              "       576.4247487 , 470.58059628,  64.61235642, 716.50671474,\n",
              "       532.11446787, 338.15984255, 468.82518124, 362.77551051,\n",
              "       644.14007198, 630.39492527, 370.51080814, 489.80303535,\n",
              "       345.26131363, 637.2045706 , 445.68363242, 499.00831437,\n",
              "       379.33171555, 615.08692761, 566.33144218, 395.44760439,\n",
              "       524.533477  , 285.36198195, 698.27470741, 500.0443474 ,\n",
              "       459.49348451, 482.87676549, 194.51826389, 663.76134889,\n",
              "       590.70957418, 318.86217704, 488.28828955, 217.18639504,\n",
              "       705.05824861, 604.94206022, 296.65494587, 408.72644953,\n",
              "       309.53007816, 655.41708784, 553.40894854, 527.76336813,\n",
              "       486.43570526, 339.27940083])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "JACfYxl9vl1U",
        "outputId": "65561fb1-d6e7-4ee1-fd1f-3a26ae8cfd59"
      },
      "source": [
        "lgb_submit = pd.read_csv(PATH + 'sample_submission.csv')\n",
        "lgb_submit['중식계'] = lunch_lgb_pred\n",
        "lgb_submit['석식계'] = dinner_lgb_pred\n",
        "lgb_submit.to_csv(PATH + 'lgb_base.csv', index=False)\n",
        "lgb_submit.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>일자</th>\n",
              "      <th>중식계</th>\n",
              "      <th>석식계</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-01-27</td>\n",
              "      <td>1079.033102</td>\n",
              "      <td>240.645834</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-01-28</td>\n",
              "      <td>924.109649</td>\n",
              "      <td>395.312532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-01-29</td>\n",
              "      <td>577.807959</td>\n",
              "      <td>230.108082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-02-01</td>\n",
              "      <td>1249.642902</td>\n",
              "      <td>536.224861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-02-02</td>\n",
              "      <td>895.409687</td>\n",
              "      <td>436.066747</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           일자          중식계         석식계\n",
              "0  2021-01-27  1079.033102  240.645834\n",
              "1  2021-01-28   924.109649  395.312532\n",
              "2  2021-01-29   577.807959  230.108082\n",
              "3  2021-02-01  1249.642902  536.224861\n",
              "4  2021-02-02   895.409687  436.066747"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMWINF0jFglK"
      },
      "source": [
        "# regex = \"\\((.*?)\\)\"\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])\n",
        "\n",
        "\n",
        "# regex = '[/*,&+-><]'\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])\n",
        "\n",
        "# regex = 'D|BLT'\n",
        "# for i in range(len(all_df)):\n",
        "#     all_df['조식메뉴'][i] = re.sub(regex, '', all_df['조식메뉴'][i])\n",
        "#     all_df['중식메뉴'][i] = re.sub(regex, '', all_df['중식메뉴'][i])\n",
        "#     all_df['석식메뉴'][i] = re.sub(regex, '', all_df['석식메뉴'][i])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQ5lnAhdJXj4"
      },
      "source": [
        "# tfidf에 입력하는 코퍼스가 공백기준으로 단어를 인식해서 그냥 위의 all_df 사용\n",
        "\n",
        "# col = ['조식메뉴', '중식메뉴', '석식메뉴']\n",
        "# for i in col:\n",
        "#     all_df[i] = all_df[i].str.split()\n",
        "# all_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_ftaXkjn1SE"
      },
      "source": [
        "- 메뉴 정리\n",
        "\n",
        "    - Tfidf로 단어를 임베딩\n",
        "    - 임베딩한 값이 특정 threshold 미만이면 없애기\n",
        "    - 예를 들어 계란후라이 tfidf 값이 0.1이면 threshold를 0.15정도로 지정해서 계란후라이 지우기\n",
        "    - 지우고 남아 있는 메뉴 리스트에서 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeIifxKohDTf"
      },
      "source": [
        "# def list_make(list, column):\n",
        "#     for i in all_df[column]:\n",
        "#         list.append(i)\n",
        "#     return list\n",
        "# breakfast_list = []\n",
        "# lunch_list = []\n",
        "# dinner_list = []\n",
        "\n",
        "# breakfast_list = list_make(breakfast_list, '조식메뉴')\n",
        "# lunch_list = list_make(lunch_list, '중식메뉴')\n",
        "# dinner_list = list_make(dinner_list, '석식메뉴')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5f7GtOjjk0a"
      },
      "source": [
        "# breakfast_list[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4RAOvfDq8zx"
      },
      "source": [
        "\n",
        "# non = []\n",
        "# def tfidf_view(sikdan):\n",
        "#     tfidf = TfidfVectorizer()\n",
        "#     sikdan_tfidf = tfidf.fit_transform(sikdan)\n",
        "#     word2id = defaultdict(lambda : 0)\n",
        "#     for idx, feature in enumerate(tfidf.get_feature_names()):\n",
        "#         word2id[feature] = idx\n",
        "#     for i, sent in enumerate(sikdan):\n",
        "#         print(' ===== document[%d] ====='%i)\n",
        "#         for token in sent.split():\n",
        "#             print([(token, sikdan_tfidf[i, word2id[token]])])\n",
        "#             if sikdan_tfidf[i, word2id[token]] < 0.001:\n",
        "#                 non.append(token)\n",
        "        \n",
        "\n",
        "# tfidf_view(breakfast_list)\n",
        "# non"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}