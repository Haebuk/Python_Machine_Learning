{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_Knowledge_Distillation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRjwzapjQcTo"
      },
      "source": [
        "- 파라미터 개수가 많은 큰 모델이 작은 모델을 가르치는 개념\n",
        "- 큰 모델의 예측과 작은 모델의 예측의 오차와 작은 모델의 손실 함수를 줄여 나가는 방향으로 작은 모델의 파라미터를 최적화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n7H55IMQFpp"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAWjo2oBRU8-"
      },
      "source": [
        "# @title 파라미터 설정\n",
        "t_epoch = 5 # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "s_epoch = 10 # @param {type:\"slider\", min:1, max:100, step:1}\n",
        "learning_rate = 0.01\n",
        "batch_size = 64 # @param {32, 64, 128, 256}{type:'raw'}\n",
        "temperature = 3 # @param {type: 'slider', min:1, max:10, step:1}\n",
        "alpha = 0.5 # @param {type: 'slider', min:0.1, max:0.9, step:0.1}"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-TuGNiyR1hy"
      },
      "source": [
        "- @파라미터 설정 시 옵션을 바로 변경하여 적용 가능"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1h4C5XPnR0GV",
        "outputId": "8bf519a4-334f-4788-f071-bfffbf93f1e7"
      },
      "source": [
        "# mnist 데이터셋 가져오기\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = np.reshape(x_train,(-1, 28, 28, 1))\n",
        "\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = np.reshape(x_test,(-1, 28, 28, 1))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CpDAFJbCSGet"
      },
      "source": [
        "- 배치 사이즈 축 추가"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xe7PoWpCSF7H",
        "outputId": "e8a3a836-4d8f-4cd6-eb14-05569a65f0bc"
      },
      "source": [
        "# teacher 모델\n",
        "i = tf.keras.Input(shape=(28, 28, 1))\n",
        "out = tf.keras.layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same')(i)\n",
        "out = tf.keras.layers.LeakyReLU(alpha=0.2)(out)\n",
        "out = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(1, 1), padding='same')(out)\n",
        "out = tf.keras.layers.Conv2D(512, (3, 3), strides=(2, 2), padding='same')(out)\n",
        "out = tf.keras.layers.Flatten()(out)\n",
        "out = tf.keras.layers.Dense(10)(out)\n",
        "t_model = tf.keras.Model(inputs=[i], outputs=[out])\n",
        "\n",
        "t_model.summary()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 14, 14, 256)       2560      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)      (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 7, 7, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                250890    \n",
            "=================================================================\n",
            "Total params: 1,433,610\n",
            "Trainable params: 1,433,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NhM779qSqPn"
      },
      "source": [
        "- 약 140만개의 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_NsZG0CSnto",
        "outputId": "89773658-6540-46c8-c80b-294c92e3f637"
      },
      "source": [
        "# student 모델\n",
        "i = tf.keras.Input(shape=(28, 28, 1))\n",
        "out = tf.keras.layers.Flatten()(i)\n",
        "out = tf.keras.layers.Dense(28)(out)\n",
        "out = tf.keras.layers.Dense(10)(out)\n",
        "\n",
        "s_model_1 = tf.keras.Model(inputs=[i], outputs=[out])\n",
        "s_model_2 = tf.keras.models.clone_model(s_model_1)\n",
        "\n",
        "s_model_1.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 28)                21980     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                290       \n",
            "=================================================================\n",
            "Total params: 22,270\n",
            "Trainable params: 22,270\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZD9hgQ84S_E9"
      },
      "source": [
        "- Dense 레이어 2개로 구성된 단순한 student 모델\n",
        "- 성능 비교를 위해 모델 하나 복제"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ZkjInUJS9_f"
      },
      "source": [
        "# teacher 모델\n",
        "t_model.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# student 모델 (distilation 적용)\n",
        "s_model_1.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])\n",
        "\n",
        "# 비교 모델 (distilation 미적용)\n",
        "s_model_2.compile(tf.keras.optimizers.Adam(learning_rate),\n",
        "                tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "                metrics=[tf.keras.metrics.SparseCategoricalAccuracy()])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhCBURHWTkwY",
        "outputId": "16dcf115-c788-4ed6-d537-7930a3e99573"
      },
      "source": [
        "# teacher 모델\n",
        "t_model.fit(x_train, y_train, batch_size=batch_size, epochs=t_epoch)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "938/938 [==============================] - 21s 5ms/step - loss: 6.2865 - sparse_categorical_accuracy: 0.9087\n",
            "Epoch 2/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 6.0644 - sparse_categorical_accuracy: 0.9560\n",
            "Epoch 3/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 3.8666 - sparse_categorical_accuracy: 0.9586\n",
            "Epoch 4/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 8.2154 - sparse_categorical_accuracy: 0.9558\n",
            "Epoch 5/5\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 9.5900 - sparse_categorical_accuracy: 0.9621\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fa94067de90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iPKnW6cT2cq"
      },
      "source": [
        "- 약 96%의 정확도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob5f4llGTsFf"
      },
      "source": [
        "# student 손실 함수\n",
        "s_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "# distilation 손실 함수\n",
        "d_loss = tf.keras.losses.KLDivergence()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThYAFpW5UA2B"
      },
      "source": [
        "- Knowledge Distilation 학습에 필요한 두 loss 정의\n",
        "- KLDivergence 손실함수: 서로 다른 두 개의 확률 분포를 비교해 유사성을 측정하는 지표\n",
        "    - 유사할 수록 값이 작음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUo8DhPLUAgH",
        "outputId": "7cb71543-92ca-4196-d34e-e8873ab6ed2e"
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IllFtX2jUM9I",
        "outputId": "717fee05-b495-4ea1-ed8a-3c381c1c7b31"
      },
      "source": [
        "batch_count = x_train.shape[0] // batch_size # 총 배치 개수\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate)\n",
        "\n",
        "for e in range(s_epoch):\n",
        "    for _ in range(batch_count):\n",
        "        batch_num = np.random.randint(0, x_train.shape[0], size=batch_size)\n",
        "        t_pred = t_model.predict(x_train[batch_num])\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            s_pred_1 = s_model_1(x_train[batch_num])\n",
        "            student_loss = s_loss(y_train[batch_num], s_pred_1)\n",
        "            distilation_loss = d_loss(\n",
        "                tf.nn.softmax(t_pred / temperature, axis=1),\n",
        "                tf.nn.softmax(s_pred_1 / temperature, axis=1),\n",
        "            )\n",
        "            loss = alpha * student_loss + (1-alpha) * distilation_loss\n",
        "\n",
        "        vars = s_model_1.trainable_variables\n",
        "        grad = tape.gradient(loss, vars)\n",
        "        opt.apply_gradients(zip(grad, vars))\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            s_pred_2 = s_model_2(x_train[batch_num])\n",
        "            student_loss = s_loss(y_train[batch_num], s_pred_2)\n",
        "        vars = s_model_2.trainable_variables\n",
        "        grad = tape.gradient(student_loss, vars)\n",
        "        opt.apply_gradients(zip(grad, vars))\n",
        "\n",
        "    print(\"epoch {}\".format(e))\n",
        "    print(\"선생님께 배운 경우\")\n",
        "    s_model_1.evaluate(x_test, y_test)\n",
        "    print('혼자 공부한 경우')\n",
        "    s_model_2.evaluate(x_test, y_test)\n",
        "    print('\\n')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4249 - sparse_categorical_accuracy: 0.9150\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3170 - sparse_categorical_accuracy: 0.9159\n",
            "\n",
            "\n",
            "epoch 1\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4426 - sparse_categorical_accuracy: 0.9163\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3192 - sparse_categorical_accuracy: 0.9132\n",
            "\n",
            "\n",
            "epoch 2\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4670 - sparse_categorical_accuracy: 0.9083\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3475 - sparse_categorical_accuracy: 0.9055\n",
            "\n",
            "\n",
            "epoch 3\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4840 - sparse_categorical_accuracy: 0.9077\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3466 - sparse_categorical_accuracy: 0.9064\n",
            "\n",
            "\n",
            "epoch 4\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4397 - sparse_categorical_accuracy: 0.9131\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3448 - sparse_categorical_accuracy: 0.9079\n",
            "\n",
            "\n",
            "epoch 5\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4457 - sparse_categorical_accuracy: 0.9153\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3150 - sparse_categorical_accuracy: 0.9177\n",
            "\n",
            "\n",
            "epoch 6\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4302 - sparse_categorical_accuracy: 0.9180\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3193 - sparse_categorical_accuracy: 0.9136\n",
            "\n",
            "\n",
            "epoch 7\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4925 - sparse_categorical_accuracy: 0.9076\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3635 - sparse_categorical_accuracy: 0.9033\n",
            "\n",
            "\n",
            "epoch 8\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4846 - sparse_categorical_accuracy: 0.9098\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3575 - sparse_categorical_accuracy: 0.9047\n",
            "\n",
            "\n",
            "epoch 9\n",
            "선생님께 배운 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.4331 - sparse_categorical_accuracy: 0.9180\n",
            "혼자 공부한 경우\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3532 - sparse_categorical_accuracy: 0.9096\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2kcGUx0Vkgb"
      },
      "source": [
        "- 배치별로 student loss와 distilation loss 계산\n",
        "- 모델 학습에 적용하는 총 손실함수는 student loss와 distilation loss를 가중 평균\n",
        "- 두 번째 epoch 부터 선생님 모델로 부터 배운 모델이 정확도가 더 높게 나옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIlGXBY0VWyo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}